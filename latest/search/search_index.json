{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OPTIMADE Python tools \u00b6 Latest release Build status Activity The aim of OPTIMADE is to develop a common API, compliant with the JSON:API 1.0 specification. This is to enable interoperability among databases that contain calculated properties of existing and hypothetical materials. This repository contains a library of tools for implementing and consuming OPTIMADE APIs using Python. Server implementations can make use of the supported MongoDB (v4) and Elasticsearch (v6) database backends, or plug in a custom backend implementation. The package also contains a server validator tool, which may be called from the shell ( optimade-validator ) or used as a GitHub Action from optimade-validator-action . The release history and changelog can be found in the changelog . Documentation \u00b6 This document, guides, and the full module API documentation can be found online at https://optimade.org/optimade-python-tools . In particular, documentation of the OPTIMADE API response data models (implemented here with pydantic ) can be found online under OPTIMADE Data Models . Installation \u00b6 Detailed installation instructions for different use cases (e.g., using the library or running a server) can be found in the installation documentation . The latest stable version of this package can be obtained from PyPI pip install optimade . The latest development version of this package can be installed from the master branch of this repository git clone https://github.com/Materials-Consortia/optimade-python-tools . Supported OPTIMADE versions \u00b6 Each release of the optimade package from this repository only targets one version of the OPTIMADE specification, summarised in the table below. OPTIMADE API version optimade version v1.0.0 v0.12.9 v1.1.0 v0.16.0 Contributing and Getting Help \u00b6 All development of this package (bug reports, suggestions, feedback and pull requests) occurs in the optimade-python-tools GitHub repository . Contribution guidelines and tips for getting help can be found in the contributing notes . How to cite \u00b6 If you use this package to access or serve OPTIMADE data, we kindly request that you consider citing the following: Andersen et al. , OPTIMADE, an API for exchanging materials data, Sci. Data 8 , 217 (2021) 10.1038/s41597-021-00974-z Evans et al. , optimade-python-tools: a Python library for serving and consuming materials data via OPTIMADE APIs. Journal of Open Source Software , 6 (65), 3458 (2021) 10.21105/joss.03458 Links \u00b6 OPTIMADE Specification , the human-readable specification that this library is based on. optimade-validator-action , a GitHub action that can be used to validate implementations from a URL (using the validator from this repo). OpenAPI , the machine-readable format used to specify the OPTIMADE API in openapi.json and index_openapi.json . Interactive documentation generated from openapi.json (see also interactive JSON editor ). pydantic , the library used for generating the OpenAPI schema from Python models . FastAPI , the framework used for generating the reference implementation expressed by the openapi.json specification. lark , the library used to parse the filter language in OPTIMADE queries.","title":"Home"},{"location":"#optimade-python-tools","text":"Latest release Build status Activity The aim of OPTIMADE is to develop a common API, compliant with the JSON:API 1.0 specification. This is to enable interoperability among databases that contain calculated properties of existing and hypothetical materials. This repository contains a library of tools for implementing and consuming OPTIMADE APIs using Python. Server implementations can make use of the supported MongoDB (v4) and Elasticsearch (v6) database backends, or plug in a custom backend implementation. The package also contains a server validator tool, which may be called from the shell ( optimade-validator ) or used as a GitHub Action from optimade-validator-action . The release history and changelog can be found in the changelog .","title":"OPTIMADE Python tools"},{"location":"#documentation","text":"This document, guides, and the full module API documentation can be found online at https://optimade.org/optimade-python-tools . In particular, documentation of the OPTIMADE API response data models (implemented here with pydantic ) can be found online under OPTIMADE Data Models .","title":"Documentation"},{"location":"#installation","text":"Detailed installation instructions for different use cases (e.g., using the library or running a server) can be found in the installation documentation . The latest stable version of this package can be obtained from PyPI pip install optimade . The latest development version of this package can be installed from the master branch of this repository git clone https://github.com/Materials-Consortia/optimade-python-tools .","title":"Installation"},{"location":"#supported-optimade-versions","text":"Each release of the optimade package from this repository only targets one version of the OPTIMADE specification, summarised in the table below. OPTIMADE API version optimade version v1.0.0 v0.12.9 v1.1.0 v0.16.0","title":"Supported OPTIMADE versions"},{"location":"#contributing-and-getting-help","text":"All development of this package (bug reports, suggestions, feedback and pull requests) occurs in the optimade-python-tools GitHub repository . Contribution guidelines and tips for getting help can be found in the contributing notes .","title":"Contributing and Getting Help"},{"location":"#how-to-cite","text":"If you use this package to access or serve OPTIMADE data, we kindly request that you consider citing the following: Andersen et al. , OPTIMADE, an API for exchanging materials data, Sci. Data 8 , 217 (2021) 10.1038/s41597-021-00974-z Evans et al. , optimade-python-tools: a Python library for serving and consuming materials data via OPTIMADE APIs. Journal of Open Source Software , 6 (65), 3458 (2021) 10.21105/joss.03458","title":"How to cite"},{"location":"#links","text":"OPTIMADE Specification , the human-readable specification that this library is based on. optimade-validator-action , a GitHub action that can be used to validate implementations from a URL (using the validator from this repo). OpenAPI , the machine-readable format used to specify the OPTIMADE API in openapi.json and index_openapi.json . Interactive documentation generated from openapi.json (see also interactive JSON editor ). pydantic , the library used for generating the OpenAPI schema from Python models . FastAPI , the framework used for generating the reference implementation expressed by the openapi.json specification. lark , the library used to parse the filter language in OPTIMADE queries.","title":"Links"},{"location":"CHANGELOG/","text":"Changelog \u00b6 Unreleased (2022-07-08) \u00b6 Full Changelog Implemented enhancements: Support for Elasticsearch v7 #1216 ( markus1978 ) Fixed bugs: Landing page not loading #1256 Config values are not cached by @classproperty #1219 Improve error handling for client when updating provider list #1222 ( ml-evs ) Closed issues: Use versioned Dockerfiles for CI services to allow dependabot to update them #1241 Wrong links to available endpoints #1214 Add configurable meta->schemas field to reference server #1208 Merged pull requests: Bump providers from fb05359 to a92e5bc #1267 ( dependabot[bot] ) Add schema parameter when calling meta_values in landing.py #1257 ( JPBergsma ) Update lark dependency to new name #1231 ( ml-evs ) Use Python 3.10 instead of 3.7 in installation instructions #1229 ( JPBergsma ) Optimisation: do not re-access mapper properties inside the request loop #1223 ( ml-evs ) Add configurable schema_url and index_schema_url options #1210 ( ml-evs ) v0.18.0 (2022-05-29) \u00b6 Full Changelog This is a feature release that includes the new optimade.client.OptimadeClient class, a client capable asynchronously querying multiple OPTIMADE APIs simultaneously. It also contains a patch for the OPTIMADE models that allows them to be used with more recent FastAPI versions without breaking OpenAPI 3.0 compatibility. Other changes can be found below. This release includes improvements to the validator to catch more cases where OPTIMADE APIs are only partially implemented. Previously, APIs that did not support filtering, pagination or limiting response fields at all (i.e., the query parameter is simply ignored) would pass most validation tests erroneously in some unlucky situations (#1180). Implemented enhancements: The validator should use a custom User-Agent header #1187 Suggestion to include an OPTIMADE python API client #932 Implementation of an OPTIMADE client #1154 ( ml-evs ) Fixed bugs: OptimadeClient crashes if an index meta-database is down #1196 Catch connection errors when populating client database list #1197 ( ml-evs ) Merged pull requests: Add a clearer error message on when trying to use client with missing deps #1200 ( ml-evs ) Use a custom User-Agent with validator #1189 ( ml-evs ) Syntactic tweaks to models and schemas for compatibility with fastapi>0.66 #1131 ( ml-evs ) v0.17.2 (2022-05-21) \u00b6 Full Changelog This release includes improvements to the validator to catch more cases where OPTIMADE APIs are only partially implemented. Previously, APIs that did not support filtering, pagination or limiting response fields at all (i.e., the query parameter is simply ignored) would pass most validation tests erroneously in some unlucky situations (#1180). Fixed bugs: Server validation incorrectly passes with various unimplemented features #1180 Merged pull requests: Harden validator for partially implemented APIs #1181 ( ml-evs ) v0.17.1 (2022-05-18) \u00b6 Full Changelog This patch release adds a pre-built Docker container for the reference server to the GitHub Container Registry (GHCR) and a series of Deployment instructions in the online documentation. The image can be easily pulled from GHCR with: docker pull ghcr.io/materials-consortia/optimade Implemented enhancements: Release a container (Docker) image for developers #1111 Closed issues: Issues with GH Changelog updater (secondary usage API requests) #976 Merged pull requests: Don't use env context for step #1178 ( CasperWA ) Docker image for optimade on ghcr.io #1171 ( CasperWA ) v0.17.0 (2022-05-10) \u00b6 Full Changelog This minor release contains fixes recommended for those deploying the optimade-python-tools reference server: The meta->data_returned field was previously incorrect when using the MongoDB backend. Incoming URL query parameters are now validated against the provided query parameters class (if using custom query parameters, this class should be extended or the parameters should use your registered provider prefix). This functionality can be disabled with the validate_query_parameters config option. The results of some queries were not reversible with MongoDB (e.g., nelements != 2 vs 2 != nelements ); this has now been fixed. Implemented enhancements: Add server check for typos in query parameters #1120 Improve handling of MongoDB ObjectIDs as OPTIMADE immutable_id #1142 ( ml-evs ) Add support for number-based pagination #1139 ( JPBergsma ) Added option to validate incoming URL query parameters #1122 ( JPBergsma ) Fixed bugs: meta->data_returned is incorrect for paginated results with MongoDB #1140 Queries with the form: 'value != prop' return entries where 'prop == None' #1133 Test on Queries on single structures fail with the check_response function. #1125 Fix incorrect meta->data_returned for paginated results with MongoDB #1141 ( ml-evs ) Fix cases where comparison first and property first queries did not match #1134 ( JPBergsma ) Closed issues: Raise error/warning when using unsupported pagination method #1132 Add missing documentation for serving custom query params and fields #1123 Merged pull requests: Use GitHub Actions for Heroku deployment #1165 ( ml-evs ) Add docs for custom provider fields and query parameters #1164 ( ml-evs ) Add deprecation warning for Python 3.7 #1157 ( ml-evs ) Added way to specify unsupported query parameters and provide a warning #1136 ( ml-evs ) Adjusted check_response so it can also handle single entries. #1130 ( JPBergsma ) Corrected link in Install.MD #1124 ( JPBergsma ) v0.16.12 (2022-03-23) \u00b6 Full Changelog Implemented enhancements: Make structure adapters infer species from species_at_sites when missing #1103 ( ml-evs ) Allow specification of provider field descriptions/units etc. in config file #1096 ( ml-evs ) Moving and adding some utilities for client code #589 ( ml-evs ) Closed issues: Allow provider field descriptions to be provided in the config #1095 v0.16.11 (2022-03-03) \u00b6 Full Changelog Merged pull requests: Remove Jinja dependency for landing page generation #1082 ( ml-evs ) v0.16.10 (2022-02-05) \u00b6 Full Changelog Fixed bugs: Distribution tests failing #1061 Security fixes: Bump elasticsearch version to avoid CVE-2021-44832 #1066 ( JPBergsma ) Merged pull requests: Use build package to build distributions #1062 ( CasperWA ) Cancel CI PR jobs that are in progress with new changes, add skip_changelog label to overrides #1057 ( ml-evs ) Prevent validator errors/retries on read timeouts #1056 ( ml-evs ) v0.16.9 (2022-01-26) \u00b6 Full Changelog Implemented enhancements: Lower validator default read timeout and allow it to be customised #1051 ( ml-evs ) Security fixes: Bump elasticsearch to avoid log4j vulnerability #1040 Closed issues: Docs reference to LarkParser failing. #1037 Merged pull requests: Update dependabot config and changelog generation #1048 ( ml-evs ) Bump elasticsearch image version to avoid any log4j issues #1041 ( ml-evs ) Make NumPy requirement py version-specific #1036 ( CasperWA ) v0.16.8 (2021-12-22) \u00b6 Full Changelog Implemented enhancements: Support for Python 3.10 #956 Fixed bugs: Overzealous validation of substring comparisons for chemical formula fields #1024 Merged pull requests: Add configurable field-specific validator overrides to set filter operators as optional #1025 ( ml-evs ) Add Python 3.10 support #957 ( ml-evs ) v0.16.7 (2021-11-21) \u00b6 Full Changelog Implemented enhancements: Stricter validation of chemical formulas in OpenAPI schema #708 Fixed bugs: chemical_formula_anonymous validator accepts incorrect proportion order if started with 1 #1002 Closed issues: Versioned docs do not redirect all links correctly #977 Missing support for timestamps/datetime in grammar #102 Merged pull requests: Fixed bug in check_anonymous_formula which caused chemical_formula_anonymous = AB2 to pass validation. #1001 ( JPBergsma ) Use diff for checking PR body #1000 ( CasperWA ) Correct PR body comparison #996 ( CasperWA ) Update dependency auto-PR message #989 ( ml-evs ) Stricter formula syntax #986 ( merkys ) Implement workflows for dependency updates #979 ( CasperWA ) Tidy up old grammars, add a development grammar for v1.2 and update filterparser tests #879 ( ml-evs ) v0.16.6 (2021-10-19) \u00b6 Full Changelog Merged pull requests: Put docs release deployment in separate job #978 ( CasperWA ) v0.16.5 (2021-10-18) \u00b6 Full Changelog Closed issues: 'elements_ratios' model validator uses double-precision machine epsilon - could be relaxed #947 Versioning in Docs #724 Merged pull requests: Fix option value for checkout in CD Docs workflow #972 ( CasperWA ) Correct default branch name to master #971 ( CasperWA ) Automate versioned documentation #951 ( CasperWA ) Add JOSS citation #949 ( ml-evs ) Some validation QoL tweaks #948 ( ml-evs ) v0.16.4 (2021-09-20) \u00b6 Full Changelog Closed issues: Code check fails because there is no valid version of jsmin #938 Be properly compliant with the new pip resolver #625 Merged pull requests: Bump providers from 357c27b to fb05359 #945 ( dependabot[bot] ) Bump providers from 368f9f6 to 357c27b #944 ( dependabot[bot] ) Bump providers from 91b51bd to 368f9f6 #942 ( dependabot[bot] ) remove the dependency on mkdocs-minify because of issue #938. #941 ( JPBergsma ) Corrected command to call uvicorn server #937 ( JPBergsma ) Use proper pip dependency resolver in publish workflow #935 ( ml-evs ) Add JOSS paper #804 ( ml-evs ) v0.16.3 (2021-09-02) \u00b6 Full Changelog Implemented enhancements: Add validation that anonymous/reduced chemical formulae are in fact reduced #913 Fixed bugs: No error/warning when specifying a config file that does not exist #930 Docker tests failing in CI: http://gh_actions_host no longer exists? #906 Fix config file warnings when file is missing #931 ( ml-evs ) Closed issues: Docs don't introduce the idea of \"models\" #910 Docs don't mention anything about where to go for support #909 run.sh does not appear to be available from the pip installation #904 Missing guide for how to set up an implementation from existing database #176 Merged pull requests: Add tutorial-style guide on setting up an API #915 ( ml-evs ) Add validator to check whether anonymous and reduced formulae are reduced #914 ( ml-evs ) Clarify the \"all models\" documentation page #912 ( ml-evs ) Add more specific 'Getting Help' info to Contributing and README #911 ( ml-evs ) Bump Materials-Consortia/optimade-validator-action from 2.5.0 to 2.6.0 #907 ( dependabot[bot] ) Clarify installation methods by use-case #905 ( ml-evs ) Relax response top-level root validator #903 ( CasperWA ) Add integrated app docs, tweak other use case docs #883 ( ml-evs ) v0.16.2 (2021-08-06) \u00b6 Full Changelog Fixed bugs: Provider fallbacks are still not working #896 Fix provider fallbacks #897 ( ml-evs ) Merged pull requests: Dependency updates for v0.16.2 #894 ( ml-evs ) Bump codecov/codecov-action from 2.0.1 to 2.0.2 #882 ( dependabot[bot] ) Bump codecov/codecov-action from 1.5.2 to 2.0.1 #878 ( dependabot[bot] ) v0.16.1 (2021-07-15) \u00b6 Full Changelog Implemented enhancements: Change MIME type to application/vnd.api+json where appropriate #875 Minor corrections + use model aliases for handle_response_fields() #876 ( CasperWA ) Fixed bugs: Wrong behaviour HAS ONLY query for MongoDB #810 Correct the behaviour of HAS ONLY with MongoDB backend #861 ( JPBergsma ) Merged pull requests: Change default MIME type to \"application/vnd.api+json\" #877 ( ml-evs ) Update elements description to match specification #874 ( ml-evs ) v0.16.0 (2021-07-06) \u00b6 Full Changelog Closed issues: Incoming model update (new field: issue_tracker) #592 Merged pull requests: Add issue_tracker field to provider model #593 ( ml-evs ) v0.15.5 (2021-07-04) \u00b6 Full Changelog Fixed bugs: NOT filter operation of mongo query for complex expressions #79 Closed issues: Remove CI psycopg2-binary install when aiida-core>1.6.3 #855 Pytest fails at Setup environment for AiiDA #853 Add timeout parameter to validator #681 Add note in installation instructions about pulling submodule for providers #370 Merged pull requests: Add request --timeout parameter to validator #860 ( ml-evs ) Bump providers from fa25ed3 to 91b51bd #858 ( dependabot[bot] ) Update to AiiDA v1.6.4 and remove CI fix #857 ( CasperWA ) Temporary fix for CI tests with AiiDA #854 ( CasperWA ) Documentation tweaks #852 ( JPBergsma ) Fix query negation in MongoDB #814 ( JPBergsma ) v0.15.4 (2021-06-15) \u00b6 Full Changelog Implemented enhancements: Missing documentation for new configuration methods #766 Closed issues: Add docs \"use case\" for the validator #841 Use specific configuration file for Heroku deployment #738 Potential submission to JOSS? #203 Add more tests #104 Merged pull requests: Tweak configuration docs #851 ( ml-evs ) Add some more tutorial-style documentation #850 ( ml-evs ) v0.15.3 (2021-06-10) \u00b6 Full Changelog Merged pull requests: Update model descriptions following spec updates #847 ( ml-evs ) v0.15.2 (2021-06-10) \u00b6 Full Changelog Implemented enhancements: Missing HTTP response codes in OpenAPI schema #763 Merged pull requests: Update response model information for routes #846 ( CasperWA ) Improve semver validation error messsage #845 ( ml-evs ) Bump codecov/codecov-action from 1.5.0 to 1.5.2 #843 ( dependabot[bot] ) v0.15.1 (2021-06-08) \u00b6 Full Changelog Closed issues: mongomock $size queries match all non-array fields for {$size: 1}, even nulls #807 Allow custom headers to be specified for validation #790 Merged pull requests: Add --headers argument to validator to allow passing e.g. API keys #806 ( ml-evs ) v0.15.0 (2021-06-01) \u00b6 Full Changelog Fixed bugs: Provider fallbacks do not get used #829 ParserError's should not return 500 HTTP status codes #812 Fix provider fallback list #830 ( ml-evs ) Return 400 Bad Request (not 500) on filter parser errors, plus filterparser module facelift #813 ( ml-evs ) Closed issues: Move aliasing code to base transformer #743 Missing optional fields are not returned as null when requested with response_fields #516 Merged pull requests: Update INSTALL docs #811 ( ml-evs ) Overhaul of filter transformers, mappers and response fields #797 ( ml-evs ) v0.14.1 (2021-05-14) \u00b6 Full Changelog Fixed bugs: [SECURITY] Cycle secrets #777 Closed issues: Do not validate extension endpoints #793 Verify that missing values are not returned in comparisons #792 Merged pull requests: Update GH actions #803 ( CasperWA ) Handling null fields in the filtertransformer and validator #796 ( ml-evs ) Filter out extension endpoints before validation #794 ( ml-evs ) Bump providers from 7a54843 to fa25ed3 #791 ( dependabot[bot] ) Bump CharMixer/auto-changelog-action from v1.2 to v1.3 #778 ( dependabot[bot] ) v0.14.0 (2021-03-26) \u00b6 Full Changelog Implemented enhancements: Rename config variable use_real_mongo to something more general #742 Custom configuration extensions & use standard pydantic way of loading config file #739 Generalising collections and adding ElasticsearchCollection #660 ( ml-evs ) Fixed bugs: Over-aggressive middleware to check versioned base URL #737 Floating point comparisons should not be tested with the validator #735 Mapper method alias_of extracts alias wrongly #667 Closed issues: Docs builds are not properly tested for each PR #747 Merged pull requests: Fix CheckWronglyVersionedBaseUrls middleware (for landing pages) #752 ( CasperWA ) Deprecate Python 3.6 support, v0.14 last supported version #751 ( CasperWA ) Run full API docs invoke task for every PR #748 ( ml-evs ) Change aliasing method names in mapper and deprecate the old #746 ( ml-evs ) Bump providers from e2074e8 to 7a54843 #741 ( dependabot[bot] ) Config updates #740 ( CasperWA ) Disable all floating-point comparisons during validation #736 ( ml-evs ) Report user errors in filter as HTTP 400 Bad Request and not 501 Not Implemented #658 ( markus1978 ) v0.13.3 (2021-03-05) \u00b6 Full Changelog Fixed bugs: Python 3.9 support invalid #728 Merged pull requests: Update pydantic to ~=1.8 #731 ( CasperWA ) Bump providers from da74513 to e2074e8 #727 ( dependabot[bot] ) v0.13.2 (2021-03-01) \u00b6 Full Changelog Implemented enhancements: Improve validation of providers #723 v0.13.1 (2021-02-23) \u00b6 Full Changelog Fixed bugs: Supported OPTIMADE __api_version__ is incorrect in latest release #712 Merged pull requests: Bump OPTIMADE version #713 ( ml-evs ) v0.13.0 (2021-02-20) \u00b6 Full Changelog Closed issues: Update species.mass model #630 Merged pull requests: Update species->mass field following specification change #631 ( ml-evs ) v0.12.9 (2021-02-10) \u00b6 Full Changelog Implemented enhancements: Improve support for timestamp queries in MongoTransformer #590 ( ml-evs ) Fixed bugs: Use Enums for pydantic model defaults instead of strings #683 Closed issues: When using --as-type in validator, one does not get a summary ( --json doesn't work) #699 Extension/import issue with mongo collection #682 Merged pull requests: Always print summary as last thing in validation #700 ( CasperWA ) Fixes for new gateway implementation #684 ( CasperWA ) v0.12.8 (2021-01-18) \u00b6 Full Changelog Implemented enhancements: Validate mandatory query field structure_features #678 Fixed bugs: Validator should not rely on meta->data_available #677 Validator should not rely on SHOULD \"meta\" field \"data_returned\" #675 Validator: remove reliance on meta fields and check mandatory queries #676 ( ml-evs ) Merged pull requests: Bump providers from 542ac0a to da74513 #679 ( dependabot[bot] ) v0.12.7 (2021-01-15) \u00b6 Full Changelog Implemented enhancements: Make content-type response checks on '/versions` endpoint optional #670 ( ml-evs ) Fixed bugs: Publish workflow fails when no changes to api docs between versions #673 /versions header Content-Type value should be granularized according to RFC requirements in validator #669 Misleading error message from validator on failure from '/versions' #668 Fix publishing workflow #674 ( ml-evs ) Merged pull requests: Update codecov coverage config file #672 ( CasperWA ) Bump providers from fe5048b to 542ac0a #671 ( dependabot[bot] ) v0.12.6 (2021-01-08) \u00b6 Full Changelog Implemented enhancements: Create base transformer #286 Fixed bugs: Our models and validator are too strict #399 Validator changes: always check unversioned '/versions' and handle rich HTML pages #665 ( ml-evs ) Closed issues: Add more prominent link to rendered docs #628 Review the required properties of StructureResourceAttributes in openapi.json #198 Merged pull requests: Added GitHub CODEOWNERS #664 ( ml-evs ) Robustness improvements to validator #659 ( ml-evs ) Update dependencies #655 ( CasperWA ) Bugfixes for elasticsearch filtertransformer comparision operators. #648 ( markus1978 ) Added \"root_path\" config parameter for FastAPI apps #634 ( markus1978 ) Bump providers from 2673be6 to fe5048b #633 ( dependabot[bot] ) Updated README and moved some files to top-level #629 ( ml-evs ) insert reading of default optimade_config.json in example run script run.sh #627 ( rartino ) Create template filtertransformer BaseTransformer #287 ( ml-evs ) v0.12.5 (2020-12-05) \u00b6 Full Changelog Closed issues: PyPI publishing build is broken by latest pip #624 Empty endpoints raise errors on validation #622 Frequency of updating online docs #452 Merged pull requests: Fix PyPI publishing in CI #623 ( ml-evs ) Change validation error to warning on empty endpoints #621 ( ml-evs ) Update dependencies #620 ( CasperWA ) Upstream fixes from specification #611 ( ml-evs ) Minor fixes for the validator #610 ( ml-evs ) include LICENSE in pip Package #594 ( jan-janssen ) Relax models to allow for all SHOULD fields to be None #560 ( ml-evs ) Python 3.9 support #558 ( ml-evs ) ReadTheDocs configuration file (v2) #485 ( CasperWA ) v0.12.4 (2020-11-16) \u00b6 Full Changelog Merged pull requests: Minor fixes for versions endpoint validation #591 ( ml-evs ) Add --minimal/--page_limit validator options and remove old code #571 ( ml-evs ) v0.12.3 (2020-11-04) \u00b6 Full Changelog Fixed bugs: GITHUB_TOKEN not useful for changelog action #587 Hill notation wrong (still) #585 Hill notation validation turning around C and H #581 Closed issues: Make structure \"deformity\" tests more robust #583 Incomplete output of optimade-validator #568 Merged pull requests: Use special release PAT for CHANGELOG generation action #588 ( CasperWA ) Check for carbon in elements for Hill #586 ( CasperWA ) Added better expected error messages to deformity tests #584 ( ml-evs ) Fix Hill ordering validation #582 ( CasperWA ) Moved CONFIG import so it does not get triggered when just importing mapper #569 ( ml-evs ) v0.12.2 (2020-10-31) \u00b6 Full Changelog Implemented enhancements: Add convenience method for adding all required middleware #536 Add model validators and regexp for chemical formulae fields #547 ( ml-evs ) Validator improvements #515 ( ml-evs ) Fixed bugs: 'Chosen entry had no value for ...' when property is not requested #514 Fix Species validators and error messages #561 ( ml-evs ) Closed issues: Chemical symbols D and T #570 Spurious validation errors in Structure->Species #559 Chemical formulae are not properly validated on model creation #546 Merged pull requests: Bump CasperWA/push-protected from v1 to v2.1.0 #573 ( dependabot[bot] ) Update deps #566 ( ml-evs ) Improve handling of MongoDB ObjectID #557 ( ml-evs ) Updated dependencies #551 ( ml-evs ) Update dependencies - remove black as direct dependency #545 ( CasperWA ) Added convenience variables for middleware and exception handlers #537 ( ml-evs ) v0.12.1 (2020-09-24) \u00b6 Full Changelog Implemented enhancements: Move entry schemas to separate submodule #511 ( ml-evs ) Closed issues: Validator should allow implementations to return \"501 Not Implemented\" for unsupported filters #518 Landing page wrong URL #371 Merged pull requests: This should ensure requirements*.txt are tested #527 ( CasperWA ) Update dependencies #526 ( CasperWA ) Fix landing page URL #519 ( shyamd ) Fixing typo validatated -> validated #506 ( merkys ) Make validator respond to KeyboardInterrupts #505 ( ml-evs ) Add support levels to validator config #503 ( ml-evs ) Enable JSON response from the validator #502 ( ml-evs ) v0.12.0 (2020-09-11) \u00b6 Full Changelog Fixed bugs: Missing field descriptions in schema for Species->name and Person->name #492 \"type\" field not marked as required for derived entry resource models #479 OpenAPI validations fails due to incorrect type of \"dimension_types\" #478 Have fallbacks for retrieving providers list #450 Commit only when necessary #495 ( CasperWA ) Fix field optonality inconsistency in schema #482 ( ml-evs ) Closed issues: Validator message for wrong version #493 Validator should validate versions endpoint #491 List of providers not included in /links endpoint for index meta-database #454 Validate bad version URLs responding with 553 Version Not Supported #427 Nonexistent property 'list' in validator tests #423 Test data_returned #402 AiiDA tests only run on Python 3.8 in CI #401 Links under top-level 'links' may be objects #394 Suggestion: use absolute imports in app code to allow re-use #298 error when browsing OpenAPI docs #192 Merged pull requests: Don't report untracked and ignored files #496 ( CasperWA ) Improved error message for bad version returning 553 #494 ( ml-evs ) Allow Link objects for pagination #484 ( ml-evs ) Absolute imports #483 ( CasperWA ) Validate OpenAPI specification in CI #481 ( ml-evs ) Update types to align with OpenAPI #480 ( CasperWA ) Unpin CI Python version for AiiDA tests #472 ( ml-evs ) Provider list fallback and list of providers in both servers' /links -endpoints #455 ( CasperWA ) SHOULD/MUST/OPTIONAL fields in models #453 ( ml-evs ) Validator overhaul #417 ( ml-evs ) v0.11.0 (2020-08-05) \u00b6 Full Changelog Implemented enhancements: Use logging more thoroughly throughout the code base #242 Implement warnings #105 Fixed bugs: Heroku is failing - raising OSError when making LOGS_DIR #448 /versions endpoint content-type parameter \"header=present\" is provided in the wrong place #418 Publish workflow cannot push to protected branch #341 Fix circular dep and extra permission error in logs #436 ( ml-evs ) Closed issues: log_dir option in config is unused #435 Allow all types of JSON API relationships #429 OPTIMADE version badge was not bumped on 1.0 release #415 Add api_hint query parameter #392 Return 553 for wrongly versioned base URLs #391 Private/dunder methods incorrectly documented in mkdocs #365 Configuration documentation #310 Improve handling of sorting in MongoDB backend #276 Merged pull requests: Catch OSError instead of PermissionError when making log dir #449 ( CasperWA ) Introduce logging #432 ( CasperWA ) New middleware to catch any OptimadeWarning s #431 ( CasperWA ) Auto-generate API reference in docs and an overhaul #430 ( CasperWA ) Bump providers from 52027b1 to 9712dd8 #428 ( dependabot[bot] ) Cleanup config files #426 ( CasperWA ) Update more unittest tests to pytest #425 ( CasperWA ) Sorting on unknown properties: returning Bad Request when appropriate #424 ( ml-evs ) Minor CI updates #422 ( CasperWA ) Add api_hint query parameter #421 ( CasperWA ) Implement 553 Version Not Supported #420 ( CasperWA ) Fix incorrect placement of header=present in versions endpoint #419 ( ml-evs ) Bump optimade-version.json to 1.0.0 #416 ( ml-evs ) Use optimade-validator-action v2 #413 ( CasperWA ) Bump providers from a96d424 to 52027b1 #389 ( dependabot[bot] ) v0.10.0 (2020-07-17) \u00b6 Full Changelog Implemented enhancements: Move tests to pytest system from unittest #270 Fixed bugs: Fix /vMAJOR/info in index server #414 ( CasperWA ) Closed issues: Validation of 'structures' type crashes #397 Validator verbosity levels need more detailed description #396 Validator treats top-level 'included' array as mandatory #393 (Un)versioned URLs #379 Merged pull requests: Temporarily run AiiDA tests on Python 3.8 only #400 ( ml-evs ) Make the example for --as_type more similar to a real use case #398 ( merkys ) Fix some validator-specific crashes #395 ( ml-evs ) Use pytest instead of unittest #390 ( CasperWA ) v0.9.8 (2020-07-03) \u00b6 Full Changelog Implemented enhancements: Set implementation version in config by default #385 ( CasperWA ) Merged pull requests: Update models, endpoints and responses to 1.0.0 #380 ( ml-evs ) v0.9.7 (2020-06-28) \u00b6 Full Changelog v0.9.6 (2020-06-28) \u00b6 Full Changelog Fixed bugs: Fix publish workflow - final(TM) fix #378 ( CasperWA ) v0.9.5 (2020-06-26) \u00b6 Full Changelog v0.9.4 (2020-06-26) \u00b6 Full Changelog v0.9.3 (2020-06-26) \u00b6 Full Changelog Merged pull requests: Fix version issues in the publish workflow #376 ( shyamd ) Bump providers from 732593a to a96d424 #368 ( dependabot[bot] ) v0.9.2 (2020-06-25) \u00b6 Full Changelog Fixed bugs: Heroku cannot handle submodules when deploying via GitHub #373 Closed issues: Updates to models (new OPTIONAL type field under properties ) #345 Add aggregatation fields to links model #344 Updates to models (nperiodic_dimensions) #343 Updates to models (changing unknown atoms) #342 Improvements/fixes for openapi.json #332 Update to v1.0.0-rc.1 #329 RST not rendering with mkdocs #307 Merged pull requests: Retrieve providers list if no submodule is found #374 ( CasperWA ) Update default implementation information #372 ( shyamd ) Bump spec version to 1.0.0-rc.2 #367 ( ml-evs ) Merge all Dependabot updates #353 ( shyamd ) Update model descriptions and openapi.json for 1.0.0-rc2 #351 ( ml-evs ) Update models according to changes during CECAM 2020 meeting #350 ( ml-evs ) Decouple changes in providers repo #312 ( shyamd ) v0.9.1 (2020-06-17) \u00b6 Full Changelog v0.9.0 (2020-06-17) \u00b6 Full Changelog Implemented enhancements: Breaking up the python tools into seperable packages #255 Run both servers as standard #238 Fixed bugs: Non-running CI job #331 Special species \"X\" not tested for non-disordered structures #304 Standardize timezone of datetime responses #288 Queries on aliased/provider fields are broken for nested properties #282 General exceptions not being put into response #281 Issue with CIF export #271 Type-cast inputs for general Error #280 ( CasperWA ) Closed issues: Update links resources #299 Need to set up mkdocs #289 Need to add custom schema entries for unit/sortable (and eventually type) #278 /info/\\<entry-endpoint> missing sortable key under each property #273 Make CI linting more useful #269 [PR SPECIFIC] Reminder: Validator test pinned to specific commit #268 Validator does not check that pagination links work #265 available_api_versions is not correctly validated #261 Implementation model should allow for any URL type in source_url #260 Extra structure endpoints in the api specification @ odbx #259 Wrong response structure at info endpoint @ cod #258 Missing base url for api's docs @ materialscloud #257 Handling of KNOWN in mongo backend #254 None values in lattice_vectors #170 Make sure that the PyPI distribution works #143 Move run.sh to a python file to be environment-agnostic #81 Merged pull requests: Another fix for release pipeline #355 ( shyamd ) Fix publish workflow #354 ( CasperWA ) Fix publish workflow #352 ( CasperWA ) Update publish workflow #340 ( shyamd ) Remove test publish action #338 ( shyamd ) Fix 'publish_TestPyPI' CI job #337 ( CasperWA ) Represent the datetime objects as UTC in RFC3339 format #333 ( fekad ) dependamat: Bump \\<package_name> v x.y.z to vx.y.(z+1) #330 ( ml-evs ) Update links resources #306 ( CasperWA ) Add special species for adapters testing #305 ( CasperWA ) Clean Up Build Environment #301 ( shyamd ) Enable CI failures for linting #300 ( ml-evs ) Adding jarvis-tools structures #297 ( knc6 ) Update Docs #295 ( shyamd ) Setup MKDocs for Documentation #294 ( shyamd ) Fix filters on nested provider/aliased fields #285 ( ml-evs ) Use heroku-shields instead of heroku-badge #284 ( CasperWA ) Add OPTIMADE logo to badge by extending JSON #283 ( CasperWA ) Add null check to mongo filtertransformer for KNOWN/UNKNOWN filters #279 ( ml-evs ) Add sortable=True to all properties #274 ( CasperWA ) Make _atom_site_label unique in CIF generation #272 ( CasperWA ) Not so quick fix to allow \"/\" at end of validator URL, plus fixes and tests for --as_type #267 ( ml-evs ) Check pagination links->next with validator #266 ( ml-evs ) Relax HTTP URL constraints on meta->implementation->source_url field. #262 ( ml-evs ) Validate lattice_vectors for all null or all float #171 ( CasperWA ) v0.8.1 (2020-04-25) \u00b6 Full Changelog Fixed bugs: Pip install missing some files #252 Merged pull requests: v0.8.1 hotfix #256 ( ml-evs ) Fix 252 missing landing page #253 ( shyamd ) v0.8.0 (2020-04-22) \u00b6 Full Changelog Implemented enhancements: Switch to pydantic's BaseSettings for the config file? #152 Remove query constraints for /links-endpoint #244 ( CasperWA ) Add adapters - Base design + 'structures' (+ 'references'... sort of) #241 ( CasperWA ) Add dependabot and last commit date badges #237 ( CasperWA ) Add mongo length operator functionality with length aliases #222 ( ml-evs ) Fixed bugs: Use Path.home() instead of ~ in default config path values #245 Closed issues: Have Dependabot take care of various requirements.txt files as well #249 Remove commented out GH Action job deps_clean-install #247 Local testing fails without default config #239 Release only when pushing to master #229 Do we need server.cfg ? #134 Implement LENGTH in query #86 Merged pull requests: Up to v0.8.0 #251 ( CasperWA ) Remove old commented GH Action job #250 ( CasperWA ) Use Path.home() instead of ~ #246 ( CasperWA ) Fix path in default config #243 ( ml-evs ) Fixes Local Tests #240 ( shyamd ) Revert \"Fix github actions for non-release tags\" #236 ( shyamd ) Enable filtering on relationships with mongo #234 ( ml-evs ) Update filter examples and validate optional cases #227 ( ml-evs ) Switch from config init to BaseSettings #226 ( shyamd ) v0.7.1 (2020-03-16) \u00b6 Full Changelog Closed issues: Fix all capitalisation of OPTIMADE #232 Remove validator action from README #230 Merged pull requests: Fix github actions for non-release tags #235 ( shyamd ) Update OPTIMADE capitalisation #233 ( ml-evs ) Update mentions of action in readme #231 ( ml-evs ) v0.7.0 (2020-03-13) \u00b6 Full Changelog Implemented enhancements: Validate all non-optional :filter: examples from the spec #213 ( ml-evs ) Fixed bugs: Some mandatory filter examples from spec do not work #217 Add txt-files in optimade.validator.data to MANIFEST #225 ( CasperWA ) Handle arbitrary nested NOT/AND/OR in queries #221 ( ml-evs ) Closed issues: Validator only validates what we have working, not what is required by the spec #182 Merged pull requests: v0.7.0 release #228 ( ml-evs ) Remove GH Action to validate OPTiMaDe instances #224 ( CasperWA ) v0.6.0 (2020-03-06) \u00b6 Full Changelog Implemented enhancements: Possibly add CORS middleware #159 Add debug flag to server #130 Make validator GitHub Action #191 ( CasperWA ) Fixed bugs: meta/query/representation value not cutting off version properly #199 URL for providers.json from Materials-Consortia has changed #186 Relationships don't work when \"/\" present in id #181 Redirect middleware not hitting single-entry endpoints #174 Closed issues: /info/ reports wrong url under available_api_versions #215 Query parameters not handled correctly #208 Test for AvailableApiVersion is correct for the wrong reasons #204 Drop '/optimade' from paths in openapi.json #197 heroku is failing #185 List properties and HAS _ operators missing #98 Checklist for OPTiMaDe v0.10.1 #29 Merged pull requests: Removed /optimade/ prefix in info response #216 ( ml-evs ) Self load data #212 ( shyamd ) Update tests for available_api_versions #211 ( CasperWA ) Up to v0.6.0 #210 ( CasperWA ) Update handling of include parameter (and other query parameters) #209 ( CasperWA ) Skip HAS ONLY test if mongomock version \\<= 3.19.0 #206 ( ml-evs ) Test mandatory queries in validator #205 ( ml-evs ) Fix include query parameter #202 ( CasperWA ) Fix meta.query.representation and remove /optimade in base URLs #201 ( CasperWA ) Use mongo for CI #196 ( ml-evs ) (Cosmetic) updates to models #195 ( CasperWA ) Add CORSMiddleware #194 ( CasperWA ) Add \"debug mode\" #190 ( CasperWA ) Use https://provider.optimade.org/providers.json #187 ( CasperWA ) Fix errors parsing IDs that contain slashes #183 ( ml-evs ) Added default mongo implementations for HAS ALL/ANY/ONLY #173 ( ml-evs ) v0.5.0 (2020-02-13) \u00b6 Full Changelog Implemented enhancements: Implement a landing page for requests to the base URL #169 Fixed bugs: 'minor' and 'patch' versioned base URL prefixes are wrong #177 Closed issues: Handle include standard JSON API query parameter #94 Merged pull requests: Bump to v0.5.0 #179 ( CasperWA ) Correctly create optional versioned base URLs #178 ( CasperWA ) Make mapper aliases configurable #175 ( ml-evs ) Add landing page at base URL #172 ( ml-evs ) Implement include query parameter #163 ( CasperWA ) Add docker for index meta-database #140 ( CasperWA ) v0.4.0 (2020-02-06) \u00b6 Full Changelog Implemented enhancements: switch to pipenv? #37 Reorder tests #162 ( CasperWA ) Fixed bugs: Server app intermingles #161 response_fields not working #154 Closed issues: Change page_page to page_number #165 Add schema-relevant parameters to query parameters #164 Alias optimade/structures/ to optimade/structure #128 Minor changes to specification v0.10.1-develop #115 Update models with new levels of REQUIRED response properties #114 Constraining list/array types in the schema #55 Merged pull requests: Bump to v0.4.0 #168 ( CasperWA ) Describe query parameters in OpenAPI schema #166 ( CasperWA ) Redirect slashed URLs #160 ( CasperWA ) New REQUIRED level properties #153 ( CasperWA ) v0.3.4 (2020-02-04) \u00b6 Full Changelog Implemented enhancements: Include develop or not? Default branch? - Create INSTALL.md #136 Fixed bugs: Excepting non-existent exception #129 Closed issues: disable serving API under /v0.10 and /v0.10.0 by default? #122 PyPI release checklist #67 Merged pull requests: Bump to v0.3.4 #158 ( CasperWA ) Fix heroku badge #157 ( ml-evs ) Move installation instructions #156 ( ml-evs ) Update base URLs #155 ( CasperWA ) Extend OpenAPI/spec description #151 ( CasperWA ) Non Local Mongo #150 ( shyamd ) v0.3.3 (2020-01-24) \u00b6 Full Changelog Fixed bugs: Lark files not being distributed #141 Merged pull requests: Updated lark-parser to 0.8.1 #149 ( ml-evs ) Split eager and standard tests to avoid unnecessary badge of shame #148 ( ml-evs ) Bump to v0.3.3 #147 ( CasperWA ) Fix root_validator issues with optional fields and made meta optional #145 ( ml-evs ) Handle JSONDecodeError s in validator #144 ( ml-evs ) v0.3.2 (2020-01-20) \u00b6 Full Changelog Implemented enhancements: Add base URL to configuration file #135 ( CasperWA ) Fixed bugs: Fix load_from_json #137 ( CasperWA ) Merged pull requests: Make sure relevant package data is included in distributions #142 ( CasperWA ) Add database page limit #139 ( CasperWA ) v0.3.1 (2020-01-17) \u00b6 Full Changelog Merged pull requests: Update requirements #138 ( CasperWA ) v0.3.0 (2020-01-14) \u00b6 Full Changelog Implemented enhancements: Implement optional implementation in top-level meta response #117 Create \"special\" index meta-database server #100 Implement relationships in server #71 Add missing /references endpoint to server #69 Automatically publish version tags to PyPI via GH Actions #107 ( CasperWA ) Using routers #99 ( CasperWA ) Add relationships functionality #91 ( ml-evs ) Added external API validator based on our pydantic models #74 ( ml-evs ) Fixed bugs: The invoke task update-openapijson is incomplete #123 Django vulnerability #108 Closed issues: info endpoint duplicated? #120 Commented-out validator #111 FastAPI v0.44.0 supports pydantic > 1.0.0 #101 Server is missing /links endpoint #89 Make sure all validators are tested #87 The sortable field must be added to models #84 Package structure #72 Possibly make /info/{endpoint} dynamic #70 setuptools package with server as \"extra\" #62 use examples from specs as resources #57 httptools dependency has build issues on GCC/Linux #54 Lark grammar file for v0.9.8 #50 type is missing in response #43 Enforce use of autoformatter #33 switch license to MIT #28 write a lark JSONTransformer / JSONdecoder #26 server.jsonapi has no additionalProperties=false #23 server.jsonapi has no patternProperties #22 Developer-friendly pre-commit openapi.json visual diff #21 add JSON schema API #12 generate static documentation on github from openapi.json #9 test how to generate a client from the openapi.json #8 come up with suggested toolchain for validating existing optimade API against openapi.json #7 add travis test that checks openapi.json is valid OpenAPI spec #6 add 2 examples of how to include documentation in python classes #5 add one-line command to update openapi.json #4 Merged pull requests: Fixed CI readme badge #133 ( ml-evs ) Add meta.description to BaseRelationshipResource #131 ( CasperWA ) Added homepage attribute to LinksResource #127 ( ml-evs ) Updated structure models and validators #126 ( ml-evs ) Minor change to fallback server.cfg #125 ( ml-evs ) Update local OpenAPI schemes prior to copying #124 ( CasperWA ) Update OpenAPI tags #121 ( CasperWA ) A few fixes related to usage as a library #119 ( ml-evs ) Add implementation to top-level meta response #118 ( CasperWA ) Add heroku deployment scripts #116 ( ltalirz ) Reorganize package #113 ( CasperWA ) Introduce grammar v0.10.1 #112 ( CasperWA ) Update to pydantic v1 #110 ( CasperWA ) Minimum requirement of django v2.2.8 #109 ( CasperWA ) Index meta-database #103 ( CasperWA ) restrict pydantic version #97 ( ltalirz ) Add /links #95 ( CasperWA ) Fix data_returned and data_available #93 ( CasperWA ) Use GitHub Actions for CI #92 ( ml-evs ) Remove inappropriate lint messages #90 ( CasperWA ) Fix dependencies #88 ( CasperWA ) Add sortable field to EntryInfoProperty model #85 ( CasperWA ) Validate illegal fields are not present under attributes and relationships #83 ( CasperWA ) Add references endpoint #78 ( CasperWA ) fix travis build #77 ( ltalirz ) Fix manual verification of elements_ratios #76 ( CasperWA ) add automatic PyPI deployment #75 ( ltalirz ) Remove reference to \"all\" endpoint and rename collections submodule #73 ( ml-evs ) Updates to README and docs for v0.10.0 #68 ( ml-evs ) Adding grammar for v0.10.0 #66 ( fekad ) Schema updates and fixes relative to the v0.10.0 spec #65 ( ml-evs ) Break requirements down on per backend basis #64 ( ml-evs ) 0.10.0 grammer, elasticsearch transformer, setuptools extra #63 ( markus1978 ) Added a Lark to Django Query converter #61 ( tachyontraveler ) Some minor fixes #60 ( ml-evs ) Added codecov to CI #59 ( ml-evs ) Enforce black via pre-commit tool #53 ( dwinston ) Update setup.py and version #51 ( dwinston ) /structure/info endpoint #49 ( fawzi ) add constrained list type #48 ( dwinston ) Refactored into submodules and added test data #47 ( ml-evs ) Update structure endpoint to pre-alpha 0.10 spec #45 ( ltalirz ) Adding Resource Links #44 ( tpurcell90 ) Reblacken #42 ( ml-evs ) Documented json #41 ( tpurcell90 ) fix example output #40 ( dwinston ) use jsonapi better at top level, add error response #36 ( fawzi ) add JSONTransformer #35 ( dwinston ) switch to MIT license #34 ( ltalirz ) Updated entry definitions and renamed Response classes #32 ( ml-evs ) update readme #31 ( ltalirz ) Seperated Links from JSON API into its own file #30 ( tpurcell90 ) simplify schema update #27 ( ltalirz ) add openapi_diff to travis #25 ( ltalirz ) Json api add #24 ( tpurcell90 ) Added JSON diff test #20 ( ml-evs ) info endpoint #19 ( fawzi ) adding run.sh script to start webserver #18 ( fawzi ) error response #17 ( fawzi ) Links can be strings #16 ( fawzi ) response should be either many (list) or one (object), not an union #15 ( fawzi ) reorg models #14 ( dwinston ) Update the OptimadeMetaResponse to development schema #13 ( ml-evs ) add openapi spec validator #10 ( ltalirz ) fix test data download #3 ( ltalirz ) [WIP] Mongoconverter #1 ( wuxiaohua1011 ) v0.1.2 (2018-06-14) \u00b6 Full Changelog v0.1.1 (2018-06-13) \u00b6 Full Changelog v0.1.0 (2018-06-05) \u00b6 Full Changelog * This Changelog was automatically generated by github_changelog_generator","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#unreleased-2022-07-08","text":"Full Changelog Implemented enhancements: Support for Elasticsearch v7 #1216 ( markus1978 ) Fixed bugs: Landing page not loading #1256 Config values are not cached by @classproperty #1219 Improve error handling for client when updating provider list #1222 ( ml-evs ) Closed issues: Use versioned Dockerfiles for CI services to allow dependabot to update them #1241 Wrong links to available endpoints #1214 Add configurable meta->schemas field to reference server #1208 Merged pull requests: Bump providers from fb05359 to a92e5bc #1267 ( dependabot[bot] ) Add schema parameter when calling meta_values in landing.py #1257 ( JPBergsma ) Update lark dependency to new name #1231 ( ml-evs ) Use Python 3.10 instead of 3.7 in installation instructions #1229 ( JPBergsma ) Optimisation: do not re-access mapper properties inside the request loop #1223 ( ml-evs ) Add configurable schema_url and index_schema_url options #1210 ( ml-evs )","title":"Unreleased (2022-07-08)"},{"location":"CHANGELOG/#v0180-2022-05-29","text":"Full Changelog This is a feature release that includes the new optimade.client.OptimadeClient class, a client capable asynchronously querying multiple OPTIMADE APIs simultaneously. It also contains a patch for the OPTIMADE models that allows them to be used with more recent FastAPI versions without breaking OpenAPI 3.0 compatibility. Other changes can be found below. This release includes improvements to the validator to catch more cases where OPTIMADE APIs are only partially implemented. Previously, APIs that did not support filtering, pagination or limiting response fields at all (i.e., the query parameter is simply ignored) would pass most validation tests erroneously in some unlucky situations (#1180). Implemented enhancements: The validator should use a custom User-Agent header #1187 Suggestion to include an OPTIMADE python API client #932 Implementation of an OPTIMADE client #1154 ( ml-evs ) Fixed bugs: OptimadeClient crashes if an index meta-database is down #1196 Catch connection errors when populating client database list #1197 ( ml-evs ) Merged pull requests: Add a clearer error message on when trying to use client with missing deps #1200 ( ml-evs ) Use a custom User-Agent with validator #1189 ( ml-evs ) Syntactic tweaks to models and schemas for compatibility with fastapi>0.66 #1131 ( ml-evs )","title":"v0.18.0 (2022-05-29)"},{"location":"CHANGELOG/#v0172-2022-05-21","text":"Full Changelog This release includes improvements to the validator to catch more cases where OPTIMADE APIs are only partially implemented. Previously, APIs that did not support filtering, pagination or limiting response fields at all (i.e., the query parameter is simply ignored) would pass most validation tests erroneously in some unlucky situations (#1180). Fixed bugs: Server validation incorrectly passes with various unimplemented features #1180 Merged pull requests: Harden validator for partially implemented APIs #1181 ( ml-evs )","title":"v0.17.2 (2022-05-21)"},{"location":"CHANGELOG/#v0171-2022-05-18","text":"Full Changelog This patch release adds a pre-built Docker container for the reference server to the GitHub Container Registry (GHCR) and a series of Deployment instructions in the online documentation. The image can be easily pulled from GHCR with: docker pull ghcr.io/materials-consortia/optimade Implemented enhancements: Release a container (Docker) image for developers #1111 Closed issues: Issues with GH Changelog updater (secondary usage API requests) #976 Merged pull requests: Don't use env context for step #1178 ( CasperWA ) Docker image for optimade on ghcr.io #1171 ( CasperWA )","title":"v0.17.1 (2022-05-18)"},{"location":"CHANGELOG/#v0170-2022-05-10","text":"Full Changelog This minor release contains fixes recommended for those deploying the optimade-python-tools reference server: The meta->data_returned field was previously incorrect when using the MongoDB backend. Incoming URL query parameters are now validated against the provided query parameters class (if using custom query parameters, this class should be extended or the parameters should use your registered provider prefix). This functionality can be disabled with the validate_query_parameters config option. The results of some queries were not reversible with MongoDB (e.g., nelements != 2 vs 2 != nelements ); this has now been fixed. Implemented enhancements: Add server check for typos in query parameters #1120 Improve handling of MongoDB ObjectIDs as OPTIMADE immutable_id #1142 ( ml-evs ) Add support for number-based pagination #1139 ( JPBergsma ) Added option to validate incoming URL query parameters #1122 ( JPBergsma ) Fixed bugs: meta->data_returned is incorrect for paginated results with MongoDB #1140 Queries with the form: 'value != prop' return entries where 'prop == None' #1133 Test on Queries on single structures fail with the check_response function. #1125 Fix incorrect meta->data_returned for paginated results with MongoDB #1141 ( ml-evs ) Fix cases where comparison first and property first queries did not match #1134 ( JPBergsma ) Closed issues: Raise error/warning when using unsupported pagination method #1132 Add missing documentation for serving custom query params and fields #1123 Merged pull requests: Use GitHub Actions for Heroku deployment #1165 ( ml-evs ) Add docs for custom provider fields and query parameters #1164 ( ml-evs ) Add deprecation warning for Python 3.7 #1157 ( ml-evs ) Added way to specify unsupported query parameters and provide a warning #1136 ( ml-evs ) Adjusted check_response so it can also handle single entries. #1130 ( JPBergsma ) Corrected link in Install.MD #1124 ( JPBergsma )","title":"v0.17.0 (2022-05-10)"},{"location":"CHANGELOG/#v01612-2022-03-23","text":"Full Changelog Implemented enhancements: Make structure adapters infer species from species_at_sites when missing #1103 ( ml-evs ) Allow specification of provider field descriptions/units etc. in config file #1096 ( ml-evs ) Moving and adding some utilities for client code #589 ( ml-evs ) Closed issues: Allow provider field descriptions to be provided in the config #1095","title":"v0.16.12 (2022-03-23)"},{"location":"CHANGELOG/#v01611-2022-03-03","text":"Full Changelog Merged pull requests: Remove Jinja dependency for landing page generation #1082 ( ml-evs )","title":"v0.16.11 (2022-03-03)"},{"location":"CHANGELOG/#v01610-2022-02-05","text":"Full Changelog Fixed bugs: Distribution tests failing #1061 Security fixes: Bump elasticsearch version to avoid CVE-2021-44832 #1066 ( JPBergsma ) Merged pull requests: Use build package to build distributions #1062 ( CasperWA ) Cancel CI PR jobs that are in progress with new changes, add skip_changelog label to overrides #1057 ( ml-evs ) Prevent validator errors/retries on read timeouts #1056 ( ml-evs )","title":"v0.16.10 (2022-02-05)"},{"location":"CHANGELOG/#v0169-2022-01-26","text":"Full Changelog Implemented enhancements: Lower validator default read timeout and allow it to be customised #1051 ( ml-evs ) Security fixes: Bump elasticsearch to avoid log4j vulnerability #1040 Closed issues: Docs reference to LarkParser failing. #1037 Merged pull requests: Update dependabot config and changelog generation #1048 ( ml-evs ) Bump elasticsearch image version to avoid any log4j issues #1041 ( ml-evs ) Make NumPy requirement py version-specific #1036 ( CasperWA )","title":"v0.16.9 (2022-01-26)"},{"location":"CHANGELOG/#v0168-2021-12-22","text":"Full Changelog Implemented enhancements: Support for Python 3.10 #956 Fixed bugs: Overzealous validation of substring comparisons for chemical formula fields #1024 Merged pull requests: Add configurable field-specific validator overrides to set filter operators as optional #1025 ( ml-evs ) Add Python 3.10 support #957 ( ml-evs )","title":"v0.16.8 (2021-12-22)"},{"location":"CHANGELOG/#v0167-2021-11-21","text":"Full Changelog Implemented enhancements: Stricter validation of chemical formulas in OpenAPI schema #708 Fixed bugs: chemical_formula_anonymous validator accepts incorrect proportion order if started with 1 #1002 Closed issues: Versioned docs do not redirect all links correctly #977 Missing support for timestamps/datetime in grammar #102 Merged pull requests: Fixed bug in check_anonymous_formula which caused chemical_formula_anonymous = AB2 to pass validation. #1001 ( JPBergsma ) Use diff for checking PR body #1000 ( CasperWA ) Correct PR body comparison #996 ( CasperWA ) Update dependency auto-PR message #989 ( ml-evs ) Stricter formula syntax #986 ( merkys ) Implement workflows for dependency updates #979 ( CasperWA ) Tidy up old grammars, add a development grammar for v1.2 and update filterparser tests #879 ( ml-evs )","title":"v0.16.7 (2021-11-21)"},{"location":"CHANGELOG/#v0166-2021-10-19","text":"Full Changelog Merged pull requests: Put docs release deployment in separate job #978 ( CasperWA )","title":"v0.16.6 (2021-10-19)"},{"location":"CHANGELOG/#v0165-2021-10-18","text":"Full Changelog Closed issues: 'elements_ratios' model validator uses double-precision machine epsilon - could be relaxed #947 Versioning in Docs #724 Merged pull requests: Fix option value for checkout in CD Docs workflow #972 ( CasperWA ) Correct default branch name to master #971 ( CasperWA ) Automate versioned documentation #951 ( CasperWA ) Add JOSS citation #949 ( ml-evs ) Some validation QoL tweaks #948 ( ml-evs )","title":"v0.16.5 (2021-10-18)"},{"location":"CHANGELOG/#v0164-2021-09-20","text":"Full Changelog Closed issues: Code check fails because there is no valid version of jsmin #938 Be properly compliant with the new pip resolver #625 Merged pull requests: Bump providers from 357c27b to fb05359 #945 ( dependabot[bot] ) Bump providers from 368f9f6 to 357c27b #944 ( dependabot[bot] ) Bump providers from 91b51bd to 368f9f6 #942 ( dependabot[bot] ) remove the dependency on mkdocs-minify because of issue #938. #941 ( JPBergsma ) Corrected command to call uvicorn server #937 ( JPBergsma ) Use proper pip dependency resolver in publish workflow #935 ( ml-evs ) Add JOSS paper #804 ( ml-evs )","title":"v0.16.4 (2021-09-20)"},{"location":"CHANGELOG/#v0163-2021-09-02","text":"Full Changelog Implemented enhancements: Add validation that anonymous/reduced chemical formulae are in fact reduced #913 Fixed bugs: No error/warning when specifying a config file that does not exist #930 Docker tests failing in CI: http://gh_actions_host no longer exists? #906 Fix config file warnings when file is missing #931 ( ml-evs ) Closed issues: Docs don't introduce the idea of \"models\" #910 Docs don't mention anything about where to go for support #909 run.sh does not appear to be available from the pip installation #904 Missing guide for how to set up an implementation from existing database #176 Merged pull requests: Add tutorial-style guide on setting up an API #915 ( ml-evs ) Add validator to check whether anonymous and reduced formulae are reduced #914 ( ml-evs ) Clarify the \"all models\" documentation page #912 ( ml-evs ) Add more specific 'Getting Help' info to Contributing and README #911 ( ml-evs ) Bump Materials-Consortia/optimade-validator-action from 2.5.0 to 2.6.0 #907 ( dependabot[bot] ) Clarify installation methods by use-case #905 ( ml-evs ) Relax response top-level root validator #903 ( CasperWA ) Add integrated app docs, tweak other use case docs #883 ( ml-evs )","title":"v0.16.3 (2021-09-02)"},{"location":"CHANGELOG/#v0162-2021-08-06","text":"Full Changelog Fixed bugs: Provider fallbacks are still not working #896 Fix provider fallbacks #897 ( ml-evs ) Merged pull requests: Dependency updates for v0.16.2 #894 ( ml-evs ) Bump codecov/codecov-action from 2.0.1 to 2.0.2 #882 ( dependabot[bot] ) Bump codecov/codecov-action from 1.5.2 to 2.0.1 #878 ( dependabot[bot] )","title":"v0.16.2 (2021-08-06)"},{"location":"CHANGELOG/#v0161-2021-07-15","text":"Full Changelog Implemented enhancements: Change MIME type to application/vnd.api+json where appropriate #875 Minor corrections + use model aliases for handle_response_fields() #876 ( CasperWA ) Fixed bugs: Wrong behaviour HAS ONLY query for MongoDB #810 Correct the behaviour of HAS ONLY with MongoDB backend #861 ( JPBergsma ) Merged pull requests: Change default MIME type to \"application/vnd.api+json\" #877 ( ml-evs ) Update elements description to match specification #874 ( ml-evs )","title":"v0.16.1 (2021-07-15)"},{"location":"CHANGELOG/#v0160-2021-07-06","text":"Full Changelog Closed issues: Incoming model update (new field: issue_tracker) #592 Merged pull requests: Add issue_tracker field to provider model #593 ( ml-evs )","title":"v0.16.0 (2021-07-06)"},{"location":"CHANGELOG/#v0155-2021-07-04","text":"Full Changelog Fixed bugs: NOT filter operation of mongo query for complex expressions #79 Closed issues: Remove CI psycopg2-binary install when aiida-core>1.6.3 #855 Pytest fails at Setup environment for AiiDA #853 Add timeout parameter to validator #681 Add note in installation instructions about pulling submodule for providers #370 Merged pull requests: Add request --timeout parameter to validator #860 ( ml-evs ) Bump providers from fa25ed3 to 91b51bd #858 ( dependabot[bot] ) Update to AiiDA v1.6.4 and remove CI fix #857 ( CasperWA ) Temporary fix for CI tests with AiiDA #854 ( CasperWA ) Documentation tweaks #852 ( JPBergsma ) Fix query negation in MongoDB #814 ( JPBergsma )","title":"v0.15.5 (2021-07-04)"},{"location":"CHANGELOG/#v0154-2021-06-15","text":"Full Changelog Implemented enhancements: Missing documentation for new configuration methods #766 Closed issues: Add docs \"use case\" for the validator #841 Use specific configuration file for Heroku deployment #738 Potential submission to JOSS? #203 Add more tests #104 Merged pull requests: Tweak configuration docs #851 ( ml-evs ) Add some more tutorial-style documentation #850 ( ml-evs )","title":"v0.15.4 (2021-06-15)"},{"location":"CHANGELOG/#v0153-2021-06-10","text":"Full Changelog Merged pull requests: Update model descriptions following spec updates #847 ( ml-evs )","title":"v0.15.3 (2021-06-10)"},{"location":"CHANGELOG/#v0152-2021-06-10","text":"Full Changelog Implemented enhancements: Missing HTTP response codes in OpenAPI schema #763 Merged pull requests: Update response model information for routes #846 ( CasperWA ) Improve semver validation error messsage #845 ( ml-evs ) Bump codecov/codecov-action from 1.5.0 to 1.5.2 #843 ( dependabot[bot] )","title":"v0.15.2 (2021-06-10)"},{"location":"CHANGELOG/#v0151-2021-06-08","text":"Full Changelog Closed issues: mongomock $size queries match all non-array fields for {$size: 1}, even nulls #807 Allow custom headers to be specified for validation #790 Merged pull requests: Add --headers argument to validator to allow passing e.g. API keys #806 ( ml-evs )","title":"v0.15.1 (2021-06-08)"},{"location":"CHANGELOG/#v0150-2021-06-01","text":"Full Changelog Fixed bugs: Provider fallbacks do not get used #829 ParserError's should not return 500 HTTP status codes #812 Fix provider fallback list #830 ( ml-evs ) Return 400 Bad Request (not 500) on filter parser errors, plus filterparser module facelift #813 ( ml-evs ) Closed issues: Move aliasing code to base transformer #743 Missing optional fields are not returned as null when requested with response_fields #516 Merged pull requests: Update INSTALL docs #811 ( ml-evs ) Overhaul of filter transformers, mappers and response fields #797 ( ml-evs )","title":"v0.15.0 (2021-06-01)"},{"location":"CHANGELOG/#v0141-2021-05-14","text":"Full Changelog Fixed bugs: [SECURITY] Cycle secrets #777 Closed issues: Do not validate extension endpoints #793 Verify that missing values are not returned in comparisons #792 Merged pull requests: Update GH actions #803 ( CasperWA ) Handling null fields in the filtertransformer and validator #796 ( ml-evs ) Filter out extension endpoints before validation #794 ( ml-evs ) Bump providers from 7a54843 to fa25ed3 #791 ( dependabot[bot] ) Bump CharMixer/auto-changelog-action from v1.2 to v1.3 #778 ( dependabot[bot] )","title":"v0.14.1 (2021-05-14)"},{"location":"CHANGELOG/#v0140-2021-03-26","text":"Full Changelog Implemented enhancements: Rename config variable use_real_mongo to something more general #742 Custom configuration extensions & use standard pydantic way of loading config file #739 Generalising collections and adding ElasticsearchCollection #660 ( ml-evs ) Fixed bugs: Over-aggressive middleware to check versioned base URL #737 Floating point comparisons should not be tested with the validator #735 Mapper method alias_of extracts alias wrongly #667 Closed issues: Docs builds are not properly tested for each PR #747 Merged pull requests: Fix CheckWronglyVersionedBaseUrls middleware (for landing pages) #752 ( CasperWA ) Deprecate Python 3.6 support, v0.14 last supported version #751 ( CasperWA ) Run full API docs invoke task for every PR #748 ( ml-evs ) Change aliasing method names in mapper and deprecate the old #746 ( ml-evs ) Bump providers from e2074e8 to 7a54843 #741 ( dependabot[bot] ) Config updates #740 ( CasperWA ) Disable all floating-point comparisons during validation #736 ( ml-evs ) Report user errors in filter as HTTP 400 Bad Request and not 501 Not Implemented #658 ( markus1978 )","title":"v0.14.0 (2021-03-26)"},{"location":"CHANGELOG/#v0133-2021-03-05","text":"Full Changelog Fixed bugs: Python 3.9 support invalid #728 Merged pull requests: Update pydantic to ~=1.8 #731 ( CasperWA ) Bump providers from da74513 to e2074e8 #727 ( dependabot[bot] )","title":"v0.13.3 (2021-03-05)"},{"location":"CHANGELOG/#v0132-2021-03-01","text":"Full Changelog Implemented enhancements: Improve validation of providers #723","title":"v0.13.2 (2021-03-01)"},{"location":"CHANGELOG/#v0131-2021-02-23","text":"Full Changelog Fixed bugs: Supported OPTIMADE __api_version__ is incorrect in latest release #712 Merged pull requests: Bump OPTIMADE version #713 ( ml-evs )","title":"v0.13.1 (2021-02-23)"},{"location":"CHANGELOG/#v0130-2021-02-20","text":"Full Changelog Closed issues: Update species.mass model #630 Merged pull requests: Update species->mass field following specification change #631 ( ml-evs )","title":"v0.13.0 (2021-02-20)"},{"location":"CHANGELOG/#v0129-2021-02-10","text":"Full Changelog Implemented enhancements: Improve support for timestamp queries in MongoTransformer #590 ( ml-evs ) Fixed bugs: Use Enums for pydantic model defaults instead of strings #683 Closed issues: When using --as-type in validator, one does not get a summary ( --json doesn't work) #699 Extension/import issue with mongo collection #682 Merged pull requests: Always print summary as last thing in validation #700 ( CasperWA ) Fixes for new gateway implementation #684 ( CasperWA )","title":"v0.12.9 (2021-02-10)"},{"location":"CHANGELOG/#v0128-2021-01-18","text":"Full Changelog Implemented enhancements: Validate mandatory query field structure_features #678 Fixed bugs: Validator should not rely on meta->data_available #677 Validator should not rely on SHOULD \"meta\" field \"data_returned\" #675 Validator: remove reliance on meta fields and check mandatory queries #676 ( ml-evs ) Merged pull requests: Bump providers from 542ac0a to da74513 #679 ( dependabot[bot] )","title":"v0.12.8 (2021-01-18)"},{"location":"CHANGELOG/#v0127-2021-01-15","text":"Full Changelog Implemented enhancements: Make content-type response checks on '/versions` endpoint optional #670 ( ml-evs ) Fixed bugs: Publish workflow fails when no changes to api docs between versions #673 /versions header Content-Type value should be granularized according to RFC requirements in validator #669 Misleading error message from validator on failure from '/versions' #668 Fix publishing workflow #674 ( ml-evs ) Merged pull requests: Update codecov coverage config file #672 ( CasperWA ) Bump providers from fe5048b to 542ac0a #671 ( dependabot[bot] )","title":"v0.12.7 (2021-01-15)"},{"location":"CHANGELOG/#v0126-2021-01-08","text":"Full Changelog Implemented enhancements: Create base transformer #286 Fixed bugs: Our models and validator are too strict #399 Validator changes: always check unversioned '/versions' and handle rich HTML pages #665 ( ml-evs ) Closed issues: Add more prominent link to rendered docs #628 Review the required properties of StructureResourceAttributes in openapi.json #198 Merged pull requests: Added GitHub CODEOWNERS #664 ( ml-evs ) Robustness improvements to validator #659 ( ml-evs ) Update dependencies #655 ( CasperWA ) Bugfixes for elasticsearch filtertransformer comparision operators. #648 ( markus1978 ) Added \"root_path\" config parameter for FastAPI apps #634 ( markus1978 ) Bump providers from 2673be6 to fe5048b #633 ( dependabot[bot] ) Updated README and moved some files to top-level #629 ( ml-evs ) insert reading of default optimade_config.json in example run script run.sh #627 ( rartino ) Create template filtertransformer BaseTransformer #287 ( ml-evs )","title":"v0.12.6 (2021-01-08)"},{"location":"CHANGELOG/#v0125-2020-12-05","text":"Full Changelog Closed issues: PyPI publishing build is broken by latest pip #624 Empty endpoints raise errors on validation #622 Frequency of updating online docs #452 Merged pull requests: Fix PyPI publishing in CI #623 ( ml-evs ) Change validation error to warning on empty endpoints #621 ( ml-evs ) Update dependencies #620 ( CasperWA ) Upstream fixes from specification #611 ( ml-evs ) Minor fixes for the validator #610 ( ml-evs ) include LICENSE in pip Package #594 ( jan-janssen ) Relax models to allow for all SHOULD fields to be None #560 ( ml-evs ) Python 3.9 support #558 ( ml-evs ) ReadTheDocs configuration file (v2) #485 ( CasperWA )","title":"v0.12.5 (2020-12-05)"},{"location":"CHANGELOG/#v0124-2020-11-16","text":"Full Changelog Merged pull requests: Minor fixes for versions endpoint validation #591 ( ml-evs ) Add --minimal/--page_limit validator options and remove old code #571 ( ml-evs )","title":"v0.12.4 (2020-11-16)"},{"location":"CHANGELOG/#v0123-2020-11-04","text":"Full Changelog Fixed bugs: GITHUB_TOKEN not useful for changelog action #587 Hill notation wrong (still) #585 Hill notation validation turning around C and H #581 Closed issues: Make structure \"deformity\" tests more robust #583 Incomplete output of optimade-validator #568 Merged pull requests: Use special release PAT for CHANGELOG generation action #588 ( CasperWA ) Check for carbon in elements for Hill #586 ( CasperWA ) Added better expected error messages to deformity tests #584 ( ml-evs ) Fix Hill ordering validation #582 ( CasperWA ) Moved CONFIG import so it does not get triggered when just importing mapper #569 ( ml-evs )","title":"v0.12.3 (2020-11-04)"},{"location":"CHANGELOG/#v0122-2020-10-31","text":"Full Changelog Implemented enhancements: Add convenience method for adding all required middleware #536 Add model validators and regexp for chemical formulae fields #547 ( ml-evs ) Validator improvements #515 ( ml-evs ) Fixed bugs: 'Chosen entry had no value for ...' when property is not requested #514 Fix Species validators and error messages #561 ( ml-evs ) Closed issues: Chemical symbols D and T #570 Spurious validation errors in Structure->Species #559 Chemical formulae are not properly validated on model creation #546 Merged pull requests: Bump CasperWA/push-protected from v1 to v2.1.0 #573 ( dependabot[bot] ) Update deps #566 ( ml-evs ) Improve handling of MongoDB ObjectID #557 ( ml-evs ) Updated dependencies #551 ( ml-evs ) Update dependencies - remove black as direct dependency #545 ( CasperWA ) Added convenience variables for middleware and exception handlers #537 ( ml-evs )","title":"v0.12.2 (2020-10-31)"},{"location":"CHANGELOG/#v0121-2020-09-24","text":"Full Changelog Implemented enhancements: Move entry schemas to separate submodule #511 ( ml-evs ) Closed issues: Validator should allow implementations to return \"501 Not Implemented\" for unsupported filters #518 Landing page wrong URL #371 Merged pull requests: This should ensure requirements*.txt are tested #527 ( CasperWA ) Update dependencies #526 ( CasperWA ) Fix landing page URL #519 ( shyamd ) Fixing typo validatated -> validated #506 ( merkys ) Make validator respond to KeyboardInterrupts #505 ( ml-evs ) Add support levels to validator config #503 ( ml-evs ) Enable JSON response from the validator #502 ( ml-evs )","title":"v0.12.1 (2020-09-24)"},{"location":"CHANGELOG/#v0120-2020-09-11","text":"Full Changelog Fixed bugs: Missing field descriptions in schema for Species->name and Person->name #492 \"type\" field not marked as required for derived entry resource models #479 OpenAPI validations fails due to incorrect type of \"dimension_types\" #478 Have fallbacks for retrieving providers list #450 Commit only when necessary #495 ( CasperWA ) Fix field optonality inconsistency in schema #482 ( ml-evs ) Closed issues: Validator message for wrong version #493 Validator should validate versions endpoint #491 List of providers not included in /links endpoint for index meta-database #454 Validate bad version URLs responding with 553 Version Not Supported #427 Nonexistent property 'list' in validator tests #423 Test data_returned #402 AiiDA tests only run on Python 3.8 in CI #401 Links under top-level 'links' may be objects #394 Suggestion: use absolute imports in app code to allow re-use #298 error when browsing OpenAPI docs #192 Merged pull requests: Don't report untracked and ignored files #496 ( CasperWA ) Improved error message for bad version returning 553 #494 ( ml-evs ) Allow Link objects for pagination #484 ( ml-evs ) Absolute imports #483 ( CasperWA ) Validate OpenAPI specification in CI #481 ( ml-evs ) Update types to align with OpenAPI #480 ( CasperWA ) Unpin CI Python version for AiiDA tests #472 ( ml-evs ) Provider list fallback and list of providers in both servers' /links -endpoints #455 ( CasperWA ) SHOULD/MUST/OPTIONAL fields in models #453 ( ml-evs ) Validator overhaul #417 ( ml-evs )","title":"v0.12.0 (2020-09-11)"},{"location":"CHANGELOG/#v0110-2020-08-05","text":"Full Changelog Implemented enhancements: Use logging more thoroughly throughout the code base #242 Implement warnings #105 Fixed bugs: Heroku is failing - raising OSError when making LOGS_DIR #448 /versions endpoint content-type parameter \"header=present\" is provided in the wrong place #418 Publish workflow cannot push to protected branch #341 Fix circular dep and extra permission error in logs #436 ( ml-evs ) Closed issues: log_dir option in config is unused #435 Allow all types of JSON API relationships #429 OPTIMADE version badge was not bumped on 1.0 release #415 Add api_hint query parameter #392 Return 553 for wrongly versioned base URLs #391 Private/dunder methods incorrectly documented in mkdocs #365 Configuration documentation #310 Improve handling of sorting in MongoDB backend #276 Merged pull requests: Catch OSError instead of PermissionError when making log dir #449 ( CasperWA ) Introduce logging #432 ( CasperWA ) New middleware to catch any OptimadeWarning s #431 ( CasperWA ) Auto-generate API reference in docs and an overhaul #430 ( CasperWA ) Bump providers from 52027b1 to 9712dd8 #428 ( dependabot[bot] ) Cleanup config files #426 ( CasperWA ) Update more unittest tests to pytest #425 ( CasperWA ) Sorting on unknown properties: returning Bad Request when appropriate #424 ( ml-evs ) Minor CI updates #422 ( CasperWA ) Add api_hint query parameter #421 ( CasperWA ) Implement 553 Version Not Supported #420 ( CasperWA ) Fix incorrect placement of header=present in versions endpoint #419 ( ml-evs ) Bump optimade-version.json to 1.0.0 #416 ( ml-evs ) Use optimade-validator-action v2 #413 ( CasperWA ) Bump providers from a96d424 to 52027b1 #389 ( dependabot[bot] )","title":"v0.11.0 (2020-08-05)"},{"location":"CHANGELOG/#v0100-2020-07-17","text":"Full Changelog Implemented enhancements: Move tests to pytest system from unittest #270 Fixed bugs: Fix /vMAJOR/info in index server #414 ( CasperWA ) Closed issues: Validation of 'structures' type crashes #397 Validator verbosity levels need more detailed description #396 Validator treats top-level 'included' array as mandatory #393 (Un)versioned URLs #379 Merged pull requests: Temporarily run AiiDA tests on Python 3.8 only #400 ( ml-evs ) Make the example for --as_type more similar to a real use case #398 ( merkys ) Fix some validator-specific crashes #395 ( ml-evs ) Use pytest instead of unittest #390 ( CasperWA )","title":"v0.10.0 (2020-07-17)"},{"location":"CHANGELOG/#v098-2020-07-03","text":"Full Changelog Implemented enhancements: Set implementation version in config by default #385 ( CasperWA ) Merged pull requests: Update models, endpoints and responses to 1.0.0 #380 ( ml-evs )","title":"v0.9.8 (2020-07-03)"},{"location":"CHANGELOG/#v097-2020-06-28","text":"Full Changelog","title":"v0.9.7 (2020-06-28)"},{"location":"CHANGELOG/#v096-2020-06-28","text":"Full Changelog Fixed bugs: Fix publish workflow - final(TM) fix #378 ( CasperWA )","title":"v0.9.6 (2020-06-28)"},{"location":"CHANGELOG/#v095-2020-06-26","text":"Full Changelog","title":"v0.9.5 (2020-06-26)"},{"location":"CHANGELOG/#v094-2020-06-26","text":"Full Changelog","title":"v0.9.4 (2020-06-26)"},{"location":"CHANGELOG/#v093-2020-06-26","text":"Full Changelog Merged pull requests: Fix version issues in the publish workflow #376 ( shyamd ) Bump providers from 732593a to a96d424 #368 ( dependabot[bot] )","title":"v0.9.3 (2020-06-26)"},{"location":"CHANGELOG/#v092-2020-06-25","text":"Full Changelog Fixed bugs: Heroku cannot handle submodules when deploying via GitHub #373 Closed issues: Updates to models (new OPTIONAL type field under properties ) #345 Add aggregatation fields to links model #344 Updates to models (nperiodic_dimensions) #343 Updates to models (changing unknown atoms) #342 Improvements/fixes for openapi.json #332 Update to v1.0.0-rc.1 #329 RST not rendering with mkdocs #307 Merged pull requests: Retrieve providers list if no submodule is found #374 ( CasperWA ) Update default implementation information #372 ( shyamd ) Bump spec version to 1.0.0-rc.2 #367 ( ml-evs ) Merge all Dependabot updates #353 ( shyamd ) Update model descriptions and openapi.json for 1.0.0-rc2 #351 ( ml-evs ) Update models according to changes during CECAM 2020 meeting #350 ( ml-evs ) Decouple changes in providers repo #312 ( shyamd )","title":"v0.9.2 (2020-06-25)"},{"location":"CHANGELOG/#v091-2020-06-17","text":"Full Changelog","title":"v0.9.1 (2020-06-17)"},{"location":"CHANGELOG/#v090-2020-06-17","text":"Full Changelog Implemented enhancements: Breaking up the python tools into seperable packages #255 Run both servers as standard #238 Fixed bugs: Non-running CI job #331 Special species \"X\" not tested for non-disordered structures #304 Standardize timezone of datetime responses #288 Queries on aliased/provider fields are broken for nested properties #282 General exceptions not being put into response #281 Issue with CIF export #271 Type-cast inputs for general Error #280 ( CasperWA ) Closed issues: Update links resources #299 Need to set up mkdocs #289 Need to add custom schema entries for unit/sortable (and eventually type) #278 /info/\\<entry-endpoint> missing sortable key under each property #273 Make CI linting more useful #269 [PR SPECIFIC] Reminder: Validator test pinned to specific commit #268 Validator does not check that pagination links work #265 available_api_versions is not correctly validated #261 Implementation model should allow for any URL type in source_url #260 Extra structure endpoints in the api specification @ odbx #259 Wrong response structure at info endpoint @ cod #258 Missing base url for api's docs @ materialscloud #257 Handling of KNOWN in mongo backend #254 None values in lattice_vectors #170 Make sure that the PyPI distribution works #143 Move run.sh to a python file to be environment-agnostic #81 Merged pull requests: Another fix for release pipeline #355 ( shyamd ) Fix publish workflow #354 ( CasperWA ) Fix publish workflow #352 ( CasperWA ) Update publish workflow #340 ( shyamd ) Remove test publish action #338 ( shyamd ) Fix 'publish_TestPyPI' CI job #337 ( CasperWA ) Represent the datetime objects as UTC in RFC3339 format #333 ( fekad ) dependamat: Bump \\<package_name> v x.y.z to vx.y.(z+1) #330 ( ml-evs ) Update links resources #306 ( CasperWA ) Add special species for adapters testing #305 ( CasperWA ) Clean Up Build Environment #301 ( shyamd ) Enable CI failures for linting #300 ( ml-evs ) Adding jarvis-tools structures #297 ( knc6 ) Update Docs #295 ( shyamd ) Setup MKDocs for Documentation #294 ( shyamd ) Fix filters on nested provider/aliased fields #285 ( ml-evs ) Use heroku-shields instead of heroku-badge #284 ( CasperWA ) Add OPTIMADE logo to badge by extending JSON #283 ( CasperWA ) Add null check to mongo filtertransformer for KNOWN/UNKNOWN filters #279 ( ml-evs ) Add sortable=True to all properties #274 ( CasperWA ) Make _atom_site_label unique in CIF generation #272 ( CasperWA ) Not so quick fix to allow \"/\" at end of validator URL, plus fixes and tests for --as_type #267 ( ml-evs ) Check pagination links->next with validator #266 ( ml-evs ) Relax HTTP URL constraints on meta->implementation->source_url field. #262 ( ml-evs ) Validate lattice_vectors for all null or all float #171 ( CasperWA )","title":"v0.9.0 (2020-06-17)"},{"location":"CHANGELOG/#v081-2020-04-25","text":"Full Changelog Fixed bugs: Pip install missing some files #252 Merged pull requests: v0.8.1 hotfix #256 ( ml-evs ) Fix 252 missing landing page #253 ( shyamd )","title":"v0.8.1 (2020-04-25)"},{"location":"CHANGELOG/#v080-2020-04-22","text":"Full Changelog Implemented enhancements: Switch to pydantic's BaseSettings for the config file? #152 Remove query constraints for /links-endpoint #244 ( CasperWA ) Add adapters - Base design + 'structures' (+ 'references'... sort of) #241 ( CasperWA ) Add dependabot and last commit date badges #237 ( CasperWA ) Add mongo length operator functionality with length aliases #222 ( ml-evs ) Fixed bugs: Use Path.home() instead of ~ in default config path values #245 Closed issues: Have Dependabot take care of various requirements.txt files as well #249 Remove commented out GH Action job deps_clean-install #247 Local testing fails without default config #239 Release only when pushing to master #229 Do we need server.cfg ? #134 Implement LENGTH in query #86 Merged pull requests: Up to v0.8.0 #251 ( CasperWA ) Remove old commented GH Action job #250 ( CasperWA ) Use Path.home() instead of ~ #246 ( CasperWA ) Fix path in default config #243 ( ml-evs ) Fixes Local Tests #240 ( shyamd ) Revert \"Fix github actions for non-release tags\" #236 ( shyamd ) Enable filtering on relationships with mongo #234 ( ml-evs ) Update filter examples and validate optional cases #227 ( ml-evs ) Switch from config init to BaseSettings #226 ( shyamd )","title":"v0.8.0 (2020-04-22)"},{"location":"CHANGELOG/#v071-2020-03-16","text":"Full Changelog Closed issues: Fix all capitalisation of OPTIMADE #232 Remove validator action from README #230 Merged pull requests: Fix github actions for non-release tags #235 ( shyamd ) Update OPTIMADE capitalisation #233 ( ml-evs ) Update mentions of action in readme #231 ( ml-evs )","title":"v0.7.1 (2020-03-16)"},{"location":"CHANGELOG/#v070-2020-03-13","text":"Full Changelog Implemented enhancements: Validate all non-optional :filter: examples from the spec #213 ( ml-evs ) Fixed bugs: Some mandatory filter examples from spec do not work #217 Add txt-files in optimade.validator.data to MANIFEST #225 ( CasperWA ) Handle arbitrary nested NOT/AND/OR in queries #221 ( ml-evs ) Closed issues: Validator only validates what we have working, not what is required by the spec #182 Merged pull requests: v0.7.0 release #228 ( ml-evs ) Remove GH Action to validate OPTiMaDe instances #224 ( CasperWA )","title":"v0.7.0 (2020-03-13)"},{"location":"CHANGELOG/#v060-2020-03-06","text":"Full Changelog Implemented enhancements: Possibly add CORS middleware #159 Add debug flag to server #130 Make validator GitHub Action #191 ( CasperWA ) Fixed bugs: meta/query/representation value not cutting off version properly #199 URL for providers.json from Materials-Consortia has changed #186 Relationships don't work when \"/\" present in id #181 Redirect middleware not hitting single-entry endpoints #174 Closed issues: /info/ reports wrong url under available_api_versions #215 Query parameters not handled correctly #208 Test for AvailableApiVersion is correct for the wrong reasons #204 Drop '/optimade' from paths in openapi.json #197 heroku is failing #185 List properties and HAS _ operators missing #98 Checklist for OPTiMaDe v0.10.1 #29 Merged pull requests: Removed /optimade/ prefix in info response #216 ( ml-evs ) Self load data #212 ( shyamd ) Update tests for available_api_versions #211 ( CasperWA ) Up to v0.6.0 #210 ( CasperWA ) Update handling of include parameter (and other query parameters) #209 ( CasperWA ) Skip HAS ONLY test if mongomock version \\<= 3.19.0 #206 ( ml-evs ) Test mandatory queries in validator #205 ( ml-evs ) Fix include query parameter #202 ( CasperWA ) Fix meta.query.representation and remove /optimade in base URLs #201 ( CasperWA ) Use mongo for CI #196 ( ml-evs ) (Cosmetic) updates to models #195 ( CasperWA ) Add CORSMiddleware #194 ( CasperWA ) Add \"debug mode\" #190 ( CasperWA ) Use https://provider.optimade.org/providers.json #187 ( CasperWA ) Fix errors parsing IDs that contain slashes #183 ( ml-evs ) Added default mongo implementations for HAS ALL/ANY/ONLY #173 ( ml-evs )","title":"v0.6.0 (2020-03-06)"},{"location":"CHANGELOG/#v050-2020-02-13","text":"Full Changelog Implemented enhancements: Implement a landing page for requests to the base URL #169 Fixed bugs: 'minor' and 'patch' versioned base URL prefixes are wrong #177 Closed issues: Handle include standard JSON API query parameter #94 Merged pull requests: Bump to v0.5.0 #179 ( CasperWA ) Correctly create optional versioned base URLs #178 ( CasperWA ) Make mapper aliases configurable #175 ( ml-evs ) Add landing page at base URL #172 ( ml-evs ) Implement include query parameter #163 ( CasperWA ) Add docker for index meta-database #140 ( CasperWA )","title":"v0.5.0 (2020-02-13)"},{"location":"CHANGELOG/#v040-2020-02-06","text":"Full Changelog Implemented enhancements: switch to pipenv? #37 Reorder tests #162 ( CasperWA ) Fixed bugs: Server app intermingles #161 response_fields not working #154 Closed issues: Change page_page to page_number #165 Add schema-relevant parameters to query parameters #164 Alias optimade/structures/ to optimade/structure #128 Minor changes to specification v0.10.1-develop #115 Update models with new levels of REQUIRED response properties #114 Constraining list/array types in the schema #55 Merged pull requests: Bump to v0.4.0 #168 ( CasperWA ) Describe query parameters in OpenAPI schema #166 ( CasperWA ) Redirect slashed URLs #160 ( CasperWA ) New REQUIRED level properties #153 ( CasperWA )","title":"v0.4.0 (2020-02-06)"},{"location":"CHANGELOG/#v034-2020-02-04","text":"Full Changelog Implemented enhancements: Include develop or not? Default branch? - Create INSTALL.md #136 Fixed bugs: Excepting non-existent exception #129 Closed issues: disable serving API under /v0.10 and /v0.10.0 by default? #122 PyPI release checklist #67 Merged pull requests: Bump to v0.3.4 #158 ( CasperWA ) Fix heroku badge #157 ( ml-evs ) Move installation instructions #156 ( ml-evs ) Update base URLs #155 ( CasperWA ) Extend OpenAPI/spec description #151 ( CasperWA ) Non Local Mongo #150 ( shyamd )","title":"v0.3.4 (2020-02-04)"},{"location":"CHANGELOG/#v033-2020-01-24","text":"Full Changelog Fixed bugs: Lark files not being distributed #141 Merged pull requests: Updated lark-parser to 0.8.1 #149 ( ml-evs ) Split eager and standard tests to avoid unnecessary badge of shame #148 ( ml-evs ) Bump to v0.3.3 #147 ( CasperWA ) Fix root_validator issues with optional fields and made meta optional #145 ( ml-evs ) Handle JSONDecodeError s in validator #144 ( ml-evs )","title":"v0.3.3 (2020-01-24)"},{"location":"CHANGELOG/#v032-2020-01-20","text":"Full Changelog Implemented enhancements: Add base URL to configuration file #135 ( CasperWA ) Fixed bugs: Fix load_from_json #137 ( CasperWA ) Merged pull requests: Make sure relevant package data is included in distributions #142 ( CasperWA ) Add database page limit #139 ( CasperWA )","title":"v0.3.2 (2020-01-20)"},{"location":"CHANGELOG/#v031-2020-01-17","text":"Full Changelog Merged pull requests: Update requirements #138 ( CasperWA )","title":"v0.3.1 (2020-01-17)"},{"location":"CHANGELOG/#v030-2020-01-14","text":"Full Changelog Implemented enhancements: Implement optional implementation in top-level meta response #117 Create \"special\" index meta-database server #100 Implement relationships in server #71 Add missing /references endpoint to server #69 Automatically publish version tags to PyPI via GH Actions #107 ( CasperWA ) Using routers #99 ( CasperWA ) Add relationships functionality #91 ( ml-evs ) Added external API validator based on our pydantic models #74 ( ml-evs ) Fixed bugs: The invoke task update-openapijson is incomplete #123 Django vulnerability #108 Closed issues: info endpoint duplicated? #120 Commented-out validator #111 FastAPI v0.44.0 supports pydantic > 1.0.0 #101 Server is missing /links endpoint #89 Make sure all validators are tested #87 The sortable field must be added to models #84 Package structure #72 Possibly make /info/{endpoint} dynamic #70 setuptools package with server as \"extra\" #62 use examples from specs as resources #57 httptools dependency has build issues on GCC/Linux #54 Lark grammar file for v0.9.8 #50 type is missing in response #43 Enforce use of autoformatter #33 switch license to MIT #28 write a lark JSONTransformer / JSONdecoder #26 server.jsonapi has no additionalProperties=false #23 server.jsonapi has no patternProperties #22 Developer-friendly pre-commit openapi.json visual diff #21 add JSON schema API #12 generate static documentation on github from openapi.json #9 test how to generate a client from the openapi.json #8 come up with suggested toolchain for validating existing optimade API against openapi.json #7 add travis test that checks openapi.json is valid OpenAPI spec #6 add 2 examples of how to include documentation in python classes #5 add one-line command to update openapi.json #4 Merged pull requests: Fixed CI readme badge #133 ( ml-evs ) Add meta.description to BaseRelationshipResource #131 ( CasperWA ) Added homepage attribute to LinksResource #127 ( ml-evs ) Updated structure models and validators #126 ( ml-evs ) Minor change to fallback server.cfg #125 ( ml-evs ) Update local OpenAPI schemes prior to copying #124 ( CasperWA ) Update OpenAPI tags #121 ( CasperWA ) A few fixes related to usage as a library #119 ( ml-evs ) Add implementation to top-level meta response #118 ( CasperWA ) Add heroku deployment scripts #116 ( ltalirz ) Reorganize package #113 ( CasperWA ) Introduce grammar v0.10.1 #112 ( CasperWA ) Update to pydantic v1 #110 ( CasperWA ) Minimum requirement of django v2.2.8 #109 ( CasperWA ) Index meta-database #103 ( CasperWA ) restrict pydantic version #97 ( ltalirz ) Add /links #95 ( CasperWA ) Fix data_returned and data_available #93 ( CasperWA ) Use GitHub Actions for CI #92 ( ml-evs ) Remove inappropriate lint messages #90 ( CasperWA ) Fix dependencies #88 ( CasperWA ) Add sortable field to EntryInfoProperty model #85 ( CasperWA ) Validate illegal fields are not present under attributes and relationships #83 ( CasperWA ) Add references endpoint #78 ( CasperWA ) fix travis build #77 ( ltalirz ) Fix manual verification of elements_ratios #76 ( CasperWA ) add automatic PyPI deployment #75 ( ltalirz ) Remove reference to \"all\" endpoint and rename collections submodule #73 ( ml-evs ) Updates to README and docs for v0.10.0 #68 ( ml-evs ) Adding grammar for v0.10.0 #66 ( fekad ) Schema updates and fixes relative to the v0.10.0 spec #65 ( ml-evs ) Break requirements down on per backend basis #64 ( ml-evs ) 0.10.0 grammer, elasticsearch transformer, setuptools extra #63 ( markus1978 ) Added a Lark to Django Query converter #61 ( tachyontraveler ) Some minor fixes #60 ( ml-evs ) Added codecov to CI #59 ( ml-evs ) Enforce black via pre-commit tool #53 ( dwinston ) Update setup.py and version #51 ( dwinston ) /structure/info endpoint #49 ( fawzi ) add constrained list type #48 ( dwinston ) Refactored into submodules and added test data #47 ( ml-evs ) Update structure endpoint to pre-alpha 0.10 spec #45 ( ltalirz ) Adding Resource Links #44 ( tpurcell90 ) Reblacken #42 ( ml-evs ) Documented json #41 ( tpurcell90 ) fix example output #40 ( dwinston ) use jsonapi better at top level, add error response #36 ( fawzi ) add JSONTransformer #35 ( dwinston ) switch to MIT license #34 ( ltalirz ) Updated entry definitions and renamed Response classes #32 ( ml-evs ) update readme #31 ( ltalirz ) Seperated Links from JSON API into its own file #30 ( tpurcell90 ) simplify schema update #27 ( ltalirz ) add openapi_diff to travis #25 ( ltalirz ) Json api add #24 ( tpurcell90 ) Added JSON diff test #20 ( ml-evs ) info endpoint #19 ( fawzi ) adding run.sh script to start webserver #18 ( fawzi ) error response #17 ( fawzi ) Links can be strings #16 ( fawzi ) response should be either many (list) or one (object), not an union #15 ( fawzi ) reorg models #14 ( dwinston ) Update the OptimadeMetaResponse to development schema #13 ( ml-evs ) add openapi spec validator #10 ( ltalirz ) fix test data download #3 ( ltalirz ) [WIP] Mongoconverter #1 ( wuxiaohua1011 )","title":"v0.3.0 (2020-01-14)"},{"location":"CHANGELOG/#v012-2018-06-14","text":"Full Changelog","title":"v0.1.2 (2018-06-14)"},{"location":"CHANGELOG/#v011-2018-06-13","text":"Full Changelog","title":"v0.1.1 (2018-06-13)"},{"location":"CHANGELOG/#v010-2018-06-05","text":"Full Changelog * This Changelog was automatically generated by github_changelog_generator","title":"v0.1.0 (2018-06-05)"},{"location":"CONTRIBUTING/","text":"Contributing and getting help \u00b6 If you run into any problems using this package, or if you have a question, suggestion or feedback, then please raise an issue on GitHub . The Materials Consortia is very open to contributions across all of its packages. This may be anything from simple feedback and raising new issues to creating new PRs . If you are interested in contributing but don't know where to begin, some issues have been marked with the good first issue label, typically where an isolated enhancement has a concrete suggestion. Simply add a comment under an issue if you are interested in tackling it! Recommendations for setting up a development environment for this package can be found in the Installation instructions . More broadly, if you would like to ask questions or contact the consortium about creating an OPTIMADE implementation for a new database, then please read the relevant \"get involved\" section on the OPTIMADE website .","title":"Contributing and getting help"},{"location":"CONTRIBUTING/#contributing-and-getting-help","text":"If you run into any problems using this package, or if you have a question, suggestion or feedback, then please raise an issue on GitHub . The Materials Consortia is very open to contributions across all of its packages. This may be anything from simple feedback and raising new issues to creating new PRs . If you are interested in contributing but don't know where to begin, some issues have been marked with the good first issue label, typically where an isolated enhancement has a concrete suggestion. Simply add a comment under an issue if you are interested in tackling it! Recommendations for setting up a development environment for this package can be found in the Installation instructions . More broadly, if you would like to ask questions or contact the consortium about creating an OPTIMADE implementation for a new database, then please read the relevant \"get involved\" section on the OPTIMADE website .","title":"Contributing and getting help"},{"location":"INSTALL/","text":"Installation \u00b6 This package can be installed from PyPI, or by cloning the repository, depending on your use-case. To use the optimade Python package as a library, (e.g., using the models for validation, parsing filters with the grammar, or using the command-line tool optimade-validator tool), it is recommended that you install the latest release of the package from PyPI with pip install optimade . If you also want to use the OPTIMADE client to query OPTIMADE APIs, you should install with the additional dependencies: pip install optimade[http_client] . If you want to run, use or modify the reference server implementation, then it is recommended that you clone this repository and install it from your local files (with pip install . , or pip install -e . for an editable installation). As an alternative, you can run the optimade container image (see the Container image section below). The index meta-database \u00b6 This package may be used to setup and run an OPTIMADE index meta-database . Clone this repository and install the package locally with pip install -e .[server] . Info To avoid installing anything locally and instead use the docker image, please see the section Container image below. There is a built-in index meta-database set up to populate a mongomock in-memory database with resources from a static json file containing the child resources you, as a database provider, want to serve under this index meta-database. The location of that json file is controllable using the index_links_path property of the configuration or setting via the environment variable optimade_index_links_path . Running the index meta-database is then as simple as writing ./run.sh index in a terminal from the root of this package. You can find it at the base URL: http://localhost:5001/v1 . Here is an example of how it may look to start your server: :~$ export OPTIMADE_CONFIG_FILE = /home/optimade_server/config.json :~$ ./path/to/optimade/run.sh index Full development installation \u00b6 The dependencies of this package can be found in setup.py with their latest supported versions. By default, a minimal set of requirements are installed to work with the filter language and the pydantic models. After cloning the repository, the install mode server (i.e. pip install .[server] ) is sufficient to run a uvicorn server using the mongomock backend (or MongoDB with pymongo , if present). The suite of development and testing tools are installed with via the install modes dev and testing . There are additionally two backend-specific install modes, elastic and mongo , as well as the all mode, which installs all dependencies. All contributed Python code, must use the black code formatter, and must pass the flake8 linter that is run automatically on all PRs. # Clone this repository to your computer git clone --recursive git@github.com:Materials-Consortia/optimade-python-tools.git cd optimade-python-tools # Ensure a Python>=3.8 (virtual) environment (example below using Anaconda/Miniconda) conda create -n optimade python = 3 .10 conda activate optimade # Install package and dependencies in editable mode (including \"dev\" requirements). pip install -e \".[dev]\" # Optional: Retrieve the list of OPTIMADE providers. (Without this submodule, some of the tests will fail because \"providers.json\" cannot be found.) git submodule update --init # Run the tests with pytest py.test # Install pre-commit environment (e.g., auto-formats code on `git commit`) pre-commit install # Optional: Install MongoDB (and set `database_backend = mongodb`) # Below method installs in conda environment and # - starts server in background # - ensures and uses ~/dbdata directory to store data conda install -c anaconda mongodb mkdir -p ~/dbdata && mongod --dbpath ~/dbdata --syslog --fork # Start a development server (auto-reload on file changes at http://localhost:5000 # You can also execute ./run.sh uvicorn optimade.server.main:app --reload --port 5000 # View auto-generated docs open http://localhost:5000/docs # View Open API Schema open http://localhost:5000/openapi.json When developing, you can run both the server and an index meta-database server at the same time (from two separate terminals). Running the following: ./run.sh index # or uvicorn optimade.server.main_index:app --reload --port 5001 will run the index meta-database server at http://localhost:5001/v1 . Testing specific backends \u00b6 In order to run the test suite for a specific backend, the OPTIMADE_DATABASE_BACKEND environment variable (or config option) can be set to one of 'mongodb' , 'mongomock' or 'elastic' (see ServerConfig.database_backend ). Tests for the two \"real\" database backends, MongoDB and Elasticsearch, require a writable, temporary database to be accessible. The easiest way to deploy these databases and run the tests is with Docker, as shown below. Docker installation instructions will depend on your system; on Linux, the docker commands below may need to be prepended with sudo , depending on your distribution. These commands should be run from a local optimade-python-tools directory. The following command starts a local Elasticsearch v6 instance, runs the test suite, then stops and deletes the containers (required as the tests insert some data): docker run -d --name elasticsearch_test -p 9200 :9200 -p 9300 :9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" elasticsearch:7.17.1 \\ && sleep 10 \\ && OPTIMADE_DATABASE_BACKEND = \"elastic\" py.test ; \\ docker container stop elasticsearch_test ; docker container rm elasticsearch_test The following command starts a local MongoDB instance, runs the test suite, then stops and deletes the containers: docker run -d --name mongo_test -p 27017 :27017 -d mongo:4.4.6 \\ && OPTIMADE_DATABASE_BACKEND = \"mongodb\" py.test ; \\ docker container stop mongo_test ; docker container rm mongo_test Container image \u00b6 Retrieve the image \u00b6 The optimade container image is available from the GitHub Container registry . To pull the latest version using Docker run the following: docker pull ghcr.io/materials-consortia/optimade:latest Note The tag, :latest , can be left out, as the latest version will be pulled by default. If you'd like to pull a specific version, this can be done by replacing latest in the command above with the version of choice, e.g., 0.17.1 . To see which versions are available, please go here . You can also install the develop version. This is an image built from the latest commit on the master branch and should never be used for production. Run a container \u00b6 When starting a container from the image there are a few choices. It is possible to run either a standard OPTIMADE server, or an index meta-database server from this image. Note, these servers can be run in separate containers at the same time. The key is setting the environment variable MAIN . MAIN Result main Standard OPTIMADE server. main_index Index meta-database OPTIMADE server. Using Docker, the following command will run a container from the image: # rm will remove container when it exits. # detach will run the server in the background. # publish will run the server from the host port 8080. # name will give the container a handy name for referencing later. docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main \\ --name my-optimade \\ ghcr.io/materials-consortia/optimade:latest The server should now be available at localhost:8080 .","title":"Installation"},{"location":"INSTALL/#installation","text":"This package can be installed from PyPI, or by cloning the repository, depending on your use-case. To use the optimade Python package as a library, (e.g., using the models for validation, parsing filters with the grammar, or using the command-line tool optimade-validator tool), it is recommended that you install the latest release of the package from PyPI with pip install optimade . If you also want to use the OPTIMADE client to query OPTIMADE APIs, you should install with the additional dependencies: pip install optimade[http_client] . If you want to run, use or modify the reference server implementation, then it is recommended that you clone this repository and install it from your local files (with pip install . , or pip install -e . for an editable installation). As an alternative, you can run the optimade container image (see the Container image section below).","title":"Installation"},{"location":"INSTALL/#the-index-meta-database","text":"This package may be used to setup and run an OPTIMADE index meta-database . Clone this repository and install the package locally with pip install -e .[server] . Info To avoid installing anything locally and instead use the docker image, please see the section Container image below. There is a built-in index meta-database set up to populate a mongomock in-memory database with resources from a static json file containing the child resources you, as a database provider, want to serve under this index meta-database. The location of that json file is controllable using the index_links_path property of the configuration or setting via the environment variable optimade_index_links_path . Running the index meta-database is then as simple as writing ./run.sh index in a terminal from the root of this package. You can find it at the base URL: http://localhost:5001/v1 . Here is an example of how it may look to start your server: :~$ export OPTIMADE_CONFIG_FILE = /home/optimade_server/config.json :~$ ./path/to/optimade/run.sh index","title":"The index meta-database"},{"location":"INSTALL/#full-development-installation","text":"The dependencies of this package can be found in setup.py with their latest supported versions. By default, a minimal set of requirements are installed to work with the filter language and the pydantic models. After cloning the repository, the install mode server (i.e. pip install .[server] ) is sufficient to run a uvicorn server using the mongomock backend (or MongoDB with pymongo , if present). The suite of development and testing tools are installed with via the install modes dev and testing . There are additionally two backend-specific install modes, elastic and mongo , as well as the all mode, which installs all dependencies. All contributed Python code, must use the black code formatter, and must pass the flake8 linter that is run automatically on all PRs. # Clone this repository to your computer git clone --recursive git@github.com:Materials-Consortia/optimade-python-tools.git cd optimade-python-tools # Ensure a Python>=3.8 (virtual) environment (example below using Anaconda/Miniconda) conda create -n optimade python = 3 .10 conda activate optimade # Install package and dependencies in editable mode (including \"dev\" requirements). pip install -e \".[dev]\" # Optional: Retrieve the list of OPTIMADE providers. (Without this submodule, some of the tests will fail because \"providers.json\" cannot be found.) git submodule update --init # Run the tests with pytest py.test # Install pre-commit environment (e.g., auto-formats code on `git commit`) pre-commit install # Optional: Install MongoDB (and set `database_backend = mongodb`) # Below method installs in conda environment and # - starts server in background # - ensures and uses ~/dbdata directory to store data conda install -c anaconda mongodb mkdir -p ~/dbdata && mongod --dbpath ~/dbdata --syslog --fork # Start a development server (auto-reload on file changes at http://localhost:5000 # You can also execute ./run.sh uvicorn optimade.server.main:app --reload --port 5000 # View auto-generated docs open http://localhost:5000/docs # View Open API Schema open http://localhost:5000/openapi.json When developing, you can run both the server and an index meta-database server at the same time (from two separate terminals). Running the following: ./run.sh index # or uvicorn optimade.server.main_index:app --reload --port 5001 will run the index meta-database server at http://localhost:5001/v1 .","title":"Full development installation"},{"location":"INSTALL/#testing-specific-backends","text":"In order to run the test suite for a specific backend, the OPTIMADE_DATABASE_BACKEND environment variable (or config option) can be set to one of 'mongodb' , 'mongomock' or 'elastic' (see ServerConfig.database_backend ). Tests for the two \"real\" database backends, MongoDB and Elasticsearch, require a writable, temporary database to be accessible. The easiest way to deploy these databases and run the tests is with Docker, as shown below. Docker installation instructions will depend on your system; on Linux, the docker commands below may need to be prepended with sudo , depending on your distribution. These commands should be run from a local optimade-python-tools directory. The following command starts a local Elasticsearch v6 instance, runs the test suite, then stops and deletes the containers (required as the tests insert some data): docker run -d --name elasticsearch_test -p 9200 :9200 -p 9300 :9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" elasticsearch:7.17.1 \\ && sleep 10 \\ && OPTIMADE_DATABASE_BACKEND = \"elastic\" py.test ; \\ docker container stop elasticsearch_test ; docker container rm elasticsearch_test The following command starts a local MongoDB instance, runs the test suite, then stops and deletes the containers: docker run -d --name mongo_test -p 27017 :27017 -d mongo:4.4.6 \\ && OPTIMADE_DATABASE_BACKEND = \"mongodb\" py.test ; \\ docker container stop mongo_test ; docker container rm mongo_test","title":"Testing specific backends"},{"location":"INSTALL/#container-image","text":"","title":"Container image"},{"location":"INSTALL/#retrieve-the-image","text":"The optimade container image is available from the GitHub Container registry . To pull the latest version using Docker run the following: docker pull ghcr.io/materials-consortia/optimade:latest Note The tag, :latest , can be left out, as the latest version will be pulled by default. If you'd like to pull a specific version, this can be done by replacing latest in the command above with the version of choice, e.g., 0.17.1 . To see which versions are available, please go here . You can also install the develop version. This is an image built from the latest commit on the master branch and should never be used for production.","title":"Retrieve the image"},{"location":"INSTALL/#run-a-container","text":"When starting a container from the image there are a few choices. It is possible to run either a standard OPTIMADE server, or an index meta-database server from this image. Note, these servers can be run in separate containers at the same time. The key is setting the environment variable MAIN . MAIN Result main Standard OPTIMADE server. main_index Index meta-database OPTIMADE server. Using Docker, the following command will run a container from the image: # rm will remove container when it exits. # detach will run the server in the background. # publish will run the server from the host port 8080. # name will give the container a handy name for referencing later. docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main \\ --name my-optimade \\ ghcr.io/materials-consortia/optimade:latest The server should now be available at localhost:8080 .","title":"Run a container"},{"location":"all_models/","text":"OPTIMADE Data Models \u00b6 This page provides documentation for the optimade.models submodule, where all the OPTIMADE (and JSON:API)-defined data models are located. For example, the three OPTIMADE entry types, structures , references and links , are defined primarily through the corresponding attribute models: StructureResourceAttributes ReferenceResourceAttributes LinksResourceAttributes As well as validating data types when creating instances of these models, this package defines several OPTIMADE-specific validators that ensure consistency between fields (e.g., the value of nsites matches the number of positions provided in cartesian_site_positions ).","title":"OPTIMADE Data Models"},{"location":"all_models/#optimade-data-models","text":"This page provides documentation for the optimade.models submodule, where all the OPTIMADE (and JSON:API)-defined data models are located. For example, the three OPTIMADE entry types, structures , references and links , are defined primarily through the corresponding attribute models: StructureResourceAttributes ReferenceResourceAttributes LinksResourceAttributes As well as validating data types when creating instances of these models, this package defines several OPTIMADE-specific validators that ensure consistency between fields (e.g., the value of nsites matches the number of positions provided in cartesian_site_positions ).","title":"OPTIMADE Data Models"},{"location":"configuration/","text":"Configuration \u00b6 Since the server implementation is built with FastAPI , which uses pydantic , the configuration is based on pydantic's Setting management . This way of handling configuration options supports various different approaches to configure the server. We recommend either or a combination of the following: Create a JSON or YAML configuration file with an implementation's complete configuration in the default location DEFAULT_CONFIG_FILE_PATH or specify its location with the OPTIMADE_CONFIG_FILE environment variable. Set environment variables prefixed with OPTIMADE_ or optimade_ . Create a custom ServerConfig object with the desired settings directly. Load settings from a secret file (see pydantic documentation for more information). The JSON configuration file \u00b6 The main way of configuring the OPTIMADE server is by creating a configuration JSON file. An example of one that works with the example implementation can be found in optimade_config.json : Configuration file for the default OPTIMADE server { \"debug\" : false , \"default_db\" : \"test_server\" , \"base_url\" : \"http://localhost:5000\" , \"implementation\" : { \"name\" : \"Example implementation\" , \"source_url\" : \"https://github.com/Materials-Consortia/optimade-python-tools\" , \"issue_tracker\" : \"https://github.com/Materials-Consortia/optimade-python-tools/issues\" , \"maintainer\" : { \"email\" : \"dev@optimade.org\" } }, \"provider\" : { \"name\" : \"Example provider\" , \"description\" : \"Provider used for examples, not to be assigned to a real database\" , \"prefix\" : \"exmpl\" , \"homepage\" : \"https://example.com\" }, \"index_base_url\" : \"http://localhost:5001\" , \"provider_fields\" : { \"structures\" : [ \"band_gap\" , { \"name\" : \"chemsys\" , \"type\" : \"string\" , \"description\" : \"A string representing the chemical system in an ordered fashion\" } ] }, \"aliases\" : { \"structures\" : { \"id\" : \"task_id\" , \"immutable_id\" : \"_id\" , \"chemical_formula_descriptive\" : \"pretty_formula\" , \"chemical_formula_reduced\" : \"pretty_formula\" , \"chemical_formula_anonymous\" : \"formula_anonymous\" } }, \"length_aliases\" : { \"structures\" : { \"chemsys\" : \"nelements\" } } } Environment variables \u00b6 In order for the implementation to know where your configuration JSON file is located, you can set an environment variable OPTIMADE_CONFIG_FILE with either the value of the absolute path to the configuration file or the relative path to the file from the current working directory of where the server is run. This variable is actually an extension of the configuration option config_file . By default, the server will try to load a JSON file called .optimade.json located in your home folder (or equivalent). Here the generally recognized environment variable prefix becomes evident, namely OPTIMADE_ or optimade_ . Hence, you can set (or overwrite) any configuration option from the server's defaults or a value read from the configuration JSON by setting an environment variable named OPTIMADE_<configuration_option> . Custom configuration options \u00b6 One can extend the current list of configuration options by sub-classing ServerConfig and adding configuration options as attributes with values of Field ( pydantic.field ). Any attribute type will be validated through pydantic as is the case for all of the regular configuration options. This is useful for, e.g., custom database backends, if one wants to utilize the general server configuration setup implemented in optimade to declare specific database information. It can also be useful if one wishes to extend and build upon the general optimade server with new endpoints and routes. Remember to instantiate an instance of the sub-class, which can be imported and used in your application. List of configuration options \u00b6 See config.py for a complete list of configuration options. The following configuration file represents the default values for all configuration options: Default values for all configuration options { \"config_file\" : \"~/.optimade.json\" , \"debug\" : false , \"insert_test_data\" : true , \"mongo_database\" : \"optimade\" , \"mongo_uri\" : \"localhost:27017\" , \"links_collection\" : \"links\" , \"references_collection\" : \"references\" , \"structures_collection\" : \"structures\" , \"page_limit\" : 20 , \"page_limit_max\" : 500 , \"default_db\" : \"test_server\" , \"base_url\" : null , \"implementation\" : { \"name\" : \"OPTIMADE Python Tools\" , \"version\" : \"0.18.0\" , \"source_url\" : \"https://github.com/Materials-Consortia/optimade-python-tools\" , \"maintainer\" : { \"email\" : \"dev@optimade.org\" } }, \"index_base_url\" : null , \"provider\" : { \"name\" : \"Example provider\" , \"description\" : \"Provider used for examples, not to be assigned to a real database\" , \"prefix\" : \"exmpl\" , \"homepage\" : \"https://example.com\" }, \"provider_fields\" : {}, \"aliases\" : {}, \"length_aliases\" : {}, \"index_links_path\" : \"./optimade/server/index_links.json\" , \"log_level\" : \"info\" , \"log_dir\" : \"/var/log/optimade/\" }","title":"Configuration"},{"location":"configuration/#configuration","text":"Since the server implementation is built with FastAPI , which uses pydantic , the configuration is based on pydantic's Setting management . This way of handling configuration options supports various different approaches to configure the server. We recommend either or a combination of the following: Create a JSON or YAML configuration file with an implementation's complete configuration in the default location DEFAULT_CONFIG_FILE_PATH or specify its location with the OPTIMADE_CONFIG_FILE environment variable. Set environment variables prefixed with OPTIMADE_ or optimade_ . Create a custom ServerConfig object with the desired settings directly. Load settings from a secret file (see pydantic documentation for more information).","title":"Configuration"},{"location":"configuration/#the-json-configuration-file","text":"The main way of configuring the OPTIMADE server is by creating a configuration JSON file. An example of one that works with the example implementation can be found in optimade_config.json : Configuration file for the default OPTIMADE server { \"debug\" : false , \"default_db\" : \"test_server\" , \"base_url\" : \"http://localhost:5000\" , \"implementation\" : { \"name\" : \"Example implementation\" , \"source_url\" : \"https://github.com/Materials-Consortia/optimade-python-tools\" , \"issue_tracker\" : \"https://github.com/Materials-Consortia/optimade-python-tools/issues\" , \"maintainer\" : { \"email\" : \"dev@optimade.org\" } }, \"provider\" : { \"name\" : \"Example provider\" , \"description\" : \"Provider used for examples, not to be assigned to a real database\" , \"prefix\" : \"exmpl\" , \"homepage\" : \"https://example.com\" }, \"index_base_url\" : \"http://localhost:5001\" , \"provider_fields\" : { \"structures\" : [ \"band_gap\" , { \"name\" : \"chemsys\" , \"type\" : \"string\" , \"description\" : \"A string representing the chemical system in an ordered fashion\" } ] }, \"aliases\" : { \"structures\" : { \"id\" : \"task_id\" , \"immutable_id\" : \"_id\" , \"chemical_formula_descriptive\" : \"pretty_formula\" , \"chemical_formula_reduced\" : \"pretty_formula\" , \"chemical_formula_anonymous\" : \"formula_anonymous\" } }, \"length_aliases\" : { \"structures\" : { \"chemsys\" : \"nelements\" } } }","title":"The JSON configuration file"},{"location":"configuration/#environment-variables","text":"In order for the implementation to know where your configuration JSON file is located, you can set an environment variable OPTIMADE_CONFIG_FILE with either the value of the absolute path to the configuration file or the relative path to the file from the current working directory of where the server is run. This variable is actually an extension of the configuration option config_file . By default, the server will try to load a JSON file called .optimade.json located in your home folder (or equivalent). Here the generally recognized environment variable prefix becomes evident, namely OPTIMADE_ or optimade_ . Hence, you can set (or overwrite) any configuration option from the server's defaults or a value read from the configuration JSON by setting an environment variable named OPTIMADE_<configuration_option> .","title":"Environment variables"},{"location":"configuration/#custom-configuration-options","text":"One can extend the current list of configuration options by sub-classing ServerConfig and adding configuration options as attributes with values of Field ( pydantic.field ). Any attribute type will be validated through pydantic as is the case for all of the regular configuration options. This is useful for, e.g., custom database backends, if one wants to utilize the general server configuration setup implemented in optimade to declare specific database information. It can also be useful if one wishes to extend and build upon the general optimade server with new endpoints and routes. Remember to instantiate an instance of the sub-class, which can be imported and used in your application.","title":"Custom configuration options"},{"location":"configuration/#list-of-configuration-options","text":"See config.py for a complete list of configuration options. The following configuration file represents the default values for all configuration options: Default values for all configuration options { \"config_file\" : \"~/.optimade.json\" , \"debug\" : false , \"insert_test_data\" : true , \"mongo_database\" : \"optimade\" , \"mongo_uri\" : \"localhost:27017\" , \"links_collection\" : \"links\" , \"references_collection\" : \"references\" , \"structures_collection\" : \"structures\" , \"page_limit\" : 20 , \"page_limit_max\" : 500 , \"default_db\" : \"test_server\" , \"base_url\" : null , \"implementation\" : { \"name\" : \"OPTIMADE Python Tools\" , \"version\" : \"0.18.0\" , \"source_url\" : \"https://github.com/Materials-Consortia/optimade-python-tools\" , \"maintainer\" : { \"email\" : \"dev@optimade.org\" } }, \"index_base_url\" : null , \"provider\" : { \"name\" : \"Example provider\" , \"description\" : \"Provider used for examples, not to be assigned to a real database\" , \"prefix\" : \"exmpl\" , \"homepage\" : \"https://example.com\" }, \"provider_fields\" : {}, \"aliases\" : {}, \"length_aliases\" : {}, \"index_links_path\" : \"./optimade/server/index_links.json\" , \"log_level\" : \"info\" , \"log_dir\" : \"/var/log/optimade/\" }","title":"List of configuration options"},{"location":"api_reference/adapters/base/","text":"base \u00b6 The base for all adapters. An entry resource adapter is a tool to wrap OPTIMADE JSON-deserialized Python dictionaries in the relevant pydantic model for the particular resource. This means data resources in an OPTIMADE REST API response can be converted to valid Python types written specifically for them. One can then use the standard pydantic functionality on the wrapped objects, reasoning about the embedded hierarchical types as well as retrieve default values for properties not supplied by the raw API response resource. Furthermore, the entry resource adapter allows conversion between the entry resource and any implemented equivalent data structure. See Reference and Structure to find out what the entry resources can be converted to for ReferenceResource s and StructureResource s, respectively. EntryAdapter \u00b6 Base class for lazy resource entry adapters. Attributes: Name Type Description ENTRY_RESOURCE EntryResource Entry resource to store entry as. _type_converters Dict [ str , Callable ] Dictionary of valid conversion types for entry. as_<_type_converters> Dict [ str , Callable ] Convert entry to a type listed in _type_converters . Source code in optimade/adapters/base.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 class EntryAdapter : \"\"\" Base class for lazy resource entry adapters. Attributes: ENTRY_RESOURCE (EntryResource): Entry resource to store entry as. _type_converters (Dict[str, Callable]): Dictionary of valid conversion types for entry. as_<_type_converters>: Convert entry to a type listed in `_type_converters`. \"\"\" ENTRY_RESOURCE : EntryResource = EntryResource _type_converters : Dict [ str , Callable ] = {} def __init__ ( self , entry : dict ) -> None : \"\"\" Parameters: entry (dict): A JSON OPTIMADE single resource entry. \"\"\" self . _entry = None self . _converted = {} self . entry = entry # Note that these return also the default values for otherwise non-provided properties. self . _common_converters = { \"json\" : self . entry . json , # Return JSON serialized string, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeljson \"dict\" : self . entry . dict , # Return Python dict, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeldict } @property def entry ( self ) -> EntryResource : \"\"\"Get OPTIMADE entry. Returns: The entry resource. \"\"\" return self . _entry @entry . setter def entry ( self , value : dict ) -> None : \"\"\"Set OPTIMADE entry. If already set, print that this can _only_ be set once. Parameters: value (dict): Raw entry to wrap in the relevant pydantic model represented by `ENTRY_RESOURCE`. \"\"\" if self . _entry is None : self . _entry = self . ENTRY_RESOURCE ( ** value ) else : LOGGER . warning ( \"entry can only be set once and is already set.\" ) def convert ( self , format : str ) -> Any : \"\"\"Convert OPTIMADE entry to desired format. Parameters: format (str): Type or format to which the entry should be converted. Raises: AttributeError: If `format` can not be found in `_type_converters` or `_common_converters`. Returns: The converted entry according to the desired format or type. \"\"\" if ( format not in self . _type_converters and format not in self . _common_converters ): raise AttributeError ( f \"Non-valid entry type to convert to: { format } \\n \" f \"Valid entry types: { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \" ) if self . _converted . get ( format , None ) is None : if format in self . _type_converters : self . _converted [ format ] = self . _type_converters [ format ]( self . entry ) else : self . _converted [ format ] = self . _common_converters [ format ]() return self . _converted [ format ] @staticmethod def _get_model_attributes ( starting_instances : Union [ Tuple [ BaseModel , ... ], List [ BaseModel ]], name : str ) -> Any : \"\"\"Helper method for retrieving the OPTIMADE model's attribute, supporting \".\"-nested attributes\"\"\" for res in starting_instances : nested_attributes = name . split ( \".\" ) for nested_attribute in nested_attributes : if nested_attribute in getattr ( res , \"__fields__\" , {}): res = getattr ( res , nested_attribute ) else : res = None break if res is not None : return res raise AttributeError def __getattr__ ( self , name : str ) -> Any : \"\"\"Get converted entry or attribute from OPTIMADE entry. Support any level of \".\"-nested OPTIMADE `ENTRY_RESOURCE` attributes, e.g., `attributes.species` for [`StuctureResource`][optimade.models.structures.StructureResource]. Note: All nested attributes must individually be subclasses of `pydantic.BaseModel`, i.e., one can not access nested attributes in lists by passing a \".\"-nested `name` to this method, e.g., `attributes.species.name` or `attributes.species[0].name` will not work for variable `name`. Order: - Try to return converted entry if using `as_<_type_converters key>`. - Try to return OPTIMADE `ENTRY_RESOURCE` (nested) attribute. - Try to return OPTIMADE `ENTRY_RESOURCE.attributes` (nested) attribute. - Raise `AttributeError`. Parameters: name (str): Requested attribute. Raises: AttributeError: If the requested attribute is not recognized. See above for the description of the order in which an attribute is tested for validity. \"\"\" # as_<entry_type> if name . startswith ( \"as_\" ): entry_type = \"_\" . join ( name . split ( \"_\" )[ 1 :]) return self . convert ( entry_type ) # Try returning ENTRY_RESOURCE attribute try : res = self . _get_model_attributes (( self . entry , self . entry . attributes ), name ) except AttributeError : pass else : return res # Non-valid attribute entry_resource_name = re . match ( r \"(<class ')([a-zA-Z_]+\\.)*([a-zA-Z_]+)('>)\" , str ( self . ENTRY_RESOURCE ) ) entry_resource_name = ( entry_resource_name . group ( 3 ) if entry_resource_name is not None else \"UNKNOWN RESOURCE\" ) raise AttributeError ( f \"Unknown attribute: { name } \\n \" \"If you want to get a converted entry as <entry_type> use `as_<entry_type>`, \" f \"where `<entry_type>` is one of { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \\n \" f \"Otherwise, you can try to retrieve an OPTIMADE { entry_resource_name } attribute or property.\" ) __getattr__ ( name ) \u00b6 Get converted entry or attribute from OPTIMADE entry. Support any level of \".\"-nested OPTIMADE ENTRY_RESOURCE attributes, e.g., attributes.species for StuctureResource . Note All nested attributes must individually be subclasses of pydantic.BaseModel , i.e., one can not access nested attributes in lists by passing a \".\"-nested name to this method, e.g., attributes.species.name or attributes.species[0].name will not work for variable name . Order: Try to return converted entry if using as_<_type_converters key> . Try to return OPTIMADE ENTRY_RESOURCE (nested) attribute. Try to return OPTIMADE ENTRY_RESOURCE.attributes (nested) attribute. Raise AttributeError . Parameters: Name Type Description Default name str Requested attribute. required Raises: Type Description AttributeError If the requested attribute is not recognized. See above for the description of the order in which an attribute is tested for validity. Source code in optimade/adapters/base.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def __getattr__ ( self , name : str ) -> Any : \"\"\"Get converted entry or attribute from OPTIMADE entry. Support any level of \".\"-nested OPTIMADE `ENTRY_RESOURCE` attributes, e.g., `attributes.species` for [`StuctureResource`][optimade.models.structures.StructureResource]. Note: All nested attributes must individually be subclasses of `pydantic.BaseModel`, i.e., one can not access nested attributes in lists by passing a \".\"-nested `name` to this method, e.g., `attributes.species.name` or `attributes.species[0].name` will not work for variable `name`. Order: - Try to return converted entry if using `as_<_type_converters key>`. - Try to return OPTIMADE `ENTRY_RESOURCE` (nested) attribute. - Try to return OPTIMADE `ENTRY_RESOURCE.attributes` (nested) attribute. - Raise `AttributeError`. Parameters: name (str): Requested attribute. Raises: AttributeError: If the requested attribute is not recognized. See above for the description of the order in which an attribute is tested for validity. \"\"\" # as_<entry_type> if name . startswith ( \"as_\" ): entry_type = \"_\" . join ( name . split ( \"_\" )[ 1 :]) return self . convert ( entry_type ) # Try returning ENTRY_RESOURCE attribute try : res = self . _get_model_attributes (( self . entry , self . entry . attributes ), name ) except AttributeError : pass else : return res # Non-valid attribute entry_resource_name = re . match ( r \"(<class ')([a-zA-Z_]+\\.)*([a-zA-Z_]+)('>)\" , str ( self . ENTRY_RESOURCE ) ) entry_resource_name = ( entry_resource_name . group ( 3 ) if entry_resource_name is not None else \"UNKNOWN RESOURCE\" ) raise AttributeError ( f \"Unknown attribute: { name } \\n \" \"If you want to get a converted entry as <entry_type> use `as_<entry_type>`, \" f \"where `<entry_type>` is one of { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \\n \" f \"Otherwise, you can try to retrieve an OPTIMADE { entry_resource_name } attribute or property.\" ) __init__ ( entry ) \u00b6 Parameters: Name Type Description Default entry dict A JSON OPTIMADE single resource entry. required Source code in optimade/adapters/base.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def __init__ ( self , entry : dict ) -> None : \"\"\" Parameters: entry (dict): A JSON OPTIMADE single resource entry. \"\"\" self . _entry = None self . _converted = {} self . entry = entry # Note that these return also the default values for otherwise non-provided properties. self . _common_converters = { \"json\" : self . entry . json , # Return JSON serialized string, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeljson \"dict\" : self . entry . dict , # Return Python dict, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeldict } convert ( format ) \u00b6 Convert OPTIMADE entry to desired format. Parameters: Name Type Description Default format str Type or format to which the entry should be converted. required Raises: Type Description AttributeError If format can not be found in _type_converters or _common_converters . Returns: Type Description Any The converted entry according to the desired format or type. Source code in optimade/adapters/base.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def convert ( self , format : str ) -> Any : \"\"\"Convert OPTIMADE entry to desired format. Parameters: format (str): Type or format to which the entry should be converted. Raises: AttributeError: If `format` can not be found in `_type_converters` or `_common_converters`. Returns: The converted entry according to the desired format or type. \"\"\" if ( format not in self . _type_converters and format not in self . _common_converters ): raise AttributeError ( f \"Non-valid entry type to convert to: { format } \\n \" f \"Valid entry types: { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \" ) if self . _converted . get ( format , None ) is None : if format in self . _type_converters : self . _converted [ format ] = self . _type_converters [ format ]( self . entry ) else : self . _converted [ format ] = self . _common_converters [ format ]() return self . _converted [ format ] entry () writable property \u00b6 Get OPTIMADE entry. Returns: Type Description EntryResource The entry resource. Source code in optimade/adapters/base.py 61 62 63 64 65 66 67 68 69 @property def entry ( self ) -> EntryResource : \"\"\"Get OPTIMADE entry. Returns: The entry resource. \"\"\" return self . _entry","title":"base"},{"location":"api_reference/adapters/base/#base","text":"The base for all adapters. An entry resource adapter is a tool to wrap OPTIMADE JSON-deserialized Python dictionaries in the relevant pydantic model for the particular resource. This means data resources in an OPTIMADE REST API response can be converted to valid Python types written specifically for them. One can then use the standard pydantic functionality on the wrapped objects, reasoning about the embedded hierarchical types as well as retrieve default values for properties not supplied by the raw API response resource. Furthermore, the entry resource adapter allows conversion between the entry resource and any implemented equivalent data structure. See Reference and Structure to find out what the entry resources can be converted to for ReferenceResource s and StructureResource s, respectively.","title":"base"},{"location":"api_reference/adapters/base/#optimade.adapters.base.EntryAdapter","text":"Base class for lazy resource entry adapters. Attributes: Name Type Description ENTRY_RESOURCE EntryResource Entry resource to store entry as. _type_converters Dict [ str , Callable ] Dictionary of valid conversion types for entry. as_<_type_converters> Dict [ str , Callable ] Convert entry to a type listed in _type_converters . Source code in optimade/adapters/base.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 class EntryAdapter : \"\"\" Base class for lazy resource entry adapters. Attributes: ENTRY_RESOURCE (EntryResource): Entry resource to store entry as. _type_converters (Dict[str, Callable]): Dictionary of valid conversion types for entry. as_<_type_converters>: Convert entry to a type listed in `_type_converters`. \"\"\" ENTRY_RESOURCE : EntryResource = EntryResource _type_converters : Dict [ str , Callable ] = {} def __init__ ( self , entry : dict ) -> None : \"\"\" Parameters: entry (dict): A JSON OPTIMADE single resource entry. \"\"\" self . _entry = None self . _converted = {} self . entry = entry # Note that these return also the default values for otherwise non-provided properties. self . _common_converters = { \"json\" : self . entry . json , # Return JSON serialized string, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeljson \"dict\" : self . entry . dict , # Return Python dict, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeldict } @property def entry ( self ) -> EntryResource : \"\"\"Get OPTIMADE entry. Returns: The entry resource. \"\"\" return self . _entry @entry . setter def entry ( self , value : dict ) -> None : \"\"\"Set OPTIMADE entry. If already set, print that this can _only_ be set once. Parameters: value (dict): Raw entry to wrap in the relevant pydantic model represented by `ENTRY_RESOURCE`. \"\"\" if self . _entry is None : self . _entry = self . ENTRY_RESOURCE ( ** value ) else : LOGGER . warning ( \"entry can only be set once and is already set.\" ) def convert ( self , format : str ) -> Any : \"\"\"Convert OPTIMADE entry to desired format. Parameters: format (str): Type or format to which the entry should be converted. Raises: AttributeError: If `format` can not be found in `_type_converters` or `_common_converters`. Returns: The converted entry according to the desired format or type. \"\"\" if ( format not in self . _type_converters and format not in self . _common_converters ): raise AttributeError ( f \"Non-valid entry type to convert to: { format } \\n \" f \"Valid entry types: { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \" ) if self . _converted . get ( format , None ) is None : if format in self . _type_converters : self . _converted [ format ] = self . _type_converters [ format ]( self . entry ) else : self . _converted [ format ] = self . _common_converters [ format ]() return self . _converted [ format ] @staticmethod def _get_model_attributes ( starting_instances : Union [ Tuple [ BaseModel , ... ], List [ BaseModel ]], name : str ) -> Any : \"\"\"Helper method for retrieving the OPTIMADE model's attribute, supporting \".\"-nested attributes\"\"\" for res in starting_instances : nested_attributes = name . split ( \".\" ) for nested_attribute in nested_attributes : if nested_attribute in getattr ( res , \"__fields__\" , {}): res = getattr ( res , nested_attribute ) else : res = None break if res is not None : return res raise AttributeError def __getattr__ ( self , name : str ) -> Any : \"\"\"Get converted entry or attribute from OPTIMADE entry. Support any level of \".\"-nested OPTIMADE `ENTRY_RESOURCE` attributes, e.g., `attributes.species` for [`StuctureResource`][optimade.models.structures.StructureResource]. Note: All nested attributes must individually be subclasses of `pydantic.BaseModel`, i.e., one can not access nested attributes in lists by passing a \".\"-nested `name` to this method, e.g., `attributes.species.name` or `attributes.species[0].name` will not work for variable `name`. Order: - Try to return converted entry if using `as_<_type_converters key>`. - Try to return OPTIMADE `ENTRY_RESOURCE` (nested) attribute. - Try to return OPTIMADE `ENTRY_RESOURCE.attributes` (nested) attribute. - Raise `AttributeError`. Parameters: name (str): Requested attribute. Raises: AttributeError: If the requested attribute is not recognized. See above for the description of the order in which an attribute is tested for validity. \"\"\" # as_<entry_type> if name . startswith ( \"as_\" ): entry_type = \"_\" . join ( name . split ( \"_\" )[ 1 :]) return self . convert ( entry_type ) # Try returning ENTRY_RESOURCE attribute try : res = self . _get_model_attributes (( self . entry , self . entry . attributes ), name ) except AttributeError : pass else : return res # Non-valid attribute entry_resource_name = re . match ( r \"(<class ')([a-zA-Z_]+\\.)*([a-zA-Z_]+)('>)\" , str ( self . ENTRY_RESOURCE ) ) entry_resource_name = ( entry_resource_name . group ( 3 ) if entry_resource_name is not None else \"UNKNOWN RESOURCE\" ) raise AttributeError ( f \"Unknown attribute: { name } \\n \" \"If you want to get a converted entry as <entry_type> use `as_<entry_type>`, \" f \"where `<entry_type>` is one of { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \\n \" f \"Otherwise, you can try to retrieve an OPTIMADE { entry_resource_name } attribute or property.\" )","title":"EntryAdapter"},{"location":"api_reference/adapters/base/#optimade.adapters.base.EntryAdapter.__getattr__","text":"Get converted entry or attribute from OPTIMADE entry. Support any level of \".\"-nested OPTIMADE ENTRY_RESOURCE attributes, e.g., attributes.species for StuctureResource . Note All nested attributes must individually be subclasses of pydantic.BaseModel , i.e., one can not access nested attributes in lists by passing a \".\"-nested name to this method, e.g., attributes.species.name or attributes.species[0].name will not work for variable name . Order: Try to return converted entry if using as_<_type_converters key> . Try to return OPTIMADE ENTRY_RESOURCE (nested) attribute. Try to return OPTIMADE ENTRY_RESOURCE.attributes (nested) attribute. Raise AttributeError . Parameters: Name Type Description Default name str Requested attribute. required Raises: Type Description AttributeError If the requested attribute is not recognized. See above for the description of the order in which an attribute is tested for validity. Source code in optimade/adapters/base.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def __getattr__ ( self , name : str ) -> Any : \"\"\"Get converted entry or attribute from OPTIMADE entry. Support any level of \".\"-nested OPTIMADE `ENTRY_RESOURCE` attributes, e.g., `attributes.species` for [`StuctureResource`][optimade.models.structures.StructureResource]. Note: All nested attributes must individually be subclasses of `pydantic.BaseModel`, i.e., one can not access nested attributes in lists by passing a \".\"-nested `name` to this method, e.g., `attributes.species.name` or `attributes.species[0].name` will not work for variable `name`. Order: - Try to return converted entry if using `as_<_type_converters key>`. - Try to return OPTIMADE `ENTRY_RESOURCE` (nested) attribute. - Try to return OPTIMADE `ENTRY_RESOURCE.attributes` (nested) attribute. - Raise `AttributeError`. Parameters: name (str): Requested attribute. Raises: AttributeError: If the requested attribute is not recognized. See above for the description of the order in which an attribute is tested for validity. \"\"\" # as_<entry_type> if name . startswith ( \"as_\" ): entry_type = \"_\" . join ( name . split ( \"_\" )[ 1 :]) return self . convert ( entry_type ) # Try returning ENTRY_RESOURCE attribute try : res = self . _get_model_attributes (( self . entry , self . entry . attributes ), name ) except AttributeError : pass else : return res # Non-valid attribute entry_resource_name = re . match ( r \"(<class ')([a-zA-Z_]+\\.)*([a-zA-Z_]+)('>)\" , str ( self . ENTRY_RESOURCE ) ) entry_resource_name = ( entry_resource_name . group ( 3 ) if entry_resource_name is not None else \"UNKNOWN RESOURCE\" ) raise AttributeError ( f \"Unknown attribute: { name } \\n \" \"If you want to get a converted entry as <entry_type> use `as_<entry_type>`, \" f \"where `<entry_type>` is one of { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \\n \" f \"Otherwise, you can try to retrieve an OPTIMADE { entry_resource_name } attribute or property.\" )","title":"__getattr__()"},{"location":"api_reference/adapters/base/#optimade.adapters.base.EntryAdapter.__init__","text":"Parameters: Name Type Description Default entry dict A JSON OPTIMADE single resource entry. required Source code in optimade/adapters/base.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def __init__ ( self , entry : dict ) -> None : \"\"\" Parameters: entry (dict): A JSON OPTIMADE single resource entry. \"\"\" self . _entry = None self . _converted = {} self . entry = entry # Note that these return also the default values for otherwise non-provided properties. self . _common_converters = { \"json\" : self . entry . json , # Return JSON serialized string, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeljson \"dict\" : self . entry . dict , # Return Python dict, see https://pydantic-docs.helpmanual.io/usage/exporting_models/#modeldict }","title":"__init__()"},{"location":"api_reference/adapters/base/#optimade.adapters.base.EntryAdapter.convert","text":"Convert OPTIMADE entry to desired format. Parameters: Name Type Description Default format str Type or format to which the entry should be converted. required Raises: Type Description AttributeError If format can not be found in _type_converters or _common_converters . Returns: Type Description Any The converted entry according to the desired format or type. Source code in optimade/adapters/base.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def convert ( self , format : str ) -> Any : \"\"\"Convert OPTIMADE entry to desired format. Parameters: format (str): Type or format to which the entry should be converted. Raises: AttributeError: If `format` can not be found in `_type_converters` or `_common_converters`. Returns: The converted entry according to the desired format or type. \"\"\" if ( format not in self . _type_converters and format not in self . _common_converters ): raise AttributeError ( f \"Non-valid entry type to convert to: { format } \\n \" f \"Valid entry types: { tuple ( self . _type_converters . keys ()) + tuple ( self . _common_converters . keys ()) } \" ) if self . _converted . get ( format , None ) is None : if format in self . _type_converters : self . _converted [ format ] = self . _type_converters [ format ]( self . entry ) else : self . _converted [ format ] = self . _common_converters [ format ]() return self . _converted [ format ]","title":"convert()"},{"location":"api_reference/adapters/base/#optimade.adapters.base.EntryAdapter.entry","text":"Get OPTIMADE entry. Returns: Type Description EntryResource The entry resource. Source code in optimade/adapters/base.py 61 62 63 64 65 66 67 68 69 @property def entry ( self ) -> EntryResource : \"\"\"Get OPTIMADE entry. Returns: The entry resource. \"\"\" return self . _entry","title":"entry()"},{"location":"api_reference/adapters/exceptions/","text":"exceptions \u00b6 ConversionError \u00b6 Could not convert entry to format Source code in optimade/adapters/exceptions.py 4 5 class ConversionError ( Exception ): \"\"\"Could not convert entry to format\"\"\"","title":"exceptions"},{"location":"api_reference/adapters/exceptions/#exceptions","text":"","title":"exceptions"},{"location":"api_reference/adapters/exceptions/#optimade.adapters.exceptions.ConversionError","text":"Could not convert entry to format Source code in optimade/adapters/exceptions.py 4 5 class ConversionError ( Exception ): \"\"\"Could not convert entry to format\"\"\"","title":"ConversionError"},{"location":"api_reference/adapters/logger/","text":"logger \u00b6 Logger for optimade.adapters","title":"logger"},{"location":"api_reference/adapters/logger/#logger","text":"Logger for optimade.adapters","title":"logger"},{"location":"api_reference/adapters/warnings/","text":"warnings \u00b6 AdapterPackageNotFound \u00b6 The package for an adapter cannot be found. Source code in optimade/adapters/warnings.py 6 7 class AdapterPackageNotFound ( OptimadeWarning ): \"\"\"The package for an adapter cannot be found.\"\"\" ConversionWarning \u00b6 A non-critical error/fallback/choice happened during conversion of an entry to format. Source code in optimade/adapters/warnings.py 10 11 class ConversionWarning ( OptimadeWarning ): \"\"\"A non-critical error/fallback/choice happened during conversion of an entry to format.\"\"\"","title":"warnings"},{"location":"api_reference/adapters/warnings/#warnings","text":"","title":"warnings"},{"location":"api_reference/adapters/warnings/#optimade.adapters.warnings.AdapterPackageNotFound","text":"The package for an adapter cannot be found. Source code in optimade/adapters/warnings.py 6 7 class AdapterPackageNotFound ( OptimadeWarning ): \"\"\"The package for an adapter cannot be found.\"\"\"","title":"AdapterPackageNotFound"},{"location":"api_reference/adapters/warnings/#optimade.adapters.warnings.ConversionWarning","text":"A non-critical error/fallback/choice happened during conversion of an entry to format. Source code in optimade/adapters/warnings.py 10 11 class ConversionWarning ( OptimadeWarning ): \"\"\"A non-critical error/fallback/choice happened during conversion of an entry to format.\"\"\"","title":"ConversionWarning"},{"location":"api_reference/adapters/references/adapter/","text":"adapter \u00b6 Reference \u00b6 Lazy reference resource converter. Go to EntryAdapter to see the full list of methods and properties. Attributes: Name Type Description ENTRY_RESOURCE ReferenceResource This adapter stores entry resources as ReferenceResource s. _type_converters Dict [ str , Callable ] Dictionary of valid conversion types for entry. There are currently no available types. as_<_type_converters> Dict [ str , Callable ] Convert entry to a type listed in _type_converters . Source code in optimade/adapters/references/adapter.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Reference ( EntryAdapter ): \"\"\" Lazy reference resource converter. Go to [`EntryAdapter`][optimade.adapters.base.EntryAdapter] to see the full list of methods and properties. Attributes: ENTRY_RESOURCE (ReferenceResource): This adapter stores entry resources as [`ReferenceResource`][optimade.models.references.ReferenceResource]s. _type_converters (Dict[str, Callable]): Dictionary of valid conversion types for entry. There are currently no available types. as_<_type_converters>: Convert entry to a type listed in `_type_converters`. \"\"\" ENTRY_RESOURCE : ReferenceResource = ReferenceResource","title":"adapter"},{"location":"api_reference/adapters/references/adapter/#adapter","text":"","title":"adapter"},{"location":"api_reference/adapters/references/adapter/#optimade.adapters.references.adapter.Reference","text":"Lazy reference resource converter. Go to EntryAdapter to see the full list of methods and properties. Attributes: Name Type Description ENTRY_RESOURCE ReferenceResource This adapter stores entry resources as ReferenceResource s. _type_converters Dict [ str , Callable ] Dictionary of valid conversion types for entry. There are currently no available types. as_<_type_converters> Dict [ str , Callable ] Convert entry to a type listed in _type_converters . Source code in optimade/adapters/references/adapter.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class Reference ( EntryAdapter ): \"\"\" Lazy reference resource converter. Go to [`EntryAdapter`][optimade.adapters.base.EntryAdapter] to see the full list of methods and properties. Attributes: ENTRY_RESOURCE (ReferenceResource): This adapter stores entry resources as [`ReferenceResource`][optimade.models.references.ReferenceResource]s. _type_converters (Dict[str, Callable]): Dictionary of valid conversion types for entry. There are currently no available types. as_<_type_converters>: Convert entry to a type listed in `_type_converters`. \"\"\" ENTRY_RESOURCE : ReferenceResource = ReferenceResource","title":"Reference"},{"location":"api_reference/adapters/structures/adapter/","text":"adapter \u00b6 Structure \u00b6 Lazy structure resource converter. Go to EntryAdapter to see the full list of methods and properties. Attributes: Name Type Description ENTRY_RESOURCE StructureResource This adapter stores entry resources as StructureResource s. _type_converters Dict [ str , Callable ] Dictionary of valid conversion types for entry. Currently available types: aiida_structuredata ase cif pdb pdbx_mmcif pymatgen jarvis as_<_type_converters> Dict [ str , Callable ] Convert entry to a type listed in _type_converters . Source code in optimade/adapters/structures/adapter.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class Structure ( EntryAdapter ): \"\"\" Lazy structure resource converter. Go to [`EntryAdapter`][optimade.adapters.base.EntryAdapter] to see the full list of methods and properties. Attributes: ENTRY_RESOURCE (StructureResource): This adapter stores entry resources as [`StructureResource`][optimade.models.structures.StructureResource]s. _type_converters (Dict[str, Callable]): Dictionary of valid conversion types for entry. Currently available types: - `aiida_structuredata` - `ase` - `cif` - `pdb` - `pdbx_mmcif` - `pymatgen` - `jarvis` as_<_type_converters>: Convert entry to a type listed in `_type_converters`. \"\"\" ENTRY_RESOURCE : StructureResource = StructureResource _type_converters = { \"aiida_structuredata\" : get_aiida_structure_data , \"ase\" : get_ase_atoms , \"cif\" : get_cif , \"pdb\" : get_pdb , \"pdbx_mmcif\" : get_pdbx_mmcif , \"pymatgen\" : get_pymatgen , \"jarvis\" : get_jarvis_atoms , }","title":"adapter"},{"location":"api_reference/adapters/structures/adapter/#adapter","text":"","title":"adapter"},{"location":"api_reference/adapters/structures/adapter/#optimade.adapters.structures.adapter.Structure","text":"Lazy structure resource converter. Go to EntryAdapter to see the full list of methods and properties. Attributes: Name Type Description ENTRY_RESOURCE StructureResource This adapter stores entry resources as StructureResource s. _type_converters Dict [ str , Callable ] Dictionary of valid conversion types for entry. Currently available types: aiida_structuredata ase cif pdb pdbx_mmcif pymatgen jarvis as_<_type_converters> Dict [ str , Callable ] Convert entry to a type listed in _type_converters . Source code in optimade/adapters/structures/adapter.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class Structure ( EntryAdapter ): \"\"\" Lazy structure resource converter. Go to [`EntryAdapter`][optimade.adapters.base.EntryAdapter] to see the full list of methods and properties. Attributes: ENTRY_RESOURCE (StructureResource): This adapter stores entry resources as [`StructureResource`][optimade.models.structures.StructureResource]s. _type_converters (Dict[str, Callable]): Dictionary of valid conversion types for entry. Currently available types: - `aiida_structuredata` - `ase` - `cif` - `pdb` - `pdbx_mmcif` - `pymatgen` - `jarvis` as_<_type_converters>: Convert entry to a type listed in `_type_converters`. \"\"\" ENTRY_RESOURCE : StructureResource = StructureResource _type_converters = { \"aiida_structuredata\" : get_aiida_structure_data , \"ase\" : get_ase_atoms , \"cif\" : get_cif , \"pdb\" : get_pdb , \"pdbx_mmcif\" : get_pdbx_mmcif , \"pymatgen\" : get_pymatgen , \"jarvis\" : get_jarvis_atoms , }","title":"Structure"},{"location":"api_reference/adapters/structures/aiida/","text":"aiida \u00b6 Convert an OPTIMADE structure, in the format of StructureResource to an AiiDA StructureData Node. For more information on the AiiDA code see their website . This conversion function relies on the aiida-core package. get_aiida_structure_data ( optimade_structure ) \u00b6 Get AiiDA StructureData from OPTIMADE structure. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description StructureData AiiDA StructureData Node. Source code in optimade/adapters/structures/aiida.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def get_aiida_structure_data ( optimade_structure : OptimadeStructure ) -> StructureData : \"\"\"Get AiiDA `StructureData` from OPTIMADE structure. Parameters: optimade_structure: OPTIMADE structure. Returns: AiiDA `StructureData` Node. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"StructureData\" )): warn ( AIIDA_NOT_FOUND , AdapterPackageNotFound ) return None attributes = optimade_structure . attributes # Convert null/None values to float(\"nan\") lattice_vectors , adjust_cell = pad_cell ( attributes . lattice_vectors ) structure = StructureData ( cell = lattice_vectors ) # If species not provided, infer data from species_at_sites species : Optional [ List [ OptimadeStructureSpecies ]] = attributes . species if not species : species = species_from_species_at_sites ( attributes . species_at_sites ) # Add Kinds for kind in species : symbols = [] concentration = [] mass = 0.0 for index , chemical_symbol in enumerate ( kind . chemical_symbols ): # NOTE: The non-chemical element identifier \"X\" is identical to how AiiDA handles this, # so it will be treated the same as any other true chemical identifier. if chemical_symbol == \"vacancy\" : # Skip. This is how AiiDA handles vacancies; # to not include them, while keeping the concentration in a site less than 1. continue else : symbols . append ( chemical_symbol ) concentration . append ( kind . concentration [ index ]) # AiiDA needs a definition for the mass, and for it to be > 0 # mass is OPTIONAL for OPTIMADE structures if kind . mass : mass += kind . concentration [ index ] * kind . mass [ index ] if not mass : warn ( f \"No mass defined for <species(name= { kind . name !r} )>, will default to setting mass to 1.0.\" , ConversionWarning , ) structure . append_kind ( Kind ( symbols = symbols , weights = concentration , mass = mass or 1.0 , name = kind . name ) ) # Add Sites for index in range ( attributes . nsites ): # range() to ensure 1-to-1 between kind and site structure . append_site ( Site ( kind_name = attributes . species_at_sites [ index ], position = attributes . cartesian_site_positions [ index ], ) ) if adjust_cell : structure . _adjust_default_cell ( pbc = [ bool ( dim . value ) for dim in attributes . dimension_types ] ) return structure","title":"aiida"},{"location":"api_reference/adapters/structures/aiida/#aiida","text":"Convert an OPTIMADE structure, in the format of StructureResource to an AiiDA StructureData Node. For more information on the AiiDA code see their website . This conversion function relies on the aiida-core package.","title":"aiida"},{"location":"api_reference/adapters/structures/aiida/#optimade.adapters.structures.aiida.get_aiida_structure_data","text":"Get AiiDA StructureData from OPTIMADE structure. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description StructureData AiiDA StructureData Node. Source code in optimade/adapters/structures/aiida.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def get_aiida_structure_data ( optimade_structure : OptimadeStructure ) -> StructureData : \"\"\"Get AiiDA `StructureData` from OPTIMADE structure. Parameters: optimade_structure: OPTIMADE structure. Returns: AiiDA `StructureData` Node. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"StructureData\" )): warn ( AIIDA_NOT_FOUND , AdapterPackageNotFound ) return None attributes = optimade_structure . attributes # Convert null/None values to float(\"nan\") lattice_vectors , adjust_cell = pad_cell ( attributes . lattice_vectors ) structure = StructureData ( cell = lattice_vectors ) # If species not provided, infer data from species_at_sites species : Optional [ List [ OptimadeStructureSpecies ]] = attributes . species if not species : species = species_from_species_at_sites ( attributes . species_at_sites ) # Add Kinds for kind in species : symbols = [] concentration = [] mass = 0.0 for index , chemical_symbol in enumerate ( kind . chemical_symbols ): # NOTE: The non-chemical element identifier \"X\" is identical to how AiiDA handles this, # so it will be treated the same as any other true chemical identifier. if chemical_symbol == \"vacancy\" : # Skip. This is how AiiDA handles vacancies; # to not include them, while keeping the concentration in a site less than 1. continue else : symbols . append ( chemical_symbol ) concentration . append ( kind . concentration [ index ]) # AiiDA needs a definition for the mass, and for it to be > 0 # mass is OPTIONAL for OPTIMADE structures if kind . mass : mass += kind . concentration [ index ] * kind . mass [ index ] if not mass : warn ( f \"No mass defined for <species(name= { kind . name !r} )>, will default to setting mass to 1.0.\" , ConversionWarning , ) structure . append_kind ( Kind ( symbols = symbols , weights = concentration , mass = mass or 1.0 , name = kind . name ) ) # Add Sites for index in range ( attributes . nsites ): # range() to ensure 1-to-1 between kind and site structure . append_site ( Site ( kind_name = attributes . species_at_sites [ index ], position = attributes . cartesian_site_positions [ index ], ) ) if adjust_cell : structure . _adjust_default_cell ( pbc = [ bool ( dim . value ) for dim in attributes . dimension_types ] ) return structure","title":"get_aiida_structure_data()"},{"location":"api_reference/adapters/structures/ase/","text":"ase \u00b6 Convert an OPTIMADE structure, in the format of StructureResource to an ASE Atoms object. This conversion function relies on the ASE code. For more information on the ASE code see their documentation . get_ase_atoms ( optimade_structure ) \u00b6 Get ASE Atoms from OPTIMADE structure. Caution Cannot handle partial occupancies (this includes vacancies). Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description Atoms ASE Atoms object. Source code in optimade/adapters/structures/ase.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def get_ase_atoms ( optimade_structure : OptimadeStructure ) -> Atoms : \"\"\"Get ASE `Atoms` from OPTIMADE structure. Caution: Cannot handle partial occupancies (this includes vacancies). Parameters: optimade_structure: OPTIMADE structure. Returns: ASE `Atoms` object. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"Atoms\" )): warn ( ASE_NOT_FOUND , AdapterPackageNotFound ) return None attributes = optimade_structure . attributes # Cannot handle partial occupancies if StructureFeatures . DISORDER in attributes . structure_features : raise ConversionError ( \"ASE cannot handle structures with partial occupancies, sorry.\" ) species = attributes . species # If species is missing, infer data from species_at_sites if not species : species = species_from_species_at_sites ( attributes . species_at_sites ) optimade_species : Dict [ str , OptimadeStructureSpecies ] = { _ . name : _ for _ in species } # Since we've made sure there are no species with more than 1 chemical symbol, # asking for index 0 will always work. if \"X\" in [ specie . chemical_symbols [ 0 ] for specie in optimade_species . values ()]: raise ConversionError ( \"ASE cannot handle structures with unknown ('X') chemical symbols, sorry.\" ) atoms = [] for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = attributes . cartesian_site_positions [ site_number ] current_species = optimade_species [ species_name ] # Argument above about chemical symbols also holds here mass = None if current_species . mass : mass = current_species . mass [ 0 ] atoms . append ( Atom ( symbol = species_name , position = site , mass = mass )) return Atoms ( symbols = atoms , cell = attributes . lattice_vectors , pbc = attributes . dimension_types )","title":"ase"},{"location":"api_reference/adapters/structures/ase/#ase","text":"Convert an OPTIMADE structure, in the format of StructureResource to an ASE Atoms object. This conversion function relies on the ASE code. For more information on the ASE code see their documentation .","title":"ase"},{"location":"api_reference/adapters/structures/ase/#optimade.adapters.structures.ase.get_ase_atoms","text":"Get ASE Atoms from OPTIMADE structure. Caution Cannot handle partial occupancies (this includes vacancies). Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description Atoms ASE Atoms object. Source code in optimade/adapters/structures/ase.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def get_ase_atoms ( optimade_structure : OptimadeStructure ) -> Atoms : \"\"\"Get ASE `Atoms` from OPTIMADE structure. Caution: Cannot handle partial occupancies (this includes vacancies). Parameters: optimade_structure: OPTIMADE structure. Returns: ASE `Atoms` object. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"Atoms\" )): warn ( ASE_NOT_FOUND , AdapterPackageNotFound ) return None attributes = optimade_structure . attributes # Cannot handle partial occupancies if StructureFeatures . DISORDER in attributes . structure_features : raise ConversionError ( \"ASE cannot handle structures with partial occupancies, sorry.\" ) species = attributes . species # If species is missing, infer data from species_at_sites if not species : species = species_from_species_at_sites ( attributes . species_at_sites ) optimade_species : Dict [ str , OptimadeStructureSpecies ] = { _ . name : _ for _ in species } # Since we've made sure there are no species with more than 1 chemical symbol, # asking for index 0 will always work. if \"X\" in [ specie . chemical_symbols [ 0 ] for specie in optimade_species . values ()]: raise ConversionError ( \"ASE cannot handle structures with unknown ('X') chemical symbols, sorry.\" ) atoms = [] for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = attributes . cartesian_site_positions [ site_number ] current_species = optimade_species [ species_name ] # Argument above about chemical symbols also holds here mass = None if current_species . mass : mass = current_species . mass [ 0 ] atoms . append ( Atom ( symbol = species_name , position = site , mass = mass )) return Atoms ( symbols = atoms , cell = attributes . lattice_vectors , pbc = attributes . dimension_types )","title":"get_ase_atoms()"},{"location":"api_reference/adapters/structures/cif/","text":"cif \u00b6 Convert an OPTIMADE structure, in the format of StructureResource to a CIF file (Crystallographic Information File). For more information on the CIF file format, see the official documentation . Note This conversion function is inspired heavily by the similar conversion function in the ASE library. See here for the original ASE code. For more information on the ASE library, see their documentation . This conversion function relies on the NumPy library. get_cif ( optimade_structure ) \u00b6 Get CIF file as string from OPTIMADE structure. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description str The CIF file as a single Python str object. Source code in optimade/adapters/structures/cif.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def get_cif ( # pylint: disable=too-many-locals,too-many-branches optimade_structure : OptimadeStructure , ) -> str : \"\"\"Get CIF file as string from OPTIMADE structure. Parameters: optimade_structure: OPTIMADE structure. Returns: The CIF file as a single Python `str` object. \"\"\" # NumPy is needed for calculations if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cif = \"\"\"# # Created from an OPTIMADE structure. # # See https://www.optimade.org and/or # https://github.com/Materials-Consortia/OPTIMADE for more information. # \"\"\" cif += f \"data_ { optimade_structure . id } \\n\\n \" attributes = optimade_structure . attributes # Do this only if there's three non-zero lattice vectors # NOTE: This also negates handling of lattice_vectors with null/None values if all ( attributes . dimension_types ): a_vector , b_vector , c_vector , alpha , beta , gamma = cell_to_cellpar ( attributes . lattice_vectors ) cif += ( f \"_cell_length_a { a_vector : g } \\n \" f \"_cell_length_b { b_vector : g } \\n \" f \"_cell_length_c { c_vector : g } \\n \" f \"_cell_angle_alpha { alpha : g } \\n \" f \"_cell_angle_beta { beta : g } \\n \" f \"_cell_angle_gamma { gamma : g } \\n\\n \" ) cif += ( \"_symmetry_space_group_name_H-M 'P 1' \\n \" \"_symmetry_int_tables_number 1 \\n\\n \" \"loop_ \\n \" \" _symmetry_equiv_pos_as_xyz \\n \" \" 'x, y, z' \\n\\n \" ) # Since some structure viewers are having issues with cartesian coordinates, # we calculate the fractional coordinates if this is a 3D structure and we have all the necessary information. if not hasattr ( attributes , \"fractional_site_positions\" ): attributes . fractional_site_positions = fractional_coordinates ( cell = attributes . lattice_vectors , cartesian_positions = attributes . cartesian_site_positions , ) # NOTE: This is otherwise a bit ahead of its time, since this OPTIMADE property is part of an open PR. # See https://github.com/Materials-Consortia/OPTIMADE/pull/206 coord_type = ( \"fract\" if hasattr ( attributes , \"fractional_site_positions\" ) else \"Cartn\" ) cif += ( \"loop_ \\n \" \" _atom_site_type_symbol \\n \" # species.chemical_symbols \" _atom_site_label \\n \" # species.name + unique int \" _atom_site_occupancy \\n \" # species.concentration f \" _atom_site_ { coord_type } _x \\n \" # cartesian_site_positions f \" _atom_site_ { coord_type } _y \\n \" # cartesian_site_positions f \" _atom_site_ { coord_type } _z \\n \" # cartesian_site_positions \" _atom_site_thermal_displace_type \\n \" # Set to 'Biso' \" _atom_site_B_iso_or_equiv \\n \" # Set to 1.0:f ) if coord_type == \"fract\" : sites = attributes . fractional_site_positions else : sites = attributes . cartesian_site_positions species : Dict [ str , OptimadeStructureSpecies ] = { species . name : species for species in attributes . species } symbol_occurences = {} for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = sites [ site_number ] current_species = species [ species_name ] for index , symbol in enumerate ( current_species . chemical_symbols ): if symbol == \"vacancy\" : continue if symbol in symbol_occurences : symbol_occurences [ symbol ] += 1 else : symbol_occurences [ symbol ] = 1 label = f \" { symbol }{ symbol_occurences [ symbol ] } \" cif += ( f \" { symbol } { label } { current_species . concentration [ index ] : 6.4f } { site [ 0 ] : 8.5f } \" f \" { site [ 1 ] : 8.5f } { site [ 2 ] : 8.5f } { 'Biso' : 4 } { '1.000' : 6 } \\n \" ) return cif","title":"cif"},{"location":"api_reference/adapters/structures/cif/#cif","text":"Convert an OPTIMADE structure, in the format of StructureResource to a CIF file (Crystallographic Information File). For more information on the CIF file format, see the official documentation . Note This conversion function is inspired heavily by the similar conversion function in the ASE library. See here for the original ASE code. For more information on the ASE library, see their documentation . This conversion function relies on the NumPy library.","title":"cif"},{"location":"api_reference/adapters/structures/cif/#optimade.adapters.structures.cif.get_cif","text":"Get CIF file as string from OPTIMADE structure. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description str The CIF file as a single Python str object. Source code in optimade/adapters/structures/cif.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 def get_cif ( # pylint: disable=too-many-locals,too-many-branches optimade_structure : OptimadeStructure , ) -> str : \"\"\"Get CIF file as string from OPTIMADE structure. Parameters: optimade_structure: OPTIMADE structure. Returns: The CIF file as a single Python `str` object. \"\"\" # NumPy is needed for calculations if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cif = \"\"\"# # Created from an OPTIMADE structure. # # See https://www.optimade.org and/or # https://github.com/Materials-Consortia/OPTIMADE for more information. # \"\"\" cif += f \"data_ { optimade_structure . id } \\n\\n \" attributes = optimade_structure . attributes # Do this only if there's three non-zero lattice vectors # NOTE: This also negates handling of lattice_vectors with null/None values if all ( attributes . dimension_types ): a_vector , b_vector , c_vector , alpha , beta , gamma = cell_to_cellpar ( attributes . lattice_vectors ) cif += ( f \"_cell_length_a { a_vector : g } \\n \" f \"_cell_length_b { b_vector : g } \\n \" f \"_cell_length_c { c_vector : g } \\n \" f \"_cell_angle_alpha { alpha : g } \\n \" f \"_cell_angle_beta { beta : g } \\n \" f \"_cell_angle_gamma { gamma : g } \\n\\n \" ) cif += ( \"_symmetry_space_group_name_H-M 'P 1' \\n \" \"_symmetry_int_tables_number 1 \\n\\n \" \"loop_ \\n \" \" _symmetry_equiv_pos_as_xyz \\n \" \" 'x, y, z' \\n\\n \" ) # Since some structure viewers are having issues with cartesian coordinates, # we calculate the fractional coordinates if this is a 3D structure and we have all the necessary information. if not hasattr ( attributes , \"fractional_site_positions\" ): attributes . fractional_site_positions = fractional_coordinates ( cell = attributes . lattice_vectors , cartesian_positions = attributes . cartesian_site_positions , ) # NOTE: This is otherwise a bit ahead of its time, since this OPTIMADE property is part of an open PR. # See https://github.com/Materials-Consortia/OPTIMADE/pull/206 coord_type = ( \"fract\" if hasattr ( attributes , \"fractional_site_positions\" ) else \"Cartn\" ) cif += ( \"loop_ \\n \" \" _atom_site_type_symbol \\n \" # species.chemical_symbols \" _atom_site_label \\n \" # species.name + unique int \" _atom_site_occupancy \\n \" # species.concentration f \" _atom_site_ { coord_type } _x \\n \" # cartesian_site_positions f \" _atom_site_ { coord_type } _y \\n \" # cartesian_site_positions f \" _atom_site_ { coord_type } _z \\n \" # cartesian_site_positions \" _atom_site_thermal_displace_type \\n \" # Set to 'Biso' \" _atom_site_B_iso_or_equiv \\n \" # Set to 1.0:f ) if coord_type == \"fract\" : sites = attributes . fractional_site_positions else : sites = attributes . cartesian_site_positions species : Dict [ str , OptimadeStructureSpecies ] = { species . name : species for species in attributes . species } symbol_occurences = {} for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = sites [ site_number ] current_species = species [ species_name ] for index , symbol in enumerate ( current_species . chemical_symbols ): if symbol == \"vacancy\" : continue if symbol in symbol_occurences : symbol_occurences [ symbol ] += 1 else : symbol_occurences [ symbol ] = 1 label = f \" { symbol }{ symbol_occurences [ symbol ] } \" cif += ( f \" { symbol } { label } { current_species . concentration [ index ] : 6.4f } { site [ 0 ] : 8.5f } \" f \" { site [ 1 ] : 8.5f } { site [ 2 ] : 8.5f } { 'Biso' : 4 } { '1.000' : 6 } \\n \" ) return cif","title":"get_cif()"},{"location":"api_reference/adapters/structures/jarvis/","text":"jarvis \u00b6 Convert an OPTIMADE structure, in the format of StructureResource to a JARVIS Atoms object. For more information on the NIST-JARVIS repository, see their website . This conversion function relies on the jarvis-tools package. Contributing author This conversion function was contributed by Kamal Choudhary ( @knc6 ). get_jarvis_atoms ( optimade_structure ) \u00b6 Get jarvis Atoms from OPTIMADE structure. Caution Cannot handle partial occupancies. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description Atoms A jarvis Atoms object. Source code in optimade/adapters/structures/jarvis.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_jarvis_atoms ( optimade_structure : OptimadeStructure ) -> Atoms : \"\"\"Get jarvis `Atoms` from OPTIMADE structure. Caution: Cannot handle partial occupancies. Parameters: optimade_structure: OPTIMADE structure. Returns: A jarvis `Atoms` object. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"Atoms\" )): warn ( JARVIS_NOT_FOUND , AdapterPackageNotFound ) return None attributes = optimade_structure . attributes # Cannot handle partial occupancies if StructureFeatures . DISORDER in attributes . structure_features : raise ConversionError ( \"jarvis-tools cannot handle structures with partial occupancies.\" ) return Atoms ( lattice_mat = attributes . lattice_vectors , elements = [ specie . name for specie in attributes . species ], coords = attributes . cartesian_site_positions , cartesian = True , )","title":"jarvis"},{"location":"api_reference/adapters/structures/jarvis/#jarvis","text":"Convert an OPTIMADE structure, in the format of StructureResource to a JARVIS Atoms object. For more information on the NIST-JARVIS repository, see their website . This conversion function relies on the jarvis-tools package. Contributing author This conversion function was contributed by Kamal Choudhary ( @knc6 ).","title":"jarvis"},{"location":"api_reference/adapters/structures/jarvis/#optimade.adapters.structures.jarvis.get_jarvis_atoms","text":"Get jarvis Atoms from OPTIMADE structure. Caution Cannot handle partial occupancies. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description Atoms A jarvis Atoms object. Source code in optimade/adapters/structures/jarvis.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_jarvis_atoms ( optimade_structure : OptimadeStructure ) -> Atoms : \"\"\"Get jarvis `Atoms` from OPTIMADE structure. Caution: Cannot handle partial occupancies. Parameters: optimade_structure: OPTIMADE structure. Returns: A jarvis `Atoms` object. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"Atoms\" )): warn ( JARVIS_NOT_FOUND , AdapterPackageNotFound ) return None attributes = optimade_structure . attributes # Cannot handle partial occupancies if StructureFeatures . DISORDER in attributes . structure_features : raise ConversionError ( \"jarvis-tools cannot handle structures with partial occupancies.\" ) return Atoms ( lattice_mat = attributes . lattice_vectors , elements = [ specie . name for specie in attributes . species ], coords = attributes . cartesian_site_positions , cartesian = True , )","title":"get_jarvis_atoms()"},{"location":"api_reference/adapters/structures/proteindatabank/","text":"proteindatabank \u00b6 Convert an OPTIMADE structure, in the format of StructureResource to a PDB file or PDBx/mmCIF file (Protein Data Bank). For more information on the file formats, see this FAQ page from the wwPDB website. Note These conversion functions are inspired heavily by the similar conversion functions in the ASE library. See here (PDB) and here (PDBx/mmCIF) for the original ASE code. For more information on the ASE library, see their documentation . These conversion functions both rely on the NumPy library. Warning Currently, the PDBx/mmCIF conversion function is not parsing as a complete PDBx/mmCIF file. get_pdb ( optimade_structure ) \u00b6 Write Protein Data Bank (PDB) structure in the old PDB format from OPTIMADE structure. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description str A PDB file as a single Python str object. Source code in optimade/adapters/structures/proteindatabank.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def get_pdb ( # pylint: disable=too-many-locals optimade_structure : OptimadeStructure , ) -> str : \"\"\"Write Protein Data Bank (PDB) structure in the old PDB format from OPTIMADE structure. Parameters: optimade_structure: OPTIMADE structure. Returns: A PDB file as a single Python `str` object. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None pdb = \"\" attributes = optimade_structure . attributes rotation = None if all ( attributes . dimension_types ): currentcell = np . asarray ( attributes . lattice_vectors ) cellpar = cell_to_cellpar ( currentcell ) exportedcell = cellpar_to_cell ( cellpar ) rotation = np . linalg . solve ( currentcell , exportedcell ) # Setting Z-value = 1 and using P1 since we have all atoms defined explicitly Z = 1 spacegroup = \"P 1\" pdb += ( f \"CRYST1 { cellpar [ 0 ] : 9.3f }{ cellpar [ 1 ] : 9.3f }{ cellpar [ 2 ] : 8.3f } \" f \" { cellpar [ 3 ] : 7.2f }{ cellpar [ 4 ] : 7.2f }{ cellpar [ 5 ] : 7.2f } { spacegroup : 11s }{ Z : 4d } \\n \" ) for i , vector in enumerate ( scaled_cell ( currentcell )): pdb += f \"SCALE { i + 1 } { vector [ 0 ] : 10.6f }{ vector [ 1 ] : 10.6f }{ vector [ 2 ] : 10.6f } { 0 : 10.5f } \\n \" # There is a limit of 5 digit numbers in this field. pdb_maxnum = 100000 bfactor = 1.0 pdb += \"MODEL 1 \\n \" species : Dict [ str , OptimadeStructureSpecies ] = { species . name : species for species in attributes . species } sites = np . asarray ( attributes . cartesian_site_positions ) if rotation is not None : sites = sites . dot ( rotation ) for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = sites [ site_number ] current_species = species [ species_name ] for index , symbol in enumerate ( current_species . chemical_symbols ): if symbol == \"vacancy\" : continue label = species_name if len ( current_species . chemical_symbols ) > 1 : if ( \"vacancy\" in current_species . chemical_symbols and len ( current_species . chemical_symbols ) == 2 ): pass else : label = f \" { symbol }{ index + 1 } \" pdb += ( f \"ATOM { site_number % pdb_maxnum : 5d } { label : 4 } MOL 1 \" f \" { site [ 0 ] : 8.3f }{ site [ 1 ] : 8.3f }{ site [ 2 ] : 8.3f } \" f \" { current_species . concentration [ index ] : 6.2f } \" f \" { bfactor : 6.2f } { symbol . upper () : 2 } \\n \" ) pdb += \"ENDMDL \\n \" return pdb get_pdbx_mmcif ( optimade_structure ) \u00b6 Write Protein Data Bank (PDB) structure in the PDBx/mmCIF format from OPTIMADE structure. Warning The result of this function can currently not be parsed as a complete PDBx/mmCIF file. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Return A modern PDBx/mmCIF file as a single Python str object. Source code in optimade/adapters/structures/proteindatabank.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def get_pdbx_mmcif ( # pylint: disable=too-many-locals optimade_structure : OptimadeStructure , ) -> str : \"\"\"Write Protein Data Bank (PDB) structure in the PDBx/mmCIF format from OPTIMADE structure. Warning: The result of this function can currently not be parsed as a complete PDBx/mmCIF file. Parameters: optimade_structure: OPTIMADE structure. Return: A modern PDBx/mmCIF file as a single Python `str` object. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cif = \"\"\"# # Created from an OPTIMADE structure. # # See https://www.optimade.org and/or # https://github.com/Materials-Consortia/OPTIMADE for more information. # # CIF 2.0 format, specifically mmCIF (PDBx). # See http://mmcif.wwpdb.org for more information. # \"\"\" entry_id = f \" { optimade_structure . type }{ optimade_structure . id } \" cif += f \"data_ { entry_id } \\n _entry.id { entry_id } \\n # \\n \" attributes = optimade_structure . attributes # Do this only if there's three non-zero lattice vectors if all ( attributes . dimension_types ): a_vector , b_vector , c_vector , alpha , beta , gamma = cell_to_cellpar ( attributes . lattice_vectors ) cif += ( f \"_cell.entry_id { entry_id } \\n \" f \"_cell.length_a { a_vector : g } \\n \" f \"_cell.length_b { b_vector : g } \\n \" f \"_cell.length_c { c_vector : g } \\n \" f \"_cell.angle_alpha { alpha : g } \\n \" f \"_cell.angle_beta { beta : g } \\n \" f \"_cell.angle_gamma { gamma : g } \\n \" \"_cell.Z_PDB 1 \\n # \\n \" ) cif += ( f \"_symmetry.entry_id { entry_id } \\n \" \"_symmetry.space_group_name_H-M 'P 1' \\n \" \"_symmetry.Int_Tables_number 1 \\n # \\n \" ) # Since some structure viewers are having issues with cartesian coordinates, # we calculate the fractional coordinates if this is a 3D structure and we have all the necessary information. if not hasattr ( attributes , \"fractional_site_positions\" ): attributes . fractional_site_positions = fractional_coordinates ( cell = attributes . lattice_vectors , cartesian_positions = attributes . cartesian_site_positions , ) # NOTE: The following lines are perhaps needed to create a \"valid\" PDBx/mmCIF file. # However, at the same time, the information here is \"default\" and will for all structures \"at this moment in time\" # be the same. I.e., no information is gained by adding this now. # If it is found that they indeed are needed to create a \"valid\" PDBx/mmCIF file, they should be included in the output. # cif += ( # \"loop_\\n\" # \"_struct_asym.id\\n\" # \"_struct_asym.entity_id\\n\" # \"A 1\\n#\\n\" # At this point, not using this feature. # ) # cif += ( # \"loop_\\n\" # \"_chem_comp.id\\n\" # \"X\\n#\\n\" # At this point, not using this feature. # ) # cif += ( # \"loop_\\n\" # \"_entity.id\\n\" # \"1\\n#\\n\" # At this point, not using this feature. # ) # NOTE: This is otherwise a bit ahead of its time, since this OPTIMADE property is part of an open PR. # See https://github.com/Materials-Consortia/OPTIMADE/pull/206 coord_type = ( \"fract\" if hasattr ( attributes , \"fractional_site_positions\" ) else \"Cartn\" ) cif += ( \"loop_ \\n \" \"_atom_site.group_PDB \\n \" # Always \"ATOM\" \"_atom_site.id \\n \" # number (1-counting) \"_atom_site.type_symbol \\n \" # species.chemical_symbols \"_atom_site.label_atom_id \\n \" # species.checmical_symbols symbol + number # For these next keys, see the comment above. # \"_atom_site.label_asym_id\\n\" # Will be set to \"A\" _struct_asym.id above # \"_atom_site.label_comp_id\\n\" # Will be set to \"X\" _chem_comp.id above # \"_atom_site.label_entity_id\\n\" # Will be set to \"1\" _entity.id above # \"_atom_site.label_seq_id\\n\" \"_atom_site.occupancy \\n \" # species.concentration f \"_atom_site. { coord_type } _x \\n \" # cartesian_site_positions f \"_atom_site. { coord_type } _y \\n \" # cartesian_site_positions f \"_atom_site. { coord_type } _z \\n \" # cartesian_site_positions \"_atom_site.thermal_displace_type \\n \" # Set to 'Biso' \"_atom_site.B_iso_or_equiv \\n \" # Set to 1.0:f ) if coord_type == \"fract\" : sites = attributes . fractional_site_positions else : sites = attributes . cartesian_site_positions species : Dict [ str , OptimadeStructureSpecies ] = { species . name : species for species in attributes . species } for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = sites [ site_number ] current_species = species [ species_name ] for index , symbol in enumerate ( current_species . chemical_symbols ): if symbol == \"vacancy\" : continue label = f \" { species_name . upper () }{ site_number + 1 } \" if len ( current_species . chemical_symbols ) > 1 : if ( \"vacancy\" in current_species . chemical_symbols and len ( current_species . chemical_symbols ) == 2 ): pass else : label = f \" { symbol . upper () }{ index + 1 } \" cif += ( f \"ATOM { site_number + 1 : 5d } { symbol } { label : 8 } \" f \" { current_species . concentration [ index ] : 6.4f } { site [ 0 ] : 8.5f } \" f \" { site [ 1 ] : 8.5f } { site [ 2 ] : 8.5f } { 'Biso' : 4 } { '1.000' : 6 } \\n \" ) return cif","title":"proteindatabank"},{"location":"api_reference/adapters/structures/proteindatabank/#proteindatabank","text":"Convert an OPTIMADE structure, in the format of StructureResource to a PDB file or PDBx/mmCIF file (Protein Data Bank). For more information on the file formats, see this FAQ page from the wwPDB website. Note These conversion functions are inspired heavily by the similar conversion functions in the ASE library. See here (PDB) and here (PDBx/mmCIF) for the original ASE code. For more information on the ASE library, see their documentation . These conversion functions both rely on the NumPy library. Warning Currently, the PDBx/mmCIF conversion function is not parsing as a complete PDBx/mmCIF file.","title":"proteindatabank"},{"location":"api_reference/adapters/structures/proteindatabank/#optimade.adapters.structures.proteindatabank.get_pdb","text":"Write Protein Data Bank (PDB) structure in the old PDB format from OPTIMADE structure. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description str A PDB file as a single Python str object. Source code in optimade/adapters/structures/proteindatabank.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def get_pdb ( # pylint: disable=too-many-locals optimade_structure : OptimadeStructure , ) -> str : \"\"\"Write Protein Data Bank (PDB) structure in the old PDB format from OPTIMADE structure. Parameters: optimade_structure: OPTIMADE structure. Returns: A PDB file as a single Python `str` object. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None pdb = \"\" attributes = optimade_structure . attributes rotation = None if all ( attributes . dimension_types ): currentcell = np . asarray ( attributes . lattice_vectors ) cellpar = cell_to_cellpar ( currentcell ) exportedcell = cellpar_to_cell ( cellpar ) rotation = np . linalg . solve ( currentcell , exportedcell ) # Setting Z-value = 1 and using P1 since we have all atoms defined explicitly Z = 1 spacegroup = \"P 1\" pdb += ( f \"CRYST1 { cellpar [ 0 ] : 9.3f }{ cellpar [ 1 ] : 9.3f }{ cellpar [ 2 ] : 8.3f } \" f \" { cellpar [ 3 ] : 7.2f }{ cellpar [ 4 ] : 7.2f }{ cellpar [ 5 ] : 7.2f } { spacegroup : 11s }{ Z : 4d } \\n \" ) for i , vector in enumerate ( scaled_cell ( currentcell )): pdb += f \"SCALE { i + 1 } { vector [ 0 ] : 10.6f }{ vector [ 1 ] : 10.6f }{ vector [ 2 ] : 10.6f } { 0 : 10.5f } \\n \" # There is a limit of 5 digit numbers in this field. pdb_maxnum = 100000 bfactor = 1.0 pdb += \"MODEL 1 \\n \" species : Dict [ str , OptimadeStructureSpecies ] = { species . name : species for species in attributes . species } sites = np . asarray ( attributes . cartesian_site_positions ) if rotation is not None : sites = sites . dot ( rotation ) for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = sites [ site_number ] current_species = species [ species_name ] for index , symbol in enumerate ( current_species . chemical_symbols ): if symbol == \"vacancy\" : continue label = species_name if len ( current_species . chemical_symbols ) > 1 : if ( \"vacancy\" in current_species . chemical_symbols and len ( current_species . chemical_symbols ) == 2 ): pass else : label = f \" { symbol }{ index + 1 } \" pdb += ( f \"ATOM { site_number % pdb_maxnum : 5d } { label : 4 } MOL 1 \" f \" { site [ 0 ] : 8.3f }{ site [ 1 ] : 8.3f }{ site [ 2 ] : 8.3f } \" f \" { current_species . concentration [ index ] : 6.2f } \" f \" { bfactor : 6.2f } { symbol . upper () : 2 } \\n \" ) pdb += \"ENDMDL \\n \" return pdb","title":"get_pdb()"},{"location":"api_reference/adapters/structures/proteindatabank/#optimade.adapters.structures.proteindatabank.get_pdbx_mmcif","text":"Write Protein Data Bank (PDB) structure in the PDBx/mmCIF format from OPTIMADE structure. Warning The result of this function can currently not be parsed as a complete PDBx/mmCIF file. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Return A modern PDBx/mmCIF file as a single Python str object. Source code in optimade/adapters/structures/proteindatabank.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 def get_pdbx_mmcif ( # pylint: disable=too-many-locals optimade_structure : OptimadeStructure , ) -> str : \"\"\"Write Protein Data Bank (PDB) structure in the PDBx/mmCIF format from OPTIMADE structure. Warning: The result of this function can currently not be parsed as a complete PDBx/mmCIF file. Parameters: optimade_structure: OPTIMADE structure. Return: A modern PDBx/mmCIF file as a single Python `str` object. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cif = \"\"\"# # Created from an OPTIMADE structure. # # See https://www.optimade.org and/or # https://github.com/Materials-Consortia/OPTIMADE for more information. # # CIF 2.0 format, specifically mmCIF (PDBx). # See http://mmcif.wwpdb.org for more information. # \"\"\" entry_id = f \" { optimade_structure . type }{ optimade_structure . id } \" cif += f \"data_ { entry_id } \\n _entry.id { entry_id } \\n # \\n \" attributes = optimade_structure . attributes # Do this only if there's three non-zero lattice vectors if all ( attributes . dimension_types ): a_vector , b_vector , c_vector , alpha , beta , gamma = cell_to_cellpar ( attributes . lattice_vectors ) cif += ( f \"_cell.entry_id { entry_id } \\n \" f \"_cell.length_a { a_vector : g } \\n \" f \"_cell.length_b { b_vector : g } \\n \" f \"_cell.length_c { c_vector : g } \\n \" f \"_cell.angle_alpha { alpha : g } \\n \" f \"_cell.angle_beta { beta : g } \\n \" f \"_cell.angle_gamma { gamma : g } \\n \" \"_cell.Z_PDB 1 \\n # \\n \" ) cif += ( f \"_symmetry.entry_id { entry_id } \\n \" \"_symmetry.space_group_name_H-M 'P 1' \\n \" \"_symmetry.Int_Tables_number 1 \\n # \\n \" ) # Since some structure viewers are having issues with cartesian coordinates, # we calculate the fractional coordinates if this is a 3D structure and we have all the necessary information. if not hasattr ( attributes , \"fractional_site_positions\" ): attributes . fractional_site_positions = fractional_coordinates ( cell = attributes . lattice_vectors , cartesian_positions = attributes . cartesian_site_positions , ) # NOTE: The following lines are perhaps needed to create a \"valid\" PDBx/mmCIF file. # However, at the same time, the information here is \"default\" and will for all structures \"at this moment in time\" # be the same. I.e., no information is gained by adding this now. # If it is found that they indeed are needed to create a \"valid\" PDBx/mmCIF file, they should be included in the output. # cif += ( # \"loop_\\n\" # \"_struct_asym.id\\n\" # \"_struct_asym.entity_id\\n\" # \"A 1\\n#\\n\" # At this point, not using this feature. # ) # cif += ( # \"loop_\\n\" # \"_chem_comp.id\\n\" # \"X\\n#\\n\" # At this point, not using this feature. # ) # cif += ( # \"loop_\\n\" # \"_entity.id\\n\" # \"1\\n#\\n\" # At this point, not using this feature. # ) # NOTE: This is otherwise a bit ahead of its time, since this OPTIMADE property is part of an open PR. # See https://github.com/Materials-Consortia/OPTIMADE/pull/206 coord_type = ( \"fract\" if hasattr ( attributes , \"fractional_site_positions\" ) else \"Cartn\" ) cif += ( \"loop_ \\n \" \"_atom_site.group_PDB \\n \" # Always \"ATOM\" \"_atom_site.id \\n \" # number (1-counting) \"_atom_site.type_symbol \\n \" # species.chemical_symbols \"_atom_site.label_atom_id \\n \" # species.checmical_symbols symbol + number # For these next keys, see the comment above. # \"_atom_site.label_asym_id\\n\" # Will be set to \"A\" _struct_asym.id above # \"_atom_site.label_comp_id\\n\" # Will be set to \"X\" _chem_comp.id above # \"_atom_site.label_entity_id\\n\" # Will be set to \"1\" _entity.id above # \"_atom_site.label_seq_id\\n\" \"_atom_site.occupancy \\n \" # species.concentration f \"_atom_site. { coord_type } _x \\n \" # cartesian_site_positions f \"_atom_site. { coord_type } _y \\n \" # cartesian_site_positions f \"_atom_site. { coord_type } _z \\n \" # cartesian_site_positions \"_atom_site.thermal_displace_type \\n \" # Set to 'Biso' \"_atom_site.B_iso_or_equiv \\n \" # Set to 1.0:f ) if coord_type == \"fract\" : sites = attributes . fractional_site_positions else : sites = attributes . cartesian_site_positions species : Dict [ str , OptimadeStructureSpecies ] = { species . name : species for species in attributes . species } for site_number in range ( attributes . nsites ): species_name = attributes . species_at_sites [ site_number ] site = sites [ site_number ] current_species = species [ species_name ] for index , symbol in enumerate ( current_species . chemical_symbols ): if symbol == \"vacancy\" : continue label = f \" { species_name . upper () }{ site_number + 1 } \" if len ( current_species . chemical_symbols ) > 1 : if ( \"vacancy\" in current_species . chemical_symbols and len ( current_species . chemical_symbols ) == 2 ): pass else : label = f \" { symbol . upper () }{ index + 1 } \" cif += ( f \"ATOM { site_number + 1 : 5d } { symbol } { label : 8 } \" f \" { current_species . concentration [ index ] : 6.4f } { site [ 0 ] : 8.5f } \" f \" { site [ 1 ] : 8.5f } { site [ 2 ] : 8.5f } { 'Biso' : 4 } { '1.000' : 6 } \\n \" ) return cif","title":"get_pdbx_mmcif()"},{"location":"api_reference/adapters/structures/pymatgen/","text":"pymatgen \u00b6 Convert an OPTIMADE structure, in the format of StructureResource to a pymatgen Molecule or Structure object. This conversion function relies on the pymatgen package. For more information on the pymatgen code see their documentation . get_pymatgen ( optimade_structure ) \u00b6 Get pymatgen Structure or Molecule from OPTIMADE structure. This function will return either a pymatgen Structure or Molecule based on the periodicity or periodic dimensionality of OPTIMADE structure. For bulk, three-dimensional structures, a pymatgen Structure is returned. This means, if the dimension_types attribute is comprised of all 1 s (or Periodicity.PERIODIC s). Otherwise, a pymatgen Molecule is returned. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description Union [ Structure , Molecule ] A pymatgen Structure or Molecule based on the periodicity of the Union [ Structure , Molecule ] OPTIMADE structure. Source code in optimade/adapters/structures/pymatgen.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_pymatgen ( optimade_structure : OptimadeStructure ) -> Union [ Structure , Molecule ]: \"\"\"Get pymatgen `Structure` or `Molecule` from OPTIMADE structure. This function will return either a pymatgen `Structure` or `Molecule` based on the periodicity or periodic dimensionality of OPTIMADE structure. For bulk, three-dimensional structures, a pymatgen `Structure` is returned. This means, if the [`dimension_types`][optimade.models.structures.StructureResourceAttributes.dimension_types] attribute is comprised of all `1`s (or [`Periodicity.PERIODIC`][optimade.models.structures.Periodicity.PERIODIC]s). Otherwise, a pymatgen `Molecule` is returned. Parameters: optimade_structure: OPTIMADE structure. Returns: A pymatgen `Structure` or `Molecule` based on the periodicity of the OPTIMADE structure. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"Structure\" )): warn ( PYMATGEN_NOT_FOUND , AdapterPackageNotFound ) return None if optimade_structure . attributes . nperiodic_dimensions == 3 or all ( optimade_structure . attributes . dimension_types ): return _get_structure ( optimade_structure ) return _get_molecule ( optimade_structure )","title":"pymatgen"},{"location":"api_reference/adapters/structures/pymatgen/#pymatgen","text":"Convert an OPTIMADE structure, in the format of StructureResource to a pymatgen Molecule or Structure object. This conversion function relies on the pymatgen package. For more information on the pymatgen code see their documentation .","title":"pymatgen"},{"location":"api_reference/adapters/structures/pymatgen/#optimade.adapters.structures.pymatgen.get_pymatgen","text":"Get pymatgen Structure or Molecule from OPTIMADE structure. This function will return either a pymatgen Structure or Molecule based on the periodicity or periodic dimensionality of OPTIMADE structure. For bulk, three-dimensional structures, a pymatgen Structure is returned. This means, if the dimension_types attribute is comprised of all 1 s (or Periodicity.PERIODIC s). Otherwise, a pymatgen Molecule is returned. Parameters: Name Type Description Default optimade_structure OptimadeStructure OPTIMADE structure. required Returns: Type Description Union [ Structure , Molecule ] A pymatgen Structure or Molecule based on the periodicity of the Union [ Structure , Molecule ] OPTIMADE structure. Source code in optimade/adapters/structures/pymatgen.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_pymatgen ( optimade_structure : OptimadeStructure ) -> Union [ Structure , Molecule ]: \"\"\"Get pymatgen `Structure` or `Molecule` from OPTIMADE structure. This function will return either a pymatgen `Structure` or `Molecule` based on the periodicity or periodic dimensionality of OPTIMADE structure. For bulk, three-dimensional structures, a pymatgen `Structure` is returned. This means, if the [`dimension_types`][optimade.models.structures.StructureResourceAttributes.dimension_types] attribute is comprised of all `1`s (or [`Periodicity.PERIODIC`][optimade.models.structures.Periodicity.PERIODIC]s). Otherwise, a pymatgen `Molecule` is returned. Parameters: optimade_structure: OPTIMADE structure. Returns: A pymatgen `Structure` or `Molecule` based on the periodicity of the OPTIMADE structure. \"\"\" if \"optimade.adapters\" in repr ( globals () . get ( \"Structure\" )): warn ( PYMATGEN_NOT_FOUND , AdapterPackageNotFound ) return None if optimade_structure . attributes . nperiodic_dimensions == 3 or all ( optimade_structure . attributes . dimension_types ): return _get_structure ( optimade_structure ) return _get_molecule ( optimade_structure )","title":"get_pymatgen()"},{"location":"api_reference/adapters/structures/utils/","text":"utils \u00b6 Utility functions to help the conversion functions along. Most of these functions rely on the NumPy library. cell_to_cellpar ( cell , radians = False ) \u00b6 Returns the cell parameters [a, b, c, alpha, beta, gamma] . Angles are in degrees unless radian=True is used. Note Based on ASE code . Parameters: Name Type Description Default cell Tuple [ Vector3D , Vector3D , Vector3D ] A Cartesian 3x3 cell. This equates to the lattice_vectors attribute. required radians bool Use radians instead of degrees (default) for angles. False Returns: Type Description List [ float ] The unit cell parameters as a list of float values. Source code in optimade/adapters/structures/utils.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def cell_to_cellpar ( cell : Tuple [ Vector3D , Vector3D , Vector3D ], radians : bool = False ) -> List [ float ]: \"\"\"Returns the cell parameters `[a, b, c, alpha, beta, gamma]`. Angles are in degrees unless `radian=True` is used. Note: Based on [ASE code](https://wiki.fysik.dtu.dk/ase/_modules/ase/geometry/cell.html#cell_to_cellpar). Parameters: cell: A Cartesian 3x3 cell. This equates to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. radians: Use radians instead of degrees (default) for angles. Returns: The unit cell parameters as a `list` of `float` values. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cell = np . asarray ( cell ) lengths = [ np . linalg . norm ( vector ) for vector in cell ] angles = [] for i in range ( 3 ): j = i - 1 k = i - 2 outer_product = lengths [ j ] * lengths [ k ] if outer_product > 1e-16 : x_vector = np . dot ( cell [ j ], cell [ k ]) / outer_product angle = 180.0 / np . pi * np . arccos ( x_vector ) else : angle = 90.0 angles . append ( angle ) if radians : angles = [ angle * np . pi / 180 for angle in angles ] return np . array ( lengths + angles ) cellpar_to_cell ( cellpar , ab_normal = ( 0 , 0 , 1 ), a_direction = None ) \u00b6 Return a 3x3 cell matrix from cellpar=[a,b,c,alpha,beta,gamma] . Angles must be in degrees. The returned cell is orientated such that a and b are normal to ab_normal and a is parallel to the projection of a_direction in the a-b plane. Default a_direction is (1,0,0), unless this is parallel to ab_normal , in which case default a_direction is (0,0,1). The returned cell has the vectors va, vb and vc along the rows. The cell will be oriented such that va and vb are normal to ab_normal and va will be along the projection of a_direction onto the a-b plane. Example cell = cellpar_to_cell([1, 2, 4, 10, 20, 30], (0, 1, 1), (1, 2, 3)) np.round(cell, 3) array([[ 0.816, -0.408, 0.408], [ 1.992, -0.13 , 0.13 ], [ 3.859, -0.745, 0.745]]) Note Direct copy of ASE code . Parameters: Name Type Description Default cellpar List [ float ] The unit cell parameters as a list of float values. Note : The angles must be given in degrees. required ab_normal Tuple [ int , int , int ] Unit vector normal to the ab-plane. (0, 0, 1) a_direction Tuple [ int , int , int ] Unit vector defining the a-direction (default: (1, 0, 0) ). None Returns: Type Description List [ Vector3D ] A Cartesian 3x3 cell. List [ Vector3D ] This should equate to the List [ Vector3D ] lattice_vectors attribute. Source code in optimade/adapters/structures/utils.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 def cellpar_to_cell ( cellpar : List [ float ], ab_normal : Tuple [ int , int , int ] = ( 0 , 0 , 1 ), a_direction : Tuple [ int , int , int ] = None , ) -> List [ Vector3D ]: \"\"\"Return a 3x3 cell matrix from `cellpar=[a,b,c,alpha,beta,gamma]`. Angles must be in degrees. The returned cell is orientated such that a and b are normal to `ab_normal` and a is parallel to the projection of `a_direction` in the a-b plane. Default `a_direction` is (1,0,0), unless this is parallel to `ab_normal`, in which case default `a_direction` is (0,0,1). The returned cell has the vectors va, vb and vc along the rows. The cell will be oriented such that va and vb are normal to `ab_normal` and va will be along the projection of `a_direction` onto the a-b plane. Example: >>> cell = cellpar_to_cell([1, 2, 4, 10, 20, 30], (0, 1, 1), (1, 2, 3)) >>> np.round(cell, 3) array([[ 0.816, -0.408, 0.408], [ 1.992, -0.13 , 0.13 ], [ 3.859, -0.745, 0.745]]) Note: Direct copy of [ASE code](https://wiki.fysik.dtu.dk/ase/_modules/ase/geometry/cell.html#cellpar_to_cell). Parameters: cellpar: The unit cell parameters as a `list` of `float` values. **Note**: The angles must be given in degrees. ab_normal: Unit vector normal to the ab-plane. a_direction: Unit vector defining the a-direction (default: `(1, 0, 0)`). Returns: A Cartesian 3x3 cell. This should equate to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None if a_direction is None : if np . linalg . norm ( np . cross ( ab_normal , ( 1 , 0 , 0 ))) < 1e-5 : a_direction = ( 0 , 0 , 1 ) else : a_direction = ( 1 , 0 , 0 ) # Define rotated X,Y,Z-system, with Z along ab_normal and X along # the projection of a_direction onto the normal plane of Z. a_direction_array = np . array ( a_direction ) Z = unit_vector ( ab_normal ) X = unit_vector ( a_direction_array - np . dot ( a_direction_array , Z ) * Z ) Y = np . cross ( Z , X ) # Express va, vb and vc in the X,Y,Z-system alpha , beta , gamma = 90.0 , 90.0 , 90.0 if isinstance ( cellpar , ( int , float )): a = b = c = cellpar elif len ( cellpar ) == 1 : a = b = c = cellpar [ 0 ] elif len ( cellpar ) == 3 : a , b , c = cellpar else : a , b , c , alpha , beta , gamma = cellpar # Handle orthorhombic cells separately to avoid rounding errors eps = 2 * np . spacing ( 90.0 , dtype = np . float64 ) # around 1.4e-14 # alpha if abs ( abs ( alpha ) - 90 ) < eps : cos_alpha = 0.0 else : cos_alpha = np . cos ( alpha * np . pi / 180.0 ) # beta if abs ( abs ( beta ) - 90 ) < eps : cos_beta = 0.0 else : cos_beta = np . cos ( beta * np . pi / 180.0 ) # gamma if abs ( gamma - 90 ) < eps : cos_gamma = 0.0 sin_gamma = 1.0 elif abs ( gamma + 90 ) < eps : cos_gamma = 0.0 sin_gamma = - 1.0 else : cos_gamma = np . cos ( gamma * np . pi / 180.0 ) sin_gamma = np . sin ( gamma * np . pi / 180.0 ) # Build the cell vectors va = a * np . array ([ 1 , 0 , 0 ]) vb = b * np . array ([ cos_gamma , sin_gamma , 0 ]) cx = cos_beta cy = ( cos_alpha - cos_beta * cos_gamma ) / sin_gamma cz_sqr = 1.0 - cx * cx - cy * cy assert cz_sqr >= 0 cz = np . sqrt ( cz_sqr ) vc = c * np . array ([ cx , cy , cz ]) # Convert to the Cartesian x,y,z-system abc = np . vstack (( va , vb , vc )) T = np . vstack (( X , Y , Z )) cell = np . dot ( abc , T ) return cell fractional_coordinates ( cell , cartesian_positions ) \u00b6 Returns fractional coordinates and wraps coordinates to [0,1[ . Note Based on ASE code . Parameters: Name Type Description Default cell Tuple [ Vector3D , Vector3D , Vector3D ] A Cartesian 3x3 cell. This equates to the lattice_vectors attribute. required cartesian_positions List [ Vector3D ] A list of cartesian atomic positions. This equates to the cartesian_site_positions attribute. required Returns: Type Description List [ Vector3D ] A list of fractional coordinates for the atomic positions. Source code in optimade/adapters/structures/utils.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def fractional_coordinates ( cell : Tuple [ Vector3D , Vector3D , Vector3D ], cartesian_positions : List [ Vector3D ] ) -> List [ Vector3D ]: \"\"\"Returns fractional coordinates and wraps coordinates to `[0,1[`. Note: Based on [ASE code](https://wiki.fysik.dtu.dk/ase/_modules/ase/atoms.html#Atoms.get_scaled_positions). Parameters: cell: A Cartesian 3x3 cell. This equates to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. cartesian_positions: A list of cartesian atomic positions. This equates to the [`cartesian_site_positions`][optimade.models.structures.StructureResourceAttributes.cartesian_site_positions] attribute. Returns: A list of fractional coordinates for the atomic positions. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cell = np . asarray ( cell ) cartesian_positions = np . asarray ( cartesian_positions ) fractional = np . linalg . solve ( cell . T , cartesian_positions . T ) . T # Expecting a bulk 3D structure here, note, this may change in the future. # See `ase.atoms:Atoms.get_scaled_positions()` for ideas on how to handle lower dimensional structures. # Furthermore, according to ASE we need to modulo 1.0 twice. # This seems to be due to small floats % 1.0 becomes 1.0, hence twice makes it 0.0. for i in range ( 3 ): fractional [:, i ] %= 1.0 fractional [:, i ] %= 1.0 return [ tuple ( position ) for position in fractional ] pad_cell ( lattice_vectors , padding = None ) \u00b6 Turn any null / None values into a float in given tuple of lattice_vectors . Parameters: Name Type Description Default lattice_vectors Tuple [ Vector3D , Vector3D , Vector3D ] A 3x3 cartesian cell. This is the lattice_vectors attribute. required padding Optional [ float ] A value with which null or None values should be replaced. None Returns: Type Description tuple The possibly redacted/padded lattice_vectors and a bool declaring whether or not tuple the value has been redacted/padded or not, i.e., whether it contained null or None tuple values. Source code in optimade/adapters/structures/utils.py 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 def pad_cell ( lattice_vectors : Tuple [ Vector3D , Vector3D , Vector3D ], padding : Optional [ float ] = None , ) -> tuple : # Setting this properly makes MkDocs fail. \"\"\"Turn any `null`/`None` values into a `float` in given `tuple` of [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors]. Parameters: lattice_vectors: A 3x3 cartesian cell. This is the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. padding: A value with which `null` or `None` values should be replaced. Returns: The possibly redacted/padded `lattice_vectors` and a `bool` declaring whether or not the value has been redacted/padded or not, i.e., whether it contained `null` or `None` values. \"\"\" return _pad_iter_of_iters ( iterable = lattice_vectors , padding = padding , outer = tuple , inner = tuple , ) scaled_cell ( cell ) \u00b6 Return a scaled 3x3 cell from cartesian 3x3 cell ( lattice_vectors ). This is based on PDB's method of calculating SCALE from CRYST data. For more info, see this site . Parameters: Name Type Description Default cell Tuple [ Vector3D , Vector3D , Vector3D ] A Cartesian 3x3 cell. This equates to the lattice_vectors attribute. required Returns: Type Description Tuple [ Vector3D , Vector3D , Vector3D ] A scaled 3x3 cell. Source code in optimade/adapters/structures/utils.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def scaled_cell ( cell : Tuple [ Vector3D , Vector3D , Vector3D ] ) -> Tuple [ Vector3D , Vector3D , Vector3D ]: \"\"\"Return a scaled 3x3 cell from cartesian 3x3 cell (`lattice_vectors`). This is based on PDB's method of calculating SCALE from CRYST data. For more info, see [this site](https://www.wwpdb.org/documentation/file-format-content/format33/sect8.html#SCALEn). Parameters: cell: A Cartesian 3x3 cell. This equates to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. Returns: A scaled 3x3 cell. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cell = np . asarray ( cell ) volume = np . dot ( cell [ 0 ], np . cross ( cell [ 1 ], cell [ 2 ])) scale = [] for i in range ( 3 ): vector = np . cross ( cell [( i + 1 ) % 3 ], cell [( i + 2 ) % 3 ]) / volume scale . append ( tuple ( vector )) return tuple ( scale ) species_from_species_at_sites ( species_at_sites ) \u00b6 When a list of species dictionaries is not provided, this function can be used to infer the species from the provided species_at_sites. In this use case, species_at_sites is assumed to provide a list of element symbols, and refers to situations with no mixed occupancy, i.e., the constructed species list will contain all unique species with concentration equal to 1 and the species_at_site tag will be used as the chemical symbol. Parameters: Name Type Description Default species_at_sites List [ str ] The list found under the species_at_sites field. required Returns: Type Description List [ OptimadeStructureSpecies ] An OPTIMADE species list. Source code in optimade/adapters/structures/utils.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def species_from_species_at_sites ( species_at_sites : List [ str ], ) -> List [ OptimadeStructureSpecies ]: \"\"\"When a list of species dictionaries is not provided, this function can be used to infer the species from the provided species_at_sites. In this use case, species_at_sites is assumed to provide a list of element symbols, and refers to situations with no mixed occupancy, i.e., the constructed species list will contain all unique species with concentration equal to 1 and the species_at_site tag will be used as the chemical symbol. Parameters: species_at_sites: The list found under the species_at_sites field. Returns: An OPTIMADE species list. \"\"\" return [ OptimadeStructureSpecies ( name = _ , concentration = [ 1.0 ], chemical_symbols = [ _ ]) for _ in set ( species_at_sites ) ] unit_vector ( x ) \u00b6 Return a unit vector in the same direction as x . Parameters: Name Type Description Default x Vector3D A three-dimensional vector. required Returns: Type Description Vector3D A unit vector in the same direction as x . Source code in optimade/adapters/structures/utils.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def unit_vector ( x : Vector3D ) -> Vector3D : \"\"\"Return a unit vector in the same direction as `x`. Parameters: x: A three-dimensional vector. Returns: A unit vector in the same direction as `x`. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None y = np . array ( x , dtype = \"float\" ) return y / np . linalg . norm ( y )","title":"utils"},{"location":"api_reference/adapters/structures/utils/#utils","text":"Utility functions to help the conversion functions along. Most of these functions rely on the NumPy library.","title":"utils"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.cell_to_cellpar","text":"Returns the cell parameters [a, b, c, alpha, beta, gamma] . Angles are in degrees unless radian=True is used. Note Based on ASE code . Parameters: Name Type Description Default cell Tuple [ Vector3D , Vector3D , Vector3D ] A Cartesian 3x3 cell. This equates to the lattice_vectors attribute. required radians bool Use radians instead of degrees (default) for angles. False Returns: Type Description List [ float ] The unit cell parameters as a list of float values. Source code in optimade/adapters/structures/utils.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def cell_to_cellpar ( cell : Tuple [ Vector3D , Vector3D , Vector3D ], radians : bool = False ) -> List [ float ]: \"\"\"Returns the cell parameters `[a, b, c, alpha, beta, gamma]`. Angles are in degrees unless `radian=True` is used. Note: Based on [ASE code](https://wiki.fysik.dtu.dk/ase/_modules/ase/geometry/cell.html#cell_to_cellpar). Parameters: cell: A Cartesian 3x3 cell. This equates to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. radians: Use radians instead of degrees (default) for angles. Returns: The unit cell parameters as a `list` of `float` values. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cell = np . asarray ( cell ) lengths = [ np . linalg . norm ( vector ) for vector in cell ] angles = [] for i in range ( 3 ): j = i - 1 k = i - 2 outer_product = lengths [ j ] * lengths [ k ] if outer_product > 1e-16 : x_vector = np . dot ( cell [ j ], cell [ k ]) / outer_product angle = 180.0 / np . pi * np . arccos ( x_vector ) else : angle = 90.0 angles . append ( angle ) if radians : angles = [ angle * np . pi / 180 for angle in angles ] return np . array ( lengths + angles )","title":"cell_to_cellpar()"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.cellpar_to_cell","text":"Return a 3x3 cell matrix from cellpar=[a,b,c,alpha,beta,gamma] . Angles must be in degrees. The returned cell is orientated such that a and b are normal to ab_normal and a is parallel to the projection of a_direction in the a-b plane. Default a_direction is (1,0,0), unless this is parallel to ab_normal , in which case default a_direction is (0,0,1). The returned cell has the vectors va, vb and vc along the rows. The cell will be oriented such that va and vb are normal to ab_normal and va will be along the projection of a_direction onto the a-b plane. Example cell = cellpar_to_cell([1, 2, 4, 10, 20, 30], (0, 1, 1), (1, 2, 3)) np.round(cell, 3) array([[ 0.816, -0.408, 0.408], [ 1.992, -0.13 , 0.13 ], [ 3.859, -0.745, 0.745]]) Note Direct copy of ASE code . Parameters: Name Type Description Default cellpar List [ float ] The unit cell parameters as a list of float values. Note : The angles must be given in degrees. required ab_normal Tuple [ int , int , int ] Unit vector normal to the ab-plane. (0, 0, 1) a_direction Tuple [ int , int , int ] Unit vector defining the a-direction (default: (1, 0, 0) ). None Returns: Type Description List [ Vector3D ] A Cartesian 3x3 cell. List [ Vector3D ] This should equate to the List [ Vector3D ] lattice_vectors attribute. Source code in optimade/adapters/structures/utils.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 def cellpar_to_cell ( cellpar : List [ float ], ab_normal : Tuple [ int , int , int ] = ( 0 , 0 , 1 ), a_direction : Tuple [ int , int , int ] = None , ) -> List [ Vector3D ]: \"\"\"Return a 3x3 cell matrix from `cellpar=[a,b,c,alpha,beta,gamma]`. Angles must be in degrees. The returned cell is orientated such that a and b are normal to `ab_normal` and a is parallel to the projection of `a_direction` in the a-b plane. Default `a_direction` is (1,0,0), unless this is parallel to `ab_normal`, in which case default `a_direction` is (0,0,1). The returned cell has the vectors va, vb and vc along the rows. The cell will be oriented such that va and vb are normal to `ab_normal` and va will be along the projection of `a_direction` onto the a-b plane. Example: >>> cell = cellpar_to_cell([1, 2, 4, 10, 20, 30], (0, 1, 1), (1, 2, 3)) >>> np.round(cell, 3) array([[ 0.816, -0.408, 0.408], [ 1.992, -0.13 , 0.13 ], [ 3.859, -0.745, 0.745]]) Note: Direct copy of [ASE code](https://wiki.fysik.dtu.dk/ase/_modules/ase/geometry/cell.html#cellpar_to_cell). Parameters: cellpar: The unit cell parameters as a `list` of `float` values. **Note**: The angles must be given in degrees. ab_normal: Unit vector normal to the ab-plane. a_direction: Unit vector defining the a-direction (default: `(1, 0, 0)`). Returns: A Cartesian 3x3 cell. This should equate to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None if a_direction is None : if np . linalg . norm ( np . cross ( ab_normal , ( 1 , 0 , 0 ))) < 1e-5 : a_direction = ( 0 , 0 , 1 ) else : a_direction = ( 1 , 0 , 0 ) # Define rotated X,Y,Z-system, with Z along ab_normal and X along # the projection of a_direction onto the normal plane of Z. a_direction_array = np . array ( a_direction ) Z = unit_vector ( ab_normal ) X = unit_vector ( a_direction_array - np . dot ( a_direction_array , Z ) * Z ) Y = np . cross ( Z , X ) # Express va, vb and vc in the X,Y,Z-system alpha , beta , gamma = 90.0 , 90.0 , 90.0 if isinstance ( cellpar , ( int , float )): a = b = c = cellpar elif len ( cellpar ) == 1 : a = b = c = cellpar [ 0 ] elif len ( cellpar ) == 3 : a , b , c = cellpar else : a , b , c , alpha , beta , gamma = cellpar # Handle orthorhombic cells separately to avoid rounding errors eps = 2 * np . spacing ( 90.0 , dtype = np . float64 ) # around 1.4e-14 # alpha if abs ( abs ( alpha ) - 90 ) < eps : cos_alpha = 0.0 else : cos_alpha = np . cos ( alpha * np . pi / 180.0 ) # beta if abs ( abs ( beta ) - 90 ) < eps : cos_beta = 0.0 else : cos_beta = np . cos ( beta * np . pi / 180.0 ) # gamma if abs ( gamma - 90 ) < eps : cos_gamma = 0.0 sin_gamma = 1.0 elif abs ( gamma + 90 ) < eps : cos_gamma = 0.0 sin_gamma = - 1.0 else : cos_gamma = np . cos ( gamma * np . pi / 180.0 ) sin_gamma = np . sin ( gamma * np . pi / 180.0 ) # Build the cell vectors va = a * np . array ([ 1 , 0 , 0 ]) vb = b * np . array ([ cos_gamma , sin_gamma , 0 ]) cx = cos_beta cy = ( cos_alpha - cos_beta * cos_gamma ) / sin_gamma cz_sqr = 1.0 - cx * cx - cy * cy assert cz_sqr >= 0 cz = np . sqrt ( cz_sqr ) vc = c * np . array ([ cx , cy , cz ]) # Convert to the Cartesian x,y,z-system abc = np . vstack (( va , vb , vc )) T = np . vstack (( X , Y , Z )) cell = np . dot ( abc , T ) return cell","title":"cellpar_to_cell()"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.fractional_coordinates","text":"Returns fractional coordinates and wraps coordinates to [0,1[ . Note Based on ASE code . Parameters: Name Type Description Default cell Tuple [ Vector3D , Vector3D , Vector3D ] A Cartesian 3x3 cell. This equates to the lattice_vectors attribute. required cartesian_positions List [ Vector3D ] A list of cartesian atomic positions. This equates to the cartesian_site_positions attribute. required Returns: Type Description List [ Vector3D ] A list of fractional coordinates for the atomic positions. Source code in optimade/adapters/structures/utils.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def fractional_coordinates ( cell : Tuple [ Vector3D , Vector3D , Vector3D ], cartesian_positions : List [ Vector3D ] ) -> List [ Vector3D ]: \"\"\"Returns fractional coordinates and wraps coordinates to `[0,1[`. Note: Based on [ASE code](https://wiki.fysik.dtu.dk/ase/_modules/ase/atoms.html#Atoms.get_scaled_positions). Parameters: cell: A Cartesian 3x3 cell. This equates to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. cartesian_positions: A list of cartesian atomic positions. This equates to the [`cartesian_site_positions`][optimade.models.structures.StructureResourceAttributes.cartesian_site_positions] attribute. Returns: A list of fractional coordinates for the atomic positions. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cell = np . asarray ( cell ) cartesian_positions = np . asarray ( cartesian_positions ) fractional = np . linalg . solve ( cell . T , cartesian_positions . T ) . T # Expecting a bulk 3D structure here, note, this may change in the future. # See `ase.atoms:Atoms.get_scaled_positions()` for ideas on how to handle lower dimensional structures. # Furthermore, according to ASE we need to modulo 1.0 twice. # This seems to be due to small floats % 1.0 becomes 1.0, hence twice makes it 0.0. for i in range ( 3 ): fractional [:, i ] %= 1.0 fractional [:, i ] %= 1.0 return [ tuple ( position ) for position in fractional ]","title":"fractional_coordinates()"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.pad_cell","text":"Turn any null / None values into a float in given tuple of lattice_vectors . Parameters: Name Type Description Default lattice_vectors Tuple [ Vector3D , Vector3D , Vector3D ] A 3x3 cartesian cell. This is the lattice_vectors attribute. required padding Optional [ float ] A value with which null or None values should be replaced. None Returns: Type Description tuple The possibly redacted/padded lattice_vectors and a bool declaring whether or not tuple the value has been redacted/padded or not, i.e., whether it contained null or None tuple values. Source code in optimade/adapters/structures/utils.py 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 def pad_cell ( lattice_vectors : Tuple [ Vector3D , Vector3D , Vector3D ], padding : Optional [ float ] = None , ) -> tuple : # Setting this properly makes MkDocs fail. \"\"\"Turn any `null`/`None` values into a `float` in given `tuple` of [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors]. Parameters: lattice_vectors: A 3x3 cartesian cell. This is the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. padding: A value with which `null` or `None` values should be replaced. Returns: The possibly redacted/padded `lattice_vectors` and a `bool` declaring whether or not the value has been redacted/padded or not, i.e., whether it contained `null` or `None` values. \"\"\" return _pad_iter_of_iters ( iterable = lattice_vectors , padding = padding , outer = tuple , inner = tuple , )","title":"pad_cell()"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.scaled_cell","text":"Return a scaled 3x3 cell from cartesian 3x3 cell ( lattice_vectors ). This is based on PDB's method of calculating SCALE from CRYST data. For more info, see this site . Parameters: Name Type Description Default cell Tuple [ Vector3D , Vector3D , Vector3D ] A Cartesian 3x3 cell. This equates to the lattice_vectors attribute. required Returns: Type Description Tuple [ Vector3D , Vector3D , Vector3D ] A scaled 3x3 cell. Source code in optimade/adapters/structures/utils.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def scaled_cell ( cell : Tuple [ Vector3D , Vector3D , Vector3D ] ) -> Tuple [ Vector3D , Vector3D , Vector3D ]: \"\"\"Return a scaled 3x3 cell from cartesian 3x3 cell (`lattice_vectors`). This is based on PDB's method of calculating SCALE from CRYST data. For more info, see [this site](https://www.wwpdb.org/documentation/file-format-content/format33/sect8.html#SCALEn). Parameters: cell: A Cartesian 3x3 cell. This equates to the [`lattice_vectors`][optimade.models.structures.StructureResourceAttributes.lattice_vectors] attribute. Returns: A scaled 3x3 cell. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None cell = np . asarray ( cell ) volume = np . dot ( cell [ 0 ], np . cross ( cell [ 1 ], cell [ 2 ])) scale = [] for i in range ( 3 ): vector = np . cross ( cell [( i + 1 ) % 3 ], cell [( i + 2 ) % 3 ]) / volume scale . append ( tuple ( vector )) return tuple ( scale )","title":"scaled_cell()"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.species_from_species_at_sites","text":"When a list of species dictionaries is not provided, this function can be used to infer the species from the provided species_at_sites. In this use case, species_at_sites is assumed to provide a list of element symbols, and refers to situations with no mixed occupancy, i.e., the constructed species list will contain all unique species with concentration equal to 1 and the species_at_site tag will be used as the chemical symbol. Parameters: Name Type Description Default species_at_sites List [ str ] The list found under the species_at_sites field. required Returns: Type Description List [ OptimadeStructureSpecies ] An OPTIMADE species list. Source code in optimade/adapters/structures/utils.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def species_from_species_at_sites ( species_at_sites : List [ str ], ) -> List [ OptimadeStructureSpecies ]: \"\"\"When a list of species dictionaries is not provided, this function can be used to infer the species from the provided species_at_sites. In this use case, species_at_sites is assumed to provide a list of element symbols, and refers to situations with no mixed occupancy, i.e., the constructed species list will contain all unique species with concentration equal to 1 and the species_at_site tag will be used as the chemical symbol. Parameters: species_at_sites: The list found under the species_at_sites field. Returns: An OPTIMADE species list. \"\"\" return [ OptimadeStructureSpecies ( name = _ , concentration = [ 1.0 ], chemical_symbols = [ _ ]) for _ in set ( species_at_sites ) ]","title":"species_from_species_at_sites()"},{"location":"api_reference/adapters/structures/utils/#optimade.adapters.structures.utils.unit_vector","text":"Return a unit vector in the same direction as x . Parameters: Name Type Description Default x Vector3D A three-dimensional vector. required Returns: Type Description Vector3D A unit vector in the same direction as x . Source code in optimade/adapters/structures/utils.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def unit_vector ( x : Vector3D ) -> Vector3D : \"\"\"Return a unit vector in the same direction as `x`. Parameters: x: A three-dimensional vector. Returns: A unit vector in the same direction as `x`. \"\"\" if globals () . get ( \"np\" , None ) is None : warn ( NUMPY_NOT_FOUND , AdapterPackageNotFound ) return None y = np . array ( x , dtype = \"float\" ) return y / np . linalg . norm ( y )","title":"unit_vector()"},{"location":"api_reference/client/cli/","text":"cli \u00b6","title":"cli"},{"location":"api_reference/client/cli/#cli","text":"","title":"cli"},{"location":"api_reference/client/client/","text":"client \u00b6 This module implements OPTIMADE client functionality for: making web requests to filter and harvest resources from OPTIMADE APIs, query multiple providers simultaneously. OptimadeClient \u00b6 This class implemements a client for executing the same queries across multiple OPTIMADE APIs simultaneously, paging and caching the results. By default, all registered OPTIMADE providers will be queried simulateneously and asynchronously, with the results collected into the all_results attribute, keyed by endpoint, filter and provider. Source code in optimade/client/client.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 class OptimadeClient : \"\"\"This class implemements a client for executing the same queries across multiple OPTIMADE APIs simultaneously, paging and caching the results. By default, all registered OPTIMADE providers will be queried simulateneously and asynchronously, with the results collected into the `all_results` attribute, keyed by endpoint, filter and provider. \"\"\" base_urls : Union [ AnyUrl , Iterable [ AnyUrl ]] \"\"\"A list (or any iterable) of OPTIMADE base URLs to query.\"\"\" all_results : Dict [ str , Dict [ str , Dict [ str , QueryResults ]]] = defaultdict ( dict ) \"\"\"A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the results from each base URL for that particular filter. \"\"\" count_results : Dict [ str , Dict [ str , Dict [ str , int ]]] = defaultdict ( dict ) \"\"\"A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the number of results from each base URL for that particular filter. \"\"\" max_results_per_provider : Optional [ int ] = None \"\"\"Maximum number of results to downlod per provider. If None, will download all. \"\"\" headers : Dict = { \"User-Agent\" : f \"optimade-python-tools/ { __version__ } \" } \"\"\"Additional HTTP headers.\"\"\" http_timeout : int \"\"\"The timeout to use for each HTTP request.\"\"\" max_attempts : int \"\"\"The maximum number of times to repeat a failed query before giving up.\"\"\" use_async : bool \"\"\"Whether or not to make all requests asynchronously using asyncio.\"\"\" __current_endpoint : Optional [ str ] = None \"\"\"Used internally when querying via `client.structures.get()` to set the chosen endpoint. Should be reset to `None` outside of all `get()` calls.\"\"\" def __init__ ( self , base_urls : Union [ None , AnyUrl , List [ AnyUrl ]] = None , max_results_per_provider : int = 1000 , headers : Optional [ Dict ] = None , http_timeout : int = 10 , max_attempts : int = 5 , use_async : bool = True , ): \"\"\"Create the OPTIMADE client object. Parameters: base_urls: A list of OPTIMADE base URLs to query. max_results_per_provider: The maximum number of results to download from each provider. headers: Any additional HTTP headers to use for the queries. http_timeout: The HTTP timeout to use per request. max_attempts: The maximum number of times to repeat a failing query. use_async: Whether or not to make all requests asynchronously. \"\"\" if not base_urls : base_urls = get_all_databases () self . max_results_per_provider = max_results_per_provider if self . max_results_per_provider in ( - 1 , 0 ): self . max_results_per_provider = None self . base_urls = base_urls if isinstance ( self . base_urls , str ): self . base_urls = [ self . base_urls ] self . base_urls = list ( self . base_urls ) if not self . base_urls : raise SystemExit ( \"Unable to access any OPTIMADE base URLs. If you believe this is an error, try manually specifying some base URLs.\" ) if headers : self . headers . update ( headers ) self . http_timeout = http_timeout self . max_attempts = max_attempts self . use_async = use_async def __getattribute__ ( self , name ): \"\"\"Allows entry endpoints to be queried via attribute access, using the allowed list for this module. Should also pass through any `extensions/<example>` endpoints. Any non-entry-endpoint name requested will be passed to the original `__getattribute__`. !!! example ```python from optimade.client import OptimadeClient cli = OptimadeClient() structures = cli.structures.get() references = cli.references.get() info_structures = cli.info.structures.get() ``` \"\"\" if name in ENDPOINTS : if self . __current_endpoint == \"info\" : self . __current_endpoint = f \"info/ { name } \" elif self . __current_endpoint == \"extensions\" : self . __current_endpoint = f \"extensions/ { name } \" else : self . __current_endpoint = name return self return super () . __getattribute__ ( name ) def get ( self , filter : str = None , endpoint : Optional [ str ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , ) -> Dict [ str , Dict [ str , Dict [ str , Dict ]]]: \"\"\"Gets the results from the endpoint and filter across the defined OPTIMADE APIs. Parameters: filter: The OPTIMADE filter string for the query. endpoint: The endpoint to query. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Performing query [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , response_fields = response_fields , page_limit = None , paginate = True , sort = sort , ) self . all_results [ endpoint ][ filter ] = results return { endpoint : { filter : { k : results [ k ] . dict () for k in results }}} def count ( self , filter : str = None , endpoint : Optional [ str ] = None ) -> Dict [ str , Dict [ str , Dict [ str , Optional [ int ]]]]: \"\"\"Counts the number of results for the filter, requiring only 1 request per provider by making use of the `meta->data_returned` key. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the number of query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Counting results for [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , page_limit = 1 , paginate = False , response_fields = None , sort = None , ) count_results = {} for base_url in results : count_results [ base_url ] = results [ base_url ] . meta . get ( \"data_returned\" , None ) if count_results [ base_url ] is None : self . _progress . print ( f \"Warning: { base_url } did not return a value for `meta->data_returned`, unable to count results.\" ) self . count_results [ endpoint ][ filter ] = count_results return { endpoint : { filter : count_results }} def _execute_queries ( self , filter : str , endpoint : str , page_limit : Optional [ int ], paginate : bool , response_fields : Optional [ List [ str ]], sort : Optional [ str ], ) -> Dict [ str , QueryResults ]: \"\"\"Executes the queries over the base URLs either asynchronously or serially, depending on the `self.use_async` setting. Parameters: filter: The OPTIMADE filter string. endpoint: The OPTIMADE endpoint to query. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. Returns: A mapping from base URL to `QueryResults` for each queried API. \"\"\" if self . use_async : # Check for a pre-existing event loop (e.g. within a Jupyter notebook) # and use it if present try : event_loop = asyncio . get_running_loop () if event_loop : self . _progress . print ( \"Detected a running event loop (e.g., Jupyter, pytest). Running in synchronous mode.\" ) except RuntimeError : event_loop = None if self . use_async and not event_loop : results = asyncio . run ( self . _get_all_async ( endpoint , filter , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) ) else : results = self . _get_all ( endpoint , filter , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) return results def get_one ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query synchronously on one API. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return self . _get_one ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results } async def _get_all_async ( self , endpoint : str , filter : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query asynchronously across all defined APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" results = await asyncio . gather ( * [ self . get_one_async ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) for base_url in self . base_urls ] ) return functools . reduce ( lambda r1 , r2 : { ** r1 , ** r2 }, results ) def _get_all ( self , endpoint : str , filter : str , page_limit : Optional [ int ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query synchronously across all defined APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" results = [ self . get_one ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) for base_url in self . base_urls ] if results : return functools . reduce ( lambda r1 , r2 : { ** r1 , ** r2 }, results ) return None async def get_one_async ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query asynchronously on one API. !!! note This method currently makes non-blocking requests to a single API, but these requests are executed serially on that API, i.e., results are pulled one page at a time, but requests will not block other async requests to other APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return await self . _get_one_async ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError , Exception , ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results } async def _get_one_async ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"See [`OptimadeClient.get_one_async`][optimade.client.OptimadeClient.get_one_async].\"\"\" next_url , _task = self . _setup ( endpoint = endpoint , base_url = base_url , filter = filter , page_limit = page_limit , response_fields = response_fields , sort = sort , ) results = QueryResults () try : async with httpx . AsyncClient ( headers = self . headers ) as client : while next_url : attempts = 0 try : r = await client . get ( next_url , follow_redirects = True , timeout = self . http_timeout ) page_results , next_url = self . _handle_response ( r , _task ) except RecoverableHTTPError : attempts += 1 if attempts > self . max_attempts : raise RuntimeError ( f \"Exceeded maximum number of retries for { next_url } \" ) await asyncio . sleep ( 1 ) continue results . update ( page_results ) if not paginate : break if ( self . max_results_per_provider and len ( results . data ) >= self . max_results_per_provider ): self . _progress . print ( f \"Reached { len ( results . data ) } results for { base_url } , exceeding `max_results_per_provider` parameter ( { self . max_results_per_provider } ). Stopping download.\" ) break return { str ( base_url ): results } finally : self . _teardown ( _task , len ( results . data )) def _get_one ( self , endpoint : str , filter : str , base_url : str , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , response_fields : Optional [ List [ str ]] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"See [`OptimadeClient.get_one`][optimade.client.OptimadeClient.get_one].\"\"\" next_url , _task = self . _setup ( endpoint = endpoint , base_url = base_url , filter = filter , page_limit = page_limit , response_fields = response_fields , sort = sort , ) results = QueryResults () try : with httpx . Client ( headers = self . headers ) as client : while next_url : attempts = 0 try : r = client . get ( next_url , follow_redirects = True , timeout = self . http_timeout ) page_results , next_url = self . _handle_response ( r , _task ) except RecoverableHTTPError : attempts += 1 if attempts > self . max_attempts : raise RuntimeError ( f \"Exceeded maximum number of retries for { next_url } \" ) time . sleep ( 1 ) continue results . update ( page_results ) if ( self . max_results_per_provider and len ( results . data ) >= self . max_results_per_provider ): self . _progress . print ( f \"Reached { len ( results . data ) } results for { base_url } , exceeding `max_results_per_provider` parameter ( { self . max_results_per_provider } ). Stopping download.\" ) break if not paginate : break return { str ( base_url ): results } finally : self . _teardown ( _task , len ( results . data )) def _setup ( self , endpoint : str , base_url : str , filter : str , page_limit : Optional [ int ], response_fields : Optional [ List [ str ]], sort : Optional [ str ], ) -> Tuple [ str , TaskID ]: \"\"\"Constructs the first query URL and creates the progress bar task. Returns: The URL for the first query and the Rich TaskID for progress logging. \"\"\" url = self . _build_url ( base_url = base_url , endpoint = endpoint , filter = filter , page_limit = page_limit , response_fields = response_fields , sort = sort , ) parsed_url = urlparse ( url ) _task = self . _progress . add_task ( description = parsed_url . netloc + parsed_url . path , total = None , ) return url , _task def _build_url ( self , base_url : str , endpoint : Optional [ str ] = \"structures\" , version : Optional [ str ] = None , filter : Optional [ str ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , ) -> str : \"\"\"Builds the URL to query based on the passed parameters. Parameters: base_url: The server's base URL. endpoint: The endpoint to query. version: The OPTIMADE version string. filter: The filter to apply to the endpoint. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: The page limit for an individual request. Returns: The overall query URL, including parameters. \"\"\" if not version : version = f 'v { __api_version__ . split ( \".\" )[ 0 ] } ' while base_url . endswith ( \"/\" ): base_url = base_url [: - 1 ] url = f \" { base_url } / { version } / { endpoint } \" # Handle params _filter : Optional [ str ] = None _response_fields : Optional [ str ] = None _page_limit : Optional [ str ] = None _sort : Optional [ str ] = None if filter : _filter = f \"filter= { filter } \" if response_fields : _response_fields = f 'response_fields= { \",\" . join ( response_fields ) } ' if page_limit : _page_limit = f \"page_limit= { page_limit } \" if sort : _sort = f \"sort= { sort } \" params = ( _filter , _response_fields , _page_limit , _sort ) params = \"&\" . join ( p for p in params if p ) if params : url += f \"? { params } \" return url def _check_filter ( self , filter : str , endpoint : str ) -> None : \"\"\"Passes the filter through [`LarkParser`][optimade.filterparser.LarkParser] from the optimade-python-tools reference server implementation. Parameters: filter: The filter string. endpoint: The endpoint being queried. If this endpoint is not \"known\" to OPTIMADE, the filter will automatically pass. Raises: RuntimeError: If the filter cannot be parsed. \"\"\" try : if endpoint in ENDPOINTS : parser = LarkParser () parser . parse ( filter ) except BadRequest as exc : self . _progress . print ( f \"[bold red]Filter [blue i] { filter !r} [/blue i] could not be parsed as an OPTIMADE filter.[/bold red]\" , Panel ( f \"[magenta] { exc } [/magenta]\" ), ) with silent_raise (): raise RuntimeError ( exc ) from None def _handle_response ( self , response : httpx . Response , _task : TaskID ) -> Tuple [ Dict [ str , Any ], str ]: \"\"\"Handle the response from the server. Parameters: response: The response from the server. _task: The Rich TaskID for this task's progressbar. Returns: A dictionary containing the results, and a link to the next page, if it exists. \"\"\" # Handle error statuses if response . status_code == 429 : raise TooManyRequestsException ( response . content ) if response . status_code != 200 : try : errors = response . json () . get ( \"errors\" ) error_message = \" \\n \" . join ( [ f \" { error [ 'title' ] } : { error [ 'detail' ] } \" for error in errors ] ) except Exception : error_message = str ( response . content ) raise RuntimeError ( f \" { response . status_code } - { response . url } : { error_message } \" ) try : r = response . json () except json . JSONDecodeError as exc : raise RuntimeError ( f \"Could not decode response as JSON: { response . content } \" ) from exc # Accumulate results with correct empty containers if missing results = { \"data\" : r . get ( \"data\" , []), \"meta\" : r . get ( \"meta\" , {}), \"links\" : r . get ( \"links\" , {}), \"included\" : r . get ( \"included\" , []), \"errors\" : r . get ( \"errors\" , []), } # Advance the progress bar for this provider self . _progress . update ( _task , advance = len ( results [ \"data\" ]), total = results [ \"meta\" ] . get ( \"data_returned\" , None ), ) next_url = results [ \"links\" ] . get ( \"next\" , None ) if isinstance ( next_url , dict ): next_url = next_url . pop ( \"href\" ) return results , next_url def _teardown ( self , _task : TaskID , num_results : int ) -> None : \"\"\"Update the finished status of the progress bar depending on the number of results. Parameters: _task: The Rich TaskID for this task's progressbar. num_results: The number of data entries returned. \"\"\" if num_results == 0 : self . _progress . update ( _task , total = None , finished = False , complete = True ) else : self . _progress . update ( _task , total = num_results , finished = True , complete = True ) __current_endpoint : Optional [ str ] = None class-attribute \u00b6 Used internally when querying via client.structures.get() to set the chosen endpoint. Should be reset to None outside of all get() calls. all_results : Dict [ str , Dict [ str , Dict [ str , QueryResults ]]] = defaultdict ( dict ) class-attribute \u00b6 A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the results from each base URL for that particular filter. count_results : Dict [ str , Dict [ str , Dict [ str , int ]]] = defaultdict ( dict ) class-attribute \u00b6 A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the number of results from each base URL for that particular filter. headers : Dict = { 'User-Agent' : f 'optimade-python-tools/ { __version__ } ' } class-attribute \u00b6 Additional HTTP headers. __getattribute__ ( name ) \u00b6 Allows entry endpoints to be queried via attribute access, using the allowed list for this module. Should also pass through any extensions/<example> endpoints. Any non-entry-endpoint name requested will be passed to the original __getattribute__ . Example from optimade.client import OptimadeClient cli = OptimadeClient () structures = cli . structures . get () references = cli . references . get () info_structures = cli . info . structures . get () Source code in optimade/client/client.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 def __getattribute__ ( self , name ): \"\"\"Allows entry endpoints to be queried via attribute access, using the allowed list for this module. Should also pass through any `extensions/<example>` endpoints. Any non-entry-endpoint name requested will be passed to the original `__getattribute__`. !!! example ```python from optimade.client import OptimadeClient cli = OptimadeClient() structures = cli.structures.get() references = cli.references.get() info_structures = cli.info.structures.get() ``` \"\"\" if name in ENDPOINTS : if self . __current_endpoint == \"info\" : self . __current_endpoint = f \"info/ { name } \" elif self . __current_endpoint == \"extensions\" : self . __current_endpoint = f \"extensions/ { name } \" else : self . __current_endpoint = name return self return super () . __getattribute__ ( name ) __init__ ( base_urls = None , max_results_per_provider = 1000 , headers = None , http_timeout = 10 , max_attempts = 5 , use_async = True ) \u00b6 Create the OPTIMADE client object. Parameters: Name Type Description Default base_urls Union [None, AnyUrl , List [ AnyUrl ]] A list of OPTIMADE base URLs to query. None max_results_per_provider int The maximum number of results to download from each provider. 1000 headers Optional [ Dict ] Any additional HTTP headers to use for the queries. None http_timeout int The HTTP timeout to use per request. 10 max_attempts int The maximum number of times to repeat a failing query. 5 use_async bool Whether or not to make all requests asynchronously. True Source code in optimade/client/client.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def __init__ ( self , base_urls : Union [ None , AnyUrl , List [ AnyUrl ]] = None , max_results_per_provider : int = 1000 , headers : Optional [ Dict ] = None , http_timeout : int = 10 , max_attempts : int = 5 , use_async : bool = True , ): \"\"\"Create the OPTIMADE client object. Parameters: base_urls: A list of OPTIMADE base URLs to query. max_results_per_provider: The maximum number of results to download from each provider. headers: Any additional HTTP headers to use for the queries. http_timeout: The HTTP timeout to use per request. max_attempts: The maximum number of times to repeat a failing query. use_async: Whether or not to make all requests asynchronously. \"\"\" if not base_urls : base_urls = get_all_databases () self . max_results_per_provider = max_results_per_provider if self . max_results_per_provider in ( - 1 , 0 ): self . max_results_per_provider = None self . base_urls = base_urls if isinstance ( self . base_urls , str ): self . base_urls = [ self . base_urls ] self . base_urls = list ( self . base_urls ) if not self . base_urls : raise SystemExit ( \"Unable to access any OPTIMADE base URLs. If you believe this is an error, try manually specifying some base URLs.\" ) if headers : self . headers . update ( headers ) self . http_timeout = http_timeout self . max_attempts = max_attempts self . use_async = use_async count ( filter = None , endpoint = None ) \u00b6 Counts the number of results for the filter, requiring only 1 request per provider by making use of the meta->data_returned key. Raises: Type Description RuntimeError If the query could not be executed. Returns: Type Description Dict [ str , Dict [ str , Dict [ str , Optional [ int ]]]] A nested mapping from endpoint, filter and base URL to the number of query results. Source code in optimade/client/client.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 def count ( self , filter : str = None , endpoint : Optional [ str ] = None ) -> Dict [ str , Dict [ str , Dict [ str , Optional [ int ]]]]: \"\"\"Counts the number of results for the filter, requiring only 1 request per provider by making use of the `meta->data_returned` key. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the number of query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Counting results for [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , page_limit = 1 , paginate = False , response_fields = None , sort = None , ) count_results = {} for base_url in results : count_results [ base_url ] = results [ base_url ] . meta . get ( \"data_returned\" , None ) if count_results [ base_url ] is None : self . _progress . print ( f \"Warning: { base_url } did not return a value for `meta->data_returned`, unable to count results.\" ) self . count_results [ endpoint ][ filter ] = count_results return { endpoint : { filter : count_results }} get ( filter = None , endpoint = None , response_fields = None , sort = None ) \u00b6 Gets the results from the endpoint and filter across the defined OPTIMADE APIs. Parameters: Name Type Description Default filter str The OPTIMADE filter string for the query. None endpoint Optional [ str ] The endpoint to query. None response_fields Optional [ List [ str ]] A list of response fields to request from the server. None sort Optional [ str ] The field by which to sort the results. None Raises: Type Description RuntimeError If the query could not be executed. Returns: Type Description Dict [ str , Dict [ str , Dict [ str , Dict ]]] A nested mapping from endpoint, filter and base URL to the query results. Source code in optimade/client/client.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def get ( self , filter : str = None , endpoint : Optional [ str ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , ) -> Dict [ str , Dict [ str , Dict [ str , Dict ]]]: \"\"\"Gets the results from the endpoint and filter across the defined OPTIMADE APIs. Parameters: filter: The OPTIMADE filter string for the query. endpoint: The endpoint to query. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Performing query [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , response_fields = response_fields , page_limit = None , paginate = True , sort = sort , ) self . all_results [ endpoint ][ filter ] = results return { endpoint : { filter : { k : results [ k ] . dict () for k in results }}} get_one ( endpoint , filter , base_url , response_fields = None , sort = None , page_limit = None , paginate = True ) \u00b6 Executes the query synchronously on one API. Parameters: Name Type Description Default endpoint str The OPTIMADE endpoint to query. required filter str The OPTIMADE filter string. required response_fields Optional [ List [ str ]] A list of response fields to request from the server. None sort Optional [ str ] The field by which to sort the results. None page_limit Optional [ int ] A page limit to enforce for each query (used in conjunction with paginate ). None paginate bool Whether to pull all pages of results (up to the value of max_results_per_provider ) or whether to return after one page. True Returns: Type Description Dict [ str , QueryResults ] A dictionary mapping from base URL to the results of the query. Source code in optimade/client/client.py 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 def get_one ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query synchronously on one API. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return self . _get_one ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results } get_one_async ( endpoint , filter , base_url , response_fields = None , sort = None , page_limit = None , paginate = True ) async \u00b6 Executes the query asynchronously on one API. Note This method currently makes non-blocking requests to a single API, but these requests are executed serially on that API, i.e., results are pulled one page at a time, but requests will not block other async requests to other APIs. Parameters: Name Type Description Default endpoint str The OPTIMADE endpoint to query. required filter str The OPTIMADE filter string. required response_fields Optional [ List [ str ]] A list of response fields to request from the server. None sort Optional [ str ] The field by which to sort the results. None page_limit Optional [ int ] A page limit to enforce for each query (used in conjunction with paginate ). None paginate bool Whether to pull all pages of results (up to the value of max_results_per_provider ) or whether to return after one page. True Returns: Type Description Dict [ str , QueryResults ] A dictionary mapping from base URL to the results of the query. Source code in optimade/client/client.py 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 async def get_one_async ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query asynchronously on one API. !!! note This method currently makes non-blocking requests to a single API, but these requests are executed serially on that API, i.e., results are pulled one page at a time, but requests will not block other async requests to other APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return await self . _get_one_async ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError , Exception , ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results }","title":"client"},{"location":"api_reference/client/client/#client","text":"This module implements OPTIMADE client functionality for: making web requests to filter and harvest resources from OPTIMADE APIs, query multiple providers simultaneously.","title":"client"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient","text":"This class implemements a client for executing the same queries across multiple OPTIMADE APIs simultaneously, paging and caching the results. By default, all registered OPTIMADE providers will be queried simulateneously and asynchronously, with the results collected into the all_results attribute, keyed by endpoint, filter and provider. Source code in optimade/client/client.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 class OptimadeClient : \"\"\"This class implemements a client for executing the same queries across multiple OPTIMADE APIs simultaneously, paging and caching the results. By default, all registered OPTIMADE providers will be queried simulateneously and asynchronously, with the results collected into the `all_results` attribute, keyed by endpoint, filter and provider. \"\"\" base_urls : Union [ AnyUrl , Iterable [ AnyUrl ]] \"\"\"A list (or any iterable) of OPTIMADE base URLs to query.\"\"\" all_results : Dict [ str , Dict [ str , Dict [ str , QueryResults ]]] = defaultdict ( dict ) \"\"\"A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the results from each base URL for that particular filter. \"\"\" count_results : Dict [ str , Dict [ str , Dict [ str , int ]]] = defaultdict ( dict ) \"\"\"A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the number of results from each base URL for that particular filter. \"\"\" max_results_per_provider : Optional [ int ] = None \"\"\"Maximum number of results to downlod per provider. If None, will download all. \"\"\" headers : Dict = { \"User-Agent\" : f \"optimade-python-tools/ { __version__ } \" } \"\"\"Additional HTTP headers.\"\"\" http_timeout : int \"\"\"The timeout to use for each HTTP request.\"\"\" max_attempts : int \"\"\"The maximum number of times to repeat a failed query before giving up.\"\"\" use_async : bool \"\"\"Whether or not to make all requests asynchronously using asyncio.\"\"\" __current_endpoint : Optional [ str ] = None \"\"\"Used internally when querying via `client.structures.get()` to set the chosen endpoint. Should be reset to `None` outside of all `get()` calls.\"\"\" def __init__ ( self , base_urls : Union [ None , AnyUrl , List [ AnyUrl ]] = None , max_results_per_provider : int = 1000 , headers : Optional [ Dict ] = None , http_timeout : int = 10 , max_attempts : int = 5 , use_async : bool = True , ): \"\"\"Create the OPTIMADE client object. Parameters: base_urls: A list of OPTIMADE base URLs to query. max_results_per_provider: The maximum number of results to download from each provider. headers: Any additional HTTP headers to use for the queries. http_timeout: The HTTP timeout to use per request. max_attempts: The maximum number of times to repeat a failing query. use_async: Whether or not to make all requests asynchronously. \"\"\" if not base_urls : base_urls = get_all_databases () self . max_results_per_provider = max_results_per_provider if self . max_results_per_provider in ( - 1 , 0 ): self . max_results_per_provider = None self . base_urls = base_urls if isinstance ( self . base_urls , str ): self . base_urls = [ self . base_urls ] self . base_urls = list ( self . base_urls ) if not self . base_urls : raise SystemExit ( \"Unable to access any OPTIMADE base URLs. If you believe this is an error, try manually specifying some base URLs.\" ) if headers : self . headers . update ( headers ) self . http_timeout = http_timeout self . max_attempts = max_attempts self . use_async = use_async def __getattribute__ ( self , name ): \"\"\"Allows entry endpoints to be queried via attribute access, using the allowed list for this module. Should also pass through any `extensions/<example>` endpoints. Any non-entry-endpoint name requested will be passed to the original `__getattribute__`. !!! example ```python from optimade.client import OptimadeClient cli = OptimadeClient() structures = cli.structures.get() references = cli.references.get() info_structures = cli.info.structures.get() ``` \"\"\" if name in ENDPOINTS : if self . __current_endpoint == \"info\" : self . __current_endpoint = f \"info/ { name } \" elif self . __current_endpoint == \"extensions\" : self . __current_endpoint = f \"extensions/ { name } \" else : self . __current_endpoint = name return self return super () . __getattribute__ ( name ) def get ( self , filter : str = None , endpoint : Optional [ str ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , ) -> Dict [ str , Dict [ str , Dict [ str , Dict ]]]: \"\"\"Gets the results from the endpoint and filter across the defined OPTIMADE APIs. Parameters: filter: The OPTIMADE filter string for the query. endpoint: The endpoint to query. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Performing query [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , response_fields = response_fields , page_limit = None , paginate = True , sort = sort , ) self . all_results [ endpoint ][ filter ] = results return { endpoint : { filter : { k : results [ k ] . dict () for k in results }}} def count ( self , filter : str = None , endpoint : Optional [ str ] = None ) -> Dict [ str , Dict [ str , Dict [ str , Optional [ int ]]]]: \"\"\"Counts the number of results for the filter, requiring only 1 request per provider by making use of the `meta->data_returned` key. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the number of query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Counting results for [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , page_limit = 1 , paginate = False , response_fields = None , sort = None , ) count_results = {} for base_url in results : count_results [ base_url ] = results [ base_url ] . meta . get ( \"data_returned\" , None ) if count_results [ base_url ] is None : self . _progress . print ( f \"Warning: { base_url } did not return a value for `meta->data_returned`, unable to count results.\" ) self . count_results [ endpoint ][ filter ] = count_results return { endpoint : { filter : count_results }} def _execute_queries ( self , filter : str , endpoint : str , page_limit : Optional [ int ], paginate : bool , response_fields : Optional [ List [ str ]], sort : Optional [ str ], ) -> Dict [ str , QueryResults ]: \"\"\"Executes the queries over the base URLs either asynchronously or serially, depending on the `self.use_async` setting. Parameters: filter: The OPTIMADE filter string. endpoint: The OPTIMADE endpoint to query. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. Returns: A mapping from base URL to `QueryResults` for each queried API. \"\"\" if self . use_async : # Check for a pre-existing event loop (e.g. within a Jupyter notebook) # and use it if present try : event_loop = asyncio . get_running_loop () if event_loop : self . _progress . print ( \"Detected a running event loop (e.g., Jupyter, pytest). Running in synchronous mode.\" ) except RuntimeError : event_loop = None if self . use_async and not event_loop : results = asyncio . run ( self . _get_all_async ( endpoint , filter , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) ) else : results = self . _get_all ( endpoint , filter , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) return results def get_one ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query synchronously on one API. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return self . _get_one ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results } async def _get_all_async ( self , endpoint : str , filter : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query asynchronously across all defined APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" results = await asyncio . gather ( * [ self . get_one_async ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) for base_url in self . base_urls ] ) return functools . reduce ( lambda r1 , r2 : { ** r1 , ** r2 }, results ) def _get_all ( self , endpoint : str , filter : str , page_limit : Optional [ int ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query synchronously across all defined APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" results = [ self . get_one ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) for base_url in self . base_urls ] if results : return functools . reduce ( lambda r1 , r2 : { ** r1 , ** r2 }, results ) return None async def get_one_async ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query asynchronously on one API. !!! note This method currently makes non-blocking requests to a single API, but these requests are executed serially on that API, i.e., results are pulled one page at a time, but requests will not block other async requests to other APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return await self . _get_one_async ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError , Exception , ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results } async def _get_one_async ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"See [`OptimadeClient.get_one_async`][optimade.client.OptimadeClient.get_one_async].\"\"\" next_url , _task = self . _setup ( endpoint = endpoint , base_url = base_url , filter = filter , page_limit = page_limit , response_fields = response_fields , sort = sort , ) results = QueryResults () try : async with httpx . AsyncClient ( headers = self . headers ) as client : while next_url : attempts = 0 try : r = await client . get ( next_url , follow_redirects = True , timeout = self . http_timeout ) page_results , next_url = self . _handle_response ( r , _task ) except RecoverableHTTPError : attempts += 1 if attempts > self . max_attempts : raise RuntimeError ( f \"Exceeded maximum number of retries for { next_url } \" ) await asyncio . sleep ( 1 ) continue results . update ( page_results ) if not paginate : break if ( self . max_results_per_provider and len ( results . data ) >= self . max_results_per_provider ): self . _progress . print ( f \"Reached { len ( results . data ) } results for { base_url } , exceeding `max_results_per_provider` parameter ( { self . max_results_per_provider } ). Stopping download.\" ) break return { str ( base_url ): results } finally : self . _teardown ( _task , len ( results . data )) def _get_one ( self , endpoint : str , filter : str , base_url : str , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , response_fields : Optional [ List [ str ]] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"See [`OptimadeClient.get_one`][optimade.client.OptimadeClient.get_one].\"\"\" next_url , _task = self . _setup ( endpoint = endpoint , base_url = base_url , filter = filter , page_limit = page_limit , response_fields = response_fields , sort = sort , ) results = QueryResults () try : with httpx . Client ( headers = self . headers ) as client : while next_url : attempts = 0 try : r = client . get ( next_url , follow_redirects = True , timeout = self . http_timeout ) page_results , next_url = self . _handle_response ( r , _task ) except RecoverableHTTPError : attempts += 1 if attempts > self . max_attempts : raise RuntimeError ( f \"Exceeded maximum number of retries for { next_url } \" ) time . sleep ( 1 ) continue results . update ( page_results ) if ( self . max_results_per_provider and len ( results . data ) >= self . max_results_per_provider ): self . _progress . print ( f \"Reached { len ( results . data ) } results for { base_url } , exceeding `max_results_per_provider` parameter ( { self . max_results_per_provider } ). Stopping download.\" ) break if not paginate : break return { str ( base_url ): results } finally : self . _teardown ( _task , len ( results . data )) def _setup ( self , endpoint : str , base_url : str , filter : str , page_limit : Optional [ int ], response_fields : Optional [ List [ str ]], sort : Optional [ str ], ) -> Tuple [ str , TaskID ]: \"\"\"Constructs the first query URL and creates the progress bar task. Returns: The URL for the first query and the Rich TaskID for progress logging. \"\"\" url = self . _build_url ( base_url = base_url , endpoint = endpoint , filter = filter , page_limit = page_limit , response_fields = response_fields , sort = sort , ) parsed_url = urlparse ( url ) _task = self . _progress . add_task ( description = parsed_url . netloc + parsed_url . path , total = None , ) return url , _task def _build_url ( self , base_url : str , endpoint : Optional [ str ] = \"structures\" , version : Optional [ str ] = None , filter : Optional [ str ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , ) -> str : \"\"\"Builds the URL to query based on the passed parameters. Parameters: base_url: The server's base URL. endpoint: The endpoint to query. version: The OPTIMADE version string. filter: The filter to apply to the endpoint. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: The page limit for an individual request. Returns: The overall query URL, including parameters. \"\"\" if not version : version = f 'v { __api_version__ . split ( \".\" )[ 0 ] } ' while base_url . endswith ( \"/\" ): base_url = base_url [: - 1 ] url = f \" { base_url } / { version } / { endpoint } \" # Handle params _filter : Optional [ str ] = None _response_fields : Optional [ str ] = None _page_limit : Optional [ str ] = None _sort : Optional [ str ] = None if filter : _filter = f \"filter= { filter } \" if response_fields : _response_fields = f 'response_fields= { \",\" . join ( response_fields ) } ' if page_limit : _page_limit = f \"page_limit= { page_limit } \" if sort : _sort = f \"sort= { sort } \" params = ( _filter , _response_fields , _page_limit , _sort ) params = \"&\" . join ( p for p in params if p ) if params : url += f \"? { params } \" return url def _check_filter ( self , filter : str , endpoint : str ) -> None : \"\"\"Passes the filter through [`LarkParser`][optimade.filterparser.LarkParser] from the optimade-python-tools reference server implementation. Parameters: filter: The filter string. endpoint: The endpoint being queried. If this endpoint is not \"known\" to OPTIMADE, the filter will automatically pass. Raises: RuntimeError: If the filter cannot be parsed. \"\"\" try : if endpoint in ENDPOINTS : parser = LarkParser () parser . parse ( filter ) except BadRequest as exc : self . _progress . print ( f \"[bold red]Filter [blue i] { filter !r} [/blue i] could not be parsed as an OPTIMADE filter.[/bold red]\" , Panel ( f \"[magenta] { exc } [/magenta]\" ), ) with silent_raise (): raise RuntimeError ( exc ) from None def _handle_response ( self , response : httpx . Response , _task : TaskID ) -> Tuple [ Dict [ str , Any ], str ]: \"\"\"Handle the response from the server. Parameters: response: The response from the server. _task: The Rich TaskID for this task's progressbar. Returns: A dictionary containing the results, and a link to the next page, if it exists. \"\"\" # Handle error statuses if response . status_code == 429 : raise TooManyRequestsException ( response . content ) if response . status_code != 200 : try : errors = response . json () . get ( \"errors\" ) error_message = \" \\n \" . join ( [ f \" { error [ 'title' ] } : { error [ 'detail' ] } \" for error in errors ] ) except Exception : error_message = str ( response . content ) raise RuntimeError ( f \" { response . status_code } - { response . url } : { error_message } \" ) try : r = response . json () except json . JSONDecodeError as exc : raise RuntimeError ( f \"Could not decode response as JSON: { response . content } \" ) from exc # Accumulate results with correct empty containers if missing results = { \"data\" : r . get ( \"data\" , []), \"meta\" : r . get ( \"meta\" , {}), \"links\" : r . get ( \"links\" , {}), \"included\" : r . get ( \"included\" , []), \"errors\" : r . get ( \"errors\" , []), } # Advance the progress bar for this provider self . _progress . update ( _task , advance = len ( results [ \"data\" ]), total = results [ \"meta\" ] . get ( \"data_returned\" , None ), ) next_url = results [ \"links\" ] . get ( \"next\" , None ) if isinstance ( next_url , dict ): next_url = next_url . pop ( \"href\" ) return results , next_url def _teardown ( self , _task : TaskID , num_results : int ) -> None : \"\"\"Update the finished status of the progress bar depending on the number of results. Parameters: _task: The Rich TaskID for this task's progressbar. num_results: The number of data entries returned. \"\"\" if num_results == 0 : self . _progress . update ( _task , total = None , finished = False , complete = True ) else : self . _progress . update ( _task , total = num_results , finished = True , complete = True )","title":"OptimadeClient"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.__current_endpoint","text":"Used internally when querying via client.structures.get() to set the chosen endpoint. Should be reset to None outside of all get() calls.","title":"__current_endpoint"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.all_results","text":"A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the results from each base URL for that particular filter.","title":"all_results"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.count_results","text":"A nested dictionary keyed by endpoint and OPTIMADE filter string that contains the number of results from each base URL for that particular filter.","title":"count_results"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.headers","text":"Additional HTTP headers.","title":"headers"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.__getattribute__","text":"Allows entry endpoints to be queried via attribute access, using the allowed list for this module. Should also pass through any extensions/<example> endpoints. Any non-entry-endpoint name requested will be passed to the original __getattribute__ . Example from optimade.client import OptimadeClient cli = OptimadeClient () structures = cli . structures . get () references = cli . references . get () info_structures = cli . info . structures . get () Source code in optimade/client/client.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 def __getattribute__ ( self , name ): \"\"\"Allows entry endpoints to be queried via attribute access, using the allowed list for this module. Should also pass through any `extensions/<example>` endpoints. Any non-entry-endpoint name requested will be passed to the original `__getattribute__`. !!! example ```python from optimade.client import OptimadeClient cli = OptimadeClient() structures = cli.structures.get() references = cli.references.get() info_structures = cli.info.structures.get() ``` \"\"\" if name in ENDPOINTS : if self . __current_endpoint == \"info\" : self . __current_endpoint = f \"info/ { name } \" elif self . __current_endpoint == \"extensions\" : self . __current_endpoint = f \"extensions/ { name } \" else : self . __current_endpoint = name return self return super () . __getattribute__ ( name )","title":"__getattribute__()"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.__init__","text":"Create the OPTIMADE client object. Parameters: Name Type Description Default base_urls Union [None, AnyUrl , List [ AnyUrl ]] A list of OPTIMADE base URLs to query. None max_results_per_provider int The maximum number of results to download from each provider. 1000 headers Optional [ Dict ] Any additional HTTP headers to use for the queries. None http_timeout int The HTTP timeout to use per request. 10 max_attempts int The maximum number of times to repeat a failing query. 5 use_async bool Whether or not to make all requests asynchronously. True Source code in optimade/client/client.py 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 def __init__ ( self , base_urls : Union [ None , AnyUrl , List [ AnyUrl ]] = None , max_results_per_provider : int = 1000 , headers : Optional [ Dict ] = None , http_timeout : int = 10 , max_attempts : int = 5 , use_async : bool = True , ): \"\"\"Create the OPTIMADE client object. Parameters: base_urls: A list of OPTIMADE base URLs to query. max_results_per_provider: The maximum number of results to download from each provider. headers: Any additional HTTP headers to use for the queries. http_timeout: The HTTP timeout to use per request. max_attempts: The maximum number of times to repeat a failing query. use_async: Whether or not to make all requests asynchronously. \"\"\" if not base_urls : base_urls = get_all_databases () self . max_results_per_provider = max_results_per_provider if self . max_results_per_provider in ( - 1 , 0 ): self . max_results_per_provider = None self . base_urls = base_urls if isinstance ( self . base_urls , str ): self . base_urls = [ self . base_urls ] self . base_urls = list ( self . base_urls ) if not self . base_urls : raise SystemExit ( \"Unable to access any OPTIMADE base URLs. If you believe this is an error, try manually specifying some base URLs.\" ) if headers : self . headers . update ( headers ) self . http_timeout = http_timeout self . max_attempts = max_attempts self . use_async = use_async","title":"__init__()"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.count","text":"Counts the number of results for the filter, requiring only 1 request per provider by making use of the meta->data_returned key. Raises: Type Description RuntimeError If the query could not be executed. Returns: Type Description Dict [ str , Dict [ str , Dict [ str , Optional [ int ]]]] A nested mapping from endpoint, filter and base URL to the number of query results. Source code in optimade/client/client.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 def count ( self , filter : str = None , endpoint : Optional [ str ] = None ) -> Dict [ str , Dict [ str , Dict [ str , Optional [ int ]]]]: \"\"\"Counts the number of results for the filter, requiring only 1 request per provider by making use of the `meta->data_returned` key. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the number of query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Counting results for [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , page_limit = 1 , paginate = False , response_fields = None , sort = None , ) count_results = {} for base_url in results : count_results [ base_url ] = results [ base_url ] . meta . get ( \"data_returned\" , None ) if count_results [ base_url ] is None : self . _progress . print ( f \"Warning: { base_url } did not return a value for `meta->data_returned`, unable to count results.\" ) self . count_results [ endpoint ][ filter ] = count_results return { endpoint : { filter : count_results }}","title":"count()"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.get","text":"Gets the results from the endpoint and filter across the defined OPTIMADE APIs. Parameters: Name Type Description Default filter str The OPTIMADE filter string for the query. None endpoint Optional [ str ] The endpoint to query. None response_fields Optional [ List [ str ]] A list of response fields to request from the server. None sort Optional [ str ] The field by which to sort the results. None Raises: Type Description RuntimeError If the query could not be executed. Returns: Type Description Dict [ str , Dict [ str , Dict [ str , Dict ]]] A nested mapping from endpoint, filter and base URL to the query results. Source code in optimade/client/client.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 def get ( self , filter : str = None , endpoint : Optional [ str ] = None , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , ) -> Dict [ str , Dict [ str , Dict [ str , Dict ]]]: \"\"\"Gets the results from the endpoint and filter across the defined OPTIMADE APIs. Parameters: filter: The OPTIMADE filter string for the query. endpoint: The endpoint to query. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. Raises: RuntimeError: If the query could not be executed. Returns: A nested mapping from endpoint, filter and base URL to the query results. \"\"\" if endpoint is None : if self . __current_endpoint is not None : endpoint = self . __current_endpoint self . __current_endpoint = None else : endpoint = \"structures\" if filter is None : filter = \"\" self . _check_filter ( filter , endpoint ) self . _progress = OptimadeClientProgress () with self . _progress : self . _progress . print ( Panel ( f \"Performing query [bold yellow] { endpoint } [/bold yellow]/?filter=[bold magenta][i] { filter } [/i][/bold magenta]\" , expand = False , ) ) results = self . _execute_queries ( filter , endpoint , response_fields = response_fields , page_limit = None , paginate = True , sort = sort , ) self . all_results [ endpoint ][ filter ] = results return { endpoint : { filter : { k : results [ k ] . dict () for k in results }}}","title":"get()"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.get_one","text":"Executes the query synchronously on one API. Parameters: Name Type Description Default endpoint str The OPTIMADE endpoint to query. required filter str The OPTIMADE filter string. required response_fields Optional [ List [ str ]] A list of response fields to request from the server. None sort Optional [ str ] The field by which to sort the results. None page_limit Optional [ int ] A page limit to enforce for each query (used in conjunction with paginate ). None paginate bool Whether to pull all pages of results (up to the value of max_results_per_provider ) or whether to return after one page. True Returns: Type Description Dict [ str , QueryResults ] A dictionary mapping from base URL to the results of the query. Source code in optimade/client/client.py 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 def get_one ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query synchronously on one API. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return self . _get_one ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results }","title":"get_one()"},{"location":"api_reference/client/client/#optimade.client.client.OptimadeClient.get_one_async","text":"Executes the query asynchronously on one API. Note This method currently makes non-blocking requests to a single API, but these requests are executed serially on that API, i.e., results are pulled one page at a time, but requests will not block other async requests to other APIs. Parameters: Name Type Description Default endpoint str The OPTIMADE endpoint to query. required filter str The OPTIMADE filter string. required response_fields Optional [ List [ str ]] A list of response fields to request from the server. None sort Optional [ str ] The field by which to sort the results. None page_limit Optional [ int ] A page limit to enforce for each query (used in conjunction with paginate ). None paginate bool Whether to pull all pages of results (up to the value of max_results_per_provider ) or whether to return after one page. True Returns: Type Description Dict [ str , QueryResults ] A dictionary mapping from base URL to the results of the query. Source code in optimade/client/client.py 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 async def get_one_async ( self , endpoint : str , filter : str , base_url : str , response_fields : Optional [ List [ str ]] = None , sort : Optional [ str ] = None , page_limit : Optional [ int ] = None , paginate : bool = True , ) -> Dict [ str , QueryResults ]: \"\"\"Executes the query asynchronously on one API. !!! note This method currently makes non-blocking requests to a single API, but these requests are executed serially on that API, i.e., results are pulled one page at a time, but requests will not block other async requests to other APIs. Parameters: endpoint: The OPTIMADE endpoint to query. filter: The OPTIMADE filter string. response_fields: A list of response fields to request from the server. sort: The field by which to sort the results. page_limit: A page limit to enforce for each query (used in conjunction with `paginate`). paginate: Whether to pull all pages of results (up to the value of `max_results_per_provider`) or whether to return after one page. Returns: A dictionary mapping from base URL to the results of the query. \"\"\" try : return await self . _get_one_async ( endpoint , filter , base_url , page_limit = page_limit , paginate = paginate , response_fields = response_fields , sort = sort , ) except ( RuntimeError , httpx . TimeoutException , json . JSONDecodeError , Exception , ) as exc : error_query_results = QueryResults () error_query_results . errors = [ str ( exc )] self . _progress . print ( f \"[red]Error[/red]: Provider { str ( base_url ) !r} returned: [red i] { exc } [/red i]\" ) return { base_url : error_query_results }","title":"get_one_async()"},{"location":"api_reference/client/utils/","text":"utils \u00b6 OptimadeClientProgress \u00b6 A wrapper around Rich.Progress that defines the OPTIMADE client progressbars. Source code in optimade/client/utils.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class OptimadeClientProgress ( Progress ): \"\"\"A wrapper around `Rich.Progress` that defines the OPTIMADE client progressbars.\"\"\" def __init__ ( self ): super () . __init__ ( SpinnerColumn ( finished_text = \"[green]\u2713\" ), TextColumn ( \"[progress.description] {task.description} \" ), BarColumn (), TaskProgressColumn ( text_format = \"[progress.completed] {task.completed} /[progress.total] {task.total} \" , text_format_no_percentage = \"[progress.completed] {task.completed} \" , ), TimeElapsedColumn (), console = Console ( stderr = True ), auto_refresh = True , refresh_per_second = 10 , ) QueryResults dataclass \u00b6 A container dataclass for the results from a given query. Source code in optimade/client/utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @dataclass class QueryResults : \"\"\"A container dataclass for the results from a given query.\"\"\" data : Union [ Dict , List [ Dict ]] = field ( default_factory = list , init = False ) errors : List [ Dict ] = field ( default_factory = list , init = False ) links : Dict = field ( default_factory = dict , init = False ) included : List [ Dict ] = field ( default_factory = list , init = False ) meta : Dict = field ( default_factory = dict , init = False ) @property def included_index ( self ) -> Set [ str ]: if not getattr ( self , \"_included_index\" , None ): self . _included_index : Set [ str ] = set () return self . _included_index def dict ( self ): return asdict ( self ) def update ( self , page_results : Dict ) -> None : \"\"\"Combine the results from one page with the existing results for a given query. Parameters: page_results: The results for the current page. \"\"\" if \"data\" in page_results : # If the `data` field is a list, add it to our existing results. # Otherwise, as is the case for `info` endpoints, `data` is a dictionary (or null) # and should be added as the only `data` field for these results. if isinstance ( page_results [ \"data\" ], list ): self . data . extend ( page_results [ \"data\" ]) elif not self . data : self . data = page_results [ \"data\" ] else : raise RuntimeError ( \"Not overwriting old `data` field in `QueryResults`.\" ) if \"errors\" in page_results : self . errors . extend ( page_results [ \"errors\" ]) # Combine meta/links fields across all pages in a sensible way, i.e., # if we really reached the last page of results, then make sure `links->next` # is null in the final response, and make sure `meta->more_data_available` is None or False. keys_to_filter = { \"links\" : ( \"next\" , \"prev\" ), \"meta\" : ( \"query\" , \"more_data_available\" ), } for top_level_key in keys_to_filter : if top_level_key not in page_results : page_results [ top_level_key ] = {} for k in keys_to_filter [ top_level_key ]: if k not in page_results [ top_level_key ]: page_results [ top_level_key ][ k ] = None getattr ( self , top_level_key ) . update ( { k : page_results [ top_level_key ][ k ] for k in page_results [ top_level_key ]} ) # Only add new unique entries to the included list for d in page_results . get ( \"included\" , []): typed_id = f \" { d [ 'type' ] } / { d [ 'id' ] } \" if typed_id not in self . included_index : self . included_index . add ( typed_id ) self . included . append ( d ) update ( page_results ) \u00b6 Combine the results from one page with the existing results for a given query. Parameters: Name Type Description Default page_results Dict The results for the current page. required Source code in optimade/client/utils.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def update ( self , page_results : Dict ) -> None : \"\"\"Combine the results from one page with the existing results for a given query. Parameters: page_results: The results for the current page. \"\"\" if \"data\" in page_results : # If the `data` field is a list, add it to our existing results. # Otherwise, as is the case for `info` endpoints, `data` is a dictionary (or null) # and should be added as the only `data` field for these results. if isinstance ( page_results [ \"data\" ], list ): self . data . extend ( page_results [ \"data\" ]) elif not self . data : self . data = page_results [ \"data\" ] else : raise RuntimeError ( \"Not overwriting old `data` field in `QueryResults`.\" ) if \"errors\" in page_results : self . errors . extend ( page_results [ \"errors\" ]) # Combine meta/links fields across all pages in a sensible way, i.e., # if we really reached the last page of results, then make sure `links->next` # is null in the final response, and make sure `meta->more_data_available` is None or False. keys_to_filter = { \"links\" : ( \"next\" , \"prev\" ), \"meta\" : ( \"query\" , \"more_data_available\" ), } for top_level_key in keys_to_filter : if top_level_key not in page_results : page_results [ top_level_key ] = {} for k in keys_to_filter [ top_level_key ]: if k not in page_results [ top_level_key ]: page_results [ top_level_key ][ k ] = None getattr ( self , top_level_key ) . update ( { k : page_results [ top_level_key ][ k ] for k in page_results [ top_level_key ]} ) # Only add new unique entries to the included list for d in page_results . get ( \"included\" , []): typed_id = f \" { d [ 'type' ] } / { d [ 'id' ] } \" if typed_id not in self . included_index : self . included_index . add ( typed_id ) self . included . append ( d ) RecoverableHTTPError \u00b6 Base class for any HTTP issues that may be recoverable by just repeating the query. Source code in optimade/client/utils.py 24 25 26 class RecoverableHTTPError ( Exception ): \"\"\"Base class for any HTTP issues that may be recoverable by just repeating the query.\"\"\" TooManyRequestsException \u00b6 For when the underlying HTTP request returns 429: Too Many Requests. Source code in optimade/client/utils.py 29 30 class TooManyRequestsException ( RecoverableHTTPError ): \"\"\"For when the underlying HTTP request returns 429: Too Many Requests.\"\"\" silent_raise () \u00b6 Raise an exception without printing a traceback, or the exception message itself. Source code in optimade/client/utils.py 120 121 122 123 124 125 126 127 128 129 130 131 @contextmanager def silent_raise (): \"\"\"Raise an exception without printing a traceback, or the exception message itself.\"\"\" default_value = getattr ( sys , \"tracebacklimit\" , 1000 ) # `1000` is a Python's default value default_excepthook = getattr ( sys , \"excepthook\" ) sys . tracebacklimit = 0 sys . excepthook = lambda type , value , traceback : None yield sys . tracebacklimit = default_value # revert changes sys . excepthook = default_excepthook","title":"utils"},{"location":"api_reference/client/utils/#utils","text":"","title":"utils"},{"location":"api_reference/client/utils/#optimade.client.utils.OptimadeClientProgress","text":"A wrapper around Rich.Progress that defines the OPTIMADE client progressbars. Source code in optimade/client/utils.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class OptimadeClientProgress ( Progress ): \"\"\"A wrapper around `Rich.Progress` that defines the OPTIMADE client progressbars.\"\"\" def __init__ ( self ): super () . __init__ ( SpinnerColumn ( finished_text = \"[green]\u2713\" ), TextColumn ( \"[progress.description] {task.description} \" ), BarColumn (), TaskProgressColumn ( text_format = \"[progress.completed] {task.completed} /[progress.total] {task.total} \" , text_format_no_percentage = \"[progress.completed] {task.completed} \" , ), TimeElapsedColumn (), console = Console ( stderr = True ), auto_refresh = True , refresh_per_second = 10 , )","title":"OptimadeClientProgress"},{"location":"api_reference/client/utils/#optimade.client.utils.QueryResults","text":"A container dataclass for the results from a given query. Source code in optimade/client/utils.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @dataclass class QueryResults : \"\"\"A container dataclass for the results from a given query.\"\"\" data : Union [ Dict , List [ Dict ]] = field ( default_factory = list , init = False ) errors : List [ Dict ] = field ( default_factory = list , init = False ) links : Dict = field ( default_factory = dict , init = False ) included : List [ Dict ] = field ( default_factory = list , init = False ) meta : Dict = field ( default_factory = dict , init = False ) @property def included_index ( self ) -> Set [ str ]: if not getattr ( self , \"_included_index\" , None ): self . _included_index : Set [ str ] = set () return self . _included_index def dict ( self ): return asdict ( self ) def update ( self , page_results : Dict ) -> None : \"\"\"Combine the results from one page with the existing results for a given query. Parameters: page_results: The results for the current page. \"\"\" if \"data\" in page_results : # If the `data` field is a list, add it to our existing results. # Otherwise, as is the case for `info` endpoints, `data` is a dictionary (or null) # and should be added as the only `data` field for these results. if isinstance ( page_results [ \"data\" ], list ): self . data . extend ( page_results [ \"data\" ]) elif not self . data : self . data = page_results [ \"data\" ] else : raise RuntimeError ( \"Not overwriting old `data` field in `QueryResults`.\" ) if \"errors\" in page_results : self . errors . extend ( page_results [ \"errors\" ]) # Combine meta/links fields across all pages in a sensible way, i.e., # if we really reached the last page of results, then make sure `links->next` # is null in the final response, and make sure `meta->more_data_available` is None or False. keys_to_filter = { \"links\" : ( \"next\" , \"prev\" ), \"meta\" : ( \"query\" , \"more_data_available\" ), } for top_level_key in keys_to_filter : if top_level_key not in page_results : page_results [ top_level_key ] = {} for k in keys_to_filter [ top_level_key ]: if k not in page_results [ top_level_key ]: page_results [ top_level_key ][ k ] = None getattr ( self , top_level_key ) . update ( { k : page_results [ top_level_key ][ k ] for k in page_results [ top_level_key ]} ) # Only add new unique entries to the included list for d in page_results . get ( \"included\" , []): typed_id = f \" { d [ 'type' ] } / { d [ 'id' ] } \" if typed_id not in self . included_index : self . included_index . add ( typed_id ) self . included . append ( d )","title":"QueryResults"},{"location":"api_reference/client/utils/#optimade.client.utils.QueryResults.update","text":"Combine the results from one page with the existing results for a given query. Parameters: Name Type Description Default page_results Dict The results for the current page. required Source code in optimade/client/utils.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def update ( self , page_results : Dict ) -> None : \"\"\"Combine the results from one page with the existing results for a given query. Parameters: page_results: The results for the current page. \"\"\" if \"data\" in page_results : # If the `data` field is a list, add it to our existing results. # Otherwise, as is the case for `info` endpoints, `data` is a dictionary (or null) # and should be added as the only `data` field for these results. if isinstance ( page_results [ \"data\" ], list ): self . data . extend ( page_results [ \"data\" ]) elif not self . data : self . data = page_results [ \"data\" ] else : raise RuntimeError ( \"Not overwriting old `data` field in `QueryResults`.\" ) if \"errors\" in page_results : self . errors . extend ( page_results [ \"errors\" ]) # Combine meta/links fields across all pages in a sensible way, i.e., # if we really reached the last page of results, then make sure `links->next` # is null in the final response, and make sure `meta->more_data_available` is None or False. keys_to_filter = { \"links\" : ( \"next\" , \"prev\" ), \"meta\" : ( \"query\" , \"more_data_available\" ), } for top_level_key in keys_to_filter : if top_level_key not in page_results : page_results [ top_level_key ] = {} for k in keys_to_filter [ top_level_key ]: if k not in page_results [ top_level_key ]: page_results [ top_level_key ][ k ] = None getattr ( self , top_level_key ) . update ( { k : page_results [ top_level_key ][ k ] for k in page_results [ top_level_key ]} ) # Only add new unique entries to the included list for d in page_results . get ( \"included\" , []): typed_id = f \" { d [ 'type' ] } / { d [ 'id' ] } \" if typed_id not in self . included_index : self . included_index . add ( typed_id ) self . included . append ( d )","title":"update()"},{"location":"api_reference/client/utils/#optimade.client.utils.RecoverableHTTPError","text":"Base class for any HTTP issues that may be recoverable by just repeating the query. Source code in optimade/client/utils.py 24 25 26 class RecoverableHTTPError ( Exception ): \"\"\"Base class for any HTTP issues that may be recoverable by just repeating the query.\"\"\"","title":"RecoverableHTTPError"},{"location":"api_reference/client/utils/#optimade.client.utils.TooManyRequestsException","text":"For when the underlying HTTP request returns 429: Too Many Requests. Source code in optimade/client/utils.py 29 30 class TooManyRequestsException ( RecoverableHTTPError ): \"\"\"For when the underlying HTTP request returns 429: Too Many Requests.\"\"\"","title":"TooManyRequestsException"},{"location":"api_reference/client/utils/#optimade.client.utils.silent_raise","text":"Raise an exception without printing a traceback, or the exception message itself. Source code in optimade/client/utils.py 120 121 122 123 124 125 126 127 128 129 130 131 @contextmanager def silent_raise (): \"\"\"Raise an exception without printing a traceback, or the exception message itself.\"\"\" default_value = getattr ( sys , \"tracebacklimit\" , 1000 ) # `1000` is a Python's default value default_excepthook = getattr ( sys , \"excepthook\" ) sys . tracebacklimit = 0 sys . excepthook = lambda type , value , traceback : None yield sys . tracebacklimit = default_value # revert changes sys . excepthook = default_excepthook","title":"silent_raise()"},{"location":"api_reference/filterparser/lark_parser/","text":"lark_parser \u00b6 This submodule implements the LarkParser class, which uses the lark library to parse filter strings with a defined OPTIMADE filter grammar into Lark.Tree objects for use by the filter transformers. LarkParser \u00b6 This class wraps a versioned OPTIMADE grammar and allows it to be parsed into Lark tree objects. Source code in optimade/filterparser/lark_parser.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 class LarkParser : \"\"\"This class wraps a versioned OPTIMADE grammar and allows it to be parsed into Lark tree objects. \"\"\" def __init__ ( self , version : Tuple [ int , int , int ] = None , variant : str = \"default\" ): \"\"\"For a given version and variant, try to load the corresponding grammar. Parameters: version: The grammar version number to use (e.g., `(1, 0, 1)` for v1.0.1). variant: The grammar variant to employ. Raises: ParserError: If the requested version/variant of the grammar does not exist. \"\"\" if not version : version = max ( _ for _ in AVAILABLE_PARSERS if AVAILABLE_PARSERS [ _ ] . get ( \"default\" ) ) if version not in AVAILABLE_PARSERS : raise ParserError ( f \"Unknown parser grammar version: { version } \" ) if variant not in AVAILABLE_PARSERS [ version ]: raise ParserError ( f \"Unknown variant of the parser: { variant } \" ) self . version = version self . variant = variant with open ( AVAILABLE_PARSERS [ version ][ variant ]) as f : self . lark = Lark ( f , maybe_placeholders = False ) self . tree = None self . filter = None def parse ( self , filter_ : str ) -> Tree : \"\"\"Parse a filter string into a `lark.Tree`. Parameters: filter_: The filter string to parse. Raises: BadRequest: If the filter cannot be parsed. Returns: The parsed filter. \"\"\" try : self . tree = self . lark . parse ( filter_ ) self . filter = filter_ return self . tree except Exception as exc : raise BadRequest ( detail = f \"Unable to parse filter { filter_ } . Lark traceback: \\n { exc } \" ) from exc def __repr__ ( self ): if isinstance ( self . tree , Tree ): return self . tree . pretty () return repr ( self . lark ) __init__ ( version = None , variant = 'default' ) \u00b6 For a given version and variant, try to load the corresponding grammar. Parameters: Name Type Description Default version Tuple [ int , int , int ] The grammar version number to use (e.g., (1, 0, 1) for v1.0.1). None variant str The grammar variant to employ. 'default' Raises: Type Description ParserError If the requested version/variant of the grammar does not exist. Source code in optimade/filterparser/lark_parser.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , version : Tuple [ int , int , int ] = None , variant : str = \"default\" ): \"\"\"For a given version and variant, try to load the corresponding grammar. Parameters: version: The grammar version number to use (e.g., `(1, 0, 1)` for v1.0.1). variant: The grammar variant to employ. Raises: ParserError: If the requested version/variant of the grammar does not exist. \"\"\" if not version : version = max ( _ for _ in AVAILABLE_PARSERS if AVAILABLE_PARSERS [ _ ] . get ( \"default\" ) ) if version not in AVAILABLE_PARSERS : raise ParserError ( f \"Unknown parser grammar version: { version } \" ) if variant not in AVAILABLE_PARSERS [ version ]: raise ParserError ( f \"Unknown variant of the parser: { variant } \" ) self . version = version self . variant = variant with open ( AVAILABLE_PARSERS [ version ][ variant ]) as f : self . lark = Lark ( f , maybe_placeholders = False ) self . tree = None self . filter = None parse ( filter_ ) \u00b6 Parse a filter string into a lark.Tree . Parameters: Name Type Description Default filter_ str The filter string to parse. required Raises: Type Description BadRequest If the filter cannot be parsed. Returns: Type Description Tree The parsed filter. Source code in optimade/filterparser/lark_parser.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def parse ( self , filter_ : str ) -> Tree : \"\"\"Parse a filter string into a `lark.Tree`. Parameters: filter_: The filter string to parse. Raises: BadRequest: If the filter cannot be parsed. Returns: The parsed filter. \"\"\" try : self . tree = self . lark . parse ( filter_ ) self . filter = filter_ return self . tree except Exception as exc : raise BadRequest ( detail = f \"Unable to parse filter { filter_ } . Lark traceback: \\n { exc } \" ) from exc ParserError \u00b6 Triggered by critical parsing errors that should lead to 500 Server Error HTTP statuses. Source code in optimade/filterparser/lark_parser.py 18 19 20 21 class ParserError ( Exception ): \"\"\"Triggered by critical parsing errors that should lead to 500 Server Error HTTP statuses. \"\"\" get_versions () \u00b6 Find grammar files within this package's grammar directory, returning a dictionary broken down by scraped grammar version (major, minor, patch) and variant (a string tag). Returns: Type Description Dict [ Tuple [ int , int , int ], Dict [ str , str ]] A mapping from version, variant to grammar file name. Source code in optimade/filterparser/lark_parser.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def get_versions () -> Dict [ Tuple [ int , int , int ], Dict [ str , str ]]: \"\"\"Find grammar files within this package's grammar directory, returning a dictionary broken down by scraped grammar version (major, minor, patch) and variant (a string tag). Returns: A mapping from version, variant to grammar file name. \"\"\" dct = defaultdict ( dict ) for filename in Path ( __file__ ) . parent . joinpath ( \"../grammar\" ) . glob ( \"*.lark\" ): tags = filename . stem . lstrip ( \"v\" ) . split ( \".\" ) version = tuple ( map ( int , tags [: 3 ])) variant = \"default\" if len ( tags ) == 3 else tags [ - 1 ] dct [ version ][ variant ] = filename return dict ( dct )","title":"lark_parser"},{"location":"api_reference/filterparser/lark_parser/#lark_parser","text":"This submodule implements the LarkParser class, which uses the lark library to parse filter strings with a defined OPTIMADE filter grammar into Lark.Tree objects for use by the filter transformers.","title":"lark_parser"},{"location":"api_reference/filterparser/lark_parser/#optimade.filterparser.lark_parser.LarkParser","text":"This class wraps a versioned OPTIMADE grammar and allows it to be parsed into Lark tree objects. Source code in optimade/filterparser/lark_parser.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 class LarkParser : \"\"\"This class wraps a versioned OPTIMADE grammar and allows it to be parsed into Lark tree objects. \"\"\" def __init__ ( self , version : Tuple [ int , int , int ] = None , variant : str = \"default\" ): \"\"\"For a given version and variant, try to load the corresponding grammar. Parameters: version: The grammar version number to use (e.g., `(1, 0, 1)` for v1.0.1). variant: The grammar variant to employ. Raises: ParserError: If the requested version/variant of the grammar does not exist. \"\"\" if not version : version = max ( _ for _ in AVAILABLE_PARSERS if AVAILABLE_PARSERS [ _ ] . get ( \"default\" ) ) if version not in AVAILABLE_PARSERS : raise ParserError ( f \"Unknown parser grammar version: { version } \" ) if variant not in AVAILABLE_PARSERS [ version ]: raise ParserError ( f \"Unknown variant of the parser: { variant } \" ) self . version = version self . variant = variant with open ( AVAILABLE_PARSERS [ version ][ variant ]) as f : self . lark = Lark ( f , maybe_placeholders = False ) self . tree = None self . filter = None def parse ( self , filter_ : str ) -> Tree : \"\"\"Parse a filter string into a `lark.Tree`. Parameters: filter_: The filter string to parse. Raises: BadRequest: If the filter cannot be parsed. Returns: The parsed filter. \"\"\" try : self . tree = self . lark . parse ( filter_ ) self . filter = filter_ return self . tree except Exception as exc : raise BadRequest ( detail = f \"Unable to parse filter { filter_ } . Lark traceback: \\n { exc } \" ) from exc def __repr__ ( self ): if isinstance ( self . tree , Tree ): return self . tree . pretty () return repr ( self . lark )","title":"LarkParser"},{"location":"api_reference/filterparser/lark_parser/#optimade.filterparser.lark_parser.LarkParser.__init__","text":"For a given version and variant, try to load the corresponding grammar. Parameters: Name Type Description Default version Tuple [ int , int , int ] The grammar version number to use (e.g., (1, 0, 1) for v1.0.1). None variant str The grammar variant to employ. 'default' Raises: Type Description ParserError If the requested version/variant of the grammar does not exist. Source code in optimade/filterparser/lark_parser.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , version : Tuple [ int , int , int ] = None , variant : str = \"default\" ): \"\"\"For a given version and variant, try to load the corresponding grammar. Parameters: version: The grammar version number to use (e.g., `(1, 0, 1)` for v1.0.1). variant: The grammar variant to employ. Raises: ParserError: If the requested version/variant of the grammar does not exist. \"\"\" if not version : version = max ( _ for _ in AVAILABLE_PARSERS if AVAILABLE_PARSERS [ _ ] . get ( \"default\" ) ) if version not in AVAILABLE_PARSERS : raise ParserError ( f \"Unknown parser grammar version: { version } \" ) if variant not in AVAILABLE_PARSERS [ version ]: raise ParserError ( f \"Unknown variant of the parser: { variant } \" ) self . version = version self . variant = variant with open ( AVAILABLE_PARSERS [ version ][ variant ]) as f : self . lark = Lark ( f , maybe_placeholders = False ) self . tree = None self . filter = None","title":"__init__()"},{"location":"api_reference/filterparser/lark_parser/#optimade.filterparser.lark_parser.LarkParser.parse","text":"Parse a filter string into a lark.Tree . Parameters: Name Type Description Default filter_ str The filter string to parse. required Raises: Type Description BadRequest If the filter cannot be parsed. Returns: Type Description Tree The parsed filter. Source code in optimade/filterparser/lark_parser.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def parse ( self , filter_ : str ) -> Tree : \"\"\"Parse a filter string into a `lark.Tree`. Parameters: filter_: The filter string to parse. Raises: BadRequest: If the filter cannot be parsed. Returns: The parsed filter. \"\"\" try : self . tree = self . lark . parse ( filter_ ) self . filter = filter_ return self . tree except Exception as exc : raise BadRequest ( detail = f \"Unable to parse filter { filter_ } . Lark traceback: \\n { exc } \" ) from exc","title":"parse()"},{"location":"api_reference/filterparser/lark_parser/#optimade.filterparser.lark_parser.ParserError","text":"Triggered by critical parsing errors that should lead to 500 Server Error HTTP statuses. Source code in optimade/filterparser/lark_parser.py 18 19 20 21 class ParserError ( Exception ): \"\"\"Triggered by critical parsing errors that should lead to 500 Server Error HTTP statuses. \"\"\"","title":"ParserError"},{"location":"api_reference/filterparser/lark_parser/#optimade.filterparser.lark_parser.get_versions","text":"Find grammar files within this package's grammar directory, returning a dictionary broken down by scraped grammar version (major, minor, patch) and variant (a string tag). Returns: Type Description Dict [ Tuple [ int , int , int ], Dict [ str , str ]] A mapping from version, variant to grammar file name. Source code in optimade/filterparser/lark_parser.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def get_versions () -> Dict [ Tuple [ int , int , int ], Dict [ str , str ]]: \"\"\"Find grammar files within this package's grammar directory, returning a dictionary broken down by scraped grammar version (major, minor, patch) and variant (a string tag). Returns: A mapping from version, variant to grammar file name. \"\"\" dct = defaultdict ( dict ) for filename in Path ( __file__ ) . parent . joinpath ( \"../grammar\" ) . glob ( \"*.lark\" ): tags = filename . stem . lstrip ( \"v\" ) . split ( \".\" ) version = tuple ( map ( int , tags [: 3 ])) variant = \"default\" if len ( tags ) == 3 else tags [ - 1 ] dct [ version ][ variant ] = filename return dict ( dct )","title":"get_versions()"},{"location":"api_reference/filtertransformers/base_transformer/","text":"base_transformer \u00b6 This submodule implements the BaseTransformer and Quantity classes for turning filters parsed by lark into backend-specific queries. BaseTransformer \u00b6 Generic filter transformer that handles various parts of the grammar in a backend non-specific way. Attributes: Name Type Description operator_map Dict [ str , str ] A map from comparison operators to their backend-specific versions. mapper A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. Source code in optimade/filtertransformers/base_transformer.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 class BaseTransformer ( Transformer , abc . ABC ): \"\"\"Generic filter transformer that handles various parts of the grammar in a backend non-specific way. Attributes: operator_map: A map from comparison operators to their backend-specific versions. mapper: A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. \"\"\" mapper : Optional [ BaseResourceMapper ] = None operator_map : Dict [ str , str ] = { \"<\" : None , \"<=\" : None , \">\" : None , \">=\" : None , \"!=\" : None , \"=\" : None , } # map from operators to their syntactic (as opposed to logical) inverse to handle # equivalence between cases like \"A > 3\" and \"3 < A\". _reversed_operator_map = { \">\" : \"<\" , \">=\" : \"<=\" , \"<\" : \">\" , \"<=\" : \">=\" , \"=\" : \"=\" , \"!=\" : \"!=\" , } _quantity_type : Type [ Quantity ] = Quantity _quantities = None def __init__ ( self , mapper : BaseResourceMapper = None ): # pylint: disable=super-init-not-called \"\"\"Initialise the transformer object, optionally loading in a resource mapper for use when post-processing. \"\"\" self . mapper = mapper @property def backend_mapping ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping between backend field names (aliases) and the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] object. \"\"\" return { quantity . backend_field : quantity for _ , quantity in self . quantities . items () } @property def quantities ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping from the OPTIMADE field name to the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] objects. \"\"\" if self . _quantities is None : self . _quantities = self . _build_quantities () return self . _quantities @quantities . setter def quantities ( self , quantities : Dict [ str , Quantity ]) -> None : self . _quantities = quantities def _build_quantities ( self ) -> Dict [ str , Quantity ]: \"\"\"Creates a dictionary of field names mapped to [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] objects from the fields registered by the mapper. \"\"\" quantities = {} if self . mapper is not None : for field in self . mapper . ALL_ATTRIBUTES : alias = self . mapper . get_backend_field ( field ) # Allow length aliases to be defined relative to either backend fields or OPTIMADE fields, # with preference for those defined from OPTIMADE fields length_alias = self . mapper . length_alias_for ( field ) or self . mapper . length_alias_for ( alias ) if field not in quantities : quantities [ field ] = self . _quantity_type ( name = field , backend_field = alias ) if length_alias : if length_alias not in quantities : quantities [ length_alias ] = self . _quantity_type ( name = length_alias , backend_field = self . mapper . get_backend_field ( length_alias ), ) quantities [ field ] . length_quantity = quantities [ length_alias ] return quantities def postprocess ( self , query ) -> Any : \"\"\"Post-process the query according to the rules defined for the backend, returning the backend-specific query. \"\"\" return query def transform ( self , tree : Tree ) -> Any : \"\"\"Transform the query using the Lark `Transformer` then run the backend-specific post-processing methods. \"\"\" return self . postprocess ( super () . transform ( tree )) def __default__ ( self , data , children , meta ): \"\"\"The default rule to call when no definition is found for a particular construct.\"\"\" raise NotImplementedError ( f \"Calling __default__, i.e., unknown grammar concept. data: { data } , children: { children } , meta: { meta } \" ) def filter ( self , arg ): \"\"\"filter: expression*\"\"\" return arg [ 0 ] if arg else None @v_args ( inline = True ) def constant ( self , value ): \"\"\"constant: string | number\"\"\" # Note: Return as is. return value @v_args ( inline = True ) def value ( self , value ): \"\"\"value: string | number | property\"\"\" # Note: Return as is. return value @v_args ( inline = True ) def non_string_value ( self , value ): \"\"\"non_string_value: number | property\"\"\" # Note: Return as is. return value @v_args ( inline = True ) def not_implemented_string ( self , value ): \"\"\"not_implemented_string: value Raises: NotImplementedError: For further information, see Materials-Consortia/OPTIMADE issue 157: https://github.com/Materials-Consortia/OPTIMADE/issues/157 \"\"\" raise NotImplementedError ( \"Comparing strings is not yet implemented.\" ) def property ( self , args : list ) -> Any : \"\"\"property: IDENTIFIER ( \".\" IDENTIFIER )* If this transformer has an associated mapper, the property will be compared to possible relationship entry types and for any supported provider prefixes. If there is a match, this rule will return a string and not a dereferenced [`Quantity`][optimade.filtertransformers.base_transformer.Quantity]. Raises: BadRequest: If the property does not match any of the above rules. \"\"\" quantity_name = str ( args [ 0 ]) # If the quantity name matches an entry type (indicating a relationship filter) # then simply return the quantity name; the inherited property # must then handle any further nested identifiers if self . mapper : if quantity_name in self . mapper . RELATIONSHIP_ENTRY_TYPES : return quantity_name if self . quantities and quantity_name not in self . quantities : # If the quantity is provider-specific, but does not match this provider, # then return the quantity name such that it can be treated as unknown. # If the prefix does not match another known provider, also emit a warning # If the prefix does match a known provider, do not return a warning. # Following [Handling unknown property names](https://github.com/Materials-Consortia/OPTIMADE/blob/master/optimade.rst#handling-unknown-property-names) if self . mapper and quantity_name . startswith ( \"_\" ): prefix = quantity_name . split ( \"_\" )[ 1 ] if prefix not in self . mapper . SUPPORTED_PREFIXES : if prefix not in self . mapper . KNOWN_PROVIDER_PREFIXES : warnings . warn ( UnknownProviderProperty ( f \"Field { quantity_name !r} has an unrecognised prefix: this property has been treated as UNKNOWN.\" ) ) return quantity_name raise BadRequest ( detail = f \"' { quantity_name } ' is not a known or searchable quantity\" ) quantity = self . quantities . get ( quantity_name , None ) if quantity is None : quantity = self . _quantity_type ( name = str ( quantity_name )) return quantity @v_args ( inline = True ) def string ( self , string ): \"\"\"string: ESCAPED_STRING\"\"\" return string . strip ( '\"' ) @v_args ( inline = True ) def signed_int ( self , number ): \"\"\"signed_int : SIGNED_INT\"\"\" return int ( number ) @v_args ( inline = True ) def number ( self , number ): \"\"\"number: SIGNED_INT | SIGNED_FLOAT\"\"\" if number . type == \"SIGNED_INT\" : type_ = int elif number . type == \"SIGNED_FLOAT\" : type_ = float return type_ ( number ) @v_args ( inline = True ) def comparison ( self , value ): \"\"\"comparison: constant_first_comparison | property_first_comparison\"\"\" # Note: Return as is. return value def value_list ( self , arg ): \"\"\"value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )*\"\"\" def value_zip ( self , arg ): \"\"\"value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)*\"\"\" pass def value_zip_list ( self , arg ): \"\"\"value_zip_list: value_zip ( \",\" value_zip )*\"\"\" def expression ( self , arg ): \"\"\"expression: expression_clause ( OR expression_clause )\"\"\" def expression_clause ( self , arg ): \"\"\"expression_clause: expression_phrase ( AND expression_phrase )*\"\"\" def expression_phrase ( self , arg ): \"\"\"expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" )\"\"\" def property_first_comparison ( self , arg ): \"\"\"property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | set_zip_op_rhs | length_op_rhs ) \"\"\" def constant_first_comparison ( self , arg ): \"\"\"constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string )\"\"\" @v_args ( inline = True ) def value_op_rhs ( self , operator , value ): \"\"\"value_op_rhs: OPERATOR value\"\"\" def known_op_rhs ( self , arg ): \"\"\"known_op_rhs: IS ( KNOWN | UNKNOWN )\"\"\" def fuzzy_string_op_rhs ( self , arg ): \"\"\"fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value\"\"\" def set_op_rhs ( self , arg ): \"\"\"set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list )\"\"\" def length_op_rhs ( self , arg ): \"\"\"length_op_rhs: LENGTH [ OPERATOR ] value\"\"\" def set_zip_op_rhs ( self , arg ): \"\"\"set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) \"\"\" def property_zip_addon ( self , arg ): \"\"\"property_zip_addon: \":\" property (\":\" property)*\"\"\" __default__ ( data , children , meta ) \u00b6 The default rule to call when no definition is found for a particular construct. Source code in optimade/filtertransformers/base_transformer.py 186 187 188 189 190 def __default__ ( self , data , children , meta ): \"\"\"The default rule to call when no definition is found for a particular construct.\"\"\" raise NotImplementedError ( f \"Calling __default__, i.e., unknown grammar concept. data: { data } , children: { children } , meta: { meta } \" ) __init__ ( mapper = None ) \u00b6 Initialise the transformer object, optionally loading in a resource mapper for use when post-processing. Source code in optimade/filtertransformers/base_transformer.py 107 108 109 110 111 112 113 114 def __init__ ( self , mapper : BaseResourceMapper = None ): # pylint: disable=super-init-not-called \"\"\"Initialise the transformer object, optionally loading in a resource mapper for use when post-processing. \"\"\" self . mapper = mapper backend_mapping () property \u00b6 A mapping between backend field names (aliases) and the corresponding Quantity object. Source code in optimade/filtertransformers/base_transformer.py 116 117 118 119 120 121 122 123 @property def backend_mapping ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping between backend field names (aliases) and the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] object. \"\"\" return { quantity . backend_field : quantity for _ , quantity in self . quantities . items () } comparison ( value ) \u00b6 comparison: constant_first_comparison | property_first_comparison Source code in optimade/filtertransformers/base_transformer.py 295 296 297 298 299 @v_args ( inline = True ) def comparison ( self , value ): \"\"\"comparison: constant_first_comparison | property_first_comparison\"\"\" # Note: Return as is. return value constant ( value ) \u00b6 constant: string | number Source code in optimade/filtertransformers/base_transformer.py 196 197 198 199 200 @v_args ( inline = True ) def constant ( self , value ): \"\"\"constant: string | number\"\"\" # Note: Return as is. return value constant_first_comparison ( arg ) \u00b6 constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string ) Source code in optimade/filtertransformers/base_transformer.py 331 332 def constant_first_comparison ( self , arg ): \"\"\"constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string )\"\"\" expression ( arg ) \u00b6 expression: expression_clause ( OR expression_clause ) Source code in optimade/filtertransformers/base_transformer.py 311 312 def expression ( self , arg ): \"\"\"expression: expression_clause ( OR expression_clause )\"\"\" expression_clause ( arg ) \u00b6 expression_clause: expression_phrase ( AND expression_phrase )* Source code in optimade/filtertransformers/base_transformer.py 314 315 def expression_clause ( self , arg ): \"\"\"expression_clause: expression_phrase ( AND expression_phrase )*\"\"\" expression_phrase ( arg ) \u00b6 expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" ) Source code in optimade/filtertransformers/base_transformer.py 317 318 def expression_phrase ( self , arg ): \"\"\"expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" )\"\"\" filter ( arg ) \u00b6 filter: expression* Source code in optimade/filtertransformers/base_transformer.py 192 193 194 def filter ( self , arg ): \"\"\"filter: expression*\"\"\" return arg [ 0 ] if arg else None fuzzy_string_op_rhs ( arg ) \u00b6 fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value Source code in optimade/filtertransformers/base_transformer.py 341 342 def fuzzy_string_op_rhs ( self , arg ): \"\"\"fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value\"\"\" known_op_rhs ( arg ) \u00b6 known_op_rhs: IS ( KNOWN | UNKNOWN ) Source code in optimade/filtertransformers/base_transformer.py 338 339 def known_op_rhs ( self , arg ): \"\"\"known_op_rhs: IS ( KNOWN | UNKNOWN )\"\"\" length_op_rhs ( arg ) \u00b6 length_op_rhs: LENGTH [ OPERATOR ] value Source code in optimade/filtertransformers/base_transformer.py 347 348 def length_op_rhs ( self , arg ): \"\"\"length_op_rhs: LENGTH [ OPERATOR ] value\"\"\" non_string_value ( value ) \u00b6 non_string_value: number | property Source code in optimade/filtertransformers/base_transformer.py 208 209 210 211 212 @v_args ( inline = True ) def non_string_value ( self , value ): \"\"\"non_string_value: number | property\"\"\" # Note: Return as is. return value not_implemented_string ( value ) \u00b6 not_implemented_string: value Raises: Type Description NotImplementedError For further information, see Materials-Consortia/OPTIMADE issue 157: https://github.com/Materials-Consortia/OPTIMADE/issues/157 Source code in optimade/filtertransformers/base_transformer.py 214 215 216 217 218 219 220 221 222 223 @v_args ( inline = True ) def not_implemented_string ( self , value ): \"\"\"not_implemented_string: value Raises: NotImplementedError: For further information, see Materials-Consortia/OPTIMADE issue 157: https://github.com/Materials-Consortia/OPTIMADE/issues/157 \"\"\" raise NotImplementedError ( \"Comparing strings is not yet implemented.\" ) number ( number ) \u00b6 number: SIGNED_INT | SIGNED_FLOAT Source code in optimade/filtertransformers/base_transformer.py 286 287 288 289 290 291 292 293 @v_args ( inline = True ) def number ( self , number ): \"\"\"number: SIGNED_INT | SIGNED_FLOAT\"\"\" if number . type == \"SIGNED_INT\" : type_ = int elif number . type == \"SIGNED_FLOAT\" : type_ = float return type_ ( number ) postprocess ( query ) \u00b6 Post-process the query according to the rules defined for the backend, returning the backend-specific query. Source code in optimade/filtertransformers/base_transformer.py 172 173 174 175 176 177 def postprocess ( self , query ) -> Any : \"\"\"Post-process the query according to the rules defined for the backend, returning the backend-specific query. \"\"\" return query property ( args ) \u00b6 property: IDENTIFIER ( \".\" IDENTIFIER )* If this transformer has an associated mapper, the property will be compared to possible relationship entry types and for any supported provider prefixes. If there is a match, this rule will return a string and not a dereferenced Quantity . Raises: Type Description BadRequest If the property does not match any of the above rules. Source code in optimade/filtertransformers/base_transformer.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 def property ( self , args : list ) -> Any : \"\"\"property: IDENTIFIER ( \".\" IDENTIFIER )* If this transformer has an associated mapper, the property will be compared to possible relationship entry types and for any supported provider prefixes. If there is a match, this rule will return a string and not a dereferenced [`Quantity`][optimade.filtertransformers.base_transformer.Quantity]. Raises: BadRequest: If the property does not match any of the above rules. \"\"\" quantity_name = str ( args [ 0 ]) # If the quantity name matches an entry type (indicating a relationship filter) # then simply return the quantity name; the inherited property # must then handle any further nested identifiers if self . mapper : if quantity_name in self . mapper . RELATIONSHIP_ENTRY_TYPES : return quantity_name if self . quantities and quantity_name not in self . quantities : # If the quantity is provider-specific, but does not match this provider, # then return the quantity name such that it can be treated as unknown. # If the prefix does not match another known provider, also emit a warning # If the prefix does match a known provider, do not return a warning. # Following [Handling unknown property names](https://github.com/Materials-Consortia/OPTIMADE/blob/master/optimade.rst#handling-unknown-property-names) if self . mapper and quantity_name . startswith ( \"_\" ): prefix = quantity_name . split ( \"_\" )[ 1 ] if prefix not in self . mapper . SUPPORTED_PREFIXES : if prefix not in self . mapper . KNOWN_PROVIDER_PREFIXES : warnings . warn ( UnknownProviderProperty ( f \"Field { quantity_name !r} has an unrecognised prefix: this property has been treated as UNKNOWN.\" ) ) return quantity_name raise BadRequest ( detail = f \"' { quantity_name } ' is not a known or searchable quantity\" ) quantity = self . quantities . get ( quantity_name , None ) if quantity is None : quantity = self . _quantity_type ( name = str ( quantity_name )) return quantity property_first_comparison ( arg ) \u00b6 property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | set_zip_op_rhs | length_op_rhs ) Source code in optimade/filtertransformers/base_transformer.py 320 321 322 323 324 325 326 327 328 329 def property_first_comparison ( self , arg ): \"\"\"property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | set_zip_op_rhs | length_op_rhs ) \"\"\" property_zip_addon ( arg ) \u00b6 property_zip_addon: \":\" property (\":\" property)* Source code in optimade/filtertransformers/base_transformer.py 358 359 def property_zip_addon ( self , arg ): \"\"\"property_zip_addon: \":\" property (\":\" property)*\"\"\" quantities () writable property \u00b6 A mapping from the OPTIMADE field name to the corresponding Quantity objects. Source code in optimade/filtertransformers/base_transformer.py 125 126 127 128 129 130 131 132 133 @property def quantities ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping from the OPTIMADE field name to the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] objects. \"\"\" if self . _quantities is None : self . _quantities = self . _build_quantities () return self . _quantities set_op_rhs ( arg ) \u00b6 set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list ) Source code in optimade/filtertransformers/base_transformer.py 344 345 def set_op_rhs ( self , arg ): \"\"\"set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list )\"\"\" set_zip_op_rhs ( arg ) \u00b6 set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) Source code in optimade/filtertransformers/base_transformer.py 350 351 352 353 354 355 356 def set_zip_op_rhs ( self , arg ): \"\"\"set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) \"\"\" signed_int ( number ) \u00b6 signed_int : SIGNED_INT Source code in optimade/filtertransformers/base_transformer.py 281 282 283 284 @v_args ( inline = True ) def signed_int ( self , number ): \"\"\"signed_int : SIGNED_INT\"\"\" return int ( number ) string ( string ) \u00b6 string: ESCAPED_STRING Source code in optimade/filtertransformers/base_transformer.py 276 277 278 279 @v_args ( inline = True ) def string ( self , string ): \"\"\"string: ESCAPED_STRING\"\"\" return string . strip ( '\"' ) transform ( tree ) \u00b6 Transform the query using the Lark Transformer then run the backend-specific post-processing methods. Source code in optimade/filtertransformers/base_transformer.py 179 180 181 182 183 184 def transform ( self , tree : Tree ) -> Any : \"\"\"Transform the query using the Lark `Transformer` then run the backend-specific post-processing methods. \"\"\" return self . postprocess ( super () . transform ( tree )) value ( value ) \u00b6 value: string | number | property Source code in optimade/filtertransformers/base_transformer.py 202 203 204 205 206 @v_args ( inline = True ) def value ( self , value ): \"\"\"value: string | number | property\"\"\" # Note: Return as is. return value value_list ( arg ) \u00b6 value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )* Source code in optimade/filtertransformers/base_transformer.py 301 302 def value_list ( self , arg ): \"\"\"value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )*\"\"\" value_op_rhs ( operator , value ) \u00b6 value_op_rhs: OPERATOR value Source code in optimade/filtertransformers/base_transformer.py 334 335 336 @v_args ( inline = True ) def value_op_rhs ( self , operator , value ): \"\"\"value_op_rhs: OPERATOR value\"\"\" value_zip ( arg ) \u00b6 value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)* Source code in optimade/filtertransformers/base_transformer.py 304 305 306 def value_zip ( self , arg ): \"\"\"value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)*\"\"\" pass value_zip_list ( arg ) \u00b6 value_zip_list: value_zip ( \",\" value_zip )* Source code in optimade/filtertransformers/base_transformer.py 308 309 def value_zip_list ( self , arg ): \"\"\"value_zip_list: value_zip ( \",\" value_zip )*\"\"\" Quantity \u00b6 Class to provide information about available quantities to the transformer. The transformer can use Quantity 's to do some semantic checks, map quantities to the underlying backend field name. Attributes: Name Type Description name The name of the quantity as used in the filter expressions. backend_field The name of the field for this quantity in the backend database, will be name by default. length_quantity Another (typically integer) Quantity that can be queried as the length of this quantity, e.g. elements and nelements . Backends can then decide whether to use this for all \"LENGTH\" queries. Source code in optimade/filtertransformers/base_transformer.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class Quantity : \"\"\"Class to provide information about available quantities to the transformer. The transformer can use [`Quantity`][optimade.filtertransformers.base_transformer.Quantity]'s to * do some semantic checks, * map quantities to the underlying backend field name. Attributes: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in the backend database, will be `name` by default. length_quantity: Another (typically integer) [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] that can be queried as the length of this quantity, e.g. `elements` and `nelements`. Backends can then decide whether to use this for all \"LENGTH\" queries. \"\"\" name : str backend_field : Optional [ str ] length_quantity : Optional [ \"Quantity\" ] def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"Quantity\" = None , ): \"\"\"Initialise the `quantity` from it's name and aliases. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in the backend database, will be `name` by default. length_quantity: Another (typically integer) [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] that can be queried as the length of this quantity, e.g. `elements` and `nelements`. Backends can then decide whether to use this for all \"LENGTH\" queries. \"\"\" self . name = name self . backend_field = backend_field if backend_field is not None else name self . length_quantity = length_quantity __init__ ( name , backend_field = None , length_quantity = None ) \u00b6 Initialise the quantity from it's name and aliases. Parameters: Name Type Description Default name str The name of the quantity as used in the filter expressions. required backend_field str The name of the field for this quantity in the backend database, will be name by default. None length_quantity Quantity Another (typically integer) Quantity that can be queried as the length of this quantity, e.g. elements and nelements . Backends can then decide whether to use this for all \"LENGTH\" queries. None Source code in optimade/filtertransformers/base_transformer.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"Quantity\" = None , ): \"\"\"Initialise the `quantity` from it's name and aliases. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in the backend database, will be `name` by default. length_quantity: Another (typically integer) [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] that can be queried as the length of this quantity, e.g. `elements` and `nelements`. Backends can then decide whether to use this for all \"LENGTH\" queries. \"\"\" self . name = name self . backend_field = backend_field if backend_field is not None else name self . length_quantity = length_quantity","title":"base_transformer"},{"location":"api_reference/filtertransformers/base_transformer/#base_transformer","text":"This submodule implements the BaseTransformer and Quantity classes for turning filters parsed by lark into backend-specific queries.","title":"base_transformer"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer","text":"Generic filter transformer that handles various parts of the grammar in a backend non-specific way. Attributes: Name Type Description operator_map Dict [ str , str ] A map from comparison operators to their backend-specific versions. mapper A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. Source code in optimade/filtertransformers/base_transformer.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 class BaseTransformer ( Transformer , abc . ABC ): \"\"\"Generic filter transformer that handles various parts of the grammar in a backend non-specific way. Attributes: operator_map: A map from comparison operators to their backend-specific versions. mapper: A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. \"\"\" mapper : Optional [ BaseResourceMapper ] = None operator_map : Dict [ str , str ] = { \"<\" : None , \"<=\" : None , \">\" : None , \">=\" : None , \"!=\" : None , \"=\" : None , } # map from operators to their syntactic (as opposed to logical) inverse to handle # equivalence between cases like \"A > 3\" and \"3 < A\". _reversed_operator_map = { \">\" : \"<\" , \">=\" : \"<=\" , \"<\" : \">\" , \"<=\" : \">=\" , \"=\" : \"=\" , \"!=\" : \"!=\" , } _quantity_type : Type [ Quantity ] = Quantity _quantities = None def __init__ ( self , mapper : BaseResourceMapper = None ): # pylint: disable=super-init-not-called \"\"\"Initialise the transformer object, optionally loading in a resource mapper for use when post-processing. \"\"\" self . mapper = mapper @property def backend_mapping ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping between backend field names (aliases) and the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] object. \"\"\" return { quantity . backend_field : quantity for _ , quantity in self . quantities . items () } @property def quantities ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping from the OPTIMADE field name to the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] objects. \"\"\" if self . _quantities is None : self . _quantities = self . _build_quantities () return self . _quantities @quantities . setter def quantities ( self , quantities : Dict [ str , Quantity ]) -> None : self . _quantities = quantities def _build_quantities ( self ) -> Dict [ str , Quantity ]: \"\"\"Creates a dictionary of field names mapped to [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] objects from the fields registered by the mapper. \"\"\" quantities = {} if self . mapper is not None : for field in self . mapper . ALL_ATTRIBUTES : alias = self . mapper . get_backend_field ( field ) # Allow length aliases to be defined relative to either backend fields or OPTIMADE fields, # with preference for those defined from OPTIMADE fields length_alias = self . mapper . length_alias_for ( field ) or self . mapper . length_alias_for ( alias ) if field not in quantities : quantities [ field ] = self . _quantity_type ( name = field , backend_field = alias ) if length_alias : if length_alias not in quantities : quantities [ length_alias ] = self . _quantity_type ( name = length_alias , backend_field = self . mapper . get_backend_field ( length_alias ), ) quantities [ field ] . length_quantity = quantities [ length_alias ] return quantities def postprocess ( self , query ) -> Any : \"\"\"Post-process the query according to the rules defined for the backend, returning the backend-specific query. \"\"\" return query def transform ( self , tree : Tree ) -> Any : \"\"\"Transform the query using the Lark `Transformer` then run the backend-specific post-processing methods. \"\"\" return self . postprocess ( super () . transform ( tree )) def __default__ ( self , data , children , meta ): \"\"\"The default rule to call when no definition is found for a particular construct.\"\"\" raise NotImplementedError ( f \"Calling __default__, i.e., unknown grammar concept. data: { data } , children: { children } , meta: { meta } \" ) def filter ( self , arg ): \"\"\"filter: expression*\"\"\" return arg [ 0 ] if arg else None @v_args ( inline = True ) def constant ( self , value ): \"\"\"constant: string | number\"\"\" # Note: Return as is. return value @v_args ( inline = True ) def value ( self , value ): \"\"\"value: string | number | property\"\"\" # Note: Return as is. return value @v_args ( inline = True ) def non_string_value ( self , value ): \"\"\"non_string_value: number | property\"\"\" # Note: Return as is. return value @v_args ( inline = True ) def not_implemented_string ( self , value ): \"\"\"not_implemented_string: value Raises: NotImplementedError: For further information, see Materials-Consortia/OPTIMADE issue 157: https://github.com/Materials-Consortia/OPTIMADE/issues/157 \"\"\" raise NotImplementedError ( \"Comparing strings is not yet implemented.\" ) def property ( self , args : list ) -> Any : \"\"\"property: IDENTIFIER ( \".\" IDENTIFIER )* If this transformer has an associated mapper, the property will be compared to possible relationship entry types and for any supported provider prefixes. If there is a match, this rule will return a string and not a dereferenced [`Quantity`][optimade.filtertransformers.base_transformer.Quantity]. Raises: BadRequest: If the property does not match any of the above rules. \"\"\" quantity_name = str ( args [ 0 ]) # If the quantity name matches an entry type (indicating a relationship filter) # then simply return the quantity name; the inherited property # must then handle any further nested identifiers if self . mapper : if quantity_name in self . mapper . RELATIONSHIP_ENTRY_TYPES : return quantity_name if self . quantities and quantity_name not in self . quantities : # If the quantity is provider-specific, but does not match this provider, # then return the quantity name such that it can be treated as unknown. # If the prefix does not match another known provider, also emit a warning # If the prefix does match a known provider, do not return a warning. # Following [Handling unknown property names](https://github.com/Materials-Consortia/OPTIMADE/blob/master/optimade.rst#handling-unknown-property-names) if self . mapper and quantity_name . startswith ( \"_\" ): prefix = quantity_name . split ( \"_\" )[ 1 ] if prefix not in self . mapper . SUPPORTED_PREFIXES : if prefix not in self . mapper . KNOWN_PROVIDER_PREFIXES : warnings . warn ( UnknownProviderProperty ( f \"Field { quantity_name !r} has an unrecognised prefix: this property has been treated as UNKNOWN.\" ) ) return quantity_name raise BadRequest ( detail = f \"' { quantity_name } ' is not a known or searchable quantity\" ) quantity = self . quantities . get ( quantity_name , None ) if quantity is None : quantity = self . _quantity_type ( name = str ( quantity_name )) return quantity @v_args ( inline = True ) def string ( self , string ): \"\"\"string: ESCAPED_STRING\"\"\" return string . strip ( '\"' ) @v_args ( inline = True ) def signed_int ( self , number ): \"\"\"signed_int : SIGNED_INT\"\"\" return int ( number ) @v_args ( inline = True ) def number ( self , number ): \"\"\"number: SIGNED_INT | SIGNED_FLOAT\"\"\" if number . type == \"SIGNED_INT\" : type_ = int elif number . type == \"SIGNED_FLOAT\" : type_ = float return type_ ( number ) @v_args ( inline = True ) def comparison ( self , value ): \"\"\"comparison: constant_first_comparison | property_first_comparison\"\"\" # Note: Return as is. return value def value_list ( self , arg ): \"\"\"value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )*\"\"\" def value_zip ( self , arg ): \"\"\"value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)*\"\"\" pass def value_zip_list ( self , arg ): \"\"\"value_zip_list: value_zip ( \",\" value_zip )*\"\"\" def expression ( self , arg ): \"\"\"expression: expression_clause ( OR expression_clause )\"\"\" def expression_clause ( self , arg ): \"\"\"expression_clause: expression_phrase ( AND expression_phrase )*\"\"\" def expression_phrase ( self , arg ): \"\"\"expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" )\"\"\" def property_first_comparison ( self , arg ): \"\"\"property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | set_zip_op_rhs | length_op_rhs ) \"\"\" def constant_first_comparison ( self , arg ): \"\"\"constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string )\"\"\" @v_args ( inline = True ) def value_op_rhs ( self , operator , value ): \"\"\"value_op_rhs: OPERATOR value\"\"\" def known_op_rhs ( self , arg ): \"\"\"known_op_rhs: IS ( KNOWN | UNKNOWN )\"\"\" def fuzzy_string_op_rhs ( self , arg ): \"\"\"fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value\"\"\" def set_op_rhs ( self , arg ): \"\"\"set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list )\"\"\" def length_op_rhs ( self , arg ): \"\"\"length_op_rhs: LENGTH [ OPERATOR ] value\"\"\" def set_zip_op_rhs ( self , arg ): \"\"\"set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) \"\"\" def property_zip_addon ( self , arg ): \"\"\"property_zip_addon: \":\" property (\":\" property)*\"\"\"","title":"BaseTransformer"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.__default__","text":"The default rule to call when no definition is found for a particular construct. Source code in optimade/filtertransformers/base_transformer.py 186 187 188 189 190 def __default__ ( self , data , children , meta ): \"\"\"The default rule to call when no definition is found for a particular construct.\"\"\" raise NotImplementedError ( f \"Calling __default__, i.e., unknown grammar concept. data: { data } , children: { children } , meta: { meta } \" )","title":"__default__()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.__init__","text":"Initialise the transformer object, optionally loading in a resource mapper for use when post-processing. Source code in optimade/filtertransformers/base_transformer.py 107 108 109 110 111 112 113 114 def __init__ ( self , mapper : BaseResourceMapper = None ): # pylint: disable=super-init-not-called \"\"\"Initialise the transformer object, optionally loading in a resource mapper for use when post-processing. \"\"\" self . mapper = mapper","title":"__init__()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.backend_mapping","text":"A mapping between backend field names (aliases) and the corresponding Quantity object. Source code in optimade/filtertransformers/base_transformer.py 116 117 118 119 120 121 122 123 @property def backend_mapping ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping between backend field names (aliases) and the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] object. \"\"\" return { quantity . backend_field : quantity for _ , quantity in self . quantities . items () }","title":"backend_mapping()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.comparison","text":"comparison: constant_first_comparison | property_first_comparison Source code in optimade/filtertransformers/base_transformer.py 295 296 297 298 299 @v_args ( inline = True ) def comparison ( self , value ): \"\"\"comparison: constant_first_comparison | property_first_comparison\"\"\" # Note: Return as is. return value","title":"comparison()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.constant","text":"constant: string | number Source code in optimade/filtertransformers/base_transformer.py 196 197 198 199 200 @v_args ( inline = True ) def constant ( self , value ): \"\"\"constant: string | number\"\"\" # Note: Return as is. return value","title":"constant()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.constant_first_comparison","text":"constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string ) Source code in optimade/filtertransformers/base_transformer.py 331 332 def constant_first_comparison ( self , arg ): \"\"\"constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string )\"\"\"","title":"constant_first_comparison()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.expression","text":"expression: expression_clause ( OR expression_clause ) Source code in optimade/filtertransformers/base_transformer.py 311 312 def expression ( self , arg ): \"\"\"expression: expression_clause ( OR expression_clause )\"\"\"","title":"expression()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.expression_clause","text":"expression_clause: expression_phrase ( AND expression_phrase )* Source code in optimade/filtertransformers/base_transformer.py 314 315 def expression_clause ( self , arg ): \"\"\"expression_clause: expression_phrase ( AND expression_phrase )*\"\"\"","title":"expression_clause()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.expression_phrase","text":"expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" ) Source code in optimade/filtertransformers/base_transformer.py 317 318 def expression_phrase ( self , arg ): \"\"\"expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" )\"\"\"","title":"expression_phrase()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.filter","text":"filter: expression* Source code in optimade/filtertransformers/base_transformer.py 192 193 194 def filter ( self , arg ): \"\"\"filter: expression*\"\"\" return arg [ 0 ] if arg else None","title":"filter()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.fuzzy_string_op_rhs","text":"fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value Source code in optimade/filtertransformers/base_transformer.py 341 342 def fuzzy_string_op_rhs ( self , arg ): \"\"\"fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value\"\"\"","title":"fuzzy_string_op_rhs()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.known_op_rhs","text":"known_op_rhs: IS ( KNOWN | UNKNOWN ) Source code in optimade/filtertransformers/base_transformer.py 338 339 def known_op_rhs ( self , arg ): \"\"\"known_op_rhs: IS ( KNOWN | UNKNOWN )\"\"\"","title":"known_op_rhs()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.length_op_rhs","text":"length_op_rhs: LENGTH [ OPERATOR ] value Source code in optimade/filtertransformers/base_transformer.py 347 348 def length_op_rhs ( self , arg ): \"\"\"length_op_rhs: LENGTH [ OPERATOR ] value\"\"\"","title":"length_op_rhs()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.non_string_value","text":"non_string_value: number | property Source code in optimade/filtertransformers/base_transformer.py 208 209 210 211 212 @v_args ( inline = True ) def non_string_value ( self , value ): \"\"\"non_string_value: number | property\"\"\" # Note: Return as is. return value","title":"non_string_value()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.not_implemented_string","text":"not_implemented_string: value Raises: Type Description NotImplementedError For further information, see Materials-Consortia/OPTIMADE issue 157: https://github.com/Materials-Consortia/OPTIMADE/issues/157 Source code in optimade/filtertransformers/base_transformer.py 214 215 216 217 218 219 220 221 222 223 @v_args ( inline = True ) def not_implemented_string ( self , value ): \"\"\"not_implemented_string: value Raises: NotImplementedError: For further information, see Materials-Consortia/OPTIMADE issue 157: https://github.com/Materials-Consortia/OPTIMADE/issues/157 \"\"\" raise NotImplementedError ( \"Comparing strings is not yet implemented.\" )","title":"not_implemented_string()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.number","text":"number: SIGNED_INT | SIGNED_FLOAT Source code in optimade/filtertransformers/base_transformer.py 286 287 288 289 290 291 292 293 @v_args ( inline = True ) def number ( self , number ): \"\"\"number: SIGNED_INT | SIGNED_FLOAT\"\"\" if number . type == \"SIGNED_INT\" : type_ = int elif number . type == \"SIGNED_FLOAT\" : type_ = float return type_ ( number )","title":"number()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.postprocess","text":"Post-process the query according to the rules defined for the backend, returning the backend-specific query. Source code in optimade/filtertransformers/base_transformer.py 172 173 174 175 176 177 def postprocess ( self , query ) -> Any : \"\"\"Post-process the query according to the rules defined for the backend, returning the backend-specific query. \"\"\" return query","title":"postprocess()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.property","text":"property: IDENTIFIER ( \".\" IDENTIFIER )* If this transformer has an associated mapper, the property will be compared to possible relationship entry types and for any supported provider prefixes. If there is a match, this rule will return a string and not a dereferenced Quantity . Raises: Type Description BadRequest If the property does not match any of the above rules. Source code in optimade/filtertransformers/base_transformer.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 def property ( self , args : list ) -> Any : \"\"\"property: IDENTIFIER ( \".\" IDENTIFIER )* If this transformer has an associated mapper, the property will be compared to possible relationship entry types and for any supported provider prefixes. If there is a match, this rule will return a string and not a dereferenced [`Quantity`][optimade.filtertransformers.base_transformer.Quantity]. Raises: BadRequest: If the property does not match any of the above rules. \"\"\" quantity_name = str ( args [ 0 ]) # If the quantity name matches an entry type (indicating a relationship filter) # then simply return the quantity name; the inherited property # must then handle any further nested identifiers if self . mapper : if quantity_name in self . mapper . RELATIONSHIP_ENTRY_TYPES : return quantity_name if self . quantities and quantity_name not in self . quantities : # If the quantity is provider-specific, but does not match this provider, # then return the quantity name such that it can be treated as unknown. # If the prefix does not match another known provider, also emit a warning # If the prefix does match a known provider, do not return a warning. # Following [Handling unknown property names](https://github.com/Materials-Consortia/OPTIMADE/blob/master/optimade.rst#handling-unknown-property-names) if self . mapper and quantity_name . startswith ( \"_\" ): prefix = quantity_name . split ( \"_\" )[ 1 ] if prefix not in self . mapper . SUPPORTED_PREFIXES : if prefix not in self . mapper . KNOWN_PROVIDER_PREFIXES : warnings . warn ( UnknownProviderProperty ( f \"Field { quantity_name !r} has an unrecognised prefix: this property has been treated as UNKNOWN.\" ) ) return quantity_name raise BadRequest ( detail = f \"' { quantity_name } ' is not a known or searchable quantity\" ) quantity = self . quantities . get ( quantity_name , None ) if quantity is None : quantity = self . _quantity_type ( name = str ( quantity_name )) return quantity","title":"property()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.property_first_comparison","text":"property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | set_zip_op_rhs | length_op_rhs ) Source code in optimade/filtertransformers/base_transformer.py 320 321 322 323 324 325 326 327 328 329 def property_first_comparison ( self , arg ): \"\"\"property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | set_zip_op_rhs | length_op_rhs ) \"\"\"","title":"property_first_comparison()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.property_zip_addon","text":"property_zip_addon: \":\" property (\":\" property)* Source code in optimade/filtertransformers/base_transformer.py 358 359 def property_zip_addon ( self , arg ): \"\"\"property_zip_addon: \":\" property (\":\" property)*\"\"\"","title":"property_zip_addon()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.quantities","text":"A mapping from the OPTIMADE field name to the corresponding Quantity objects. Source code in optimade/filtertransformers/base_transformer.py 125 126 127 128 129 130 131 132 133 @property def quantities ( self ) -> Dict [ str , Quantity ]: \"\"\"A mapping from the OPTIMADE field name to the corresponding [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] objects. \"\"\" if self . _quantities is None : self . _quantities = self . _build_quantities () return self . _quantities","title":"quantities()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.set_op_rhs","text":"set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list ) Source code in optimade/filtertransformers/base_transformer.py 344 345 def set_op_rhs ( self , arg ): \"\"\"set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list )\"\"\"","title":"set_op_rhs()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.set_zip_op_rhs","text":"set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) Source code in optimade/filtertransformers/base_transformer.py 350 351 352 353 354 355 356 def set_zip_op_rhs ( self , arg ): \"\"\"set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) \"\"\"","title":"set_zip_op_rhs()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.signed_int","text":"signed_int : SIGNED_INT Source code in optimade/filtertransformers/base_transformer.py 281 282 283 284 @v_args ( inline = True ) def signed_int ( self , number ): \"\"\"signed_int : SIGNED_INT\"\"\" return int ( number )","title":"signed_int()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.string","text":"string: ESCAPED_STRING Source code in optimade/filtertransformers/base_transformer.py 276 277 278 279 @v_args ( inline = True ) def string ( self , string ): \"\"\"string: ESCAPED_STRING\"\"\" return string . strip ( '\"' )","title":"string()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.transform","text":"Transform the query using the Lark Transformer then run the backend-specific post-processing methods. Source code in optimade/filtertransformers/base_transformer.py 179 180 181 182 183 184 def transform ( self , tree : Tree ) -> Any : \"\"\"Transform the query using the Lark `Transformer` then run the backend-specific post-processing methods. \"\"\" return self . postprocess ( super () . transform ( tree ))","title":"transform()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.value","text":"value: string | number | property Source code in optimade/filtertransformers/base_transformer.py 202 203 204 205 206 @v_args ( inline = True ) def value ( self , value ): \"\"\"value: string | number | property\"\"\" # Note: Return as is. return value","title":"value()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.value_list","text":"value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )* Source code in optimade/filtertransformers/base_transformer.py 301 302 def value_list ( self , arg ): \"\"\"value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )*\"\"\"","title":"value_list()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.value_op_rhs","text":"value_op_rhs: OPERATOR value Source code in optimade/filtertransformers/base_transformer.py 334 335 336 @v_args ( inline = True ) def value_op_rhs ( self , operator , value ): \"\"\"value_op_rhs: OPERATOR value\"\"\"","title":"value_op_rhs()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.value_zip","text":"value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)* Source code in optimade/filtertransformers/base_transformer.py 304 305 306 def value_zip ( self , arg ): \"\"\"value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)*\"\"\" pass","title":"value_zip()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.BaseTransformer.value_zip_list","text":"value_zip_list: value_zip ( \",\" value_zip )* Source code in optimade/filtertransformers/base_transformer.py 308 309 def value_zip_list ( self , arg ): \"\"\"value_zip_list: value_zip ( \",\" value_zip )*\"\"\"","title":"value_zip_list()"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.Quantity","text":"Class to provide information about available quantities to the transformer. The transformer can use Quantity 's to do some semantic checks, map quantities to the underlying backend field name. Attributes: Name Type Description name The name of the quantity as used in the filter expressions. backend_field The name of the field for this quantity in the backend database, will be name by default. length_quantity Another (typically integer) Quantity that can be queried as the length of this quantity, e.g. elements and nelements . Backends can then decide whether to use this for all \"LENGTH\" queries. Source code in optimade/filtertransformers/base_transformer.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class Quantity : \"\"\"Class to provide information about available quantities to the transformer. The transformer can use [`Quantity`][optimade.filtertransformers.base_transformer.Quantity]'s to * do some semantic checks, * map quantities to the underlying backend field name. Attributes: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in the backend database, will be `name` by default. length_quantity: Another (typically integer) [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] that can be queried as the length of this quantity, e.g. `elements` and `nelements`. Backends can then decide whether to use this for all \"LENGTH\" queries. \"\"\" name : str backend_field : Optional [ str ] length_quantity : Optional [ \"Quantity\" ] def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"Quantity\" = None , ): \"\"\"Initialise the `quantity` from it's name and aliases. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in the backend database, will be `name` by default. length_quantity: Another (typically integer) [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] that can be queried as the length of this quantity, e.g. `elements` and `nelements`. Backends can then decide whether to use this for all \"LENGTH\" queries. \"\"\" self . name = name self . backend_field = backend_field if backend_field is not None else name self . length_quantity = length_quantity","title":"Quantity"},{"location":"api_reference/filtertransformers/base_transformer/#optimade.filtertransformers.base_transformer.Quantity.__init__","text":"Initialise the quantity from it's name and aliases. Parameters: Name Type Description Default name str The name of the quantity as used in the filter expressions. required backend_field str The name of the field for this quantity in the backend database, will be name by default. None length_quantity Quantity Another (typically integer) Quantity that can be queried as the length of this quantity, e.g. elements and nelements . Backends can then decide whether to use this for all \"LENGTH\" queries. None Source code in optimade/filtertransformers/base_transformer.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"Quantity\" = None , ): \"\"\"Initialise the `quantity` from it's name and aliases. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in the backend database, will be `name` by default. length_quantity: Another (typically integer) [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] that can be queried as the length of this quantity, e.g. `elements` and `nelements`. Backends can then decide whether to use this for all \"LENGTH\" queries. \"\"\" self . name = name self . backend_field = backend_field if backend_field is not None else name self . length_quantity = length_quantity","title":"__init__()"},{"location":"api_reference/filtertransformers/elasticsearch/","text":"elasticsearch \u00b6 ElasticTransformer \u00b6 Transformer that transforms v0.10.1 / v1.0 grammar parse trees into Elasticsearch queries. Uses elasticsearch_dsl and will produce an elasticsearch_dsl.Q instance. Source code in optimade/filtertransformers/elasticsearch.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 class ElasticTransformer ( BaseTransformer ): \"\"\"Transformer that transforms ``v0.10.1``/`v1.0` grammar parse trees into Elasticsearch queries. Uses elasticsearch_dsl and will produce an `elasticsearch_dsl.Q` instance. \"\"\" operator_map = { \"<\" : \"lt\" , \"<=\" : \"lte\" , \">\" : \"gt\" , \">=\" : \"gte\" , } _quantity_type : Type [ ElasticsearchQuantity ] = ElasticsearchQuantity def __init__ ( self , mapper : BaseResourceMapper = None , quantities : Dict [ str , Quantity ] = None ): if quantities is not None : self . quantities = quantities super () . __init__ ( mapper = mapper ) def _field ( self , quantity : Union [ str , Quantity ], nested : Quantity = None ) -> str : \"\"\"Used to unwrap from `property` to the string backend field name. If passed a `Quantity` (or a derived `ElasticsearchQuantity`), this method returns the backend field name, modulo some handling of nested fields. If passed a string quantity name: - Check that the name does not match a relationship type, raising a `NotImplementedError` if it does. - If the string is prefixed by an underscore, assume this is a provider-specific field from another provider and simply return it. The original `property` rule would have already filtered out provider fields for this backend appropriately as `Quantity` objects. Returns: The field name to use for database queries. \"\"\" if isinstance ( quantity , str ): if quantity in self . mapper . RELATIONSHIP_ENTRY_TYPES : raise NotImplementedError ( f \"Unable to filter on relationships with type { quantity !r} \" ) # In this case, the property rule has already filtered out fields # that do not match this provider, so this indicates an \"other provider\" # field that should be passed over if quantity . startswith ( \"_\" ): return quantity if nested is not None : return \" %s . %s \" % ( nested . backend_field , quantity . name ) return quantity . backend_field def _query_op ( self , quantity : Union [ ElasticsearchQuantity , str ], op : str , value : Union [ str , float , int ], nested : ElasticsearchQuantity = None , ) -> Q : \"\"\"Return a range, match, or term query for the given quantity, comparison operator, and value. Returns: An elasticsearch_dsl query. Raises: BadRequest: If the query is not well-defined or is not supported. \"\"\" field = self . _field ( quantity , nested = nested ) if op in self . operator_map : return Q ( \"range\" , ** { field : { self . operator_map [ op ]: value }}) # If quantity is an \"other provider\" field then use Keyword as the default # mapping type. These queries should not match on anything as the field # is not present in the index. elastic_mapping_type = Keyword if isinstance ( quantity , ElasticsearchQuantity ): elastic_mapping_type = quantity . elastic_mapping_type if elastic_mapping_type == Text : query_type = \"match\" elif elastic_mapping_type in [ Keyword , Integer ]: query_type = \"term\" else : raise NotImplementedError ( \"Quantity has unsupported ES field type\" ) if op in [ \"=\" , \"\" ]: return Q ( query_type , ** { field : value }) if op == \"!=\" : # != queries must also include an existence check # Note that for MongoDB, `$exists` will include null-valued fields, # where as in ES `exists` excludes them. # pylint: disable=invalid-unary-operand-type return ~ Q ( query_type , ** { field : value }) & Q ( \"exists\" , field = field ) def _has_query_op ( self , quantities , op , predicate_zip_list ): \"\"\"Returns a bool query that combines the operator calls `_query_op` for each predicate and zipped quantity predicate combination. \"\"\" if op == \"HAS\" : kind = \"must\" # in case of HAS we do a must over the \"list\" of the one given element elif op == \"HAS ALL\" : kind = \"must\" elif op == \"HAS ANY\" : kind = \"should\" elif op == \"HAS ONLY\" : # HAS ONLY comes with heavy limitations, because there is no such thing # in elastic search. Only supported for elements, where we can construct # an anonymous \"formula\" based on elements sorted by order number and # can do a = comparision to check if all elements are contained # @ml-evs: Disabling this HAS ONLY workaround as tests are not passing raise NotImplementedError ( \"HAS ONLY queries are not currently supported by the Elasticsearch backend.\" ) # from optimade.models import CHEMICAL_SYMBOLS, ATOMIC_NUMBERS # if len(quantities) > 1: # raise NotImplementedError(\"HAS ONLY is not supported with zip\") # quantity = quantities[0] # if quantity.has_only_quantity is None: # raise NotImplementedError( # \"HAS ONLY is not supported by %s\" % quantity.name # ) # def values(): # for predicates in predicate_zip_list: # if len(predicates) != 1: # raise NotImplementedError(\"Tuples not supported in HAS ONLY\") # op, value = predicates[0] # if op != \"=\": # raise NotImplementedError( # \"Predicated not supported in HAS ONLY\" # ) # if not isinstance(value, str): # raise NotImplementedError(\"Only strings supported in HAS ONLY\") # yield value # try: # order_numbers = list([ATOMIC_NUMBERS[element] for element in values()]) # order_numbers.sort() # value = \"\".join( # [CHEMICAL_SYMBOLS[number - 1] for number in order_numbers] # ) # except KeyError: # raise NotImplementedError( # \"HAS ONLY is only supported for chemical symbols\" # ) # return Q(\"term\", **{quantity.has_only_quantity.name: value}) else : raise NotImplementedError ( f \"Unrecognised operation { op } .\" ) queries = [ self . _has_query ( quantities , predicates ) for predicates in predicate_zip_list ] return Q ( \"bool\" , ** { kind : queries }) def _has_query ( self , quantities , predicates ): \"\"\" Returns a bool query that combines the operator queries ():func:`_query_op`) for quantity pericate combination. \"\"\" if len ( quantities ) != len ( predicates ): raise ValueError ( \"Tuple length does not match: %s <o> %s \" % ( \":\" . join ( quantities ), \":\" . join ( predicates )) ) if len ( quantities ) == 1 : o , value = predicates [ 0 ] return self . _query_op ( quantities [ 0 ], o , value ) nested_quantity = quantities [ 0 ] . nested_quantity same_nested_quantity = any ( q . nested_quantity != nested_quantity for q in quantities ) if nested_quantity is None or same_nested_quantity : raise NotImplementedError ( \"Expression with tuples are only supported for %s \" % \", \" . join ( quantities ) ) queries = [ self . _query_op ( quantity , o , value , nested = nested_quantity ) for quantity , ( o , value ) in zip ( quantities , predicates ) ] return Q ( \"nested\" , path = self . _field ( nested_quantity ), query = dict ( bool = dict ( must = queries )), ) def __default__ ( self , tree , children , * args , ** kwargs ): \"\"\"Default behavior for rules that only replace one symbol with another\"\"\" return children [ 0 ] def filter ( self , args ): # filter: expression* if len ( args ) == 1 : return args [ 0 ] return Q ( \"bool\" , ** { \"must\" : args }) def expression_clause ( self , args ): # expression_clause: expression_phrase ( _AND expression_phrase )* result = args [ 0 ] for arg in args [ 1 :]: result &= arg return result def expression ( self , args ): # expression: expression_clause ( _OR expression_clause )* result = args [ 0 ] for arg in args [ 1 :]: result |= arg return result def expression_phrase ( self , args ): # expression_phrase: [ NOT ] ( operator | \"(\" expression \")\" ) if args [ 0 ] == \"NOT\" : return ~ args [ 1 ] return args [ 0 ] @v_args ( inline = True ) def property_first_comparison ( self , quantity , query ): # property_first_comparison: property *_rhs return query ( quantity ) @v_args ( inline = True ) def constant_first_comparison ( self , value , op , quantity ): # constant_first_comparison: constant OPERATOR ( non_string_value | ...not_implemented_string ) if not isinstance ( quantity , Quantity ): raise TypeError ( \"Only quantities can be compared to constant values.\" ) return self . _query_op ( quantity , self . _reversed_operator_map [ op ], value ) @v_args ( inline = True ) def value_op_rhs ( self , op , value ): # value_op_rhs: OPERATOR value return lambda quantity : self . _query_op ( quantity , op , value ) def length_op_rhs ( self , args ): # length_op_rhs: LENGTH [ OPERATOR ] signed_int value = args [ - 1 ] if len ( args ) == 3 : op = args [ 1 ] else : op = \"=\" def query ( quantity ): # This is only the case if quantity is an \"other\" provider's field, # in which case, we should treat it as unknown and try to do a null query if isinstance ( quantity , str ): return self . _query_op ( quantity , op , value ) if quantity . length_quantity is None : raise NotImplementedError ( f \"LENGTH is not supported for { quantity . name !r} \" ) quantity = quantity . length_quantity return self . _query_op ( quantity , op , value ) return query @v_args ( inline = True ) def known_op_rhs ( self , _ , value ): # known_op_rhs: IS ( KNOWN | UNKNOWN ) def query ( quantity ): query = Q ( \"exists\" , field = self . _field ( quantity )) if value == \"KNOWN\" : return query elif value == \"UNKNOWN\" : return ~ query # pylint: disable=invalid-unary-operand-type raise NotImplementedError return query def set_op_rhs ( self , args ): # set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ... ) values = args [ - 1 ] if not isinstance ( values , list ): if len ( args ) == 3 : op = args [ 1 ] else : op = \"=\" values = [( op , values )] if len ( args ) == 3 : op = \"HAS \" + args [ 1 ] else : op = \"HAS\" return lambda quantity : self . _has_query_op ( [ quantity ], op , [[ value ] for value in values ] ) def set_zip_op_rhs ( self , args ): # set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) add_on = args [ 0 ] values = args [ - 1 ] if len ( args ) == 4 : op = \"HAS \" + args [ 2 ] else : op = \"HAS\" values = [ values ] return lambda quantity : self . _has_query_op ([ quantity ] + add_on , op , values ) def property_zip_addon ( self , args ): raise NotImplementedError ( \"Correlated list queries are not supported.\" ) return args def value_zip ( self , args ): raise NotImplementedError ( \"Correlated list queries are not supported.\" ) return self . value_list ( args ) def value_zip_list ( self , args ): raise NotImplementedError ( \"Correlated list queries are not supported.\" ) return args def value_list ( self , args ): result = [] op = \"=\" for arg in args : if arg in [ \"<\" , \"<=\" , \">\" , \">=\" , \"!=\" , \"=\" ]: op = arg else : result . append ( ( op , arg , ) ) op = \"=\" return result def fuzzy_string_op_rhs ( self , args ): op = args [ 0 ] value = args [ - 1 ] if op == \"CONTAINS\" : wildcard = \"* %s *\" % value if op == \"STARTS\" : wildcard = \" %s *\" % value if op == \"ENDS\" : wildcard = \"* %s \" % value return lambda quantity : Q ( \"wildcard\" , ** { self . _field ( quantity ): wildcard }) @v_args ( inline = True ) def string ( self , string ): # string: ESCAPED_STRING return string . strip ( '\"' ) @v_args ( inline = True ) def signed_int ( self , number ): # signed_int : SIGNED_INT return int ( number ) @v_args ( inline = True ) def number ( self , number ): # number: SIGNED_INT | SIGNED_FLOAT if number . type == \"SIGNED_INT\" : type_ = int elif number . type == \"SIGNED_FLOAT\" : type_ = float return type_ ( number ) __default__ ( tree , children , * args , ** kwargs ) \u00b6 Default behavior for rules that only replace one symbol with another Source code in optimade/filtertransformers/elasticsearch.py 290 291 292 def __default__ ( self , tree , children , * args , ** kwargs ): \"\"\"Default behavior for rules that only replace one symbol with another\"\"\" return children [ 0 ] ElasticsearchQuantity \u00b6 Elasticsearch-specific extension of the underlying Quantity class. Attributes: Name Type Description name str The name of the quantity as used in the filter expressions. backend_field Optional [ str ] The name of the field for this quantity in Elasticsearch, will be name by default. elastic_mapping_type A decendent of an elasticsearch_dsl.Field that denotes which mapping type was used in the Elasticsearch index. length_quantity Optional [ ElasticsearchQuantity ] Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in CHEMICAL_SYMBOLS ) and quantities with this attribute. nested_quantity To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. Source code in optimade/filtertransformers/elasticsearch.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class ElasticsearchQuantity ( Quantity ): \"\"\"Elasticsearch-specific extension of the underlying [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] class. Attributes: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in Elasticsearch, will be ``name`` by default. elastic_mapping_type: A decendent of an `elasticsearch_dsl.Field` that denotes which mapping type was used in the Elasticsearch index. length_quantity: Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity: Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in ``CHEMICAL_SYMBOLS``) and quantities with this attribute. nested_quantity: To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. \"\"\" name : str backend_field : Optional [ str ] length_quantity : Optional [ \"ElasticsearchQuantity\" ] elastic_mapping_type : Optional [ Field ] has_only_quantity : Optional [ \"ElasticsearchQuantity\" ] nested_quantity : Optional [ \"ElasticsearchQuantity\" ] def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"ElasticsearchQuantity\" = None , elastic_mapping_type : Field = None , has_only_quantity : \"ElasticsearchQuantity\" = None , nested_quantity : \"ElasticsearchQuantity\" = None , ): \"\"\"Initialise the quantity from its name, aliases and mapping type. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in Elasticsearch, will be ``name`` by default. elastic_mapping_type: A decendent of an `elasticsearch_dsl.Field` that denotes which mapping type was used in the Elasticsearch index. length_quantity: Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity: Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in ``CHEMICAL_SYMBOLS``) and quantities with this attribute. nested_quantity: To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. \"\"\" super () . __init__ ( name , backend_field , length_quantity ) self . elastic_mapping_type = ( Keyword if elastic_mapping_type is None else elastic_mapping_type ) self . has_only_quantity = has_only_quantity self . nested_quantity = nested_quantity __init__ ( name , backend_field = None , length_quantity = None , elastic_mapping_type = None , has_only_quantity = None , nested_quantity = None ) \u00b6 Initialise the quantity from its name, aliases and mapping type. Parameters: Name Type Description Default name str The name of the quantity as used in the filter expressions. required backend_field str The name of the field for this quantity in Elasticsearch, will be name by default. None elastic_mapping_type Field A decendent of an elasticsearch_dsl.Field that denotes which mapping type was used in the Elasticsearch index. None length_quantity ElasticsearchQuantity Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. None has_only_quantity ElasticsearchQuantity Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in CHEMICAL_SYMBOLS ) and quantities with this attribute. None nested_quantity ElasticsearchQuantity To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. None Source code in optimade/filtertransformers/elasticsearch.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"ElasticsearchQuantity\" = None , elastic_mapping_type : Field = None , has_only_quantity : \"ElasticsearchQuantity\" = None , nested_quantity : \"ElasticsearchQuantity\" = None , ): \"\"\"Initialise the quantity from its name, aliases and mapping type. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in Elasticsearch, will be ``name`` by default. elastic_mapping_type: A decendent of an `elasticsearch_dsl.Field` that denotes which mapping type was used in the Elasticsearch index. length_quantity: Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity: Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in ``CHEMICAL_SYMBOLS``) and quantities with this attribute. nested_quantity: To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. \"\"\" super () . __init__ ( name , backend_field , length_quantity ) self . elastic_mapping_type = ( Keyword if elastic_mapping_type is None else elastic_mapping_type ) self . has_only_quantity = has_only_quantity self . nested_quantity = nested_quantity","title":"elasticsearch"},{"location":"api_reference/filtertransformers/elasticsearch/#elasticsearch","text":"","title":"elasticsearch"},{"location":"api_reference/filtertransformers/elasticsearch/#optimade.filtertransformers.elasticsearch.ElasticTransformer","text":"Transformer that transforms v0.10.1 / v1.0 grammar parse trees into Elasticsearch queries. Uses elasticsearch_dsl and will produce an elasticsearch_dsl.Q instance. Source code in optimade/filtertransformers/elasticsearch.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 class ElasticTransformer ( BaseTransformer ): \"\"\"Transformer that transforms ``v0.10.1``/`v1.0` grammar parse trees into Elasticsearch queries. Uses elasticsearch_dsl and will produce an `elasticsearch_dsl.Q` instance. \"\"\" operator_map = { \"<\" : \"lt\" , \"<=\" : \"lte\" , \">\" : \"gt\" , \">=\" : \"gte\" , } _quantity_type : Type [ ElasticsearchQuantity ] = ElasticsearchQuantity def __init__ ( self , mapper : BaseResourceMapper = None , quantities : Dict [ str , Quantity ] = None ): if quantities is not None : self . quantities = quantities super () . __init__ ( mapper = mapper ) def _field ( self , quantity : Union [ str , Quantity ], nested : Quantity = None ) -> str : \"\"\"Used to unwrap from `property` to the string backend field name. If passed a `Quantity` (or a derived `ElasticsearchQuantity`), this method returns the backend field name, modulo some handling of nested fields. If passed a string quantity name: - Check that the name does not match a relationship type, raising a `NotImplementedError` if it does. - If the string is prefixed by an underscore, assume this is a provider-specific field from another provider and simply return it. The original `property` rule would have already filtered out provider fields for this backend appropriately as `Quantity` objects. Returns: The field name to use for database queries. \"\"\" if isinstance ( quantity , str ): if quantity in self . mapper . RELATIONSHIP_ENTRY_TYPES : raise NotImplementedError ( f \"Unable to filter on relationships with type { quantity !r} \" ) # In this case, the property rule has already filtered out fields # that do not match this provider, so this indicates an \"other provider\" # field that should be passed over if quantity . startswith ( \"_\" ): return quantity if nested is not None : return \" %s . %s \" % ( nested . backend_field , quantity . name ) return quantity . backend_field def _query_op ( self , quantity : Union [ ElasticsearchQuantity , str ], op : str , value : Union [ str , float , int ], nested : ElasticsearchQuantity = None , ) -> Q : \"\"\"Return a range, match, or term query for the given quantity, comparison operator, and value. Returns: An elasticsearch_dsl query. Raises: BadRequest: If the query is not well-defined or is not supported. \"\"\" field = self . _field ( quantity , nested = nested ) if op in self . operator_map : return Q ( \"range\" , ** { field : { self . operator_map [ op ]: value }}) # If quantity is an \"other provider\" field then use Keyword as the default # mapping type. These queries should not match on anything as the field # is not present in the index. elastic_mapping_type = Keyword if isinstance ( quantity , ElasticsearchQuantity ): elastic_mapping_type = quantity . elastic_mapping_type if elastic_mapping_type == Text : query_type = \"match\" elif elastic_mapping_type in [ Keyword , Integer ]: query_type = \"term\" else : raise NotImplementedError ( \"Quantity has unsupported ES field type\" ) if op in [ \"=\" , \"\" ]: return Q ( query_type , ** { field : value }) if op == \"!=\" : # != queries must also include an existence check # Note that for MongoDB, `$exists` will include null-valued fields, # where as in ES `exists` excludes them. # pylint: disable=invalid-unary-operand-type return ~ Q ( query_type , ** { field : value }) & Q ( \"exists\" , field = field ) def _has_query_op ( self , quantities , op , predicate_zip_list ): \"\"\"Returns a bool query that combines the operator calls `_query_op` for each predicate and zipped quantity predicate combination. \"\"\" if op == \"HAS\" : kind = \"must\" # in case of HAS we do a must over the \"list\" of the one given element elif op == \"HAS ALL\" : kind = \"must\" elif op == \"HAS ANY\" : kind = \"should\" elif op == \"HAS ONLY\" : # HAS ONLY comes with heavy limitations, because there is no such thing # in elastic search. Only supported for elements, where we can construct # an anonymous \"formula\" based on elements sorted by order number and # can do a = comparision to check if all elements are contained # @ml-evs: Disabling this HAS ONLY workaround as tests are not passing raise NotImplementedError ( \"HAS ONLY queries are not currently supported by the Elasticsearch backend.\" ) # from optimade.models import CHEMICAL_SYMBOLS, ATOMIC_NUMBERS # if len(quantities) > 1: # raise NotImplementedError(\"HAS ONLY is not supported with zip\") # quantity = quantities[0] # if quantity.has_only_quantity is None: # raise NotImplementedError( # \"HAS ONLY is not supported by %s\" % quantity.name # ) # def values(): # for predicates in predicate_zip_list: # if len(predicates) != 1: # raise NotImplementedError(\"Tuples not supported in HAS ONLY\") # op, value = predicates[0] # if op != \"=\": # raise NotImplementedError( # \"Predicated not supported in HAS ONLY\" # ) # if not isinstance(value, str): # raise NotImplementedError(\"Only strings supported in HAS ONLY\") # yield value # try: # order_numbers = list([ATOMIC_NUMBERS[element] for element in values()]) # order_numbers.sort() # value = \"\".join( # [CHEMICAL_SYMBOLS[number - 1] for number in order_numbers] # ) # except KeyError: # raise NotImplementedError( # \"HAS ONLY is only supported for chemical symbols\" # ) # return Q(\"term\", **{quantity.has_only_quantity.name: value}) else : raise NotImplementedError ( f \"Unrecognised operation { op } .\" ) queries = [ self . _has_query ( quantities , predicates ) for predicates in predicate_zip_list ] return Q ( \"bool\" , ** { kind : queries }) def _has_query ( self , quantities , predicates ): \"\"\" Returns a bool query that combines the operator queries ():func:`_query_op`) for quantity pericate combination. \"\"\" if len ( quantities ) != len ( predicates ): raise ValueError ( \"Tuple length does not match: %s <o> %s \" % ( \":\" . join ( quantities ), \":\" . join ( predicates )) ) if len ( quantities ) == 1 : o , value = predicates [ 0 ] return self . _query_op ( quantities [ 0 ], o , value ) nested_quantity = quantities [ 0 ] . nested_quantity same_nested_quantity = any ( q . nested_quantity != nested_quantity for q in quantities ) if nested_quantity is None or same_nested_quantity : raise NotImplementedError ( \"Expression with tuples are only supported for %s \" % \", \" . join ( quantities ) ) queries = [ self . _query_op ( quantity , o , value , nested = nested_quantity ) for quantity , ( o , value ) in zip ( quantities , predicates ) ] return Q ( \"nested\" , path = self . _field ( nested_quantity ), query = dict ( bool = dict ( must = queries )), ) def __default__ ( self , tree , children , * args , ** kwargs ): \"\"\"Default behavior for rules that only replace one symbol with another\"\"\" return children [ 0 ] def filter ( self , args ): # filter: expression* if len ( args ) == 1 : return args [ 0 ] return Q ( \"bool\" , ** { \"must\" : args }) def expression_clause ( self , args ): # expression_clause: expression_phrase ( _AND expression_phrase )* result = args [ 0 ] for arg in args [ 1 :]: result &= arg return result def expression ( self , args ): # expression: expression_clause ( _OR expression_clause )* result = args [ 0 ] for arg in args [ 1 :]: result |= arg return result def expression_phrase ( self , args ): # expression_phrase: [ NOT ] ( operator | \"(\" expression \")\" ) if args [ 0 ] == \"NOT\" : return ~ args [ 1 ] return args [ 0 ] @v_args ( inline = True ) def property_first_comparison ( self , quantity , query ): # property_first_comparison: property *_rhs return query ( quantity ) @v_args ( inline = True ) def constant_first_comparison ( self , value , op , quantity ): # constant_first_comparison: constant OPERATOR ( non_string_value | ...not_implemented_string ) if not isinstance ( quantity , Quantity ): raise TypeError ( \"Only quantities can be compared to constant values.\" ) return self . _query_op ( quantity , self . _reversed_operator_map [ op ], value ) @v_args ( inline = True ) def value_op_rhs ( self , op , value ): # value_op_rhs: OPERATOR value return lambda quantity : self . _query_op ( quantity , op , value ) def length_op_rhs ( self , args ): # length_op_rhs: LENGTH [ OPERATOR ] signed_int value = args [ - 1 ] if len ( args ) == 3 : op = args [ 1 ] else : op = \"=\" def query ( quantity ): # This is only the case if quantity is an \"other\" provider's field, # in which case, we should treat it as unknown and try to do a null query if isinstance ( quantity , str ): return self . _query_op ( quantity , op , value ) if quantity . length_quantity is None : raise NotImplementedError ( f \"LENGTH is not supported for { quantity . name !r} \" ) quantity = quantity . length_quantity return self . _query_op ( quantity , op , value ) return query @v_args ( inline = True ) def known_op_rhs ( self , _ , value ): # known_op_rhs: IS ( KNOWN | UNKNOWN ) def query ( quantity ): query = Q ( \"exists\" , field = self . _field ( quantity )) if value == \"KNOWN\" : return query elif value == \"UNKNOWN\" : return ~ query # pylint: disable=invalid-unary-operand-type raise NotImplementedError return query def set_op_rhs ( self , args ): # set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ... ) values = args [ - 1 ] if not isinstance ( values , list ): if len ( args ) == 3 : op = args [ 1 ] else : op = \"=\" values = [( op , values )] if len ( args ) == 3 : op = \"HAS \" + args [ 1 ] else : op = \"HAS\" return lambda quantity : self . _has_query_op ( [ quantity ], op , [[ value ] for value in values ] ) def set_zip_op_rhs ( self , args ): # set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | ANY value_zip_list ) add_on = args [ 0 ] values = args [ - 1 ] if len ( args ) == 4 : op = \"HAS \" + args [ 2 ] else : op = \"HAS\" values = [ values ] return lambda quantity : self . _has_query_op ([ quantity ] + add_on , op , values ) def property_zip_addon ( self , args ): raise NotImplementedError ( \"Correlated list queries are not supported.\" ) return args def value_zip ( self , args ): raise NotImplementedError ( \"Correlated list queries are not supported.\" ) return self . value_list ( args ) def value_zip_list ( self , args ): raise NotImplementedError ( \"Correlated list queries are not supported.\" ) return args def value_list ( self , args ): result = [] op = \"=\" for arg in args : if arg in [ \"<\" , \"<=\" , \">\" , \">=\" , \"!=\" , \"=\" ]: op = arg else : result . append ( ( op , arg , ) ) op = \"=\" return result def fuzzy_string_op_rhs ( self , args ): op = args [ 0 ] value = args [ - 1 ] if op == \"CONTAINS\" : wildcard = \"* %s *\" % value if op == \"STARTS\" : wildcard = \" %s *\" % value if op == \"ENDS\" : wildcard = \"* %s \" % value return lambda quantity : Q ( \"wildcard\" , ** { self . _field ( quantity ): wildcard }) @v_args ( inline = True ) def string ( self , string ): # string: ESCAPED_STRING return string . strip ( '\"' ) @v_args ( inline = True ) def signed_int ( self , number ): # signed_int : SIGNED_INT return int ( number ) @v_args ( inline = True ) def number ( self , number ): # number: SIGNED_INT | SIGNED_FLOAT if number . type == \"SIGNED_INT\" : type_ = int elif number . type == \"SIGNED_FLOAT\" : type_ = float return type_ ( number )","title":"ElasticTransformer"},{"location":"api_reference/filtertransformers/elasticsearch/#optimade.filtertransformers.elasticsearch.ElasticTransformer.__default__","text":"Default behavior for rules that only replace one symbol with another Source code in optimade/filtertransformers/elasticsearch.py 290 291 292 def __default__ ( self , tree , children , * args , ** kwargs ): \"\"\"Default behavior for rules that only replace one symbol with another\"\"\" return children [ 0 ]","title":"__default__()"},{"location":"api_reference/filtertransformers/elasticsearch/#optimade.filtertransformers.elasticsearch.ElasticsearchQuantity","text":"Elasticsearch-specific extension of the underlying Quantity class. Attributes: Name Type Description name str The name of the quantity as used in the filter expressions. backend_field Optional [ str ] The name of the field for this quantity in Elasticsearch, will be name by default. elastic_mapping_type A decendent of an elasticsearch_dsl.Field that denotes which mapping type was used in the Elasticsearch index. length_quantity Optional [ ElasticsearchQuantity ] Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in CHEMICAL_SYMBOLS ) and quantities with this attribute. nested_quantity To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. Source code in optimade/filtertransformers/elasticsearch.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class ElasticsearchQuantity ( Quantity ): \"\"\"Elasticsearch-specific extension of the underlying [`Quantity`][optimade.filtertransformers.base_transformer.Quantity] class. Attributes: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in Elasticsearch, will be ``name`` by default. elastic_mapping_type: A decendent of an `elasticsearch_dsl.Field` that denotes which mapping type was used in the Elasticsearch index. length_quantity: Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity: Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in ``CHEMICAL_SYMBOLS``) and quantities with this attribute. nested_quantity: To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. \"\"\" name : str backend_field : Optional [ str ] length_quantity : Optional [ \"ElasticsearchQuantity\" ] elastic_mapping_type : Optional [ Field ] has_only_quantity : Optional [ \"ElasticsearchQuantity\" ] nested_quantity : Optional [ \"ElasticsearchQuantity\" ] def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"ElasticsearchQuantity\" = None , elastic_mapping_type : Field = None , has_only_quantity : \"ElasticsearchQuantity\" = None , nested_quantity : \"ElasticsearchQuantity\" = None , ): \"\"\"Initialise the quantity from its name, aliases and mapping type. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in Elasticsearch, will be ``name`` by default. elastic_mapping_type: A decendent of an `elasticsearch_dsl.Field` that denotes which mapping type was used in the Elasticsearch index. length_quantity: Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity: Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in ``CHEMICAL_SYMBOLS``) and quantities with this attribute. nested_quantity: To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. \"\"\" super () . __init__ ( name , backend_field , length_quantity ) self . elastic_mapping_type = ( Keyword if elastic_mapping_type is None else elastic_mapping_type ) self . has_only_quantity = has_only_quantity self . nested_quantity = nested_quantity","title":"ElasticsearchQuantity"},{"location":"api_reference/filtertransformers/elasticsearch/#optimade.filtertransformers.elasticsearch.ElasticsearchQuantity.__init__","text":"Initialise the quantity from its name, aliases and mapping type. Parameters: Name Type Description Default name str The name of the quantity as used in the filter expressions. required backend_field str The name of the field for this quantity in Elasticsearch, will be name by default. None elastic_mapping_type Field A decendent of an elasticsearch_dsl.Field that denotes which mapping type was used in the Elasticsearch index. None length_quantity ElasticsearchQuantity Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. None has_only_quantity ElasticsearchQuantity Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in CHEMICAL_SYMBOLS ) and quantities with this attribute. None nested_quantity ElasticsearchQuantity To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. None Source code in optimade/filtertransformers/elasticsearch.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def __init__ ( self , name : str , backend_field : str = None , length_quantity : \"ElasticsearchQuantity\" = None , elastic_mapping_type : Field = None , has_only_quantity : \"ElasticsearchQuantity\" = None , nested_quantity : \"ElasticsearchQuantity\" = None , ): \"\"\"Initialise the quantity from its name, aliases and mapping type. Parameters: name: The name of the quantity as used in the filter expressions. backend_field: The name of the field for this quantity in Elasticsearch, will be ``name`` by default. elastic_mapping_type: A decendent of an `elasticsearch_dsl.Field` that denotes which mapping type was used in the Elasticsearch index. length_quantity: Elasticsearch does not support length of arrays, but we can map fields with array to other fields with ints about the array length. The LENGTH operator will only be supported for quantities with this attribute. has_only_quantity: Elasticsearch does not support exclusive search on arrays, like a list of chemical elements. But, we can order all elements by atomic number and use a keyword field with all elements to perform this search. This only works for elements (i.e. labels in ``CHEMICAL_SYMBOLS``) and quantities with this attribute. nested_quantity: To support optimade's 'zipped tuple' feature (e.g. 'elements:elements_ratios HAS \"H\":>0.33), we use elasticsearch nested objects and nested queries. This quantity will provide the field for the nested object that contains the quantity (and others). The zipped tuples will only work for quantities that share the same nested object quantity. \"\"\" super () . __init__ ( name , backend_field , length_quantity ) self . elastic_mapping_type = ( Keyword if elastic_mapping_type is None else elastic_mapping_type ) self . has_only_quantity = has_only_quantity self . nested_quantity = nested_quantity","title":"__init__()"},{"location":"api_reference/filtertransformers/mongo/","text":"mongo \u00b6 This submodule implements the MongoTransformer , which takes the parsed filter and converts it to a valid pymongo/BSON query. MongoTransformer \u00b6 A filter transformer for the MongoDB backend. Parses a lark tree into a dictionary representation to be used by pymongo or mongomock. Uses post-processing functions to handle some specific edge-cases for MongoDB. Attributes: Name Type Description operator_map A map from comparison operators to the mongoDB specific versions. inverse_operator_map A map from operators to their logical inverse. mapper A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. Source code in optimade/filtertransformers/mongo.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 class MongoTransformer ( BaseTransformer ): \"\"\"A filter transformer for the MongoDB backend. Parses a lark tree into a dictionary representation to be used by pymongo or mongomock. Uses post-processing functions to handle some specific edge-cases for MongoDB. Attributes: operator_map: A map from comparison operators to the mongoDB specific versions. inverse_operator_map: A map from operators to their logical inverse. mapper: A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. \"\"\" operator_map = { \"<\" : \"$lt\" , \"<=\" : \"$lte\" , \">\" : \"$gt\" , \">=\" : \"$gte\" , \"!=\" : \"$ne\" , \"=\" : \"$eq\" , } inverse_operator_map = { \"$lt\" : \"$gte\" , \"$lte\" : \"$gt\" , \"$gt\" : \"$lte\" , \"$gte\" : \"$lt\" , \"$ne\" : \"$eq\" , \"$eq\" : \"$ne\" , \"$in\" : \"$nin\" , \"$nin\" : \"$in\" , } def postprocess ( self , query : Dict [ str , Any ]): \"\"\"Used to post-process the nested dictionary of the parsed query.\"\"\" query = self . _apply_relationship_filtering ( query ) query = self . _apply_length_operators ( query ) query = self . _apply_unknown_or_null_filter ( query ) query = self . _apply_has_only_filter ( query ) query = self . _apply_mongo_id_filter ( query ) query = self . _apply_mongo_date_filter ( query ) return query def value_list ( self , arg ): # value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )* # NOTE: no support for optional OPERATOR, yet, so this takes the # parsed values and returns an error if that is being attempted for value in arg : if str ( value ) in self . operator_map . keys (): raise NotImplementedError ( f \"OPERATOR { value } inside value_list { arg } not implemented.\" ) return arg def value_zip ( self , arg ): # value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)* raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def value_zip_list ( self , arg ): # value_zip_list: value_zip ( \",\" value_zip )* raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def expression ( self , arg ): # expression: expression_clause ( OR expression_clause ) # expression with and without 'OR' return { \"$or\" : arg } if len ( arg ) > 1 else arg [ 0 ] def expression_clause ( self , arg ): # expression_clause: expression_phrase ( AND expression_phrase )* # expression_clause with and without 'AND' return { \"$and\" : arg } if len ( arg ) > 1 else arg [ 0 ] def expression_phrase ( self , arg ): # expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" ) return self . _recursive_expression_phrase ( arg ) @v_args ( inline = True ) def property_first_comparison ( self , quantity , query ): # property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | # set_zip_op_rhs | length_op_rhs ) # Awkwardly, MongoDB will match null fields in $ne filters, # so we need to add a check for null equality in evey $ne query. if \"$ne\" in query : return { \"$and\" : [{ quantity : query }, { quantity : { \"$ne\" : None }}]} # Check if a $size query is being made (indicating a length_op_rhs filter); if so, check for # a defined length alias to replace the $size call with the corresponding filter on the # length quantity then carefully merge the two queries. # # e.g. `(\"elements\", {\"$size\": 2, \"$all\": [\"Ag\", \"Au\"]})` should become # `{\"elements\": {\"$all\": [\"Ag\", \"Au\"]}, \"nelements\": 2}` if the `elements` -> `nelements` # length alias is defined. if \"$size\" in query : if ( getattr ( self . backend_mapping . get ( quantity ), \"length_quantity\" , None ) is not None ): size_query = { self . backend_mapping [ quantity ] . length_quantity . backend_field : query . pop ( \"$size\" ) } final_query = {} if query : final_query = { quantity : query } for q in size_query : if q in final_query : final_query [ q ] . update ( size_query [ q ]) else : final_query [ q ] = size_query [ q ] return final_query return { quantity : query } def constant_first_comparison ( self , arg ): # constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string ) return self . property_first_comparison ( arg [ 2 ], { self . operator_map [ self . _reversed_operator_map [ arg [ 1 ]]]: arg [ 0 ]} ) @v_args ( inline = True ) def value_op_rhs ( self , operator , value ): # value_op_rhs: OPERATOR value return { self . operator_map [ operator ]: value } def known_op_rhs ( self , arg ): # known_op_rhs: IS ( KNOWN | UNKNOWN ) # The OPTIMADE spec also required a type comparison with null, this must be post-processed # so here we use a special key \"#known\" which will get replaced in post-processing with the # expanded dict return { \"#known\" : arg [ 1 ] == \"KNOWN\" } def fuzzy_string_op_rhs ( self , arg ): # fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value # The WITH keyword may be omitted. if isinstance ( arg [ 1 ], Token ) and arg [ 1 ] . type == \"WITH\" : pattern = arg [ 2 ] else : pattern = arg [ 1 ] # CONTAINS if arg [ 0 ] == \"CONTAINS\" : regex = f \" { pattern } \" elif arg [ 0 ] == \"STARTS\" : regex = f \"^ { pattern } \" elif arg [ 0 ] == \"ENDS\" : regex = f \" { pattern } $\" return { \"$regex\" : regex } def set_op_rhs ( self , arg ): # set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list ) if len ( arg ) == 2 : # only value without OPERATOR return { \"$in\" : arg [ 1 :]} if arg [ 1 ] == \"ALL\" : return { \"$all\" : arg [ 2 ]} if arg [ 1 ] == \"ANY\" : return { \"$in\" : arg [ 2 ]} if arg [ 1 ] == \"ONLY\" : return { \"#only\" : arg [ 2 ]} # value with OPERATOR raise NotImplementedError ( f \"set_op_rhs not implemented for use with OPERATOR. Given: { arg } \" ) def property ( self , args ): # property: IDENTIFIER ( \".\" IDENTIFIER )* quantity = super () . property ( args ) if isinstance ( quantity , Quantity ): quantity = quantity . backend_field return \".\" . join ([ quantity ] + args [ 1 :]) def length_op_rhs ( self , arg ): # length_op_rhs: LENGTH [ OPERATOR ] value if len ( arg ) == 2 or ( len ( arg ) == 3 and arg [ 1 ] == \"=\" ): return { \"$size\" : arg [ - 1 ]} if arg [ 1 ] in self . operator_map and arg [ 1 ] != \"!=\" : # create an invalid query that needs to be post-processed # e.g. {'$size': {'$gt': 2}}, which is not allowed by Mongo. return { \"$size\" : { self . operator_map [ arg [ 1 ]]: arg [ - 1 ]}} raise NotImplementedError ( f \"Operator { arg [ 1 ] } not implemented for LENGTH filter.\" ) def set_zip_op_rhs ( self , arg ): # set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | # ANY value_zip_list ) raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def property_zip_addon ( self , arg ): # property_zip_addon: \":\" property (\":\" property)* raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def _recursive_expression_phrase ( self , arg : List ) -> Dict [ str , Any ]: \"\"\"Helper function for parsing `expression_phrase`. Recursively sorts out the correct precedence for `$not`, `$and` and `$or`. Parameters: arg: A list containing the expression to be evaluated and whether it is negated, e.g., `[\"NOT\", expr]` or just `[expr]`. Returns: The evaluated filter as a nested dictionary. \"\"\" def handle_not_and ( arg : Dict [ str , List ]) -> Dict [ str , List ]: \"\"\"Handle the case of `~(A & B) -> (~A | ~B)`. We have to check for the special case in which the \"and\" was created by a previous NOT, e.g., `NOT (NOT ({\"a\": {\"$eq\": 6}})) -> NOT({\"$and\": [{\"a\": {\"$ne\": 6}},{\"a\": {\"$ne\": None}}]})` Parameters: arg: A dictionary with key `\"$and\"` containing a list of expressions. Returns: A dictionary with key `\"$or\"` containing a list of the appropriate negated expressions. \"\"\" expr1 = arg [ \"$and\" ][ 0 ] expr2 = arg [ \"$and\" ][ 1 ] if expr1 . keys () == expr2 . keys (): key = list ( expr1 . keys ())[ 0 ] for e , f in itertools . permutations (( expr1 , expr2 )): if e . get ( key ) == { \"$ne\" : None }: return self . _recursive_expression_phrase ([ \"NOT\" , f ]) return { \"$or\" : [ self . _recursive_expression_phrase ([ \"NOT\" , subdict ]) for subdict in arg [ \"$and\" ] ] } def handle_not_or ( arg : Dict [ str , List ]) -> Dict [ str , List ]: \"\"\"Handle the case of ~(A | B) -> (~A & ~B). !!! note Although the MongoDB `$nor` could be used here, it is not convenient as it will also return documents where the filtered field is missing when testing for inequality. Parameters: arg: A dictionary with key `\"$or\"` containing a list of expressions. Returns: A dictionary with key `\"$and\"` that lists the appropriate negated expressions. \"\"\" return { \"$and\" : [ self . _recursive_expression_phrase ([ \"NOT\" , subdict ]) for subdict in arg [ \"$or\" ] ] } if len ( arg ) == 1 : # without NOT return arg [ 0 ] if \"$or\" in arg [ 1 ]: return handle_not_or ( arg [ 1 ]) if \"$and\" in arg [ 1 ]: return handle_not_and ( arg [ 1 ]) prop , expr = next ( iter ( arg [ 1 ] . items ())) operator , value = next ( iter ( expr . items ())) if operator == \"$not\" : # Case of double negation e.g. NOT(\"$not\":{ ...}) return { prop : value } # If the NOT operator occurs at the lowest nesting level, # the expression can be simplified by using the opposite operator and removing the not. if operator in self . inverse_operator_map : filter_ = { prop : { self . inverse_operator_map [ operator ]: value }} if operator in ( \"$in\" , \"$eq\" ): filter_ = { \"$and\" : [ filter_ , { prop : { \"$ne\" : None }}]} return filter_ filter_ = { prop : { \"$not\" : expr }} if \"#known\" in expr : return filter_ return { \"$and\" : [ filter_ , { prop : { \"$ne\" : None }}]} def _apply_length_operators ( self , filter_ : dict ) -> dict : \"\"\"Check for any invalid pymongo queries that involve applying a comparison operator to the length of a field, and transform them into a test for existence of the relevant entry, e.g. \"list LENGTH > 3\" becomes \"does the 4th list entry exist?\". \"\"\" def check_for_length_op_filter ( _ , expr ): return ( isinstance ( expr , dict ) and \"$size\" in expr and isinstance ( expr [ \"$size\" ], dict ) ) def apply_length_op ( subdict , prop , expr ): # assumes that the dictionary only has one element by design # (we just made it above in the transformer) operator , value = list ( expr [ \"$size\" ] . items ())[ 0 ] if operator in self . operator_map . values () and operator != \"$ne\" : # worth being explicit here, I think _prop = None existence = None if operator == \"$gt\" : _prop = f \" { prop } . { value + 1 } \" existence = True elif operator == \"$gte\" : _prop = f \" { prop } . { value } \" existence = True elif operator == \"$lt\" : _prop = f \" { prop } . { value } \" existence = False elif operator == \"$lte\" : _prop = f \" { prop } . { value + 1 } \" existence = False if _prop is not None : subdict . pop ( prop ) subdict [ _prop ] = { \"$exists\" : existence } return subdict return recursive_postprocessing ( filter_ , check_for_length_op_filter , apply_length_op , ) def _apply_relationship_filtering ( self , filter_ : dict ) -> dict : \"\"\"Check query for property names that match the entry types, and transform them as relationship filters rather than property filters. \"\"\" def check_for_entry_type ( prop , _ ): return str ( prop ) . count ( \".\" ) == 1 and str ( prop ) . split ( \".\" )[ 0 ] in ( \"structures\" , \"references\" , ) def replace_with_relationship ( subdict , prop , expr ): _prop , _field = str ( prop ) . split ( \".\" ) if _field != \"id\" : raise NotImplementedError ( f 'Cannot filter relationships by field \" { _field } \", only \"id\" is supported.' ) subdict [ f \"relationships. { _prop } .data. { _field } \" ] = expr subdict . pop ( prop ) return subdict return recursive_postprocessing ( filter_ , check_for_entry_type , replace_with_relationship ) def _apply_has_only_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces the magic key `\"#only\"` with the proper 'HAS ONLY' query. \"\"\" def check_for_only_filter ( _ , expr ): \"\"\"Find cases where the magic key `\"#only\"` is in the query.\"\"\" return isinstance ( expr , dict ) and ( \"#only\" in expr ) def replace_only_filter ( subdict : dict , prop : str , expr : dict ): \"\"\"Replace the magic key `\"#only\"` (added by this transformer) with an `$elemMatch`-based query. The first part of the query selects all the documents that contain any value that does not match any target values for the property `prop`. Subsequently, this selection is inverted, to get the documents that only have the allowed values. This inversion also selects documents with edge-case values such as null or empty lists; these are removed in the second part of the query that makes sure that only documents with lists that have at least one value are selected. \"\"\" if \"$and\" not in subdict : subdict [ \"$and\" ] = [] if prop . startswith ( \"relationships.\" ): if prop not in ( \"relationships.references.data.id\" , \"relationships.structures.data.id\" , ): raise BadRequest ( f \"Unable to query on unrecognised field { prop } .\" ) first_part_prop = \".\" . join ( prop . split ( \".\" )[: - 1 ]) subdict [ \"$and\" ] . append ( { first_part_prop : { \"$not\" : { \"$elemMatch\" : { \"id\" : { \"$nin\" : expr [ \"#only\" ]}}} } } ) subdict [ \"$and\" ] . append ({ first_part_prop + \".0\" : { \"$exists\" : True }}) else : subdict [ \"$and\" ] . append ( { prop : { \"$not\" : { \"$elemMatch\" : { \"$nin\" : expr [ \"#only\" ]}}}} ) subdict [ \"$and\" ] . append ({ prop + \".0\" : { \"$exists\" : True }}) subdict . pop ( prop ) return subdict return recursive_postprocessing ( filter_ , check_for_only_filter , replace_only_filter ) def _apply_unknown_or_null_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces the check for KNOWN with a check for existence and a check for not null, and the inverse for UNKNOWN. \"\"\" def check_for_known_filter ( _ , expr ): \"\"\"Find cases where the query dict looks like `{\"field\": {\"#known\": T/F}}` or `{\"field\": \"$not\": {\"#known\": T/F}}`, which is a magic word for KNOWN/UNKNOWN filters in this transformer. \"\"\" return isinstance ( expr , dict ) and ( \"#known\" in expr or \"#known\" in expr . get ( \"$not\" , {}) ) def replace_known_filter_with_or ( subdict , prop , expr ): \"\"\"Replace magic key `\"#known\"` (added by this transformer) with the appropriate combination of `$exists` and/or test for nullity. combination of $exists and/or $eq/$ne null. \"\"\" not_ = set ( expr . keys ()) == { \"$not\" } if not_ : expr = expr [ \"$not\" ] exists = expr [ \"#known\" ] ^ not_ top_level_key = \"$or\" comparison_operator = \"$eq\" if exists : top_level_key = \"$and\" comparison_operator = \"$ne\" if top_level_key not in subdict : subdict [ top_level_key ] = [] subdict [ top_level_key ] . append ({ prop : { \"$exists\" : exists }}) subdict [ top_level_key ] . append ({ prop : { comparison_operator : None }}) subdict . pop ( prop ) return subdict return recursive_postprocessing ( filter_ , check_for_known_filter , replace_known_filter_with_or ) def _apply_mongo_id_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces any operations on the special Mongodb `_id` key with the corresponding operation on a BSON `ObjectId` type. \"\"\" def check_for_id_key ( prop , _ ): \"\"\"Find cases where the query dict is operating on the `_id` field.\"\"\" return prop == \"_id\" def replace_str_id_with_objectid ( subdict , prop , expr ): from bson import ObjectId for operator in subdict [ prop ]: val = subdict [ prop ][ operator ] if operator not in ( \"$eq\" , \"$ne\" ): if self . mapper is not None : prop = self . mapper . get_optimade_field ( prop ) raise NotImplementedError ( f \"Operator { operator } not supported for query on field { prop !r} , can only test for equality\" ) if isinstance ( val , str ): subdict [ prop ][ operator ] = ObjectId ( val ) return subdict return recursive_postprocessing ( filter_ , check_for_id_key , replace_str_id_with_objectid ) def _apply_mongo_date_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces any operations on suspected timestamp properties with the corresponding operation on a BSON `DateTime` type. \"\"\" def check_for_timestamp_field ( prop , _ ): \"\"\"Find cases where the query dict is operating on a timestamp field.\"\"\" if self . mapper is not None : prop = self . mapper . get_optimade_field ( prop ) return prop == \"last_modified\" def replace_str_date_with_datetime ( subdict , prop , expr ): \"\"\"Encode suspected dates in with BSON.\"\"\" import bson.json_util for operator in subdict [ prop ]: query_datetime = bson . json_util . loads ( bson . json_util . dumps ({ \"$date\" : subdict [ prop ][ operator ]}), json_options = bson . json_util . DEFAULT_JSON_OPTIONS . with_options ( tz_aware = True , tzinfo = bson . tz_util . utc ), ) if query_datetime . microsecond != 0 : warnings . warn ( f \"Query for timestamp { subdict [ prop ][ operator ] !r} for field { prop !r} contained microseconds, which is not RFC3339 compliant. \" \"This may cause undefined behaviour for the underlying database.\" , TimestampNotRFCCompliant , ) subdict [ prop ][ operator ] = query_datetime return subdict return recursive_postprocessing ( filter_ , check_for_timestamp_field , replace_str_date_with_datetime ) postprocess ( query ) \u00b6 Used to post-process the nested dictionary of the parsed query. Source code in optimade/filtertransformers/mongo.py 57 58 59 60 61 62 63 64 65 def postprocess ( self , query : Dict [ str , Any ]): \"\"\"Used to post-process the nested dictionary of the parsed query.\"\"\" query = self . _apply_relationship_filtering ( query ) query = self . _apply_length_operators ( query ) query = self . _apply_unknown_or_null_filter ( query ) query = self . _apply_has_only_filter ( query ) query = self . _apply_mongo_id_filter ( query ) query = self . _apply_mongo_date_filter ( query ) return query recursive_postprocessing ( filter_ , condition , replacement ) \u00b6 Recursively descend into the query, checking each dictionary (contained in a list, or as an entry in another dictionary) for the condition passed. If the condition is true, apply the replacement to the dictionary. Parameters: Name Type Description Default filter_ list/dict the filter_ to process. required condition callable a function that returns True if the replacement function should be applied. It should take as arguments the property and expression from the filter_, as would be returned by iterating over filter_.items() . required replacement callable a function that returns the processed dictionary. It should take as arguments the dictionary to modify, the property and the expression (as described above). required Example For the simple case of replacing one field name with another, the following functions could be used: def condition ( prop , expr ): return prop == \"field_name_old\" def replacement ( d , prop , expr ): d [ \"field_name_old\" ] = d . pop ( prop ) filter_ = recursive_postprocessing ( filter_ , condition , replacement ) Source code in optimade/filtertransformers/mongo.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 def recursive_postprocessing ( filter_ , condition , replacement ): \"\"\"Recursively descend into the query, checking each dictionary (contained in a list, or as an entry in another dictionary) for the condition passed. If the condition is true, apply the replacement to the dictionary. Parameters: filter_ (list/dict): the filter_ to process. condition (callable): a function that returns True if the replacement function should be applied. It should take as arguments the property and expression from the filter_, as would be returned by iterating over `filter_.items()`. replacement (callable): a function that returns the processed dictionary. It should take as arguments the dictionary to modify, the property and the expression (as described above). Example: For the simple case of replacing one field name with another, the following functions could be used: ```python def condition(prop, expr): return prop == \"field_name_old\" def replacement(d, prop, expr): d[\"field_name_old\"] = d.pop(prop) filter_ = recursive_postprocessing( filter_, condition, replacement ) ``` \"\"\" if isinstance ( filter_ , list ): result = [ recursive_postprocessing ( q , condition , replacement ) for q in filter_ ] return result if isinstance ( filter_ , dict ): # this could potentially lead to memory leaks if the filter_ is *heavily* nested _cached_filter = copy . deepcopy ( filter_ ) for prop , expr in filter_ . items (): if condition ( prop , expr ): _cached_filter = replacement ( _cached_filter , prop , expr ) elif isinstance ( expr , list ): _cached_filter [ prop ] = [ recursive_postprocessing ( q , condition , replacement ) for q in expr ] return _cached_filter return filter_","title":"mongo"},{"location":"api_reference/filtertransformers/mongo/#mongo","text":"This submodule implements the MongoTransformer , which takes the parsed filter and converts it to a valid pymongo/BSON query.","title":"mongo"},{"location":"api_reference/filtertransformers/mongo/#optimade.filtertransformers.mongo.MongoTransformer","text":"A filter transformer for the MongoDB backend. Parses a lark tree into a dictionary representation to be used by pymongo or mongomock. Uses post-processing functions to handle some specific edge-cases for MongoDB. Attributes: Name Type Description operator_map A map from comparison operators to the mongoDB specific versions. inverse_operator_map A map from operators to their logical inverse. mapper A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. Source code in optimade/filtertransformers/mongo.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 class MongoTransformer ( BaseTransformer ): \"\"\"A filter transformer for the MongoDB backend. Parses a lark tree into a dictionary representation to be used by pymongo or mongomock. Uses post-processing functions to handle some specific edge-cases for MongoDB. Attributes: operator_map: A map from comparison operators to the mongoDB specific versions. inverse_operator_map: A map from operators to their logical inverse. mapper: A resource mapper object that defines the expected fields and acts as a container for various field-related configuration. \"\"\" operator_map = { \"<\" : \"$lt\" , \"<=\" : \"$lte\" , \">\" : \"$gt\" , \">=\" : \"$gte\" , \"!=\" : \"$ne\" , \"=\" : \"$eq\" , } inverse_operator_map = { \"$lt\" : \"$gte\" , \"$lte\" : \"$gt\" , \"$gt\" : \"$lte\" , \"$gte\" : \"$lt\" , \"$ne\" : \"$eq\" , \"$eq\" : \"$ne\" , \"$in\" : \"$nin\" , \"$nin\" : \"$in\" , } def postprocess ( self , query : Dict [ str , Any ]): \"\"\"Used to post-process the nested dictionary of the parsed query.\"\"\" query = self . _apply_relationship_filtering ( query ) query = self . _apply_length_operators ( query ) query = self . _apply_unknown_or_null_filter ( query ) query = self . _apply_has_only_filter ( query ) query = self . _apply_mongo_id_filter ( query ) query = self . _apply_mongo_date_filter ( query ) return query def value_list ( self , arg ): # value_list: [ OPERATOR ] value ( \",\" [ OPERATOR ] value )* # NOTE: no support for optional OPERATOR, yet, so this takes the # parsed values and returns an error if that is being attempted for value in arg : if str ( value ) in self . operator_map . keys (): raise NotImplementedError ( f \"OPERATOR { value } inside value_list { arg } not implemented.\" ) return arg def value_zip ( self , arg ): # value_zip: [ OPERATOR ] value \":\" [ OPERATOR ] value (\":\" [ OPERATOR ] value)* raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def value_zip_list ( self , arg ): # value_zip_list: value_zip ( \",\" value_zip )* raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def expression ( self , arg ): # expression: expression_clause ( OR expression_clause ) # expression with and without 'OR' return { \"$or\" : arg } if len ( arg ) > 1 else arg [ 0 ] def expression_clause ( self , arg ): # expression_clause: expression_phrase ( AND expression_phrase )* # expression_clause with and without 'AND' return { \"$and\" : arg } if len ( arg ) > 1 else arg [ 0 ] def expression_phrase ( self , arg ): # expression_phrase: [ NOT ] ( comparison | \"(\" expression \")\" ) return self . _recursive_expression_phrase ( arg ) @v_args ( inline = True ) def property_first_comparison ( self , quantity , query ): # property_first_comparison: property ( value_op_rhs | known_op_rhs | fuzzy_string_op_rhs | set_op_rhs | # set_zip_op_rhs | length_op_rhs ) # Awkwardly, MongoDB will match null fields in $ne filters, # so we need to add a check for null equality in evey $ne query. if \"$ne\" in query : return { \"$and\" : [{ quantity : query }, { quantity : { \"$ne\" : None }}]} # Check if a $size query is being made (indicating a length_op_rhs filter); if so, check for # a defined length alias to replace the $size call with the corresponding filter on the # length quantity then carefully merge the two queries. # # e.g. `(\"elements\", {\"$size\": 2, \"$all\": [\"Ag\", \"Au\"]})` should become # `{\"elements\": {\"$all\": [\"Ag\", \"Au\"]}, \"nelements\": 2}` if the `elements` -> `nelements` # length alias is defined. if \"$size\" in query : if ( getattr ( self . backend_mapping . get ( quantity ), \"length_quantity\" , None ) is not None ): size_query = { self . backend_mapping [ quantity ] . length_quantity . backend_field : query . pop ( \"$size\" ) } final_query = {} if query : final_query = { quantity : query } for q in size_query : if q in final_query : final_query [ q ] . update ( size_query [ q ]) else : final_query [ q ] = size_query [ q ] return final_query return { quantity : query } def constant_first_comparison ( self , arg ): # constant_first_comparison: constant OPERATOR ( non_string_value | not_implemented_string ) return self . property_first_comparison ( arg [ 2 ], { self . operator_map [ self . _reversed_operator_map [ arg [ 1 ]]]: arg [ 0 ]} ) @v_args ( inline = True ) def value_op_rhs ( self , operator , value ): # value_op_rhs: OPERATOR value return { self . operator_map [ operator ]: value } def known_op_rhs ( self , arg ): # known_op_rhs: IS ( KNOWN | UNKNOWN ) # The OPTIMADE spec also required a type comparison with null, this must be post-processed # so here we use a special key \"#known\" which will get replaced in post-processing with the # expanded dict return { \"#known\" : arg [ 1 ] == \"KNOWN\" } def fuzzy_string_op_rhs ( self , arg ): # fuzzy_string_op_rhs: CONTAINS value | STARTS [ WITH ] value | ENDS [ WITH ] value # The WITH keyword may be omitted. if isinstance ( arg [ 1 ], Token ) and arg [ 1 ] . type == \"WITH\" : pattern = arg [ 2 ] else : pattern = arg [ 1 ] # CONTAINS if arg [ 0 ] == \"CONTAINS\" : regex = f \" { pattern } \" elif arg [ 0 ] == \"STARTS\" : regex = f \"^ { pattern } \" elif arg [ 0 ] == \"ENDS\" : regex = f \" { pattern } $\" return { \"$regex\" : regex } def set_op_rhs ( self , arg ): # set_op_rhs: HAS ( [ OPERATOR ] value | ALL value_list | ANY value_list | ONLY value_list ) if len ( arg ) == 2 : # only value without OPERATOR return { \"$in\" : arg [ 1 :]} if arg [ 1 ] == \"ALL\" : return { \"$all\" : arg [ 2 ]} if arg [ 1 ] == \"ANY\" : return { \"$in\" : arg [ 2 ]} if arg [ 1 ] == \"ONLY\" : return { \"#only\" : arg [ 2 ]} # value with OPERATOR raise NotImplementedError ( f \"set_op_rhs not implemented for use with OPERATOR. Given: { arg } \" ) def property ( self , args ): # property: IDENTIFIER ( \".\" IDENTIFIER )* quantity = super () . property ( args ) if isinstance ( quantity , Quantity ): quantity = quantity . backend_field return \".\" . join ([ quantity ] + args [ 1 :]) def length_op_rhs ( self , arg ): # length_op_rhs: LENGTH [ OPERATOR ] value if len ( arg ) == 2 or ( len ( arg ) == 3 and arg [ 1 ] == \"=\" ): return { \"$size\" : arg [ - 1 ]} if arg [ 1 ] in self . operator_map and arg [ 1 ] != \"!=\" : # create an invalid query that needs to be post-processed # e.g. {'$size': {'$gt': 2}}, which is not allowed by Mongo. return { \"$size\" : { self . operator_map [ arg [ 1 ]]: arg [ - 1 ]}} raise NotImplementedError ( f \"Operator { arg [ 1 ] } not implemented for LENGTH filter.\" ) def set_zip_op_rhs ( self , arg ): # set_zip_op_rhs: property_zip_addon HAS ( value_zip | ONLY value_zip_list | ALL value_zip_list | # ANY value_zip_list ) raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def property_zip_addon ( self , arg ): # property_zip_addon: \":\" property (\":\" property)* raise NotImplementedError ( \"Correlated list queries are not supported.\" ) def _recursive_expression_phrase ( self , arg : List ) -> Dict [ str , Any ]: \"\"\"Helper function for parsing `expression_phrase`. Recursively sorts out the correct precedence for `$not`, `$and` and `$or`. Parameters: arg: A list containing the expression to be evaluated and whether it is negated, e.g., `[\"NOT\", expr]` or just `[expr]`. Returns: The evaluated filter as a nested dictionary. \"\"\" def handle_not_and ( arg : Dict [ str , List ]) -> Dict [ str , List ]: \"\"\"Handle the case of `~(A & B) -> (~A | ~B)`. We have to check for the special case in which the \"and\" was created by a previous NOT, e.g., `NOT (NOT ({\"a\": {\"$eq\": 6}})) -> NOT({\"$and\": [{\"a\": {\"$ne\": 6}},{\"a\": {\"$ne\": None}}]})` Parameters: arg: A dictionary with key `\"$and\"` containing a list of expressions. Returns: A dictionary with key `\"$or\"` containing a list of the appropriate negated expressions. \"\"\" expr1 = arg [ \"$and\" ][ 0 ] expr2 = arg [ \"$and\" ][ 1 ] if expr1 . keys () == expr2 . keys (): key = list ( expr1 . keys ())[ 0 ] for e , f in itertools . permutations (( expr1 , expr2 )): if e . get ( key ) == { \"$ne\" : None }: return self . _recursive_expression_phrase ([ \"NOT\" , f ]) return { \"$or\" : [ self . _recursive_expression_phrase ([ \"NOT\" , subdict ]) for subdict in arg [ \"$and\" ] ] } def handle_not_or ( arg : Dict [ str , List ]) -> Dict [ str , List ]: \"\"\"Handle the case of ~(A | B) -> (~A & ~B). !!! note Although the MongoDB `$nor` could be used here, it is not convenient as it will also return documents where the filtered field is missing when testing for inequality. Parameters: arg: A dictionary with key `\"$or\"` containing a list of expressions. Returns: A dictionary with key `\"$and\"` that lists the appropriate negated expressions. \"\"\" return { \"$and\" : [ self . _recursive_expression_phrase ([ \"NOT\" , subdict ]) for subdict in arg [ \"$or\" ] ] } if len ( arg ) == 1 : # without NOT return arg [ 0 ] if \"$or\" in arg [ 1 ]: return handle_not_or ( arg [ 1 ]) if \"$and\" in arg [ 1 ]: return handle_not_and ( arg [ 1 ]) prop , expr = next ( iter ( arg [ 1 ] . items ())) operator , value = next ( iter ( expr . items ())) if operator == \"$not\" : # Case of double negation e.g. NOT(\"$not\":{ ...}) return { prop : value } # If the NOT operator occurs at the lowest nesting level, # the expression can be simplified by using the opposite operator and removing the not. if operator in self . inverse_operator_map : filter_ = { prop : { self . inverse_operator_map [ operator ]: value }} if operator in ( \"$in\" , \"$eq\" ): filter_ = { \"$and\" : [ filter_ , { prop : { \"$ne\" : None }}]} return filter_ filter_ = { prop : { \"$not\" : expr }} if \"#known\" in expr : return filter_ return { \"$and\" : [ filter_ , { prop : { \"$ne\" : None }}]} def _apply_length_operators ( self , filter_ : dict ) -> dict : \"\"\"Check for any invalid pymongo queries that involve applying a comparison operator to the length of a field, and transform them into a test for existence of the relevant entry, e.g. \"list LENGTH > 3\" becomes \"does the 4th list entry exist?\". \"\"\" def check_for_length_op_filter ( _ , expr ): return ( isinstance ( expr , dict ) and \"$size\" in expr and isinstance ( expr [ \"$size\" ], dict ) ) def apply_length_op ( subdict , prop , expr ): # assumes that the dictionary only has one element by design # (we just made it above in the transformer) operator , value = list ( expr [ \"$size\" ] . items ())[ 0 ] if operator in self . operator_map . values () and operator != \"$ne\" : # worth being explicit here, I think _prop = None existence = None if operator == \"$gt\" : _prop = f \" { prop } . { value + 1 } \" existence = True elif operator == \"$gte\" : _prop = f \" { prop } . { value } \" existence = True elif operator == \"$lt\" : _prop = f \" { prop } . { value } \" existence = False elif operator == \"$lte\" : _prop = f \" { prop } . { value + 1 } \" existence = False if _prop is not None : subdict . pop ( prop ) subdict [ _prop ] = { \"$exists\" : existence } return subdict return recursive_postprocessing ( filter_ , check_for_length_op_filter , apply_length_op , ) def _apply_relationship_filtering ( self , filter_ : dict ) -> dict : \"\"\"Check query for property names that match the entry types, and transform them as relationship filters rather than property filters. \"\"\" def check_for_entry_type ( prop , _ ): return str ( prop ) . count ( \".\" ) == 1 and str ( prop ) . split ( \".\" )[ 0 ] in ( \"structures\" , \"references\" , ) def replace_with_relationship ( subdict , prop , expr ): _prop , _field = str ( prop ) . split ( \".\" ) if _field != \"id\" : raise NotImplementedError ( f 'Cannot filter relationships by field \" { _field } \", only \"id\" is supported.' ) subdict [ f \"relationships. { _prop } .data. { _field } \" ] = expr subdict . pop ( prop ) return subdict return recursive_postprocessing ( filter_ , check_for_entry_type , replace_with_relationship ) def _apply_has_only_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces the magic key `\"#only\"` with the proper 'HAS ONLY' query. \"\"\" def check_for_only_filter ( _ , expr ): \"\"\"Find cases where the magic key `\"#only\"` is in the query.\"\"\" return isinstance ( expr , dict ) and ( \"#only\" in expr ) def replace_only_filter ( subdict : dict , prop : str , expr : dict ): \"\"\"Replace the magic key `\"#only\"` (added by this transformer) with an `$elemMatch`-based query. The first part of the query selects all the documents that contain any value that does not match any target values for the property `prop`. Subsequently, this selection is inverted, to get the documents that only have the allowed values. This inversion also selects documents with edge-case values such as null or empty lists; these are removed in the second part of the query that makes sure that only documents with lists that have at least one value are selected. \"\"\" if \"$and\" not in subdict : subdict [ \"$and\" ] = [] if prop . startswith ( \"relationships.\" ): if prop not in ( \"relationships.references.data.id\" , \"relationships.structures.data.id\" , ): raise BadRequest ( f \"Unable to query on unrecognised field { prop } .\" ) first_part_prop = \".\" . join ( prop . split ( \".\" )[: - 1 ]) subdict [ \"$and\" ] . append ( { first_part_prop : { \"$not\" : { \"$elemMatch\" : { \"id\" : { \"$nin\" : expr [ \"#only\" ]}}} } } ) subdict [ \"$and\" ] . append ({ first_part_prop + \".0\" : { \"$exists\" : True }}) else : subdict [ \"$and\" ] . append ( { prop : { \"$not\" : { \"$elemMatch\" : { \"$nin\" : expr [ \"#only\" ]}}}} ) subdict [ \"$and\" ] . append ({ prop + \".0\" : { \"$exists\" : True }}) subdict . pop ( prop ) return subdict return recursive_postprocessing ( filter_ , check_for_only_filter , replace_only_filter ) def _apply_unknown_or_null_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces the check for KNOWN with a check for existence and a check for not null, and the inverse for UNKNOWN. \"\"\" def check_for_known_filter ( _ , expr ): \"\"\"Find cases where the query dict looks like `{\"field\": {\"#known\": T/F}}` or `{\"field\": \"$not\": {\"#known\": T/F}}`, which is a magic word for KNOWN/UNKNOWN filters in this transformer. \"\"\" return isinstance ( expr , dict ) and ( \"#known\" in expr or \"#known\" in expr . get ( \"$not\" , {}) ) def replace_known_filter_with_or ( subdict , prop , expr ): \"\"\"Replace magic key `\"#known\"` (added by this transformer) with the appropriate combination of `$exists` and/or test for nullity. combination of $exists and/or $eq/$ne null. \"\"\" not_ = set ( expr . keys ()) == { \"$not\" } if not_ : expr = expr [ \"$not\" ] exists = expr [ \"#known\" ] ^ not_ top_level_key = \"$or\" comparison_operator = \"$eq\" if exists : top_level_key = \"$and\" comparison_operator = \"$ne\" if top_level_key not in subdict : subdict [ top_level_key ] = [] subdict [ top_level_key ] . append ({ prop : { \"$exists\" : exists }}) subdict [ top_level_key ] . append ({ prop : { comparison_operator : None }}) subdict . pop ( prop ) return subdict return recursive_postprocessing ( filter_ , check_for_known_filter , replace_known_filter_with_or ) def _apply_mongo_id_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces any operations on the special Mongodb `_id` key with the corresponding operation on a BSON `ObjectId` type. \"\"\" def check_for_id_key ( prop , _ ): \"\"\"Find cases where the query dict is operating on the `_id` field.\"\"\" return prop == \"_id\" def replace_str_id_with_objectid ( subdict , prop , expr ): from bson import ObjectId for operator in subdict [ prop ]: val = subdict [ prop ][ operator ] if operator not in ( \"$eq\" , \"$ne\" ): if self . mapper is not None : prop = self . mapper . get_optimade_field ( prop ) raise NotImplementedError ( f \"Operator { operator } not supported for query on field { prop !r} , can only test for equality\" ) if isinstance ( val , str ): subdict [ prop ][ operator ] = ObjectId ( val ) return subdict return recursive_postprocessing ( filter_ , check_for_id_key , replace_str_id_with_objectid ) def _apply_mongo_date_filter ( self , filter_ : dict ) -> dict : \"\"\"This method loops through the query and replaces any operations on suspected timestamp properties with the corresponding operation on a BSON `DateTime` type. \"\"\" def check_for_timestamp_field ( prop , _ ): \"\"\"Find cases where the query dict is operating on a timestamp field.\"\"\" if self . mapper is not None : prop = self . mapper . get_optimade_field ( prop ) return prop == \"last_modified\" def replace_str_date_with_datetime ( subdict , prop , expr ): \"\"\"Encode suspected dates in with BSON.\"\"\" import bson.json_util for operator in subdict [ prop ]: query_datetime = bson . json_util . loads ( bson . json_util . dumps ({ \"$date\" : subdict [ prop ][ operator ]}), json_options = bson . json_util . DEFAULT_JSON_OPTIONS . with_options ( tz_aware = True , tzinfo = bson . tz_util . utc ), ) if query_datetime . microsecond != 0 : warnings . warn ( f \"Query for timestamp { subdict [ prop ][ operator ] !r} for field { prop !r} contained microseconds, which is not RFC3339 compliant. \" \"This may cause undefined behaviour for the underlying database.\" , TimestampNotRFCCompliant , ) subdict [ prop ][ operator ] = query_datetime return subdict return recursive_postprocessing ( filter_ , check_for_timestamp_field , replace_str_date_with_datetime )","title":"MongoTransformer"},{"location":"api_reference/filtertransformers/mongo/#optimade.filtertransformers.mongo.MongoTransformer.postprocess","text":"Used to post-process the nested dictionary of the parsed query. Source code in optimade/filtertransformers/mongo.py 57 58 59 60 61 62 63 64 65 def postprocess ( self , query : Dict [ str , Any ]): \"\"\"Used to post-process the nested dictionary of the parsed query.\"\"\" query = self . _apply_relationship_filtering ( query ) query = self . _apply_length_operators ( query ) query = self . _apply_unknown_or_null_filter ( query ) query = self . _apply_has_only_filter ( query ) query = self . _apply_mongo_id_filter ( query ) query = self . _apply_mongo_date_filter ( query ) return query","title":"postprocess()"},{"location":"api_reference/filtertransformers/mongo/#optimade.filtertransformers.mongo.recursive_postprocessing","text":"Recursively descend into the query, checking each dictionary (contained in a list, or as an entry in another dictionary) for the condition passed. If the condition is true, apply the replacement to the dictionary. Parameters: Name Type Description Default filter_ list/dict the filter_ to process. required condition callable a function that returns True if the replacement function should be applied. It should take as arguments the property and expression from the filter_, as would be returned by iterating over filter_.items() . required replacement callable a function that returns the processed dictionary. It should take as arguments the dictionary to modify, the property and the expression (as described above). required Example For the simple case of replacing one field name with another, the following functions could be used: def condition ( prop , expr ): return prop == \"field_name_old\" def replacement ( d , prop , expr ): d [ \"field_name_old\" ] = d . pop ( prop ) filter_ = recursive_postprocessing ( filter_ , condition , replacement ) Source code in optimade/filtertransformers/mongo.py 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 def recursive_postprocessing ( filter_ , condition , replacement ): \"\"\"Recursively descend into the query, checking each dictionary (contained in a list, or as an entry in another dictionary) for the condition passed. If the condition is true, apply the replacement to the dictionary. Parameters: filter_ (list/dict): the filter_ to process. condition (callable): a function that returns True if the replacement function should be applied. It should take as arguments the property and expression from the filter_, as would be returned by iterating over `filter_.items()`. replacement (callable): a function that returns the processed dictionary. It should take as arguments the dictionary to modify, the property and the expression (as described above). Example: For the simple case of replacing one field name with another, the following functions could be used: ```python def condition(prop, expr): return prop == \"field_name_old\" def replacement(d, prop, expr): d[\"field_name_old\"] = d.pop(prop) filter_ = recursive_postprocessing( filter_, condition, replacement ) ``` \"\"\" if isinstance ( filter_ , list ): result = [ recursive_postprocessing ( q , condition , replacement ) for q in filter_ ] return result if isinstance ( filter_ , dict ): # this could potentially lead to memory leaks if the filter_ is *heavily* nested _cached_filter = copy . deepcopy ( filter_ ) for prop , expr in filter_ . items (): if condition ( prop , expr ): _cached_filter = replacement ( _cached_filter , prop , expr ) elif isinstance ( expr , list ): _cached_filter [ prop ] = [ recursive_postprocessing ( q , condition , replacement ) for q in expr ] return _cached_filter return filter_","title":"recursive_postprocessing()"},{"location":"api_reference/models/baseinfo/","text":"baseinfo \u00b6 AvailableApiVersion \u00b6 A JSON object containing information about an available API version Source code in optimade/models/baseinfo.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class AvailableApiVersion ( BaseModel ): \"\"\"A JSON object containing information about an available API version\"\"\" url : AnyHttpUrl = StrictField ( ... , description = \"A string specifying a versioned base URL that MUST adhere to the rules in section Base URL\" , pattern = r \".+/v[0-1](\\.[0-9]+)*/?$\" , ) version : SemanticVersion = StrictField ( ... , description = \"\"\"A string containing the full version number of the API served at that versioned base URL. The version number string MUST NOT be prefixed by, e.g., 'v'. Examples: `1.0.0`, `1.0.0-rc.2`.\"\"\" , ) @validator ( \"url\" ) def url_must_be_versioned_base_url ( cls , v ): \"\"\"The URL must be a valid versioned Base URL\"\"\" if not re . match ( r \".+/v[0-1](\\.[0-9]+)*/?$\" , v ): raise ValueError ( f \"url MUST be a versioned base URL. It is: { v } \" ) return v @root_validator ( pre = False , skip_on_failure = True ) def crosscheck_url_and_version ( cls , values ): \"\"\"Check that URL version and API version are compatible.\"\"\" url_version = ( values [ \"url\" ] . split ( \"/\" )[ - 2 if values [ \"url\" ] . endswith ( \"/\" ) else - 1 ] . replace ( \"v\" , \"\" ) ) # as with version urls, we need to split any release tags or build metadata out of these URLs url_version = tuple ( int ( val ) for val in url_version . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) api_version = tuple ( int ( val ) for val in values [ \"version\" ] . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) if any ( a != b for a , b in zip ( url_version , api_version )): raise ValueError ( f \"API version { api_version } is not compatible with url version { url_version } .\" ) return values url : AnyHttpUrl = StrictField ( Ellipsis , description = 'A string specifying a versioned base URL that MUST adhere to the rules in section Base URL' , pattern = '.+/v[0-1]( \\\\ .[0-9]+)*/?$' ) class-attribute \u00b6 version : SemanticVersion = StrictField ( Ellipsis , description = \"A string containing the full version number of the API served at that versioned base URL. \\n The version number string MUST NOT be prefixed by, e.g., 'v'. \\n Examples: `1.0.0`, `1.0.0-rc.2`.\" ) class-attribute \u00b6 crosscheck_url_and_version ( values ) \u00b6 Check that URL version and API version are compatible. Source code in optimade/models/baseinfo.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @root_validator ( pre = False , skip_on_failure = True ) def crosscheck_url_and_version ( cls , values ): \"\"\"Check that URL version and API version are compatible.\"\"\" url_version = ( values [ \"url\" ] . split ( \"/\" )[ - 2 if values [ \"url\" ] . endswith ( \"/\" ) else - 1 ] . replace ( \"v\" , \"\" ) ) # as with version urls, we need to split any release tags or build metadata out of these URLs url_version = tuple ( int ( val ) for val in url_version . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) api_version = tuple ( int ( val ) for val in values [ \"version\" ] . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) if any ( a != b for a , b in zip ( url_version , api_version )): raise ValueError ( f \"API version { api_version } is not compatible with url version { url_version } .\" ) return values url_must_be_versioned_base_url ( v ) \u00b6 The URL must be a valid versioned Base URL Source code in optimade/models/baseinfo.py 30 31 32 33 34 35 @validator ( \"url\" ) def url_must_be_versioned_base_url ( cls , v ): \"\"\"The URL must be a valid versioned Base URL\"\"\" if not re . match ( r \".+/v[0-1](\\.[0-9]+)*/?$\" , v ): raise ValueError ( f \"url MUST be a versioned base URL. It is: { v } \" ) return v BaseInfoAttributes \u00b6 Attributes for Base URL Info endpoint Source code in optimade/models/baseinfo.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class BaseInfoAttributes ( BaseModel ): \"\"\"Attributes for Base URL Info endpoint\"\"\" api_version : SemanticVersion = StrictField ( ... , description = \"\"\"Presently used full version of the OPTIMADE API. The version number string MUST NOT be prefixed by, e.g., \"v\". Examples: `1.0.0`, `1.0.0-rc.2`.\"\"\" , ) available_api_versions : List [ AvailableApiVersion ] = StrictField ( ... , description = \"A list of dictionaries of available API versions at other base URLs\" , ) formats : List [ str ] = StrictField ( default = [ \"json\" ], description = \"List of available output formats.\" ) available_endpoints : List [ str ] = StrictField ( ... , description = \"List of available endpoints (i.e., the string to be appended to the versioned base URL).\" , ) entry_types_by_format : Dict [ str , List [ str ]] = StrictField ( ... , description = \"Available entry endpoints as a function of output formats.\" ) is_index : Optional [ bool ] = StrictField ( default = False , description = \"If true, this is an index meta-database base URL (see section Index Meta-Database). \" \"If this member is not provided, the client MUST assume this is not an index meta-database base URL \" \"(i.e., the default is for `is_index` to be `false`).\" , ) @validator ( \"entry_types_by_format\" , check_fields = False ) def formats_and_endpoints_must_be_valid ( cls , v , values ): for format_ , endpoints in v . items (): if format_ not in values [ \"formats\" ]: raise ValueError ( f \"' { format_ } ' must be listed in formats to be valid\" ) for endpoint in endpoints : if endpoint not in values [ \"available_endpoints\" ]: raise ValueError ( f \"' { endpoint } ' must be listed in available_endpoints to be valid\" ) return v api_version : SemanticVersion = StrictField ( Ellipsis , description = 'Presently used full version of the OPTIMADE API. \\n The version number string MUST NOT be prefixed by, e.g., \"v\". \\n Examples: `1.0.0`, `1.0.0-rc.2`.' ) class-attribute \u00b6 available_api_versions : List [ AvailableApiVersion ] = StrictField ( Ellipsis , description = 'A list of dictionaries of available API versions at other base URLs' ) class-attribute \u00b6 available_endpoints : List [ str ] = StrictField ( Ellipsis , description = 'List of available endpoints (i.e., the string to be appended to the versioned base URL).' ) class-attribute \u00b6 entry_types_by_format : Dict [ str , List [ str ]] = StrictField ( Ellipsis , description = 'Available entry endpoints as a function of output formats.' ) class-attribute \u00b6 formats : List [ str ] = StrictField ( default = [ 'json' ], description = 'List of available output formats.' ) class-attribute \u00b6 is_index : Optional [ bool ] = StrictField ( default = False , description = 'If true, this is an index meta-database base URL (see section Index Meta-Database). If this member is not provided, the client MUST assume this is not an index meta-database base URL (i.e., the default is for `is_index` to be `false`).' ) class-attribute \u00b6 formats_and_endpoints_must_be_valid ( v , values ) \u00b6 Source code in optimade/models/baseinfo.py 89 90 91 92 93 94 95 96 97 98 99 @validator ( \"entry_types_by_format\" , check_fields = False ) def formats_and_endpoints_must_be_valid ( cls , v , values ): for format_ , endpoints in v . items (): if format_ not in values [ \"formats\" ]: raise ValueError ( f \"' { format_ } ' must be listed in formats to be valid\" ) for endpoint in endpoints : if endpoint not in values [ \"available_endpoints\" ]: raise ValueError ( f \"' { endpoint } ' must be listed in available_endpoints to be valid\" ) return v BaseInfoResource \u00b6 Source code in optimade/models/baseinfo.py 102 103 104 105 class BaseInfoResource ( Resource ): id : str = Field ( \"/\" , regex = \"^/$\" ) type : str = Field ( \"info\" , regex = \"^info$\" ) attributes : BaseInfoAttributes = Field ( ... ) attributes : BaseInfoAttributes = Field ( Ellipsis ) class-attribute \u00b6 id : str = Field ( '/' , regex = '^/$' ) class-attribute \u00b6 type : str = Field ( 'info' , regex = '^info$' ) class-attribute \u00b6","title":"baseinfo"},{"location":"api_reference/models/baseinfo/#baseinfo","text":"","title":"baseinfo"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.AvailableApiVersion","text":"A JSON object containing information about an available API version Source code in optimade/models/baseinfo.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class AvailableApiVersion ( BaseModel ): \"\"\"A JSON object containing information about an available API version\"\"\" url : AnyHttpUrl = StrictField ( ... , description = \"A string specifying a versioned base URL that MUST adhere to the rules in section Base URL\" , pattern = r \".+/v[0-1](\\.[0-9]+)*/?$\" , ) version : SemanticVersion = StrictField ( ... , description = \"\"\"A string containing the full version number of the API served at that versioned base URL. The version number string MUST NOT be prefixed by, e.g., 'v'. Examples: `1.0.0`, `1.0.0-rc.2`.\"\"\" , ) @validator ( \"url\" ) def url_must_be_versioned_base_url ( cls , v ): \"\"\"The URL must be a valid versioned Base URL\"\"\" if not re . match ( r \".+/v[0-1](\\.[0-9]+)*/?$\" , v ): raise ValueError ( f \"url MUST be a versioned base URL. It is: { v } \" ) return v @root_validator ( pre = False , skip_on_failure = True ) def crosscheck_url_and_version ( cls , values ): \"\"\"Check that URL version and API version are compatible.\"\"\" url_version = ( values [ \"url\" ] . split ( \"/\" )[ - 2 if values [ \"url\" ] . endswith ( \"/\" ) else - 1 ] . replace ( \"v\" , \"\" ) ) # as with version urls, we need to split any release tags or build metadata out of these URLs url_version = tuple ( int ( val ) for val in url_version . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) api_version = tuple ( int ( val ) for val in values [ \"version\" ] . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) if any ( a != b for a , b in zip ( url_version , api_version )): raise ValueError ( f \"API version { api_version } is not compatible with url version { url_version } .\" ) return values","title":"AvailableApiVersion"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.AvailableApiVersion.url","text":"","title":"url"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.AvailableApiVersion.version","text":"","title":"version"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.AvailableApiVersion.crosscheck_url_and_version","text":"Check that URL version and API version are compatible. Source code in optimade/models/baseinfo.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 @root_validator ( pre = False , skip_on_failure = True ) def crosscheck_url_and_version ( cls , values ): \"\"\"Check that URL version and API version are compatible.\"\"\" url_version = ( values [ \"url\" ] . split ( \"/\" )[ - 2 if values [ \"url\" ] . endswith ( \"/\" ) else - 1 ] . replace ( \"v\" , \"\" ) ) # as with version urls, we need to split any release tags or build metadata out of these URLs url_version = tuple ( int ( val ) for val in url_version . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) api_version = tuple ( int ( val ) for val in values [ \"version\" ] . split ( \"-\" )[ 0 ] . split ( \"+\" )[ 0 ] . split ( \".\" ) ) if any ( a != b for a , b in zip ( url_version , api_version )): raise ValueError ( f \"API version { api_version } is not compatible with url version { url_version } .\" ) return values","title":"crosscheck_url_and_version()"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.AvailableApiVersion.url_must_be_versioned_base_url","text":"The URL must be a valid versioned Base URL Source code in optimade/models/baseinfo.py 30 31 32 33 34 35 @validator ( \"url\" ) def url_must_be_versioned_base_url ( cls , v ): \"\"\"The URL must be a valid versioned Base URL\"\"\" if not re . match ( r \".+/v[0-1](\\.[0-9]+)*/?$\" , v ): raise ValueError ( f \"url MUST be a versioned base URL. It is: { v } \" ) return v","title":"url_must_be_versioned_base_url()"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes","text":"Attributes for Base URL Info endpoint Source code in optimade/models/baseinfo.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class BaseInfoAttributes ( BaseModel ): \"\"\"Attributes for Base URL Info endpoint\"\"\" api_version : SemanticVersion = StrictField ( ... , description = \"\"\"Presently used full version of the OPTIMADE API. The version number string MUST NOT be prefixed by, e.g., \"v\". Examples: `1.0.0`, `1.0.0-rc.2`.\"\"\" , ) available_api_versions : List [ AvailableApiVersion ] = StrictField ( ... , description = \"A list of dictionaries of available API versions at other base URLs\" , ) formats : List [ str ] = StrictField ( default = [ \"json\" ], description = \"List of available output formats.\" ) available_endpoints : List [ str ] = StrictField ( ... , description = \"List of available endpoints (i.e., the string to be appended to the versioned base URL).\" , ) entry_types_by_format : Dict [ str , List [ str ]] = StrictField ( ... , description = \"Available entry endpoints as a function of output formats.\" ) is_index : Optional [ bool ] = StrictField ( default = False , description = \"If true, this is an index meta-database base URL (see section Index Meta-Database). \" \"If this member is not provided, the client MUST assume this is not an index meta-database base URL \" \"(i.e., the default is for `is_index` to be `false`).\" , ) @validator ( \"entry_types_by_format\" , check_fields = False ) def formats_and_endpoints_must_be_valid ( cls , v , values ): for format_ , endpoints in v . items (): if format_ not in values [ \"formats\" ]: raise ValueError ( f \"' { format_ } ' must be listed in formats to be valid\" ) for endpoint in endpoints : if endpoint not in values [ \"available_endpoints\" ]: raise ValueError ( f \"' { endpoint } ' must be listed in available_endpoints to be valid\" ) return v","title":"BaseInfoAttributes"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.api_version","text":"","title":"api_version"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.available_api_versions","text":"","title":"available_api_versions"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.available_endpoints","text":"","title":"available_endpoints"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.entry_types_by_format","text":"","title":"entry_types_by_format"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.formats","text":"","title":"formats"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.is_index","text":"","title":"is_index"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoAttributes.formats_and_endpoints_must_be_valid","text":"Source code in optimade/models/baseinfo.py 89 90 91 92 93 94 95 96 97 98 99 @validator ( \"entry_types_by_format\" , check_fields = False ) def formats_and_endpoints_must_be_valid ( cls , v , values ): for format_ , endpoints in v . items (): if format_ not in values [ \"formats\" ]: raise ValueError ( f \"' { format_ } ' must be listed in formats to be valid\" ) for endpoint in endpoints : if endpoint not in values [ \"available_endpoints\" ]: raise ValueError ( f \"' { endpoint } ' must be listed in available_endpoints to be valid\" ) return v","title":"formats_and_endpoints_must_be_valid()"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoResource","text":"Source code in optimade/models/baseinfo.py 102 103 104 105 class BaseInfoResource ( Resource ): id : str = Field ( \"/\" , regex = \"^/$\" ) type : str = Field ( \"info\" , regex = \"^info$\" ) attributes : BaseInfoAttributes = Field ( ... )","title":"BaseInfoResource"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoResource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoResource.id","text":"","title":"id"},{"location":"api_reference/models/baseinfo/#optimade.models.baseinfo.BaseInfoResource.type","text":"","title":"type"},{"location":"api_reference/models/entries/","text":"entries \u00b6 EntryInfoProperty \u00b6 Source code in optimade/models/entries.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 class EntryInfoProperty ( BaseModel ): description : str = StrictField ( ... , description = \"A human-readable description of the entry property\" ) unit : Optional [ str ] = StrictField ( None , description = \"\"\"The physical unit of the entry property. This MUST be a valid representation of units according to version 2.1 of [The Unified Code for Units of Measure](https://unitsofmeasure.org/ucum.html). It is RECOMMENDED that non-standard (non-SI) units are described in the description for the property.\"\"\" , ) sortable : Optional [ bool ] = StrictField ( None , description = \"\"\"Defines whether the entry property can be used for sorting with the \"sort\" parameter. If the entry listing endpoint supports sorting, this key MUST be present for sortable properties with value `true`.\"\"\" , ) type : Optional [ DataType ] = StrictField ( None , title = \"Type\" , description = \"\"\"The type of the property's value. This MUST be any of the types defined in the Data types section. For the purpose of compatibility with future versions of this specification, a client MUST accept values that are not `string` values specifying any of the OPTIMADE Data types, but MUST then also disregard the `type` field. Note, if the value is a nested type, only the outermost type should be reported. E.g., for the entry resource `structures`, the `species` property is defined as a list of dictionaries, hence its `type` value would be `list`.\"\"\" , ) description : str = StrictField ( Ellipsis , description = 'A human-readable description of the entry property' ) class-attribute \u00b6 sortable : Optional [ bool ] = StrictField ( None , description = 'Defines whether the entry property can be used for sorting with the \"sort\" parameter. \\n If the entry listing endpoint supports sorting, this key MUST be present for sortable properties with value `true`.' ) class-attribute \u00b6 type : Optional [ DataType ] = StrictField ( None , title = 'Type' , description = \"The type of the property's value. \\n This MUST be any of the types defined in the Data types section. \\n For the purpose of compatibility with future versions of this specification, a client MUST accept values that are not `string` values specifying any of the OPTIMADE Data types, but MUST then also disregard the `type` field. \\n Note, if the value is a nested type, only the outermost type should be reported. \\n E.g., for the entry resource `structures`, the `species` property is defined as a list of dictionaries, hence its `type` value would be `list`.\" ) class-attribute \u00b6 unit : Optional [ str ] = StrictField ( None , description = 'The physical unit of the entry property. \\n This MUST be a valid representation of units according to version 2.1 of [The Unified Code for Units of Measure](https://unitsofmeasure.org/ucum.html). \\n It is RECOMMENDED that non-standard (non-SI) units are described in the description for the property.' ) class-attribute \u00b6 EntryInfoResource \u00b6 Source code in optimade/models/entries.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 class EntryInfoResource ( BaseModel ): formats : List [ str ] = StrictField ( ... , description = \"List of output formats available for this type of entry.\" ) description : str = StrictField ( ... , description = \"Description of the entry.\" ) properties : Dict [ str , EntryInfoProperty ] = StrictField ( ... , description = \"A dictionary describing queryable properties for this entry type, where each key is a property name.\" , ) output_fields_by_format : Dict [ str , List [ str ]] = StrictField ( ... , description = \"Dictionary of available output fields for this entry type, where the keys are the values of the `formats` list and the values are the keys of the `properties` dictionary.\" , ) description : str = StrictField ( Ellipsis , description = 'Description of the entry.' ) class-attribute \u00b6 formats : List [ str ] = StrictField ( Ellipsis , description = 'List of output formats available for this type of entry.' ) class-attribute \u00b6 output_fields_by_format : Dict [ str , List [ str ]] = StrictField ( Ellipsis , description = 'Dictionary of available output fields for this entry type, where the keys are the values of the `formats` list and the values are the keys of the `properties` dictionary.' ) class-attribute \u00b6 properties : Dict [ str , EntryInfoProperty ] = StrictField ( Ellipsis , description = 'A dictionary describing queryable properties for this entry type, where each key is a property name.' ) class-attribute \u00b6 EntryRelationships \u00b6 This model wraps the JSON API Relationships to include type-specific top level keys. Source code in optimade/models/entries.py 43 44 45 46 47 48 49 50 51 52 53 54 class EntryRelationships ( Relationships ): \"\"\"This model wraps the JSON API Relationships to include type-specific top level keys.\"\"\" references : Optional [ ReferenceRelationship ] = StrictField ( None , description = \"Object containing links to relationships with entries of the `references` type.\" , ) structures : Optional [ StructureRelationship ] = StrictField ( None , description = \"Object containing links to relationships with entries of the `structures` type.\" , ) references : Optional [ ReferenceRelationship ] = StrictField ( None , description = 'Object containing links to relationships with entries of the `references` type.' ) class-attribute \u00b6 structures : Optional [ StructureRelationship ] = StrictField ( None , description = 'Object containing links to relationships with entries of the `structures` type.' ) class-attribute \u00b6 EntryResource \u00b6 The base model for an entry resource. Source code in optimade/models/entries.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class EntryResource ( Resource ): \"\"\"The base model for an entry resource.\"\"\" id : str = OptimadeField ( ... , description = \"\"\"An entry's ID as defined in section Definition of Terms. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - **Examples**: - `\"db/1234567\"` - `\"cod/2000000\"` - `\"cod/2000000@1234567\"` - `\"nomad/L1234567890\"` - `\"42\"`\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) type : str = OptimadeField ( description = \"\"\"The name of the type of an entry. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - MUST be an existing entry type. - The entry of type `<type>` and ID `<id>` MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. - **Example**: `\"structures\"`\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) attributes : EntryResourceAttributes = StrictField ( ... , description = \"\"\"A dictionary, containing key-value pairs representing the entry's properties, except for `type` and `id`. Database-provider-specific properties need to include the database-provider-specific prefix (see section on Database-Provider-Specific Namespace Prefixes).\"\"\" , ) relationships : Optional [ EntryRelationships ] = StrictField ( None , description = \"\"\"A dictionary containing references to other entries according to the description in section Relationships encoded as [JSON API Relationships](https://jsonapi.org/format/1.0/#document-resource-object-relationships). The OPTIONAL human-readable description of the relationship MAY be provided in the `description` field inside the `meta` dictionary of the JSON API resource identifier object.\"\"\" , ) attributes : EntryResourceAttributes = StrictField ( Ellipsis , description = \"A dictionary, containing key-value pairs representing the entry's properties, except for `type` and `id`. \\n Database-provider-specific properties need to include the database-provider-specific prefix (see section on Database-Provider-Specific Namespace Prefixes).\" ) class-attribute \u00b6 id : str = OptimadeField ( Ellipsis , description = 'An entry \\' s ID as defined in section Definition of Terms. \\n\\n - **Type**: string. \\n\\n - **Requirements/Conventions**: \\n - **Support**: MUST be supported by all implementations, MUST NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - **Response**: REQUIRED in the response. \\n\\n - **Examples**: \\n - `\"db/1234567\"` \\n - `\"cod/2000000\"` \\n - `\"cod/2000000@1234567\"` \\n - `\"nomad/L1234567890\"` \\n - `\"42\"`' , support = SupportLevel . MUST , queryable = SupportLevel . MUST ) class-attribute \u00b6 relationships : Optional [ EntryRelationships ] = StrictField ( None , description = 'A dictionary containing references to other entries according to the description in section Relationships encoded as [JSON API Relationships](https://jsonapi.org/format/1.0/#document-resource-object-relationships). \\n The OPTIONAL human-readable description of the relationship MAY be provided in the `description` field inside the `meta` dictionary of the JSON API resource identifier object.' ) class-attribute \u00b6 type : str = OptimadeField ( description = 'The name of the type of an entry. \\n\\n - **Type**: string. \\n\\n - **Requirements/Conventions**: \\n - **Support**: MUST be supported by all implementations, MUST NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - **Response**: REQUIRED in the response. \\n - MUST be an existing entry type. \\n - The entry of type `<type>` and ID `<id>` MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. \\n\\n - **Example**: `\"structures\"`' , support = SupportLevel . MUST , queryable = SupportLevel . MUST ) class-attribute \u00b6 EntryResourceAttributes \u00b6 Contains key-value pairs representing the entry's properties. Source code in optimade/models/entries.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class EntryResourceAttributes ( Attributes ): \"\"\"Contains key-value pairs representing the entry's properties.\"\"\" immutable_id : Optional [ str ] = OptimadeField ( None , description = \"\"\"The entry's immutable ID (e.g., an UUID). This is important for databases having preferred IDs that point to \"the latest version\" of a record, but still offer access to older variants. This ID maps to the version-specific record, in case it changes in the future. - **Type**: string. - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Examples**: - `\"8bd3e750-b477-41a0-9b11-3a799f21b44f\"` - `\"fjeiwoj,54;@=%<>#32\"` (Strings that are not URL-safe are allowed.)\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . MUST , ) last_modified : Optional [ datetime ] = OptimadeField ( ... , description = \"\"\"Date and time representing when the entry was last modified. - **Type**: timestamp. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response unless the query parameter `response_fields` is present and does not include this property. - **Example**: - As part of JSON response format: `\"2007-04-05T14:30:20Z\"` (i.e., encoded as an [RFC 3339 Internet Date/Time Format](https://tools.ietf.org/html/rfc3339#section-5.6) string.)\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) @validator ( \"immutable_id\" , pre = True ) def cast_immutable_id_to_str ( cls , value ): \"\"\"Convenience validator for casting `immutable_id` to a string.\"\"\" if value is not None and not isinstance ( value , str ): value = str ( value ) return value immutable_id : Optional [ str ] = OptimadeField ( None , description = 'The entry \\' s immutable ID (e.g., an UUID). This is important for databases having preferred IDs that point to \"the latest version\" of a record, but still offer access to older variants. This ID maps to the version-specific record, in case it changes in the future. \\n\\n - **Type**: string. \\n\\n - **Requirements/Conventions**: \\n - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n\\n - **Examples**: \\n - `\"8bd3e750-b477-41a0-9b11-3a799f21b44f\"` \\n - `\"fjeiwoj,54;@=%<>#32\"` (Strings that are not URL-safe are allowed.)' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . MUST ) class-attribute \u00b6 last_modified : Optional [ datetime ] = OptimadeField ( Ellipsis , description = 'Date and time representing when the entry was last modified. \\n\\n - **Type**: timestamp. \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - **Response**: REQUIRED in the response unless the query parameter `response_fields` is present and does not include this property. \\n\\n - **Example**: \\n - As part of JSON response format: `\"2007-04-05T14:30:20Z\"` (i.e., encoded as an [RFC 3339 Internet Date/Time Format](https://tools.ietf.org/html/rfc3339#section-5.6) string.)' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST ) class-attribute \u00b6 cast_immutable_id_to_str ( value ) \u00b6 Convenience validator for casting immutable_id to a string. Source code in optimade/models/entries.py 94 95 96 97 98 99 100 @validator ( \"immutable_id\" , pre = True ) def cast_immutable_id_to_str ( cls , value ): \"\"\"Convenience validator for casting `immutable_id` to a string.\"\"\" if value is not None and not isinstance ( value , str ): value = str ( value ) return value ReferenceRelationship \u00b6 Source code in optimade/models/entries.py 35 36 class ReferenceRelationship ( TypedRelationship ): _req_type = \"references\" StructureRelationship \u00b6 Source code in optimade/models/entries.py 39 40 class StructureRelationship ( TypedRelationship ): _req_type = \"structures\" TypedRelationship \u00b6 Source code in optimade/models/entries.py 20 21 22 23 24 25 26 27 28 29 30 31 32 class TypedRelationship ( Relationship ): # This may be updated when moving to Python 3.8 @validator ( \"data\" ) def check_rel_type ( cls , data ): if not isinstance ( data , list ): # All relationships at this point are empty-to-many relationships in JSON:API: # https://jsonapi.org/format/1.0/#document-resource-object-linkage raise ValueError ( \"`data` key in a relationship must always store a list.\" ) if hasattr ( cls , \"_req_type\" ) and any ( getattr ( obj , \"type\" , None ) != cls . _req_type for obj in data ): raise ValueError ( \"Object stored in relationship data has wrong type\" ) return data check_rel_type ( data ) \u00b6 Source code in optimade/models/entries.py 22 23 24 25 26 27 28 29 30 31 32 @validator ( \"data\" ) def check_rel_type ( cls , data ): if not isinstance ( data , list ): # All relationships at this point are empty-to-many relationships in JSON:API: # https://jsonapi.org/format/1.0/#document-resource-object-linkage raise ValueError ( \"`data` key in a relationship must always store a list.\" ) if hasattr ( cls , \"_req_type\" ) and any ( getattr ( obj , \"type\" , None ) != cls . _req_type for obj in data ): raise ValueError ( \"Object stored in relationship data has wrong type\" ) return data","title":"entries"},{"location":"api_reference/models/entries/#entries","text":"","title":"entries"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoProperty","text":"Source code in optimade/models/entries.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 class EntryInfoProperty ( BaseModel ): description : str = StrictField ( ... , description = \"A human-readable description of the entry property\" ) unit : Optional [ str ] = StrictField ( None , description = \"\"\"The physical unit of the entry property. This MUST be a valid representation of units according to version 2.1 of [The Unified Code for Units of Measure](https://unitsofmeasure.org/ucum.html). It is RECOMMENDED that non-standard (non-SI) units are described in the description for the property.\"\"\" , ) sortable : Optional [ bool ] = StrictField ( None , description = \"\"\"Defines whether the entry property can be used for sorting with the \"sort\" parameter. If the entry listing endpoint supports sorting, this key MUST be present for sortable properties with value `true`.\"\"\" , ) type : Optional [ DataType ] = StrictField ( None , title = \"Type\" , description = \"\"\"The type of the property's value. This MUST be any of the types defined in the Data types section. For the purpose of compatibility with future versions of this specification, a client MUST accept values that are not `string` values specifying any of the OPTIMADE Data types, but MUST then also disregard the `type` field. Note, if the value is a nested type, only the outermost type should be reported. E.g., for the entry resource `structures`, the `species` property is defined as a list of dictionaries, hence its `type` value would be `list`.\"\"\" , )","title":"EntryInfoProperty"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoProperty.description","text":"","title":"description"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoProperty.sortable","text":"","title":"sortable"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoProperty.type","text":"","title":"type"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoProperty.unit","text":"","title":"unit"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoResource","text":"Source code in optimade/models/entries.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 class EntryInfoResource ( BaseModel ): formats : List [ str ] = StrictField ( ... , description = \"List of output formats available for this type of entry.\" ) description : str = StrictField ( ... , description = \"Description of the entry.\" ) properties : Dict [ str , EntryInfoProperty ] = StrictField ( ... , description = \"A dictionary describing queryable properties for this entry type, where each key is a property name.\" , ) output_fields_by_format : Dict [ str , List [ str ]] = StrictField ( ... , description = \"Dictionary of available output fields for this entry type, where the keys are the values of the `formats` list and the values are the keys of the `properties` dictionary.\" , )","title":"EntryInfoResource"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoResource.description","text":"","title":"description"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoResource.formats","text":"","title":"formats"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoResource.output_fields_by_format","text":"","title":"output_fields_by_format"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryInfoResource.properties","text":"","title":"properties"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryRelationships","text":"This model wraps the JSON API Relationships to include type-specific top level keys. Source code in optimade/models/entries.py 43 44 45 46 47 48 49 50 51 52 53 54 class EntryRelationships ( Relationships ): \"\"\"This model wraps the JSON API Relationships to include type-specific top level keys.\"\"\" references : Optional [ ReferenceRelationship ] = StrictField ( None , description = \"Object containing links to relationships with entries of the `references` type.\" , ) structures : Optional [ StructureRelationship ] = StrictField ( None , description = \"Object containing links to relationships with entries of the `structures` type.\" , )","title":"EntryRelationships"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryRelationships.references","text":"","title":"references"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryRelationships.structures","text":"","title":"structures"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResource","text":"The base model for an entry resource. Source code in optimade/models/entries.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class EntryResource ( Resource ): \"\"\"The base model for an entry resource.\"\"\" id : str = OptimadeField ( ... , description = \"\"\"An entry's ID as defined in section Definition of Terms. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - **Examples**: - `\"db/1234567\"` - `\"cod/2000000\"` - `\"cod/2000000@1234567\"` - `\"nomad/L1234567890\"` - `\"42\"`\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) type : str = OptimadeField ( description = \"\"\"The name of the type of an entry. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - MUST be an existing entry type. - The entry of type `<type>` and ID `<id>` MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. - **Example**: `\"structures\"`\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) attributes : EntryResourceAttributes = StrictField ( ... , description = \"\"\"A dictionary, containing key-value pairs representing the entry's properties, except for `type` and `id`. Database-provider-specific properties need to include the database-provider-specific prefix (see section on Database-Provider-Specific Namespace Prefixes).\"\"\" , ) relationships : Optional [ EntryRelationships ] = StrictField ( None , description = \"\"\"A dictionary containing references to other entries according to the description in section Relationships encoded as [JSON API Relationships](https://jsonapi.org/format/1.0/#document-resource-object-relationships). The OPTIONAL human-readable description of the relationship MAY be provided in the `description` field inside the `meta` dictionary of the JSON API resource identifier object.\"\"\" , )","title":"EntryResource"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResource.id","text":"","title":"id"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResource.relationships","text":"","title":"relationships"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResource.type","text":"","title":"type"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResourceAttributes","text":"Contains key-value pairs representing the entry's properties. Source code in optimade/models/entries.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class EntryResourceAttributes ( Attributes ): \"\"\"Contains key-value pairs representing the entry's properties.\"\"\" immutable_id : Optional [ str ] = OptimadeField ( None , description = \"\"\"The entry's immutable ID (e.g., an UUID). This is important for databases having preferred IDs that point to \"the latest version\" of a record, but still offer access to older variants. This ID maps to the version-specific record, in case it changes in the future. - **Type**: string. - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Examples**: - `\"8bd3e750-b477-41a0-9b11-3a799f21b44f\"` - `\"fjeiwoj,54;@=%<>#32\"` (Strings that are not URL-safe are allowed.)\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . MUST , ) last_modified : Optional [ datetime ] = OptimadeField ( ... , description = \"\"\"Date and time representing when the entry was last modified. - **Type**: timestamp. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response unless the query parameter `response_fields` is present and does not include this property. - **Example**: - As part of JSON response format: `\"2007-04-05T14:30:20Z\"` (i.e., encoded as an [RFC 3339 Internet Date/Time Format](https://tools.ietf.org/html/rfc3339#section-5.6) string.)\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) @validator ( \"immutable_id\" , pre = True ) def cast_immutable_id_to_str ( cls , value ): \"\"\"Convenience validator for casting `immutable_id` to a string.\"\"\" if value is not None and not isinstance ( value , str ): value = str ( value ) return value","title":"EntryResourceAttributes"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResourceAttributes.immutable_id","text":"","title":"immutable_id"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResourceAttributes.last_modified","text":"","title":"last_modified"},{"location":"api_reference/models/entries/#optimade.models.entries.EntryResourceAttributes.cast_immutable_id_to_str","text":"Convenience validator for casting immutable_id to a string. Source code in optimade/models/entries.py 94 95 96 97 98 99 100 @validator ( \"immutable_id\" , pre = True ) def cast_immutable_id_to_str ( cls , value ): \"\"\"Convenience validator for casting `immutable_id` to a string.\"\"\" if value is not None and not isinstance ( value , str ): value = str ( value ) return value","title":"cast_immutable_id_to_str()"},{"location":"api_reference/models/entries/#optimade.models.entries.ReferenceRelationship","text":"Source code in optimade/models/entries.py 35 36 class ReferenceRelationship ( TypedRelationship ): _req_type = \"references\"","title":"ReferenceRelationship"},{"location":"api_reference/models/entries/#optimade.models.entries.StructureRelationship","text":"Source code in optimade/models/entries.py 39 40 class StructureRelationship ( TypedRelationship ): _req_type = \"structures\"","title":"StructureRelationship"},{"location":"api_reference/models/entries/#optimade.models.entries.TypedRelationship","text":"Source code in optimade/models/entries.py 20 21 22 23 24 25 26 27 28 29 30 31 32 class TypedRelationship ( Relationship ): # This may be updated when moving to Python 3.8 @validator ( \"data\" ) def check_rel_type ( cls , data ): if not isinstance ( data , list ): # All relationships at this point are empty-to-many relationships in JSON:API: # https://jsonapi.org/format/1.0/#document-resource-object-linkage raise ValueError ( \"`data` key in a relationship must always store a list.\" ) if hasattr ( cls , \"_req_type\" ) and any ( getattr ( obj , \"type\" , None ) != cls . _req_type for obj in data ): raise ValueError ( \"Object stored in relationship data has wrong type\" ) return data","title":"TypedRelationship"},{"location":"api_reference/models/entries/#optimade.models.entries.TypedRelationship.check_rel_type","text":"Source code in optimade/models/entries.py 22 23 24 25 26 27 28 29 30 31 32 @validator ( \"data\" ) def check_rel_type ( cls , data ): if not isinstance ( data , list ): # All relationships at this point are empty-to-many relationships in JSON:API: # https://jsonapi.org/format/1.0/#document-resource-object-linkage raise ValueError ( \"`data` key in a relationship must always store a list.\" ) if hasattr ( cls , \"_req_type\" ) and any ( getattr ( obj , \"type\" , None ) != cls . _req_type for obj in data ): raise ValueError ( \"Object stored in relationship data has wrong type\" ) return data","title":"check_rel_type()"},{"location":"api_reference/models/index_metadb/","text":"index_metadb \u00b6 DefaultRelationship \u00b6 Enumeration of key(s) for relationship dictionary in IndexInfoResource Source code in optimade/models/index_metadb.py 20 21 22 23 class DefaultRelationship ( Enum ): \"\"\"Enumeration of key(s) for relationship dictionary in IndexInfoResource\"\"\" DEFAULT = \"default\" DEFAULT = 'default' class-attribute \u00b6 IndexInfoAttributes \u00b6 Attributes for Base URL Info endpoint for an Index Meta-Database Source code in optimade/models/index_metadb.py 26 27 28 29 30 31 32 class IndexInfoAttributes ( BaseInfoAttributes ): \"\"\"Attributes for Base URL Info endpoint for an Index Meta-Database\"\"\" is_index : bool = StrictField ( True , description = \"This must be `true` since this is an index meta-database (see section Index Meta-Database).\" , ) is_index : bool = StrictField ( True , description = 'This must be `true` since this is an index meta-database (see section Index Meta-Database).' ) class-attribute \u00b6 IndexInfoResource \u00b6 Index Meta-Database Base URL Info endpoint resource Source code in optimade/models/index_metadb.py 51 52 53 54 55 56 57 58 59 60 61 62 class IndexInfoResource ( BaseInfoResource ): \"\"\"Index Meta-Database Base URL Info endpoint resource\"\"\" attributes : IndexInfoAttributes = Field ( ... ) relationships : Union [ None , Dict [ DefaultRelationship , IndexRelationship ] ] = StrictField ( ... , title = \"Relationships\" , description = \"\"\"Reference to the Links identifier object under the `links` endpoint that the provider has chosen as their 'default' OPTIMADE API database. A client SHOULD present this database as the first choice when an end-user chooses this provider.\"\"\" , ) attributes : IndexInfoAttributes = Field ( Ellipsis ) class-attribute \u00b6 relationships : Union [ None , Dict [ DefaultRelationship , IndexRelationship ]] = StrictField ( Ellipsis , title = 'Relationships' , description = \"Reference to the Links identifier object under the `links` endpoint that the provider has chosen as their 'default' OPTIMADE API database. \\n A client SHOULD present this database as the first choice when an end-user chooses this provider.\" ) class-attribute \u00b6 IndexRelationship \u00b6 Index Meta-Database relationship Source code in optimade/models/index_metadb.py 41 42 43 44 45 46 47 48 class IndexRelationship ( BaseModel ): \"\"\"Index Meta-Database relationship\"\"\" data : Union [ None , RelatedLinksResource ] = StrictField ( ... , description = \"\"\"[JSON API resource linkage](http://jsonapi.org/format/1.0/#document-links). It MUST be either `null` or contain a single Links identifier object with the fields `id` and `type`\"\"\" , ) data : Union [ None , RelatedLinksResource ] = StrictField ( Ellipsis , description = '[JSON API resource linkage](http://jsonapi.org/format/1.0/#document-links). \\n It MUST be either `null` or contain a single Links identifier object with the fields `id` and `type`' ) class-attribute \u00b6 RelatedLinksResource \u00b6 A related Links resource object Source code in optimade/models/index_metadb.py 35 36 37 38 class RelatedLinksResource ( BaseResource ): \"\"\"A related Links resource object\"\"\" type : str = Field ( \"links\" , regex = \"^links$\" ) type : str = Field ( 'links' , regex = '^links$' ) class-attribute \u00b6","title":"index_metadb"},{"location":"api_reference/models/index_metadb/#index_metadb","text":"","title":"index_metadb"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.DefaultRelationship","text":"Enumeration of key(s) for relationship dictionary in IndexInfoResource Source code in optimade/models/index_metadb.py 20 21 22 23 class DefaultRelationship ( Enum ): \"\"\"Enumeration of key(s) for relationship dictionary in IndexInfoResource\"\"\" DEFAULT = \"default\"","title":"DefaultRelationship"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.DefaultRelationship.DEFAULT","text":"","title":"DEFAULT"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexInfoAttributes","text":"Attributes for Base URL Info endpoint for an Index Meta-Database Source code in optimade/models/index_metadb.py 26 27 28 29 30 31 32 class IndexInfoAttributes ( BaseInfoAttributes ): \"\"\"Attributes for Base URL Info endpoint for an Index Meta-Database\"\"\" is_index : bool = StrictField ( True , description = \"This must be `true` since this is an index meta-database (see section Index Meta-Database).\" , )","title":"IndexInfoAttributes"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexInfoAttributes.is_index","text":"","title":"is_index"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexInfoResource","text":"Index Meta-Database Base URL Info endpoint resource Source code in optimade/models/index_metadb.py 51 52 53 54 55 56 57 58 59 60 61 62 class IndexInfoResource ( BaseInfoResource ): \"\"\"Index Meta-Database Base URL Info endpoint resource\"\"\" attributes : IndexInfoAttributes = Field ( ... ) relationships : Union [ None , Dict [ DefaultRelationship , IndexRelationship ] ] = StrictField ( ... , title = \"Relationships\" , description = \"\"\"Reference to the Links identifier object under the `links` endpoint that the provider has chosen as their 'default' OPTIMADE API database. A client SHOULD present this database as the first choice when an end-user chooses this provider.\"\"\" , )","title":"IndexInfoResource"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexInfoResource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexInfoResource.relationships","text":"","title":"relationships"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexRelationship","text":"Index Meta-Database relationship Source code in optimade/models/index_metadb.py 41 42 43 44 45 46 47 48 class IndexRelationship ( BaseModel ): \"\"\"Index Meta-Database relationship\"\"\" data : Union [ None , RelatedLinksResource ] = StrictField ( ... , description = \"\"\"[JSON API resource linkage](http://jsonapi.org/format/1.0/#document-links). It MUST be either `null` or contain a single Links identifier object with the fields `id` and `type`\"\"\" , )","title":"IndexRelationship"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.IndexRelationship.data","text":"","title":"data"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.RelatedLinksResource","text":"A related Links resource object Source code in optimade/models/index_metadb.py 35 36 37 38 class RelatedLinksResource ( BaseResource ): \"\"\"A related Links resource object\"\"\" type : str = Field ( \"links\" , regex = \"^links$\" )","title":"RelatedLinksResource"},{"location":"api_reference/models/index_metadb/#optimade.models.index_metadb.RelatedLinksResource.type","text":"","title":"type"},{"location":"api_reference/models/jsonapi/","text":"jsonapi \u00b6 This module should reproduce JSON API v1.0 https://jsonapi.org/format/1.0/ Attributes \u00b6 Members of the attributes object (\"attributes\") represent information about the resource object in which it's defined. The keys for Attributes MUST NOT be relationships links id type Source code in optimade/models/jsonapi.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 class Attributes ( BaseModel ): \"\"\" Members of the attributes object (\"attributes\\\") represent information about the resource object in which it's defined. The keys for Attributes MUST NOT be: relationships links id type \"\"\" class Config : extra = \"allow\" @root_validator ( pre = True ) def check_illegal_attributes_fields ( cls , values ): illegal_fields = ( \"relationships\" , \"links\" , \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Attributes\" ) return values Config \u00b6 Source code in optimade/models/jsonapi.py 287 288 class Config : extra = \"allow\" extra = 'allow' class-attribute \u00b6 check_illegal_attributes_fields ( values ) \u00b6 Source code in optimade/models/jsonapi.py 290 291 292 293 294 295 296 297 298 @root_validator ( pre = True ) def check_illegal_attributes_fields ( cls , values ): illegal_fields = ( \"relationships\" , \"links\" , \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Attributes\" ) return values BaseResource \u00b6 Minimum requirements to represent a Resource Source code in optimade/models/jsonapi.py 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 class BaseResource ( BaseModel ): \"\"\"Minimum requirements to represent a Resource\"\"\" id : str = StrictField ( ... , description = \"Resource ID\" ) type : str = StrictField ( ... , description = \"Resource type\" ) class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"BaseResource\" ]) -> None : \"\"\"Ensure `id` and `type` are the first two entries in the list required properties. Note: This _requires_ that `id` and `type` are the _first_ model fields defined for all sub-models of `BaseResource`. \"\"\" if \"id\" not in schema . get ( \"required\" , []): schema [ \"required\" ] = [ \"id\" ] + schema . get ( \"required\" , []) if \"type\" not in schema . get ( \"required\" , []): required = [] for field in schema . get ( \"required\" , []): required . append ( field ) if field == \"id\" : # To make sure the property order match the listed properties, # this ensures \"type\" is added immediately after \"id\". required . append ( \"type\" ) schema [ \"required\" ] = required id : str = StrictField ( Ellipsis , description = 'Resource ID' ) class-attribute \u00b6 type : str = StrictField ( Ellipsis , description = 'Resource type' ) class-attribute \u00b6 Config \u00b6 Source code in optimade/models/jsonapi.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"BaseResource\" ]) -> None : \"\"\"Ensure `id` and `type` are the first two entries in the list required properties. Note: This _requires_ that `id` and `type` are the _first_ model fields defined for all sub-models of `BaseResource`. \"\"\" if \"id\" not in schema . get ( \"required\" , []): schema [ \"required\" ] = [ \"id\" ] + schema . get ( \"required\" , []) if \"type\" not in schema . get ( \"required\" , []): required = [] for field in schema . get ( \"required\" , []): required . append ( field ) if field == \"id\" : # To make sure the property order match the listed properties, # this ensures \"type\" is added immediately after \"id\". required . append ( \"type\" ) schema [ \"required\" ] = required schema_extra ( schema , model ) staticmethod \u00b6 Ensure id and type are the first two entries in the list required properties. Note This requires that id and type are the first model fields defined for all sub-models of BaseResource . Source code in optimade/models/jsonapi.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"BaseResource\" ]) -> None : \"\"\"Ensure `id` and `type` are the first two entries in the list required properties. Note: This _requires_ that `id` and `type` are the _first_ model fields defined for all sub-models of `BaseResource`. \"\"\" if \"id\" not in schema . get ( \"required\" , []): schema [ \"required\" ] = [ \"id\" ] + schema . get ( \"required\" , []) if \"type\" not in schema . get ( \"required\" , []): required = [] for field in schema . get ( \"required\" , []): required . append ( field ) if field == \"id\" : # To make sure the property order match the listed properties, # this ensures \"type\" is added immediately after \"id\". required . append ( \"type\" ) schema [ \"required\" ] = required Error \u00b6 An error response Source code in optimade/models/jsonapi.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 class Error ( BaseModel ): \"\"\"An error response\"\"\" id : Optional [ str ] = StrictField ( None , description = \"A unique identifier for this particular occurrence of the problem.\" , ) links : Optional [ ErrorLinks ] = StrictField ( None , description = \"A links object storing about\" ) status : Optional [ str ] = StrictField ( None , description = \"the HTTP status code applicable to this problem, expressed as a string value.\" , ) code : Optional [ str ] = StrictField ( None , description = \"an application-specific error code, expressed as a string value.\" , ) title : Optional [ str ] = StrictField ( None , description = \"A short, human-readable summary of the problem. \" \"It **SHOULD NOT** change from occurrence to occurrence of the problem, except for purposes of localization.\" , ) detail : Optional [ str ] = StrictField ( None , description = \"A human-readable explanation specific to this occurrence of the problem.\" , ) source : Optional [ ErrorSource ] = StrictField ( None , description = \"An object containing references to the source of the error\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object containing non-standard meta-information about the error.\" , ) def __hash__ ( self ): return hash ( self . json ()) code : Optional [ str ] = StrictField ( None , description = 'an application-specific error code, expressed as a string value.' ) class-attribute \u00b6 detail : Optional [ str ] = StrictField ( None , description = 'A human-readable explanation specific to this occurrence of the problem.' ) class-attribute \u00b6 id : Optional [ str ] = StrictField ( None , description = 'A unique identifier for this particular occurrence of the problem.' ) class-attribute \u00b6 links : Optional [ ErrorLinks ] = StrictField ( None , description = 'A links object storing about' ) class-attribute \u00b6 meta : Optional [ Meta ] = StrictField ( None , description = 'a meta object containing non-standard meta-information about the error.' ) class-attribute \u00b6 source : Optional [ ErrorSource ] = StrictField ( None , description = 'An object containing references to the source of the error' ) class-attribute \u00b6 status : Optional [ str ] = StrictField ( None , description = 'the HTTP status code applicable to this problem, expressed as a string value.' ) class-attribute \u00b6 title : Optional [ str ] = StrictField ( None , description = 'A short, human-readable summary of the problem. It **SHOULD NOT** change from occurrence to occurrence of the problem, except for purposes of localization.' ) class-attribute \u00b6 __hash__ () \u00b6 Source code in optimade/models/jsonapi.py 158 159 def __hash__ ( self ): return hash ( self . json ()) ErrorLinks \u00b6 A Links object specific to Error objects Source code in optimade/models/jsonapi.py 100 101 102 103 104 105 106 class ErrorLinks ( BaseModel ): \"\"\"A Links object specific to Error objects\"\"\" about : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link that leads to further details about this particular occurrence of the problem.\" , ) about : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'A link that leads to further details about this particular occurrence of the problem.' ) class-attribute \u00b6 ErrorSource \u00b6 an object containing references to the source of the error Source code in optimade/models/jsonapi.py 109 110 111 112 113 114 115 116 117 118 119 120 class ErrorSource ( BaseModel ): \"\"\"an object containing references to the source of the error\"\"\" pointer : Optional [ str ] = StrictField ( None , description = \"a JSON Pointer [RFC6901] to the associated entity in the request document \" '[e.g. \"/data\" for a primary data object, or \"/data/attributes/title\" for a specific attribute].' , ) parameter : Optional [ str ] = StrictField ( None , description = \"a string indicating which URI query parameter caused the error.\" , ) parameter : Optional [ str ] = StrictField ( None , description = 'a string indicating which URI query parameter caused the error.' ) class-attribute \u00b6 pointer : Optional [ str ] = StrictField ( None , description = 'a JSON Pointer [RFC6901] to the associated entity in the request document [e.g. \"/data\" for a primary data object, or \"/data/attributes/title\" for a specific attribute].' ) class-attribute \u00b6 JsonApi \u00b6 An object describing the server's implementation Source code in optimade/models/jsonapi.py 49 50 51 52 53 54 55 56 57 class JsonApi ( BaseModel ): \"\"\"An object describing the server's implementation\"\"\" version : str = StrictField ( default = \"1.0\" , description = \"Version of the json API used\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"Non-standard meta information\" ) meta : Optional [ Meta ] = StrictField ( None , description = 'Non-standard meta information' ) class-attribute \u00b6 version : str = StrictField ( default = '1.0' , description = 'Version of the json API used' ) class-attribute \u00b6 Link \u00b6 A link MUST be represented as either: a string containing the link's URL or a link object. Source code in optimade/models/jsonapi.py 39 40 41 42 43 44 45 46 class Link ( BaseModel ): \"\"\"A link **MUST** be represented as either: a string containing the link's URL or a link object.\"\"\" href : AnyUrl = StrictField ( ... , description = \"a string containing the link\u2019s URL.\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object containing non-standard meta-information about the link.\" , ) href : AnyUrl = StrictField ( Ellipsis , description = 'a string containing the link\u2019s URL.' ) class-attribute \u00b6 meta : Optional [ Meta ] = StrictField ( None , description = 'a meta object containing non-standard meta-information about the link.' ) class-attribute \u00b6 Meta \u00b6 Non-standard meta-information that can not be represented as an attribute or relationship. Source code in optimade/models/jsonapi.py 32 33 34 35 36 class Meta ( BaseModel ): \"\"\"Non-standard meta-information that can not be represented as an attribute or relationship.\"\"\" class Config : extra = \"allow\" Config \u00b6 Source code in optimade/models/jsonapi.py 35 36 class Config : extra = \"allow\" extra = 'allow' class-attribute \u00b6 Relationship \u00b6 Representation references from the resource object in which it\u2019s defined to other resource objects. Source code in optimade/models/jsonapi.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 class Relationship ( BaseModel ): \"\"\"Representation references from the resource object in which it\u2019s defined to other resource objects.\"\"\" links : Optional [ RelationshipLinks ] = StrictField ( None , description = \"a links object containing at least one of the following: self, related\" , ) data : Optional [ Union [ BaseResource , List [ BaseResource ]]] = StrictField ( None , description = \"Resource linkage\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object that contains non-standard meta-information about the relationship.\" , ) @root_validator ( pre = True ) def at_least_one_relationship_key_must_be_set ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'links', 'data', or 'meta' MUST be specified for Relationship\" ) return values data : Optional [ Union [ BaseResource , List [ BaseResource ]]] = StrictField ( None , description = 'Resource linkage' ) class-attribute \u00b6 links : Optional [ RelationshipLinks ] = StrictField ( None , description = 'a links object containing at least one of the following: self, related' ) class-attribute \u00b6 meta : Optional [ Meta ] = StrictField ( None , description = 'a meta object that contains non-standard meta-information about the relationship.' ) class-attribute \u00b6 at_least_one_relationship_key_must_be_set ( values ) \u00b6 Source code in optimade/models/jsonapi.py 237 238 239 240 241 242 243 244 245 246 @root_validator ( pre = True ) def at_least_one_relationship_key_must_be_set ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'links', 'data', or 'meta' MUST be specified for Relationship\" ) return values RelationshipLinks \u00b6 A resource object MAY contain references to other resource objects (\"relationships\"). Relationships may be to-one or to-many. Relationships can be specified by including a member in a resource's links object. Source code in optimade/models/jsonapi.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 class RelationshipLinks ( BaseModel ): \"\"\"A resource object **MAY** contain references to other resource objects (\"relationships\"). Relationships may be to-one or to-many. Relationships can be specified by including a member in a resource's links object. \"\"\" self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"\"\"A link for the relationship itself (a 'relationship link'). This link allows the client to directly manipulate the relationship. When fetched successfully, this link returns the [linkage](https://jsonapi.org/format/1.0/#document-resource-object-linkage) for the related resources as its primary data. (See [Fetching Relationships](https://jsonapi.org/format/1.0/#fetching-relationships).)\"\"\" , ) related : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A [related resource link](https://jsonapi.org/format/1.0/#document-resource-object-related-resource-links).\" , ) @root_validator ( pre = True ) def either_self_or_related_must_be_specified ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'self' or 'related' MUST be specified for RelationshipLinks\" ) return values related : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'A [related resource link](https://jsonapi.org/format/1.0/#document-resource-object-related-resource-links).' ) class-attribute \u00b6 self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link for the relationship itself (a 'relationship link'). \\n This link allows the client to directly manipulate the relationship. \\n When fetched successfully, this link returns the [linkage](https://jsonapi.org/format/1.0/#document-resource-object-linkage) for the related resources as its primary data. \\n (See [Fetching Relationships](https://jsonapi.org/format/1.0/#fetching-relationships).)\" ) class-attribute \u00b6 either_self_or_related_must_be_specified ( values ) \u00b6 Source code in optimade/models/jsonapi.py 210 211 212 213 214 215 216 217 218 219 @root_validator ( pre = True ) def either_self_or_related_must_be_specified ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'self' or 'related' MUST be specified for RelationshipLinks\" ) return values Relationships \u00b6 Members of the relationships object (\"relationships\") represent references from the resource object in which it's defined to other resource objects. Keys MUST NOT be type id Source code in optimade/models/jsonapi.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 class Relationships ( BaseModel ): \"\"\" Members of the relationships object (\\\"relationships\\\") represent references from the resource object in which it's defined to other resource objects. Keys MUST NOT be: type id \"\"\" @root_validator ( pre = True ) def check_illegal_relationships_fields ( cls , values ): illegal_fields = ( \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Relationships\" ) return values check_illegal_relationships_fields ( values ) \u00b6 Source code in optimade/models/jsonapi.py 257 258 259 260 261 262 263 264 265 @root_validator ( pre = True ) def check_illegal_relationships_fields ( cls , values ): illegal_fields = ( \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Relationships\" ) return values Resource \u00b6 Resource objects appear in a JSON API document to represent resources. Source code in optimade/models/jsonapi.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 class Resource ( BaseResource ): \"\"\"Resource objects appear in a JSON API document to represent resources.\"\"\" links : Optional [ ResourceLinks ] = StrictField ( None , description = \"a links object containing links related to the resource.\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object containing non-standard meta-information about a resource that can not be represented as an attribute or relationship.\" , ) attributes : Optional [ Attributes ] = StrictField ( None , description = \"an attributes object representing some of the resource\u2019s data.\" , ) relationships : Optional [ Relationships ] = StrictField ( None , description = \"\"\"[Relationships object](https://jsonapi.org/format/1.0/#document-resource-object-relationships) describing relationships between the resource and other JSON API resources.\"\"\" , ) attributes : Optional [ Attributes ] = StrictField ( None , description = 'an attributes object representing some of the resource\u2019s data.' ) class-attribute \u00b6 links : Optional [ ResourceLinks ] = StrictField ( None , description = 'a links object containing links related to the resource.' ) class-attribute \u00b6 meta : Optional [ Meta ] = StrictField ( None , description = 'a meta object containing non-standard meta-information about a resource that can not be represented as an attribute or relationship.' ) class-attribute \u00b6 relationships : Optional [ Relationships ] = StrictField ( None , description = '[Relationships object](https://jsonapi.org/format/1.0/#document-resource-object-relationships) \\n describing relationships between the resource and other JSON API resources.' ) class-attribute \u00b6 ResourceLinks \u00b6 A Resource Links object Source code in optimade/models/jsonapi.py 268 269 270 271 272 273 274 class ResourceLinks ( BaseModel ): \"\"\"A Resource Links object\"\"\" self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link that identifies the resource represented by the resource object.\" , ) self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'A link that identifies the resource represented by the resource object.' ) class-attribute \u00b6 Response \u00b6 A top-level response Source code in optimade/models/jsonapi.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 class Response ( BaseModel ): \"\"\"A top-level response\"\"\" data : Optional [ Union [ None , Resource , List [ Resource ]]] = StrictField ( None , description = \"Outputted Data\" , uniqueItems = True ) meta : Optional [ Meta ] = StrictField ( None , description = \"A meta object containing non-standard information related to the Success\" , ) errors : Optional [ List [ Error ]] = StrictField ( None , description = \"A list of unique errors\" , uniqueItems = True ) included : Optional [ List [ Resource ]] = StrictField ( None , description = \"A list of unique included resources\" , uniqueItems = True ) links : Optional [ ToplevelLinks ] = StrictField ( None , description = \"Links associated with the primary data or errors\" ) jsonapi : Optional [ JsonApi ] = StrictField ( None , description = \"Information about the JSON API used\" ) @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): required_fields = ( \"data\" , \"meta\" , \"errors\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response\" ) if \"errors\" in values and not values . get ( \"errors\" ): raise ValueError ( \"Errors MUST NOT be an empty or 'null' value.\" ) return values class Config : \"\"\"The specification mandates that datetimes must be encoded following [RFC3339](https://tools.ietf.org/html/rfc3339), which does not support fractional seconds, thus they must be stripped in the response. This can cause issues when the underlying database contains fields that do include microseconds, as filters may return unexpected results. \"\"\" json_encoders = { datetime : lambda v : v . astimezone ( timezone . utc ) . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), } data : Optional [ Union [ None , Resource , List [ Resource ]]] = StrictField ( None , description = 'Outputted Data' , uniqueItems = True ) class-attribute \u00b6 errors : Optional [ List [ Error ]] = StrictField ( None , description = 'A list of unique errors' , uniqueItems = True ) class-attribute \u00b6 included : Optional [ List [ Resource ]] = StrictField ( None , description = 'A list of unique included resources' , uniqueItems = True ) class-attribute \u00b6 jsonapi : Optional [ JsonApi ] = StrictField ( None , description = 'Information about the JSON API used' ) class-attribute \u00b6 links : Optional [ ToplevelLinks ] = StrictField ( None , description = 'Links associated with the primary data or errors' ) class-attribute \u00b6 meta : Optional [ Meta ] = StrictField ( None , description = 'A meta object containing non-standard information related to the Success' ) class-attribute \u00b6 Config \u00b6 The specification mandates that datetimes must be encoded following RFC3339 , which does not support fractional seconds, thus they must be stripped in the response. This can cause issues when the underlying database contains fields that do include microseconds, as filters may return unexpected results. Source code in optimade/models/jsonapi.py 356 357 358 359 360 361 362 363 364 365 366 367 368 class Config : \"\"\"The specification mandates that datetimes must be encoded following [RFC3339](https://tools.ietf.org/html/rfc3339), which does not support fractional seconds, thus they must be stripped in the response. This can cause issues when the underlying database contains fields that do include microseconds, as filters may return unexpected results. \"\"\" json_encoders = { datetime : lambda v : v . astimezone ( timezone . utc ) . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), } json_encoders = { datetime : lambda v : v . astimezone ( timezone . utc ) . strftime ( '%Y-%m- %d T%H:%M:%SZ' )} class-attribute \u00b6 either_data_meta_or_errors_must_be_set ( values ) \u00b6 Source code in optimade/models/jsonapi.py 345 346 347 348 349 350 351 352 353 354 @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): required_fields = ( \"data\" , \"meta\" , \"errors\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response\" ) if \"errors\" in values and not values . get ( \"errors\" ): raise ValueError ( \"Errors MUST NOT be an empty or 'null' value.\" ) return values ToplevelLinks \u00b6 A set of Links objects, possibly including pagination Source code in optimade/models/jsonapi.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 class ToplevelLinks ( BaseModel ): \"\"\"A set of Links objects, possibly including pagination\"\"\" self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link to itself\" ) related : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A related resource link\" ) # Pagination first : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The first page of data\" ) last : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The last page of data\" ) prev : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The previous page of data\" ) next : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The next page of data\" ) @root_validator ( pre = False ) def check_additional_keys_are_links ( cls , values ): \"\"\"The `ToplevelLinks` class allows any additional keys, as long as they are also Links or Urls themselves. \"\"\" for key , value in values . items (): if key not in cls . schema ()[ \"properties\" ]: values [ key ] = parse_obj_as ( Optional [ Union [ AnyUrl , Link ]], value ) return values class Config : extra = \"allow\" first : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'The first page of data' ) class-attribute \u00b6 last : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'The last page of data' ) class-attribute \u00b6 next : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'The next page of data' ) class-attribute \u00b6 prev : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'The previous page of data' ) class-attribute \u00b6 related : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'A related resource link' ) class-attribute \u00b6 self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = 'A link to itself' ) class-attribute \u00b6 Config \u00b6 Source code in optimade/models/jsonapi.py 96 97 class Config : extra = \"allow\" extra = 'allow' class-attribute \u00b6 check_additional_keys_are_links ( values ) \u00b6 The ToplevelLinks class allows any additional keys, as long as they are also Links or Urls themselves. Source code in optimade/models/jsonapi.py 84 85 86 87 88 89 90 91 92 93 94 @root_validator ( pre = False ) def check_additional_keys_are_links ( cls , values ): \"\"\"The `ToplevelLinks` class allows any additional keys, as long as they are also Links or Urls themselves. \"\"\" for key , value in values . items (): if key not in cls . schema ()[ \"properties\" ]: values [ key ] = parse_obj_as ( Optional [ Union [ AnyUrl , Link ]], value ) return values","title":"jsonapi"},{"location":"api_reference/models/jsonapi/#jsonapi","text":"This module should reproduce JSON API v1.0 https://jsonapi.org/format/1.0/","title":"jsonapi"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Attributes","text":"Members of the attributes object (\"attributes\") represent information about the resource object in which it's defined. The keys for Attributes MUST NOT be relationships links id type Source code in optimade/models/jsonapi.py 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 class Attributes ( BaseModel ): \"\"\" Members of the attributes object (\"attributes\\\") represent information about the resource object in which it's defined. The keys for Attributes MUST NOT be: relationships links id type \"\"\" class Config : extra = \"allow\" @root_validator ( pre = True ) def check_illegal_attributes_fields ( cls , values ): illegal_fields = ( \"relationships\" , \"links\" , \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Attributes\" ) return values","title":"Attributes"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Attributes.Config","text":"Source code in optimade/models/jsonapi.py 287 288 class Config : extra = \"allow\"","title":"Config"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Attributes.Config.extra","text":"","title":"extra"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Attributes.check_illegal_attributes_fields","text":"Source code in optimade/models/jsonapi.py 290 291 292 293 294 295 296 297 298 @root_validator ( pre = True ) def check_illegal_attributes_fields ( cls , values ): illegal_fields = ( \"relationships\" , \"links\" , \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Attributes\" ) return values","title":"check_illegal_attributes_fields()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.BaseResource","text":"Minimum requirements to represent a Resource Source code in optimade/models/jsonapi.py 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 class BaseResource ( BaseModel ): \"\"\"Minimum requirements to represent a Resource\"\"\" id : str = StrictField ( ... , description = \"Resource ID\" ) type : str = StrictField ( ... , description = \"Resource type\" ) class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"BaseResource\" ]) -> None : \"\"\"Ensure `id` and `type` are the first two entries in the list required properties. Note: This _requires_ that `id` and `type` are the _first_ model fields defined for all sub-models of `BaseResource`. \"\"\" if \"id\" not in schema . get ( \"required\" , []): schema [ \"required\" ] = [ \"id\" ] + schema . get ( \"required\" , []) if \"type\" not in schema . get ( \"required\" , []): required = [] for field in schema . get ( \"required\" , []): required . append ( field ) if field == \"id\" : # To make sure the property order match the listed properties, # this ensures \"type\" is added immediately after \"id\". required . append ( \"type\" ) schema [ \"required\" ] = required","title":"BaseResource"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.BaseResource.id","text":"","title":"id"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.BaseResource.type","text":"","title":"type"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.BaseResource.Config","text":"Source code in optimade/models/jsonapi.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"BaseResource\" ]) -> None : \"\"\"Ensure `id` and `type` are the first two entries in the list required properties. Note: This _requires_ that `id` and `type` are the _first_ model fields defined for all sub-models of `BaseResource`. \"\"\" if \"id\" not in schema . get ( \"required\" , []): schema [ \"required\" ] = [ \"id\" ] + schema . get ( \"required\" , []) if \"type\" not in schema . get ( \"required\" , []): required = [] for field in schema . get ( \"required\" , []): required . append ( field ) if field == \"id\" : # To make sure the property order match the listed properties, # this ensures \"type\" is added immediately after \"id\". required . append ( \"type\" ) schema [ \"required\" ] = required","title":"Config"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.BaseResource.Config.schema_extra","text":"Ensure id and type are the first two entries in the list required properties. Note This requires that id and type are the first model fields defined for all sub-models of BaseResource . Source code in optimade/models/jsonapi.py 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"BaseResource\" ]) -> None : \"\"\"Ensure `id` and `type` are the first two entries in the list required properties. Note: This _requires_ that `id` and `type` are the _first_ model fields defined for all sub-models of `BaseResource`. \"\"\" if \"id\" not in schema . get ( \"required\" , []): schema [ \"required\" ] = [ \"id\" ] + schema . get ( \"required\" , []) if \"type\" not in schema . get ( \"required\" , []): required = [] for field in schema . get ( \"required\" , []): required . append ( field ) if field == \"id\" : # To make sure the property order match the listed properties, # this ensures \"type\" is added immediately after \"id\". required . append ( \"type\" ) schema [ \"required\" ] = required","title":"schema_extra()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error","text":"An error response Source code in optimade/models/jsonapi.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 class Error ( BaseModel ): \"\"\"An error response\"\"\" id : Optional [ str ] = StrictField ( None , description = \"A unique identifier for this particular occurrence of the problem.\" , ) links : Optional [ ErrorLinks ] = StrictField ( None , description = \"A links object storing about\" ) status : Optional [ str ] = StrictField ( None , description = \"the HTTP status code applicable to this problem, expressed as a string value.\" , ) code : Optional [ str ] = StrictField ( None , description = \"an application-specific error code, expressed as a string value.\" , ) title : Optional [ str ] = StrictField ( None , description = \"A short, human-readable summary of the problem. \" \"It **SHOULD NOT** change from occurrence to occurrence of the problem, except for purposes of localization.\" , ) detail : Optional [ str ] = StrictField ( None , description = \"A human-readable explanation specific to this occurrence of the problem.\" , ) source : Optional [ ErrorSource ] = StrictField ( None , description = \"An object containing references to the source of the error\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object containing non-standard meta-information about the error.\" , ) def __hash__ ( self ): return hash ( self . json ())","title":"Error"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.code","text":"","title":"code"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.detail","text":"","title":"detail"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.id","text":"","title":"id"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.links","text":"","title":"links"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.meta","text":"","title":"meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.source","text":"","title":"source"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.status","text":"","title":"status"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.title","text":"","title":"title"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Error.__hash__","text":"Source code in optimade/models/jsonapi.py 158 159 def __hash__ ( self ): return hash ( self . json ())","title":"__hash__()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ErrorLinks","text":"A Links object specific to Error objects Source code in optimade/models/jsonapi.py 100 101 102 103 104 105 106 class ErrorLinks ( BaseModel ): \"\"\"A Links object specific to Error objects\"\"\" about : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link that leads to further details about this particular occurrence of the problem.\" , )","title":"ErrorLinks"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ErrorLinks.about","text":"","title":"about"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ErrorSource","text":"an object containing references to the source of the error Source code in optimade/models/jsonapi.py 109 110 111 112 113 114 115 116 117 118 119 120 class ErrorSource ( BaseModel ): \"\"\"an object containing references to the source of the error\"\"\" pointer : Optional [ str ] = StrictField ( None , description = \"a JSON Pointer [RFC6901] to the associated entity in the request document \" '[e.g. \"/data\" for a primary data object, or \"/data/attributes/title\" for a specific attribute].' , ) parameter : Optional [ str ] = StrictField ( None , description = \"a string indicating which URI query parameter caused the error.\" , )","title":"ErrorSource"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ErrorSource.parameter","text":"","title":"parameter"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ErrorSource.pointer","text":"","title":"pointer"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.JsonApi","text":"An object describing the server's implementation Source code in optimade/models/jsonapi.py 49 50 51 52 53 54 55 56 57 class JsonApi ( BaseModel ): \"\"\"An object describing the server's implementation\"\"\" version : str = StrictField ( default = \"1.0\" , description = \"Version of the json API used\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"Non-standard meta information\" )","title":"JsonApi"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.JsonApi.meta","text":"","title":"meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.JsonApi.version","text":"","title":"version"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Link","text":"A link MUST be represented as either: a string containing the link's URL or a link object. Source code in optimade/models/jsonapi.py 39 40 41 42 43 44 45 46 class Link ( BaseModel ): \"\"\"A link **MUST** be represented as either: a string containing the link's URL or a link object.\"\"\" href : AnyUrl = StrictField ( ... , description = \"a string containing the link\u2019s URL.\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object containing non-standard meta-information about the link.\" , )","title":"Link"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Link.href","text":"","title":"href"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Link.meta","text":"","title":"meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Meta","text":"Non-standard meta-information that can not be represented as an attribute or relationship. Source code in optimade/models/jsonapi.py 32 33 34 35 36 class Meta ( BaseModel ): \"\"\"Non-standard meta-information that can not be represented as an attribute or relationship.\"\"\" class Config : extra = \"allow\"","title":"Meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Meta.Config","text":"Source code in optimade/models/jsonapi.py 35 36 class Config : extra = \"allow\"","title":"Config"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Meta.Config.extra","text":"","title":"extra"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationship","text":"Representation references from the resource object in which it\u2019s defined to other resource objects. Source code in optimade/models/jsonapi.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 class Relationship ( BaseModel ): \"\"\"Representation references from the resource object in which it\u2019s defined to other resource objects.\"\"\" links : Optional [ RelationshipLinks ] = StrictField ( None , description = \"a links object containing at least one of the following: self, related\" , ) data : Optional [ Union [ BaseResource , List [ BaseResource ]]] = StrictField ( None , description = \"Resource linkage\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object that contains non-standard meta-information about the relationship.\" , ) @root_validator ( pre = True ) def at_least_one_relationship_key_must_be_set ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'links', 'data', or 'meta' MUST be specified for Relationship\" ) return values","title":"Relationship"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationship.data","text":"","title":"data"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationship.links","text":"","title":"links"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationship.meta","text":"","title":"meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationship.at_least_one_relationship_key_must_be_set","text":"Source code in optimade/models/jsonapi.py 237 238 239 240 241 242 243 244 245 246 @root_validator ( pre = True ) def at_least_one_relationship_key_must_be_set ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'links', 'data', or 'meta' MUST be specified for Relationship\" ) return values","title":"at_least_one_relationship_key_must_be_set()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.RelationshipLinks","text":"A resource object MAY contain references to other resource objects (\"relationships\"). Relationships may be to-one or to-many. Relationships can be specified by including a member in a resource's links object. Source code in optimade/models/jsonapi.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 class RelationshipLinks ( BaseModel ): \"\"\"A resource object **MAY** contain references to other resource objects (\"relationships\"). Relationships may be to-one or to-many. Relationships can be specified by including a member in a resource's links object. \"\"\" self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"\"\"A link for the relationship itself (a 'relationship link'). This link allows the client to directly manipulate the relationship. When fetched successfully, this link returns the [linkage](https://jsonapi.org/format/1.0/#document-resource-object-linkage) for the related resources as its primary data. (See [Fetching Relationships](https://jsonapi.org/format/1.0/#fetching-relationships).)\"\"\" , ) related : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A [related resource link](https://jsonapi.org/format/1.0/#document-resource-object-related-resource-links).\" , ) @root_validator ( pre = True ) def either_self_or_related_must_be_specified ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'self' or 'related' MUST be specified for RelationshipLinks\" ) return values","title":"RelationshipLinks"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.RelationshipLinks.related","text":"","title":"related"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.RelationshipLinks.self","text":"","title":"self"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.RelationshipLinks.either_self_or_related_must_be_specified","text":"Source code in optimade/models/jsonapi.py 210 211 212 213 214 215 216 217 218 219 @root_validator ( pre = True ) def either_self_or_related_must_be_specified ( cls , values ): for value in values . values (): if value is not None : break else : raise ValueError ( \"Either 'self' or 'related' MUST be specified for RelationshipLinks\" ) return values","title":"either_self_or_related_must_be_specified()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationships","text":"Members of the relationships object (\"relationships\") represent references from the resource object in which it's defined to other resource objects. Keys MUST NOT be type id Source code in optimade/models/jsonapi.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 class Relationships ( BaseModel ): \"\"\" Members of the relationships object (\\\"relationships\\\") represent references from the resource object in which it's defined to other resource objects. Keys MUST NOT be: type id \"\"\" @root_validator ( pre = True ) def check_illegal_relationships_fields ( cls , values ): illegal_fields = ( \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Relationships\" ) return values","title":"Relationships"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Relationships.check_illegal_relationships_fields","text":"Source code in optimade/models/jsonapi.py 257 258 259 260 261 262 263 264 265 @root_validator ( pre = True ) def check_illegal_relationships_fields ( cls , values ): illegal_fields = ( \"id\" , \"type\" ) for field in illegal_fields : if field in values : raise ValueError ( f \" { illegal_fields } MUST NOT be fields under Relationships\" ) return values","title":"check_illegal_relationships_fields()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Resource","text":"Resource objects appear in a JSON API document to represent resources. Source code in optimade/models/jsonapi.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 class Resource ( BaseResource ): \"\"\"Resource objects appear in a JSON API document to represent resources.\"\"\" links : Optional [ ResourceLinks ] = StrictField ( None , description = \"a links object containing links related to the resource.\" ) meta : Optional [ Meta ] = StrictField ( None , description = \"a meta object containing non-standard meta-information about a resource that can not be represented as an attribute or relationship.\" , ) attributes : Optional [ Attributes ] = StrictField ( None , description = \"an attributes object representing some of the resource\u2019s data.\" , ) relationships : Optional [ Relationships ] = StrictField ( None , description = \"\"\"[Relationships object](https://jsonapi.org/format/1.0/#document-resource-object-relationships) describing relationships between the resource and other JSON API resources.\"\"\" , )","title":"Resource"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Resource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Resource.links","text":"","title":"links"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Resource.meta","text":"","title":"meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Resource.relationships","text":"","title":"relationships"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ResourceLinks","text":"A Resource Links object Source code in optimade/models/jsonapi.py 268 269 270 271 272 273 274 class ResourceLinks ( BaseModel ): \"\"\"A Resource Links object\"\"\" self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link that identifies the resource represented by the resource object.\" , )","title":"ResourceLinks"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ResourceLinks.self","text":"","title":"self"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response","text":"A top-level response Source code in optimade/models/jsonapi.py 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 class Response ( BaseModel ): \"\"\"A top-level response\"\"\" data : Optional [ Union [ None , Resource , List [ Resource ]]] = StrictField ( None , description = \"Outputted Data\" , uniqueItems = True ) meta : Optional [ Meta ] = StrictField ( None , description = \"A meta object containing non-standard information related to the Success\" , ) errors : Optional [ List [ Error ]] = StrictField ( None , description = \"A list of unique errors\" , uniqueItems = True ) included : Optional [ List [ Resource ]] = StrictField ( None , description = \"A list of unique included resources\" , uniqueItems = True ) links : Optional [ ToplevelLinks ] = StrictField ( None , description = \"Links associated with the primary data or errors\" ) jsonapi : Optional [ JsonApi ] = StrictField ( None , description = \"Information about the JSON API used\" ) @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): required_fields = ( \"data\" , \"meta\" , \"errors\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response\" ) if \"errors\" in values and not values . get ( \"errors\" ): raise ValueError ( \"Errors MUST NOT be an empty or 'null' value.\" ) return values class Config : \"\"\"The specification mandates that datetimes must be encoded following [RFC3339](https://tools.ietf.org/html/rfc3339), which does not support fractional seconds, thus they must be stripped in the response. This can cause issues when the underlying database contains fields that do include microseconds, as filters may return unexpected results. \"\"\" json_encoders = { datetime : lambda v : v . astimezone ( timezone . utc ) . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), }","title":"Response"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.data","text":"","title":"data"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.errors","text":"","title":"errors"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.included","text":"","title":"included"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.jsonapi","text":"","title":"jsonapi"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.links","text":"","title":"links"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.meta","text":"","title":"meta"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.Config","text":"The specification mandates that datetimes must be encoded following RFC3339 , which does not support fractional seconds, thus they must be stripped in the response. This can cause issues when the underlying database contains fields that do include microseconds, as filters may return unexpected results. Source code in optimade/models/jsonapi.py 356 357 358 359 360 361 362 363 364 365 366 367 368 class Config : \"\"\"The specification mandates that datetimes must be encoded following [RFC3339](https://tools.ietf.org/html/rfc3339), which does not support fractional seconds, thus they must be stripped in the response. This can cause issues when the underlying database contains fields that do include microseconds, as filters may return unexpected results. \"\"\" json_encoders = { datetime : lambda v : v . astimezone ( timezone . utc ) . strftime ( \"%Y-%m- %d T%H:%M:%SZ\" ), }","title":"Config"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.Config.json_encoders","text":"","title":"json_encoders"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.Response.either_data_meta_or_errors_must_be_set","text":"Source code in optimade/models/jsonapi.py 345 346 347 348 349 350 351 352 353 354 @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): required_fields = ( \"data\" , \"meta\" , \"errors\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response\" ) if \"errors\" in values and not values . get ( \"errors\" ): raise ValueError ( \"Errors MUST NOT be an empty or 'null' value.\" ) return values","title":"either_data_meta_or_errors_must_be_set()"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks","text":"A set of Links objects, possibly including pagination Source code in optimade/models/jsonapi.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 class ToplevelLinks ( BaseModel ): \"\"\"A set of Links objects, possibly including pagination\"\"\" self : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A link to itself\" ) related : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"A related resource link\" ) # Pagination first : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The first page of data\" ) last : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The last page of data\" ) prev : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The previous page of data\" ) next : Optional [ Union [ AnyUrl , Link ]] = StrictField ( None , description = \"The next page of data\" ) @root_validator ( pre = False ) def check_additional_keys_are_links ( cls , values ): \"\"\"The `ToplevelLinks` class allows any additional keys, as long as they are also Links or Urls themselves. \"\"\" for key , value in values . items (): if key not in cls . schema ()[ \"properties\" ]: values [ key ] = parse_obj_as ( Optional [ Union [ AnyUrl , Link ]], value ) return values class Config : extra = \"allow\"","title":"ToplevelLinks"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.first","text":"","title":"first"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.last","text":"","title":"last"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.next","text":"","title":"next"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.prev","text":"","title":"prev"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.related","text":"","title":"related"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.self","text":"","title":"self"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.Config","text":"Source code in optimade/models/jsonapi.py 96 97 class Config : extra = \"allow\"","title":"Config"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.Config.extra","text":"","title":"extra"},{"location":"api_reference/models/jsonapi/#optimade.models.jsonapi.ToplevelLinks.check_additional_keys_are_links","text":"The ToplevelLinks class allows any additional keys, as long as they are also Links or Urls themselves. Source code in optimade/models/jsonapi.py 84 85 86 87 88 89 90 91 92 93 94 @root_validator ( pre = False ) def check_additional_keys_are_links ( cls , values ): \"\"\"The `ToplevelLinks` class allows any additional keys, as long as they are also Links or Urls themselves. \"\"\" for key , value in values . items (): if key not in cls . schema ()[ \"properties\" ]: values [ key ] = parse_obj_as ( Optional [ Union [ AnyUrl , Link ]], value ) return values","title":"check_additional_keys_are_links()"},{"location":"api_reference/models/links/","text":"links \u00b6 Aggregate \u00b6 Enumeration of aggregate values Source code in optimade/models/links.py 30 31 32 33 34 35 36 class Aggregate ( Enum ): \"\"\"Enumeration of aggregate values\"\"\" OK = \"ok\" TEST = \"test\" STAGING = \"staging\" NO = \"no\" NO = 'no' class-attribute \u00b6 OK = 'ok' class-attribute \u00b6 STAGING = 'staging' class-attribute \u00b6 TEST = 'test' class-attribute \u00b6 LinkType \u00b6 Enumeration of link_type values Source code in optimade/models/links.py 21 22 23 24 25 26 27 class LinkType ( Enum ): \"\"\"Enumeration of link_type values\"\"\" CHILD = \"child\" ROOT = \"root\" EXTERNAL = \"external\" PROVIDERS = \"providers\" CHILD = 'child' class-attribute \u00b6 EXTERNAL = 'external' class-attribute \u00b6 PROVIDERS = 'providers' class-attribute \u00b6 ROOT = 'root' class-attribute \u00b6 LinksResource \u00b6 A Links endpoint resource object Source code in optimade/models/links.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class LinksResource ( EntryResource ): \"\"\"A Links endpoint resource object\"\"\" type : str = StrictField ( \"links\" , description = \"These objects are described in detail in the section Links Endpoint\" , regex = \"^links$\" , ) attributes : LinksResourceAttributes = StrictField ( ... , description = \"A dictionary containing key-value pairs representing the Links resource's properties.\" , ) @root_validator ( pre = True ) def relationships_must_not_be_present ( cls , values ): if values . get ( \"relationships\" , None ) is not None : raise ValueError ( '\"relationships\" is not allowed for links resources' ) return values attributes : LinksResourceAttributes = StrictField ( Ellipsis , description = \"A dictionary containing key-value pairs representing the Links resource's properties.\" ) class-attribute \u00b6 type : str = StrictField ( 'links' , description = 'These objects are described in detail in the section Links Endpoint' , regex = '^links$' ) class-attribute \u00b6 relationships_must_not_be_present ( values ) \u00b6 Source code in optimade/models/links.py 103 104 105 106 107 @root_validator ( pre = True ) def relationships_must_not_be_present ( cls , values ): if values . get ( \"relationships\" , None ) is not None : raise ValueError ( '\"relationships\" is not allowed for links resources' ) return values LinksResourceAttributes \u00b6 Links endpoint resource object attributes Source code in optimade/models/links.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class LinksResourceAttributes ( Attributes ): \"\"\"Links endpoint resource object attributes\"\"\" name : str = StrictField ( ... , description = \"Human-readable name for the OPTIMADE API implementation, e.g., for use in clients to show the name to the end-user.\" , ) description : str = StrictField ( ... , description = \"Human-readable description for the OPTIMADE API implementation, e.g., for use in clients to show a description to the end-user.\" , ) base_url : Optional [ Union [ AnyUrl , Link ]] = StrictField ( ... , description = \"JSON API links object, pointing to the base URL for this implementation\" , ) homepage : Optional [ Union [ AnyUrl , Link ]] = StrictField ( ... , description = \"JSON API links object, pointing to a homepage URL for this implementation\" , ) link_type : LinkType = StrictField ( ... , title = \"Link Type\" , description = \"\"\"The type of the linked relation. MUST be one of these values: 'child', 'root', 'external', 'providers'.\"\"\" , ) aggregate : Optional [ Aggregate ] = StrictField ( Aggregate . OK , title = \"Aggregate\" , description = \"\"\"A string indicating whether a client that is following links to aggregate results from different OPTIMADE implementations should follow this link or not. This flag SHOULD NOT be indicated for links where `link_type` is not `child`. If not specified, clients MAY assume that the value is `ok`. If specified, and the value is anything different than `ok`, the client MUST assume that the server is suggesting not to follow the link during aggregation by default (also if the value is not among the known ones, in case a future specification adds new accepted values). Specific values indicate the reason why the server is providing the suggestion. A client MAY follow the link anyway if it has reason to do so (e.g., if the client is looking for all test databases, it MAY follow the links marked with `aggregate`=`test`). If specified, it MUST be one of the values listed in section Link Aggregate Options.\"\"\" , ) no_aggregate_reason : Optional [ str ] = StrictField ( None , description = \"\"\"An OPTIONAL human-readable string indicating the reason for suggesting not to aggregate results following the link. It SHOULD NOT be present if `aggregate`=`ok`.\"\"\" , ) aggregate : Optional [ Aggregate ] = StrictField ( Aggregate . OK , title = 'Aggregate' , description = 'A string indicating whether a client that is following links to aggregate results from different OPTIMADE implementations should follow this link or not. \\n This flag SHOULD NOT be indicated for links where `link_type` is not `child`. \\n\\n If not specified, clients MAY assume that the value is `ok`. \\n If specified, and the value is anything different than `ok`, the client MUST assume that the server is suggesting not to follow the link during aggregation by default (also if the value is not among the known ones, in case a future specification adds new accepted values). \\n\\n Specific values indicate the reason why the server is providing the suggestion. \\n A client MAY follow the link anyway if it has reason to do so (e.g., if the client is looking for all test databases, it MAY follow the links marked with `aggregate`=`test`). \\n\\n If specified, it MUST be one of the values listed in section Link Aggregate Options.' ) class-attribute \u00b6 base_url : Optional [ Union [ AnyUrl , Link ]] = StrictField ( Ellipsis , description = 'JSON API links object, pointing to the base URL for this implementation' ) class-attribute \u00b6 description : str = StrictField ( Ellipsis , description = 'Human-readable description for the OPTIMADE API implementation, e.g., for use in clients to show a description to the end-user.' ) class-attribute \u00b6 homepage : Optional [ Union [ AnyUrl , Link ]] = StrictField ( Ellipsis , description = 'JSON API links object, pointing to a homepage URL for this implementation' ) class-attribute \u00b6 link_type : LinkType = StrictField ( Ellipsis , title = 'Link Type' , description = \"The type of the linked relation. \\n MUST be one of these values: 'child', 'root', 'external', 'providers'.\" ) class-attribute \u00b6 name : str = StrictField ( Ellipsis , description = 'Human-readable name for the OPTIMADE API implementation, e.g., for use in clients to show the name to the end-user.' ) class-attribute \u00b6 no_aggregate_reason : Optional [ str ] = StrictField ( None , description = 'An OPTIONAL human-readable string indicating the reason for suggesting not to aggregate results following the link. \\n It SHOULD NOT be present if `aggregate`=`ok`.' ) class-attribute \u00b6","title":"links"},{"location":"api_reference/models/links/#links","text":"","title":"links"},{"location":"api_reference/models/links/#optimade.models.links.Aggregate","text":"Enumeration of aggregate values Source code in optimade/models/links.py 30 31 32 33 34 35 36 class Aggregate ( Enum ): \"\"\"Enumeration of aggregate values\"\"\" OK = \"ok\" TEST = \"test\" STAGING = \"staging\" NO = \"no\"","title":"Aggregate"},{"location":"api_reference/models/links/#optimade.models.links.Aggregate.NO","text":"","title":"NO"},{"location":"api_reference/models/links/#optimade.models.links.Aggregate.OK","text":"","title":"OK"},{"location":"api_reference/models/links/#optimade.models.links.Aggregate.STAGING","text":"","title":"STAGING"},{"location":"api_reference/models/links/#optimade.models.links.Aggregate.TEST","text":"","title":"TEST"},{"location":"api_reference/models/links/#optimade.models.links.LinkType","text":"Enumeration of link_type values Source code in optimade/models/links.py 21 22 23 24 25 26 27 class LinkType ( Enum ): \"\"\"Enumeration of link_type values\"\"\" CHILD = \"child\" ROOT = \"root\" EXTERNAL = \"external\" PROVIDERS = \"providers\"","title":"LinkType"},{"location":"api_reference/models/links/#optimade.models.links.LinkType.CHILD","text":"","title":"CHILD"},{"location":"api_reference/models/links/#optimade.models.links.LinkType.EXTERNAL","text":"","title":"EXTERNAL"},{"location":"api_reference/models/links/#optimade.models.links.LinkType.PROVIDERS","text":"","title":"PROVIDERS"},{"location":"api_reference/models/links/#optimade.models.links.LinkType.ROOT","text":"","title":"ROOT"},{"location":"api_reference/models/links/#optimade.models.links.LinksResource","text":"A Links endpoint resource object Source code in optimade/models/links.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 class LinksResource ( EntryResource ): \"\"\"A Links endpoint resource object\"\"\" type : str = StrictField ( \"links\" , description = \"These objects are described in detail in the section Links Endpoint\" , regex = \"^links$\" , ) attributes : LinksResourceAttributes = StrictField ( ... , description = \"A dictionary containing key-value pairs representing the Links resource's properties.\" , ) @root_validator ( pre = True ) def relationships_must_not_be_present ( cls , values ): if values . get ( \"relationships\" , None ) is not None : raise ValueError ( '\"relationships\" is not allowed for links resources' ) return values","title":"LinksResource"},{"location":"api_reference/models/links/#optimade.models.links.LinksResource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/links/#optimade.models.links.LinksResource.type","text":"","title":"type"},{"location":"api_reference/models/links/#optimade.models.links.LinksResource.relationships_must_not_be_present","text":"Source code in optimade/models/links.py 103 104 105 106 107 @root_validator ( pre = True ) def relationships_must_not_be_present ( cls , values ): if values . get ( \"relationships\" , None ) is not None : raise ValueError ( '\"relationships\" is not allowed for links resources' ) return values","title":"relationships_must_not_be_present()"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes","text":"Links endpoint resource object attributes Source code in optimade/models/links.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class LinksResourceAttributes ( Attributes ): \"\"\"Links endpoint resource object attributes\"\"\" name : str = StrictField ( ... , description = \"Human-readable name for the OPTIMADE API implementation, e.g., for use in clients to show the name to the end-user.\" , ) description : str = StrictField ( ... , description = \"Human-readable description for the OPTIMADE API implementation, e.g., for use in clients to show a description to the end-user.\" , ) base_url : Optional [ Union [ AnyUrl , Link ]] = StrictField ( ... , description = \"JSON API links object, pointing to the base URL for this implementation\" , ) homepage : Optional [ Union [ AnyUrl , Link ]] = StrictField ( ... , description = \"JSON API links object, pointing to a homepage URL for this implementation\" , ) link_type : LinkType = StrictField ( ... , title = \"Link Type\" , description = \"\"\"The type of the linked relation. MUST be one of these values: 'child', 'root', 'external', 'providers'.\"\"\" , ) aggregate : Optional [ Aggregate ] = StrictField ( Aggregate . OK , title = \"Aggregate\" , description = \"\"\"A string indicating whether a client that is following links to aggregate results from different OPTIMADE implementations should follow this link or not. This flag SHOULD NOT be indicated for links where `link_type` is not `child`. If not specified, clients MAY assume that the value is `ok`. If specified, and the value is anything different than `ok`, the client MUST assume that the server is suggesting not to follow the link during aggregation by default (also if the value is not among the known ones, in case a future specification adds new accepted values). Specific values indicate the reason why the server is providing the suggestion. A client MAY follow the link anyway if it has reason to do so (e.g., if the client is looking for all test databases, it MAY follow the links marked with `aggregate`=`test`). If specified, it MUST be one of the values listed in section Link Aggregate Options.\"\"\" , ) no_aggregate_reason : Optional [ str ] = StrictField ( None , description = \"\"\"An OPTIONAL human-readable string indicating the reason for suggesting not to aggregate results following the link. It SHOULD NOT be present if `aggregate`=`ok`.\"\"\" , )","title":"LinksResourceAttributes"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.aggregate","text":"","title":"aggregate"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.base_url","text":"","title":"base_url"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.description","text":"","title":"description"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.homepage","text":"","title":"homepage"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.link_type","text":"","title":"link_type"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.name","text":"","title":"name"},{"location":"api_reference/models/links/#optimade.models.links.LinksResourceAttributes.no_aggregate_reason","text":"","title":"no_aggregate_reason"},{"location":"api_reference/models/optimade_json/","text":"optimade_json \u00b6 Modified JSON API v1.0 for OPTIMADE API BaseRelationshipMeta \u00b6 Specific meta field for base relationship resource Source code in optimade/models/optimade_json.py 356 357 358 359 360 361 class BaseRelationshipMeta ( jsonapi . Meta ): \"\"\"Specific meta field for base relationship resource\"\"\" description : str = StrictField ( ... , description = \"OPTIONAL human-readable description of the relationship.\" ) description : str = StrictField ( Ellipsis , description = 'OPTIONAL human-readable description of the relationship.' ) class-attribute \u00b6 BaseRelationshipResource \u00b6 Minimum requirements to represent a relationship resource Source code in optimade/models/optimade_json.py 364 365 366 367 368 369 370 class BaseRelationshipResource ( jsonapi . BaseResource ): \"\"\"Minimum requirements to represent a relationship resource\"\"\" meta : Optional [ BaseRelationshipMeta ] = StrictField ( None , description = \"Relationship meta field. MUST contain 'description' if supplied.\" , ) meta : Optional [ BaseRelationshipMeta ] = StrictField ( None , description = \"Relationship meta field. MUST contain 'description' if supplied.\" ) class-attribute \u00b6 DataType \u00b6 Optimade Data Types See the section \"Data types\" in the OPTIMADE API specification for more information. Source code in optimade/models/optimade_json.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class DataType ( Enum ): \"\"\"Optimade Data Types See the section \"Data types\" in the OPTIMADE API specification for more information. \"\"\" STRING = \"string\" INTEGER = \"integer\" FLOAT = \"float\" BOOLEAN = \"boolean\" TIMESTAMP = \"timestamp\" LIST = \"list\" DICTIONARY = \"dictionary\" UNKNOWN = \"unknown\" @classmethod def get_values ( cls ): \"\"\"Get OPTIMADE data types (enum values) as a (sorted) list\"\"\" return sorted (( _ . value for _ in cls )) @classmethod def from_python_type ( cls , python_type : Union [ type , str , object ]): \"\"\"Get OPTIMADE data type from a Python type\"\"\" mapping = { \"bool\" : cls . BOOLEAN , \"int\" : cls . INTEGER , \"float\" : cls . FLOAT , \"complex\" : None , \"generator\" : cls . LIST , \"list\" : cls . LIST , \"tuple\" : cls . LIST , \"range\" : cls . LIST , \"hash\" : cls . INTEGER , \"str\" : cls . STRING , \"bytes\" : cls . STRING , \"bytearray\" : None , \"memoryview\" : None , \"set\" : cls . LIST , \"frozenset\" : cls . LIST , \"dict\" : cls . DICTIONARY , \"dict_keys\" : cls . LIST , \"dict_values\" : cls . LIST , \"dict_items\" : cls . LIST , \"NoneType\" : cls . UNKNOWN , \"None\" : cls . UNKNOWN , \"datetime\" : cls . TIMESTAMP , \"date\" : cls . TIMESTAMP , \"time\" : cls . TIMESTAMP , \"datetime.datetime\" : cls . TIMESTAMP , \"datetime.date\" : cls . TIMESTAMP , \"datetime.time\" : cls . TIMESTAMP , } if isinstance ( python_type , type ): python_type = python_type . __name__ elif isinstance ( python_type , object ): if str ( python_type ) in mapping : python_type = str ( python_type ) else : python_type = type ( python_type ) . __name__ return mapping . get ( python_type , None ) @classmethod def from_json_type ( cls , json_type : str ): \"\"\"Get OPTIMADE data type from a named JSON type\"\"\" mapping = { \"string\" : cls . STRING , \"integer\" : cls . INTEGER , \"number\" : cls . FLOAT , # actually includes both integer and float \"object\" : cls . DICTIONARY , \"array\" : cls . LIST , \"boolean\" : cls . BOOLEAN , \"null\" : cls . UNKNOWN , # OpenAPI \"format\"s: \"double\" : cls . FLOAT , \"float\" : cls . FLOAT , \"int32\" : cls . INTEGER , \"int64\" : cls . INTEGER , \"date\" : cls . TIMESTAMP , \"date-time\" : cls . TIMESTAMP , \"password\" : cls . STRING , \"byte\" : cls . STRING , \"binary\" : cls . STRING , # Non-OpenAPI \"format\"s, but may still be used by pydantic/FastAPI \"email\" : cls . STRING , \"uuid\" : cls . STRING , \"uri\" : cls . STRING , \"hostname\" : cls . STRING , \"ipv4\" : cls . STRING , \"ipv6\" : cls . STRING , } return mapping . get ( json_type , None ) BOOLEAN = 'boolean' class-attribute \u00b6 DICTIONARY = 'dictionary' class-attribute \u00b6 FLOAT = 'float' class-attribute \u00b6 INTEGER = 'integer' class-attribute \u00b6 LIST = 'list' class-attribute \u00b6 STRING = 'string' class-attribute \u00b6 TIMESTAMP = 'timestamp' class-attribute \u00b6 UNKNOWN = 'unknown' class-attribute \u00b6 from_json_type ( json_type ) classmethod \u00b6 Get OPTIMADE data type from a named JSON type Source code in optimade/models/optimade_json.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 @classmethod def from_json_type ( cls , json_type : str ): \"\"\"Get OPTIMADE data type from a named JSON type\"\"\" mapping = { \"string\" : cls . STRING , \"integer\" : cls . INTEGER , \"number\" : cls . FLOAT , # actually includes both integer and float \"object\" : cls . DICTIONARY , \"array\" : cls . LIST , \"boolean\" : cls . BOOLEAN , \"null\" : cls . UNKNOWN , # OpenAPI \"format\"s: \"double\" : cls . FLOAT , \"float\" : cls . FLOAT , \"int32\" : cls . INTEGER , \"int64\" : cls . INTEGER , \"date\" : cls . TIMESTAMP , \"date-time\" : cls . TIMESTAMP , \"password\" : cls . STRING , \"byte\" : cls . STRING , \"binary\" : cls . STRING , # Non-OpenAPI \"format\"s, but may still be used by pydantic/FastAPI \"email\" : cls . STRING , \"uuid\" : cls . STRING , \"uri\" : cls . STRING , \"hostname\" : cls . STRING , \"ipv4\" : cls . STRING , \"ipv6\" : cls . STRING , } return mapping . get ( json_type , None ) from_python_type ( python_type ) classmethod \u00b6 Get OPTIMADE data type from a Python type Source code in optimade/models/optimade_json.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @classmethod def from_python_type ( cls , python_type : Union [ type , str , object ]): \"\"\"Get OPTIMADE data type from a Python type\"\"\" mapping = { \"bool\" : cls . BOOLEAN , \"int\" : cls . INTEGER , \"float\" : cls . FLOAT , \"complex\" : None , \"generator\" : cls . LIST , \"list\" : cls . LIST , \"tuple\" : cls . LIST , \"range\" : cls . LIST , \"hash\" : cls . INTEGER , \"str\" : cls . STRING , \"bytes\" : cls . STRING , \"bytearray\" : None , \"memoryview\" : None , \"set\" : cls . LIST , \"frozenset\" : cls . LIST , \"dict\" : cls . DICTIONARY , \"dict_keys\" : cls . LIST , \"dict_values\" : cls . LIST , \"dict_items\" : cls . LIST , \"NoneType\" : cls . UNKNOWN , \"None\" : cls . UNKNOWN , \"datetime\" : cls . TIMESTAMP , \"date\" : cls . TIMESTAMP , \"time\" : cls . TIMESTAMP , \"datetime.datetime\" : cls . TIMESTAMP , \"datetime.date\" : cls . TIMESTAMP , \"datetime.time\" : cls . TIMESTAMP , } if isinstance ( python_type , type ): python_type = python_type . __name__ elif isinstance ( python_type , object ): if str ( python_type ) in mapping : python_type = str ( python_type ) else : python_type = type ( python_type ) . __name__ return mapping . get ( python_type , None ) get_values () classmethod \u00b6 Get OPTIMADE data types (enum values) as a (sorted) list Source code in optimade/models/optimade_json.py 45 46 47 48 @classmethod def get_values ( cls ): \"\"\"Get OPTIMADE data types (enum values) as a (sorted) list\"\"\" return sorted (( _ . value for _ in cls )) Implementation \u00b6 Information on the server implementation Source code in optimade/models/optimade_json.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 class Implementation ( BaseModel ): \"\"\"Information on the server implementation\"\"\" name : Optional [ str ] = StrictField ( None , description = \"name of the implementation\" ) version : Optional [ str ] = StrictField ( None , description = \"version string of the current implementation\" ) homepage : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the homepage of the implementation.\" , ) source_url : Optional [ Union [ AnyUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the implementation source, either downloadable archive or version control system.\" , ) maintainer : Optional [ ImplementationMaintainer ] = StrictField ( None , description = \"A dictionary providing details about the maintainer of the implementation.\" , ) issue_tracker : Optional [ Union [ AnyUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the implementation's issue tracker.\" , ) homepage : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , description = 'A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the homepage of the implementation.' ) class-attribute \u00b6 issue_tracker : Optional [ Union [ AnyUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the implementation's issue tracker.\" ) class-attribute \u00b6 maintainer : Optional [ ImplementationMaintainer ] = StrictField ( None , description = 'A dictionary providing details about the maintainer of the implementation.' ) class-attribute \u00b6 name : Optional [ str ] = StrictField ( None , description = 'name of the implementation' ) class-attribute \u00b6 source_url : Optional [ Union [ AnyUrl , jsonapi . Link ]] = StrictField ( None , description = 'A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the implementation source, either downloadable archive or version control system.' ) class-attribute \u00b6 version : Optional [ str ] = StrictField ( None , description = 'version string of the current implementation' ) class-attribute \u00b6 ImplementationMaintainer \u00b6 Details about the maintainer of the implementation Source code in optimade/models/optimade_json.py 216 217 218 219 class ImplementationMaintainer ( BaseModel ): \"\"\"Details about the maintainer of the implementation\"\"\" email : EmailStr = StrictField ( ... , description = \"the maintainer's email address\" ) email : EmailStr = StrictField ( Ellipsis , description = \"the maintainer's email address\" ) class-attribute \u00b6 OptimadeError \u00b6 detail MUST be present Source code in optimade/models/optimade_json.py 126 127 128 129 130 131 132 class OptimadeError ( jsonapi . Error ): \"\"\"detail MUST be present\"\"\" detail : str = StrictField ( ... , description = \"A human-readable explanation specific to this occurrence of the problem.\" , ) detail : str = StrictField ( Ellipsis , description = 'A human-readable explanation specific to this occurrence of the problem.' ) class-attribute \u00b6 Provider \u00b6 Information on the database provider of the implementation. Source code in optimade/models/optimade_json.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 class Provider ( BaseModel ): \"\"\"Information on the database provider of the implementation.\"\"\" name : str = StrictField ( ... , description = \"a short name for the database provider\" ) description : str = StrictField ( ... , description = \"a longer description of the database provider\" ) prefix : str = StrictField ( ... , regex = r \"^[a-z]([a-z]|[0-9]|_)*$\" , description = \"database-provider-specific prefix as found in section Database-Provider-Specific Namespace Prefixes.\" , ) homepage : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , description = \"a [JSON API links object](http://jsonapi.org/format/1.0#document-links) \" \"pointing to homepage of the database provider, either \" \"directly as a string, or as a link object.\" , ) description : str = StrictField ( Ellipsis , description = 'a longer description of the database provider' ) class-attribute \u00b6 homepage : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , description = 'a [JSON API links object](http://jsonapi.org/format/1.0#document-links) pointing to homepage of the database provider, either directly as a string, or as a link object.' ) class-attribute \u00b6 name : str = StrictField ( Ellipsis , description = 'a short name for the database provider' ) class-attribute \u00b6 prefix : str = StrictField ( Ellipsis , regex = '^[a-z]([a-z]|[0-9]|_)*$' , description = 'database-provider-specific prefix as found in section Database-Provider-Specific Namespace Prefixes.' ) class-attribute \u00b6 Relationship \u00b6 Similar to normal JSON API relationship, but with addition of OPTIONAL meta field for a resource. Source code in optimade/models/optimade_json.py 373 374 375 376 377 378 class Relationship ( jsonapi . Relationship ): \"\"\"Similar to normal JSON API relationship, but with addition of OPTIONAL meta field for a resource.\"\"\" data : Optional [ Union [ BaseRelationshipResource , List [ BaseRelationshipResource ]] ] = StrictField ( None , description = \"Resource linkage\" , uniqueItems = True ) data : Optional [ Union [ BaseRelationshipResource , List [ BaseRelationshipResource ]]] = StrictField ( None , description = 'Resource linkage' , uniqueItems = True ) class-attribute \u00b6 ResponseMeta \u00b6 A JSON API meta member that contains JSON API meta objects of non-standard meta-information. OPTIONAL additional information global to the query that is not specified in this document, MUST start with a database-provider-specific prefix. Source code in optimade/models/optimade_json.py 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 class ResponseMeta ( jsonapi . Meta ): \"\"\" A [JSON API meta member](https://jsonapi.org/format/1.0#document-meta) that contains JSON API meta objects of non-standard meta-information. OPTIONAL additional information global to the query that is not specified in this document, MUST start with a database-provider-specific prefix. \"\"\" query : ResponseMetaQuery = StrictField ( ... , description = \"Information on the Query that was requested\" ) api_version : SemanticVersion = StrictField ( ... , description = \"\"\"Presently used full version of the OPTIMADE API. The version number string MUST NOT be prefixed by, e.g., \"v\". Examples: `1.0.0`, `1.0.0-rc.2`.\"\"\" , ) more_data_available : bool = StrictField ( ... , description = \"`false` if the response contains all data for the request (e.g., a request issued to a single entry endpoint, or a `filter` query at the last page of a paginated response) and `true` if the response is incomplete in the sense that multiple objects match the request, and not all of them have been included in the response (e.g., a query with multiple pages that is not at the last page).\" , ) # start of \"SHOULD\" fields for meta response optimade_schema : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , alias = \"schema\" , description = \"\"\"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) that points to a schema for the response. If it is a string, or a dictionary containing no `meta` field, the provided URL MUST point at an [OpenAPI](https://swagger.io/specification/) schema. It is possible that future versions of this specification allows for alternative schema types. Hence, if the `meta` field of the JSON API links object is provided and contains a field `schema_type` that is not equal to the string `OpenAPI` the client MUST not handle failures to parse the schema or to validate the response against the schema as errors.\"\"\" , ) time_stamp : Optional [ datetime ] = StrictField ( None , description = \"A timestamp containing the date and time at which the query was executed.\" , ) data_returned : Optional [ int ] = StrictField ( None , description = \"An integer containing the total number of data resource objects returned for the current `filter` query, independent of pagination.\" , ge = 0 , ) provider : Optional [ Provider ] = StrictField ( None , description = \"information on the database provider of the implementation.\" ) # start of \"MAY\" fields for meta response data_available : Optional [ int ] = StrictField ( None , description = \"An integer containing the total number of data resource objects available in the database for the endpoint.\" , ) last_id : Optional [ str ] = StrictField ( None , description = \"a string containing the last ID returned\" ) response_message : Optional [ str ] = StrictField ( None , description = \"response string from the server\" ) implementation : Optional [ Implementation ] = StrictField ( None , description = \"a dictionary describing the server implementation\" ) warnings : Optional [ List [ Warnings ]] = StrictField ( None , description = \"\"\"A list of warning resource objects representing non-critical errors or warnings. A warning resource object is defined similarly to a [JSON API error object](http://jsonapi.org/format/1.0/#error-objects), but MUST also include the field `type`, which MUST have the value `\"warning\"`. The field `detail` MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. The field `status`, representing a HTTP response status code, MUST NOT be present for a warning resource object. This is an exclusive field for error resource objects.\"\"\" , uniqueItems = True , ) api_version : SemanticVersion = StrictField ( Ellipsis , description = 'Presently used full version of the OPTIMADE API. \\n The version number string MUST NOT be prefixed by, e.g., \"v\". \\n Examples: `1.0.0`, `1.0.0-rc.2`.' ) class-attribute \u00b6 data_available : Optional [ int ] = StrictField ( None , description = 'An integer containing the total number of data resource objects available in the database for the endpoint.' ) class-attribute \u00b6 data_returned : Optional [ int ] = StrictField ( None , description = 'An integer containing the total number of data resource objects returned for the current `filter` query, independent of pagination.' , ge = 0 ) class-attribute \u00b6 implementation : Optional [ Implementation ] = StrictField ( None , description = 'a dictionary describing the server implementation' ) class-attribute \u00b6 last_id : Optional [ str ] = StrictField ( None , description = 'a string containing the last ID returned' ) class-attribute \u00b6 more_data_available : bool = StrictField ( Ellipsis , description = '`false` if the response contains all data for the request (e.g., a request issued to a single entry endpoint, or a `filter` query at the last page of a paginated response) and `true` if the response is incomplete in the sense that multiple objects match the request, and not all of them have been included in the response (e.g., a query with multiple pages that is not at the last page).' ) class-attribute \u00b6 optimade_schema : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , alias = 'schema' , description = 'A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) that points to a schema for the response. \\n If it is a string, or a dictionary containing no `meta` field, the provided URL MUST point at an [OpenAPI](https://swagger.io/specification/) schema. \\n It is possible that future versions of this specification allows for alternative schema types. \\n Hence, if the `meta` field of the JSON API links object is provided and contains a field `schema_type` that is not equal to the string `OpenAPI` the client MUST not handle failures to parse the schema or to validate the response against the schema as errors.' ) class-attribute \u00b6 provider : Optional [ Provider ] = StrictField ( None , description = 'information on the database provider of the implementation.' ) class-attribute \u00b6 query : ResponseMetaQuery = StrictField ( Ellipsis , description = 'Information on the Query that was requested' ) class-attribute \u00b6 response_message : Optional [ str ] = StrictField ( None , description = 'response string from the server' ) class-attribute \u00b6 time_stamp : Optional [ datetime ] = StrictField ( None , description = 'A timestamp containing the date and time at which the query was executed.' ) class-attribute \u00b6 warnings : Optional [ List [ Warnings ]] = StrictField ( None , description = 'A list of warning resource objects representing non-critical errors or warnings. \\n A warning resource object is defined similarly to a [JSON API error object](http://jsonapi.org/format/1.0/#error-objects), but MUST also include the field `type`, which MUST have the value `\"warning\"`. \\n The field `detail` MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. \\n The field `status`, representing a HTTP response status code, MUST NOT be present for a warning resource object. \\n This is an exclusive field for error resource objects.' , uniqueItems = True ) class-attribute \u00b6 ResponseMetaQuery \u00b6 Information on the query that was requested. Source code in optimade/models/optimade_json.py 181 182 183 184 185 186 187 188 189 190 class ResponseMetaQuery ( BaseModel ): \"\"\"Information on the query that was requested.\"\"\" representation : str = StrictField ( ... , description = \"\"\"A string with the part of the URL following the versioned or unversioned base URL that serves the API. Query parameters that have not been used in processing the request MAY be omitted. In particular, if no query parameters have been involved in processing the request, the query part of the URL MAY be excluded. Example: `/structures?filter=nelements=2`\"\"\" , ) representation : str = StrictField ( Ellipsis , description = 'A string with the part of the URL following the versioned or unversioned base URL that serves the API. \\n Query parameters that have not been used in processing the request MAY be omitted. \\n In particular, if no query parameters have been involved in processing the request, the query part of the URL MAY be excluded. \\n Example: `/structures?filter=nelements=2`' ) class-attribute \u00b6 Success \u00b6 errors are not allowed Source code in optimade/models/optimade_json.py 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 class Success ( jsonapi . Response ): \"\"\"errors are not allowed\"\"\" meta : ResponseMeta = StrictField ( ... , description = \"A meta object containing non-standard information\" ) @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): \"\"\"Overwriting the existing validation function, since 'errors' MUST NOT be set.\"\"\" required_fields = ( \"data\" , \"meta\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response.\" ) # errors MUST be skipped if \"errors\" in values : raise ValueError ( \"'errors' MUST be skipped for a successful response.\" ) return values meta : ResponseMeta = StrictField ( Ellipsis , description = 'A meta object containing non-standard information' ) class-attribute \u00b6 either_data_meta_or_errors_must_be_set ( values ) \u00b6 Overwriting the existing validation function, since 'errors' MUST NOT be set. Source code in optimade/models/optimade_json.py 340 341 342 343 344 345 346 347 348 349 350 351 352 353 @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): \"\"\"Overwriting the existing validation function, since 'errors' MUST NOT be set.\"\"\" required_fields = ( \"data\" , \"meta\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response.\" ) # errors MUST be skipped if \"errors\" in values : raise ValueError ( \"'errors' MUST be skipped for a successful response.\" ) return values Warnings \u00b6 OPTIMADE-specific warning class based on OPTIMADE-specific JSON API Error. From the specification: A warning resource object is defined similarly to a JSON API error object, but MUST also include the field type, which MUST have the value \"warning\". The field detail MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. Note: Must be named \"Warnings\", since \"Warning\" is a built-in Python class. Source code in optimade/models/optimade_json.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 class Warnings ( OptimadeError ): \"\"\"OPTIMADE-specific warning class based on OPTIMADE-specific JSON API Error. From the specification: A warning resource object is defined similarly to a JSON API error object, but MUST also include the field type, which MUST have the value \"warning\". The field detail MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. Note: Must be named \"Warnings\", since \"Warning\" is a built-in Python class. \"\"\" type : str = StrictField ( \"warning\" , description = 'Warnings must be of type \"warning\"' , regex = \"^warning$\" , ) @root_validator ( pre = True ) def status_must_not_be_specified ( cls , values ): if values . get ( \"status\" , None ) is not None : raise ValueError ( \"status MUST NOT be specified for warnings\" ) return values class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"Warnings\" ]) -> None : \"\"\"Update OpenAPI JSON schema model for `Warning`. * Ensure `type` is in the list required properties and in the correct place. * Remove `status` property. This property is not allowed for `Warning`, nor is it a part of the OPTIMADE definition of the `Warning` object. Note: Since `type` is the _last_ model field defined, it will simply be appended. \"\"\" if \"required\" in schema : if \"type\" not in schema [ \"required\" ]: schema [ \"required\" ] . append ( \"type\" ) else : schema [ \"required\" ] = [ \"type\" ] schema . get ( \"properties\" , {}) . pop ( \"status\" , None ) type : str = StrictField ( 'warning' , description = 'Warnings must be of type \"warning\"' , regex = '^warning$' ) class-attribute \u00b6 Config \u00b6 Source code in optimade/models/optimade_json.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"Warnings\" ]) -> None : \"\"\"Update OpenAPI JSON schema model for `Warning`. * Ensure `type` is in the list required properties and in the correct place. * Remove `status` property. This property is not allowed for `Warning`, nor is it a part of the OPTIMADE definition of the `Warning` object. Note: Since `type` is the _last_ model field defined, it will simply be appended. \"\"\" if \"required\" in schema : if \"type\" not in schema [ \"required\" ]: schema [ \"required\" ] . append ( \"type\" ) else : schema [ \"required\" ] = [ \"type\" ] schema . get ( \"properties\" , {}) . pop ( \"status\" , None ) schema_extra ( schema , model ) staticmethod \u00b6 Update OpenAPI JSON schema model for Warning . Ensure type is in the list required properties and in the correct place. Remove status property. This property is not allowed for Warning , nor is it a part of the OPTIMADE definition of the Warning object. Note Since type is the last model field defined, it will simply be appended. Source code in optimade/models/optimade_json.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"Warnings\" ]) -> None : \"\"\"Update OpenAPI JSON schema model for `Warning`. * Ensure `type` is in the list required properties and in the correct place. * Remove `status` property. This property is not allowed for `Warning`, nor is it a part of the OPTIMADE definition of the `Warning` object. Note: Since `type` is the _last_ model field defined, it will simply be appended. \"\"\" if \"required\" in schema : if \"type\" not in schema [ \"required\" ]: schema [ \"required\" ] . append ( \"type\" ) else : schema [ \"required\" ] = [ \"type\" ] schema . get ( \"properties\" , {}) . pop ( \"status\" , None ) status_must_not_be_specified ( values ) \u00b6 Source code in optimade/models/optimade_json.py 153 154 155 156 157 @root_validator ( pre = True ) def status_must_not_be_specified ( cls , values ): if values . get ( \"status\" , None ) is not None : raise ValueError ( \"status MUST NOT be specified for warnings\" ) return values","title":"optimade_json"},{"location":"api_reference/models/optimade_json/#optimade_json","text":"Modified JSON API v1.0 for OPTIMADE API","title":"optimade_json"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.BaseRelationshipMeta","text":"Specific meta field for base relationship resource Source code in optimade/models/optimade_json.py 356 357 358 359 360 361 class BaseRelationshipMeta ( jsonapi . Meta ): \"\"\"Specific meta field for base relationship resource\"\"\" description : str = StrictField ( ... , description = \"OPTIONAL human-readable description of the relationship.\" )","title":"BaseRelationshipMeta"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.BaseRelationshipMeta.description","text":"","title":"description"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.BaseRelationshipResource","text":"Minimum requirements to represent a relationship resource Source code in optimade/models/optimade_json.py 364 365 366 367 368 369 370 class BaseRelationshipResource ( jsonapi . BaseResource ): \"\"\"Minimum requirements to represent a relationship resource\"\"\" meta : Optional [ BaseRelationshipMeta ] = StrictField ( None , description = \"Relationship meta field. MUST contain 'description' if supplied.\" , )","title":"BaseRelationshipResource"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.BaseRelationshipResource.meta","text":"","title":"meta"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType","text":"Optimade Data Types See the section \"Data types\" in the OPTIMADE API specification for more information. Source code in optimade/models/optimade_json.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 class DataType ( Enum ): \"\"\"Optimade Data Types See the section \"Data types\" in the OPTIMADE API specification for more information. \"\"\" STRING = \"string\" INTEGER = \"integer\" FLOAT = \"float\" BOOLEAN = \"boolean\" TIMESTAMP = \"timestamp\" LIST = \"list\" DICTIONARY = \"dictionary\" UNKNOWN = \"unknown\" @classmethod def get_values ( cls ): \"\"\"Get OPTIMADE data types (enum values) as a (sorted) list\"\"\" return sorted (( _ . value for _ in cls )) @classmethod def from_python_type ( cls , python_type : Union [ type , str , object ]): \"\"\"Get OPTIMADE data type from a Python type\"\"\" mapping = { \"bool\" : cls . BOOLEAN , \"int\" : cls . INTEGER , \"float\" : cls . FLOAT , \"complex\" : None , \"generator\" : cls . LIST , \"list\" : cls . LIST , \"tuple\" : cls . LIST , \"range\" : cls . LIST , \"hash\" : cls . INTEGER , \"str\" : cls . STRING , \"bytes\" : cls . STRING , \"bytearray\" : None , \"memoryview\" : None , \"set\" : cls . LIST , \"frozenset\" : cls . LIST , \"dict\" : cls . DICTIONARY , \"dict_keys\" : cls . LIST , \"dict_values\" : cls . LIST , \"dict_items\" : cls . LIST , \"NoneType\" : cls . UNKNOWN , \"None\" : cls . UNKNOWN , \"datetime\" : cls . TIMESTAMP , \"date\" : cls . TIMESTAMP , \"time\" : cls . TIMESTAMP , \"datetime.datetime\" : cls . TIMESTAMP , \"datetime.date\" : cls . TIMESTAMP , \"datetime.time\" : cls . TIMESTAMP , } if isinstance ( python_type , type ): python_type = python_type . __name__ elif isinstance ( python_type , object ): if str ( python_type ) in mapping : python_type = str ( python_type ) else : python_type = type ( python_type ) . __name__ return mapping . get ( python_type , None ) @classmethod def from_json_type ( cls , json_type : str ): \"\"\"Get OPTIMADE data type from a named JSON type\"\"\" mapping = { \"string\" : cls . STRING , \"integer\" : cls . INTEGER , \"number\" : cls . FLOAT , # actually includes both integer and float \"object\" : cls . DICTIONARY , \"array\" : cls . LIST , \"boolean\" : cls . BOOLEAN , \"null\" : cls . UNKNOWN , # OpenAPI \"format\"s: \"double\" : cls . FLOAT , \"float\" : cls . FLOAT , \"int32\" : cls . INTEGER , \"int64\" : cls . INTEGER , \"date\" : cls . TIMESTAMP , \"date-time\" : cls . TIMESTAMP , \"password\" : cls . STRING , \"byte\" : cls . STRING , \"binary\" : cls . STRING , # Non-OpenAPI \"format\"s, but may still be used by pydantic/FastAPI \"email\" : cls . STRING , \"uuid\" : cls . STRING , \"uri\" : cls . STRING , \"hostname\" : cls . STRING , \"ipv4\" : cls . STRING , \"ipv6\" : cls . STRING , } return mapping . get ( json_type , None )","title":"DataType"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.BOOLEAN","text":"","title":"BOOLEAN"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.DICTIONARY","text":"","title":"DICTIONARY"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.FLOAT","text":"","title":"FLOAT"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.INTEGER","text":"","title":"INTEGER"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.LIST","text":"","title":"LIST"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.STRING","text":"","title":"STRING"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.TIMESTAMP","text":"","title":"TIMESTAMP"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.UNKNOWN","text":"","title":"UNKNOWN"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.from_json_type","text":"Get OPTIMADE data type from a named JSON type Source code in optimade/models/optimade_json.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 @classmethod def from_json_type ( cls , json_type : str ): \"\"\"Get OPTIMADE data type from a named JSON type\"\"\" mapping = { \"string\" : cls . STRING , \"integer\" : cls . INTEGER , \"number\" : cls . FLOAT , # actually includes both integer and float \"object\" : cls . DICTIONARY , \"array\" : cls . LIST , \"boolean\" : cls . BOOLEAN , \"null\" : cls . UNKNOWN , # OpenAPI \"format\"s: \"double\" : cls . FLOAT , \"float\" : cls . FLOAT , \"int32\" : cls . INTEGER , \"int64\" : cls . INTEGER , \"date\" : cls . TIMESTAMP , \"date-time\" : cls . TIMESTAMP , \"password\" : cls . STRING , \"byte\" : cls . STRING , \"binary\" : cls . STRING , # Non-OpenAPI \"format\"s, but may still be used by pydantic/FastAPI \"email\" : cls . STRING , \"uuid\" : cls . STRING , \"uri\" : cls . STRING , \"hostname\" : cls . STRING , \"ipv4\" : cls . STRING , \"ipv6\" : cls . STRING , } return mapping . get ( json_type , None )","title":"from_json_type()"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.from_python_type","text":"Get OPTIMADE data type from a Python type Source code in optimade/models/optimade_json.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @classmethod def from_python_type ( cls , python_type : Union [ type , str , object ]): \"\"\"Get OPTIMADE data type from a Python type\"\"\" mapping = { \"bool\" : cls . BOOLEAN , \"int\" : cls . INTEGER , \"float\" : cls . FLOAT , \"complex\" : None , \"generator\" : cls . LIST , \"list\" : cls . LIST , \"tuple\" : cls . LIST , \"range\" : cls . LIST , \"hash\" : cls . INTEGER , \"str\" : cls . STRING , \"bytes\" : cls . STRING , \"bytearray\" : None , \"memoryview\" : None , \"set\" : cls . LIST , \"frozenset\" : cls . LIST , \"dict\" : cls . DICTIONARY , \"dict_keys\" : cls . LIST , \"dict_values\" : cls . LIST , \"dict_items\" : cls . LIST , \"NoneType\" : cls . UNKNOWN , \"None\" : cls . UNKNOWN , \"datetime\" : cls . TIMESTAMP , \"date\" : cls . TIMESTAMP , \"time\" : cls . TIMESTAMP , \"datetime.datetime\" : cls . TIMESTAMP , \"datetime.date\" : cls . TIMESTAMP , \"datetime.time\" : cls . TIMESTAMP , } if isinstance ( python_type , type ): python_type = python_type . __name__ elif isinstance ( python_type , object ): if str ( python_type ) in mapping : python_type = str ( python_type ) else : python_type = type ( python_type ) . __name__ return mapping . get ( python_type , None )","title":"from_python_type()"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.DataType.get_values","text":"Get OPTIMADE data types (enum values) as a (sorted) list Source code in optimade/models/optimade_json.py 45 46 47 48 @classmethod def get_values ( cls ): \"\"\"Get OPTIMADE data types (enum values) as a (sorted) list\"\"\" return sorted (( _ . value for _ in cls ))","title":"get_values()"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation","text":"Information on the server implementation Source code in optimade/models/optimade_json.py 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 class Implementation ( BaseModel ): \"\"\"Information on the server implementation\"\"\" name : Optional [ str ] = StrictField ( None , description = \"name of the implementation\" ) version : Optional [ str ] = StrictField ( None , description = \"version string of the current implementation\" ) homepage : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the homepage of the implementation.\" , ) source_url : Optional [ Union [ AnyUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the implementation source, either downloadable archive or version control system.\" , ) maintainer : Optional [ ImplementationMaintainer ] = StrictField ( None , description = \"A dictionary providing details about the maintainer of the implementation.\" , ) issue_tracker : Optional [ Union [ AnyUrl , jsonapi . Link ]] = StrictField ( None , description = \"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) pointing to the implementation's issue tracker.\" , )","title":"Implementation"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation.homepage","text":"","title":"homepage"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation.issue_tracker","text":"","title":"issue_tracker"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation.maintainer","text":"","title":"maintainer"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation.name","text":"","title":"name"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation.source_url","text":"","title":"source_url"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Implementation.version","text":"","title":"version"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ImplementationMaintainer","text":"Details about the maintainer of the implementation Source code in optimade/models/optimade_json.py 216 217 218 219 class ImplementationMaintainer ( BaseModel ): \"\"\"Details about the maintainer of the implementation\"\"\" email : EmailStr = StrictField ( ... , description = \"the maintainer's email address\" )","title":"ImplementationMaintainer"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ImplementationMaintainer.email","text":"","title":"email"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.OptimadeError","text":"detail MUST be present Source code in optimade/models/optimade_json.py 126 127 128 129 130 131 132 class OptimadeError ( jsonapi . Error ): \"\"\"detail MUST be present\"\"\" detail : str = StrictField ( ... , description = \"A human-readable explanation specific to this occurrence of the problem.\" , )","title":"OptimadeError"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.OptimadeError.detail","text":"","title":"detail"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Provider","text":"Information on the database provider of the implementation. Source code in optimade/models/optimade_json.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 class Provider ( BaseModel ): \"\"\"Information on the database provider of the implementation.\"\"\" name : str = StrictField ( ... , description = \"a short name for the database provider\" ) description : str = StrictField ( ... , description = \"a longer description of the database provider\" ) prefix : str = StrictField ( ... , regex = r \"^[a-z]([a-z]|[0-9]|_)*$\" , description = \"database-provider-specific prefix as found in section Database-Provider-Specific Namespace Prefixes.\" , ) homepage : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , description = \"a [JSON API links object](http://jsonapi.org/format/1.0#document-links) \" \"pointing to homepage of the database provider, either \" \"directly as a string, or as a link object.\" , )","title":"Provider"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Provider.description","text":"","title":"description"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Provider.homepage","text":"","title":"homepage"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Provider.name","text":"","title":"name"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Provider.prefix","text":"","title":"prefix"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Relationship","text":"Similar to normal JSON API relationship, but with addition of OPTIONAL meta field for a resource. Source code in optimade/models/optimade_json.py 373 374 375 376 377 378 class Relationship ( jsonapi . Relationship ): \"\"\"Similar to normal JSON API relationship, but with addition of OPTIONAL meta field for a resource.\"\"\" data : Optional [ Union [ BaseRelationshipResource , List [ BaseRelationshipResource ]] ] = StrictField ( None , description = \"Resource linkage\" , uniqueItems = True )","title":"Relationship"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Relationship.data","text":"","title":"data"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta","text":"A JSON API meta member that contains JSON API meta objects of non-standard meta-information. OPTIONAL additional information global to the query that is not specified in this document, MUST start with a database-provider-specific prefix. Source code in optimade/models/optimade_json.py 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 class ResponseMeta ( jsonapi . Meta ): \"\"\" A [JSON API meta member](https://jsonapi.org/format/1.0#document-meta) that contains JSON API meta objects of non-standard meta-information. OPTIONAL additional information global to the query that is not specified in this document, MUST start with a database-provider-specific prefix. \"\"\" query : ResponseMetaQuery = StrictField ( ... , description = \"Information on the Query that was requested\" ) api_version : SemanticVersion = StrictField ( ... , description = \"\"\"Presently used full version of the OPTIMADE API. The version number string MUST NOT be prefixed by, e.g., \"v\". Examples: `1.0.0`, `1.0.0-rc.2`.\"\"\" , ) more_data_available : bool = StrictField ( ... , description = \"`false` if the response contains all data for the request (e.g., a request issued to a single entry endpoint, or a `filter` query at the last page of a paginated response) and `true` if the response is incomplete in the sense that multiple objects match the request, and not all of them have been included in the response (e.g., a query with multiple pages that is not at the last page).\" , ) # start of \"SHOULD\" fields for meta response optimade_schema : Optional [ Union [ AnyHttpUrl , jsonapi . Link ]] = StrictField ( None , alias = \"schema\" , description = \"\"\"A [JSON API links object](http://jsonapi.org/format/1.0/#document-links) that points to a schema for the response. If it is a string, or a dictionary containing no `meta` field, the provided URL MUST point at an [OpenAPI](https://swagger.io/specification/) schema. It is possible that future versions of this specification allows for alternative schema types. Hence, if the `meta` field of the JSON API links object is provided and contains a field `schema_type` that is not equal to the string `OpenAPI` the client MUST not handle failures to parse the schema or to validate the response against the schema as errors.\"\"\" , ) time_stamp : Optional [ datetime ] = StrictField ( None , description = \"A timestamp containing the date and time at which the query was executed.\" , ) data_returned : Optional [ int ] = StrictField ( None , description = \"An integer containing the total number of data resource objects returned for the current `filter` query, independent of pagination.\" , ge = 0 , ) provider : Optional [ Provider ] = StrictField ( None , description = \"information on the database provider of the implementation.\" ) # start of \"MAY\" fields for meta response data_available : Optional [ int ] = StrictField ( None , description = \"An integer containing the total number of data resource objects available in the database for the endpoint.\" , ) last_id : Optional [ str ] = StrictField ( None , description = \"a string containing the last ID returned\" ) response_message : Optional [ str ] = StrictField ( None , description = \"response string from the server\" ) implementation : Optional [ Implementation ] = StrictField ( None , description = \"a dictionary describing the server implementation\" ) warnings : Optional [ List [ Warnings ]] = StrictField ( None , description = \"\"\"A list of warning resource objects representing non-critical errors or warnings. A warning resource object is defined similarly to a [JSON API error object](http://jsonapi.org/format/1.0/#error-objects), but MUST also include the field `type`, which MUST have the value `\"warning\"`. The field `detail` MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. The field `status`, representing a HTTP response status code, MUST NOT be present for a warning resource object. This is an exclusive field for error resource objects.\"\"\" , uniqueItems = True , )","title":"ResponseMeta"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.api_version","text":"","title":"api_version"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.data_available","text":"","title":"data_available"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.data_returned","text":"","title":"data_returned"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.implementation","text":"","title":"implementation"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.last_id","text":"","title":"last_id"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.more_data_available","text":"","title":"more_data_available"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.optimade_schema","text":"","title":"optimade_schema"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.provider","text":"","title":"provider"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.query","text":"","title":"query"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.response_message","text":"","title":"response_message"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.time_stamp","text":"","title":"time_stamp"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMeta.warnings","text":"","title":"warnings"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMetaQuery","text":"Information on the query that was requested. Source code in optimade/models/optimade_json.py 181 182 183 184 185 186 187 188 189 190 class ResponseMetaQuery ( BaseModel ): \"\"\"Information on the query that was requested.\"\"\" representation : str = StrictField ( ... , description = \"\"\"A string with the part of the URL following the versioned or unversioned base URL that serves the API. Query parameters that have not been used in processing the request MAY be omitted. In particular, if no query parameters have been involved in processing the request, the query part of the URL MAY be excluded. Example: `/structures?filter=nelements=2`\"\"\" , )","title":"ResponseMetaQuery"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.ResponseMetaQuery.representation","text":"","title":"representation"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Success","text":"errors are not allowed Source code in optimade/models/optimade_json.py 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 class Success ( jsonapi . Response ): \"\"\"errors are not allowed\"\"\" meta : ResponseMeta = StrictField ( ... , description = \"A meta object containing non-standard information\" ) @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): \"\"\"Overwriting the existing validation function, since 'errors' MUST NOT be set.\"\"\" required_fields = ( \"data\" , \"meta\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response.\" ) # errors MUST be skipped if \"errors\" in values : raise ValueError ( \"'errors' MUST be skipped for a successful response.\" ) return values","title":"Success"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Success.meta","text":"","title":"meta"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Success.either_data_meta_or_errors_must_be_set","text":"Overwriting the existing validation function, since 'errors' MUST NOT be set. Source code in optimade/models/optimade_json.py 340 341 342 343 344 345 346 347 348 349 350 351 352 353 @root_validator ( pre = True ) def either_data_meta_or_errors_must_be_set ( cls , values ): \"\"\"Overwriting the existing validation function, since 'errors' MUST NOT be set.\"\"\" required_fields = ( \"data\" , \"meta\" ) if not any ( field in values for field in required_fields ): raise ValueError ( f \"At least one of { required_fields } MUST be specified in the top-level response.\" ) # errors MUST be skipped if \"errors\" in values : raise ValueError ( \"'errors' MUST be skipped for a successful response.\" ) return values","title":"either_data_meta_or_errors_must_be_set()"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Warnings","text":"OPTIMADE-specific warning class based on OPTIMADE-specific JSON API Error. From the specification: A warning resource object is defined similarly to a JSON API error object, but MUST also include the field type, which MUST have the value \"warning\". The field detail MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. Note: Must be named \"Warnings\", since \"Warning\" is a built-in Python class. Source code in optimade/models/optimade_json.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 class Warnings ( OptimadeError ): \"\"\"OPTIMADE-specific warning class based on OPTIMADE-specific JSON API Error. From the specification: A warning resource object is defined similarly to a JSON API error object, but MUST also include the field type, which MUST have the value \"warning\". The field detail MUST be present and SHOULD contain a non-critical message, e.g., reporting unrecognized search attributes or deprecated features. Note: Must be named \"Warnings\", since \"Warning\" is a built-in Python class. \"\"\" type : str = StrictField ( \"warning\" , description = 'Warnings must be of type \"warning\"' , regex = \"^warning$\" , ) @root_validator ( pre = True ) def status_must_not_be_specified ( cls , values ): if values . get ( \"status\" , None ) is not None : raise ValueError ( \"status MUST NOT be specified for warnings\" ) return values class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"Warnings\" ]) -> None : \"\"\"Update OpenAPI JSON schema model for `Warning`. * Ensure `type` is in the list required properties and in the correct place. * Remove `status` property. This property is not allowed for `Warning`, nor is it a part of the OPTIMADE definition of the `Warning` object. Note: Since `type` is the _last_ model field defined, it will simply be appended. \"\"\" if \"required\" in schema : if \"type\" not in schema [ \"required\" ]: schema [ \"required\" ] . append ( \"type\" ) else : schema [ \"required\" ] = [ \"type\" ] schema . get ( \"properties\" , {}) . pop ( \"status\" , None )","title":"Warnings"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Warnings.type","text":"","title":"type"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Warnings.Config","text":"Source code in optimade/models/optimade_json.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"Warnings\" ]) -> None : \"\"\"Update OpenAPI JSON schema model for `Warning`. * Ensure `type` is in the list required properties and in the correct place. * Remove `status` property. This property is not allowed for `Warning`, nor is it a part of the OPTIMADE definition of the `Warning` object. Note: Since `type` is the _last_ model field defined, it will simply be appended. \"\"\" if \"required\" in schema : if \"type\" not in schema [ \"required\" ]: schema [ \"required\" ] . append ( \"type\" ) else : schema [ \"required\" ] = [ \"type\" ] schema . get ( \"properties\" , {}) . pop ( \"status\" , None )","title":"Config"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Warnings.Config.schema_extra","text":"Update OpenAPI JSON schema model for Warning . Ensure type is in the list required properties and in the correct place. Remove status property. This property is not allowed for Warning , nor is it a part of the OPTIMADE definition of the Warning object. Note Since type is the last model field defined, it will simply be appended. Source code in optimade/models/optimade_json.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 @staticmethod def schema_extra ( schema : Dict [ str , Any ], model : Type [ \"Warnings\" ]) -> None : \"\"\"Update OpenAPI JSON schema model for `Warning`. * Ensure `type` is in the list required properties and in the correct place. * Remove `status` property. This property is not allowed for `Warning`, nor is it a part of the OPTIMADE definition of the `Warning` object. Note: Since `type` is the _last_ model field defined, it will simply be appended. \"\"\" if \"required\" in schema : if \"type\" not in schema [ \"required\" ]: schema [ \"required\" ] . append ( \"type\" ) else : schema [ \"required\" ] = [ \"type\" ] schema . get ( \"properties\" , {}) . pop ( \"status\" , None )","title":"schema_extra()"},{"location":"api_reference/models/optimade_json/#optimade.models.optimade_json.Warnings.status_must_not_be_specified","text":"Source code in optimade/models/optimade_json.py 153 154 155 156 157 @root_validator ( pre = True ) def status_must_not_be_specified ( cls , values ): if values . get ( \"status\" , None ) is not None : raise ValueError ( \"status MUST NOT be specified for warnings\" ) return values","title":"status_must_not_be_specified()"},{"location":"api_reference/models/references/","text":"references \u00b6 Person \u00b6 A person, i.e., an author, editor or other. Source code in optimade/models/references.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class Person ( BaseModel ): \"\"\"A person, i.e., an author, editor or other.\"\"\" name : str = OptimadeField ( ... , description = \"\"\"Full name of the person, REQUIRED.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) firstname : Optional [ str ] = OptimadeField ( None , description = \"\"\"First name of the person.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) lastname : Optional [ str ] = OptimadeField ( None , description = \"\"\"Last name of the person.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) firstname : Optional [ str ] = OptimadeField ( None , description = 'First name of the person.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 lastname : Optional [ str ] = OptimadeField ( None , description = 'Last name of the person.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 name : str = OptimadeField ( Ellipsis , description = 'Full name of the person, REQUIRED.' , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 ReferenceResource \u00b6 The references entries describe bibliographic references. The following properties are used to provide the bibliographic details: address , annote , booktitle , chapter , crossref , edition , howpublished , institution , journal , key , month , note , number , organization , pages , publisher , school , series , title , volume , year : meanings of these properties match the BibTeX specification , values are strings; bib_type : type of the reference, corresponding to type property in the BibTeX specification, value is string; authors and editors : lists of person objects which are dictionaries with the following keys: name : Full name of the person, REQUIRED. firstname , lastname : Parts of the person's name, OPTIONAL. doi and url : values are strings. Requirements/Conventions : Support : OPTIONAL support in implementations, i.e., any of the properties MAY be null . Query : Support for queries on any of these properties is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. Every references entry MUST contain at least one of the properties. Source code in optimade/models/references.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 class ReferenceResource ( EntryResource ): \"\"\"The `references` entries describe bibliographic references. The following properties are used to provide the bibliographic details: - **address**, **annote**, **booktitle**, **chapter**, **crossref**, **edition**, **howpublished**, **institution**, **journal**, **key**, **month**, **note**, **number**, **organization**, **pages**, **publisher**, **school**, **series**, **title**, **volume**, **year**: meanings of these properties match the [BibTeX specification](http://bibtexml.sourceforge.net/btxdoc.pdf), values are strings; - **bib_type**: type of the reference, corresponding to **type** property in the BibTeX specification, value is string; - **authors** and **editors**: lists of *person objects* which are dictionaries with the following keys: - **name**: Full name of the person, REQUIRED. - **firstname**, **lastname**: Parts of the person's name, OPTIONAL. - **doi** and **url**: values are strings. - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., any of the properties MAY be `null`. - **Query**: Support for queries on any of these properties is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - Every references entry MUST contain at least one of the properties. \"\"\" type : str = OptimadeField ( \"references\" , description = \"\"\"The name of the type of an entry. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - MUST be an existing entry type. - The entry of type <type> and ID <id> MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. - **Example**: `\"structures\"`\"\"\" , regex = \"^references$\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) attributes : ReferenceResourceAttributes @validator ( \"attributes\" ) def validate_attributes ( cls , v ): if not any ( prop [ 1 ] is not None for prop in v ): raise ValueError ( \"reference object must have at least one field defined\" ) return v attributes : ReferenceResourceAttributes class-attribute \u00b6 type : str = OptimadeField ( 'references' , description = 'The name of the type of an entry. \\n - **Type**: string. \\n - **Requirements/Conventions**: \\n - **Support**: MUST be supported by all implementations, MUST NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - **Response**: REQUIRED in the response. \\n - MUST be an existing entry type. \\n - The entry of type <type> and ID <id> MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. \\n - **Example**: `\"structures\"`' , regex = '^references$' , support = SupportLevel . MUST , queryable = SupportLevel . MUST ) class-attribute \u00b6 validate_attributes ( v ) \u00b6 Source code in optimade/models/references.py 268 269 270 271 272 @validator ( \"attributes\" ) def validate_attributes ( cls , v ): if not any ( prop [ 1 ] is not None for prop in v ): raise ValueError ( \"reference object must have at least one field defined\" ) return v ReferenceResourceAttributes \u00b6 Model that stores the attributes of a reference. Many properties match the meaning described in the BibTeX specification . Source code in optimade/models/references.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 class ReferenceResourceAttributes ( EntryResourceAttributes ): \"\"\"Model that stores the attributes of a reference. Many properties match the meaning described in the [BibTeX specification](http://bibtexml.sourceforge.net/btxdoc.pdf). \"\"\" authors : Optional [ List [ Person ]] = OptimadeField ( None , description = \"List of person objects containing the authors of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) editors : Optional [ List [ Person ]] = OptimadeField ( None , description = \"List of person objects containing the editors of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) doi : Optional [ str ] = OptimadeField ( None , description = \"The digital object identifier of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) url : Optional [ AnyUrl ] = OptimadeField ( None , description = \"The URL of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) address : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) annote : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) booktitle : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) chapter : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) crossref : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) edition : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) howpublished : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) institution : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) journal : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) key : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) month : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) note : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) number : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) organization : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) pages : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) publisher : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) school : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) series : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) title : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) bib_type : Optional [ str ] = OptimadeField ( None , description = \"Type of the reference, corresponding to the **type** property in the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) volume : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) year : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) address : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 annote : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 authors : Optional [ List [ Person ]] = OptimadeField ( None , description = 'List of person objects containing the authors of the reference.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 bib_type : Optional [ str ] = OptimadeField ( None , description = 'Type of the reference, corresponding to the **type** property in the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 booktitle : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 chapter : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 crossref : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 doi : Optional [ str ] = OptimadeField ( None , description = 'The digital object identifier of the reference.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 edition : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 editors : Optional [ List [ Person ]] = OptimadeField ( None , description = 'List of person objects containing the editors of the reference.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 howpublished : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 institution : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 journal : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 key : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 month : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 note : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 number : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 organization : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 pages : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 publisher : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 school : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 series : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 title : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 url : Optional [ AnyUrl ] = OptimadeField ( None , description = 'The URL of the reference.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 volume : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 year : Optional [ str ] = OptimadeField ( None , description = 'Meaning of property matches the BiBTeX specification.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6","title":"references"},{"location":"api_reference/models/references/#references","text":"","title":"references"},{"location":"api_reference/models/references/#optimade.models.references.Person","text":"A person, i.e., an author, editor or other. Source code in optimade/models/references.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class Person ( BaseModel ): \"\"\"A person, i.e., an author, editor or other.\"\"\" name : str = OptimadeField ( ... , description = \"\"\"Full name of the person, REQUIRED.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) firstname : Optional [ str ] = OptimadeField ( None , description = \"\"\"First name of the person.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) lastname : Optional [ str ] = OptimadeField ( None , description = \"\"\"Last name of the person.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , )","title":"Person"},{"location":"api_reference/models/references/#optimade.models.references.Person.firstname","text":"","title":"firstname"},{"location":"api_reference/models/references/#optimade.models.references.Person.lastname","text":"","title":"lastname"},{"location":"api_reference/models/references/#optimade.models.references.Person.name","text":"","title":"name"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResource","text":"The references entries describe bibliographic references. The following properties are used to provide the bibliographic details: address , annote , booktitle , chapter , crossref , edition , howpublished , institution , journal , key , month , note , number , organization , pages , publisher , school , series , title , volume , year : meanings of these properties match the BibTeX specification , values are strings; bib_type : type of the reference, corresponding to type property in the BibTeX specification, value is string; authors and editors : lists of person objects which are dictionaries with the following keys: name : Full name of the person, REQUIRED. firstname , lastname : Parts of the person's name, OPTIONAL. doi and url : values are strings. Requirements/Conventions : Support : OPTIONAL support in implementations, i.e., any of the properties MAY be null . Query : Support for queries on any of these properties is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. Every references entry MUST contain at least one of the properties. Source code in optimade/models/references.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 class ReferenceResource ( EntryResource ): \"\"\"The `references` entries describe bibliographic references. The following properties are used to provide the bibliographic details: - **address**, **annote**, **booktitle**, **chapter**, **crossref**, **edition**, **howpublished**, **institution**, **journal**, **key**, **month**, **note**, **number**, **organization**, **pages**, **publisher**, **school**, **series**, **title**, **volume**, **year**: meanings of these properties match the [BibTeX specification](http://bibtexml.sourceforge.net/btxdoc.pdf), values are strings; - **bib_type**: type of the reference, corresponding to **type** property in the BibTeX specification, value is string; - **authors** and **editors**: lists of *person objects* which are dictionaries with the following keys: - **name**: Full name of the person, REQUIRED. - **firstname**, **lastname**: Parts of the person's name, OPTIONAL. - **doi** and **url**: values are strings. - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., any of the properties MAY be `null`. - **Query**: Support for queries on any of these properties is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - Every references entry MUST contain at least one of the properties. \"\"\" type : str = OptimadeField ( \"references\" , description = \"\"\"The name of the type of an entry. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - MUST be an existing entry type. - The entry of type <type> and ID <id> MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. - **Example**: `\"structures\"`\"\"\" , regex = \"^references$\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) attributes : ReferenceResourceAttributes @validator ( \"attributes\" ) def validate_attributes ( cls , v ): if not any ( prop [ 1 ] is not None for prop in v ): raise ValueError ( \"reference object must have at least one field defined\" ) return v","title":"ReferenceResource"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResource.type","text":"","title":"type"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResource.validate_attributes","text":"Source code in optimade/models/references.py 268 269 270 271 272 @validator ( \"attributes\" ) def validate_attributes ( cls , v ): if not any ( prop [ 1 ] is not None for prop in v ): raise ValueError ( \"reference object must have at least one field defined\" ) return v","title":"validate_attributes()"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes","text":"Model that stores the attributes of a reference. Many properties match the meaning described in the BibTeX specification . Source code in optimade/models/references.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 class ReferenceResourceAttributes ( EntryResourceAttributes ): \"\"\"Model that stores the attributes of a reference. Many properties match the meaning described in the [BibTeX specification](http://bibtexml.sourceforge.net/btxdoc.pdf). \"\"\" authors : Optional [ List [ Person ]] = OptimadeField ( None , description = \"List of person objects containing the authors of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) editors : Optional [ List [ Person ]] = OptimadeField ( None , description = \"List of person objects containing the editors of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) doi : Optional [ str ] = OptimadeField ( None , description = \"The digital object identifier of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) url : Optional [ AnyUrl ] = OptimadeField ( None , description = \"The URL of the reference.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) address : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) annote : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) booktitle : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) chapter : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) crossref : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) edition : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) howpublished : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) institution : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) journal : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) key : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) month : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) note : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) number : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) organization : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) pages : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) publisher : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) school : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) series : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) title : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) bib_type : Optional [ str ] = OptimadeField ( None , description = \"Type of the reference, corresponding to the **type** property in the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) volume : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) year : Optional [ str ] = OptimadeField ( None , description = \"Meaning of property matches the BiBTeX specification.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , )","title":"ReferenceResourceAttributes"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.address","text":"","title":"address"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.annote","text":"","title":"annote"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.authors","text":"","title":"authors"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.bib_type","text":"","title":"bib_type"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.booktitle","text":"","title":"booktitle"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.chapter","text":"","title":"chapter"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.crossref","text":"","title":"crossref"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.doi","text":"","title":"doi"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.edition","text":"","title":"edition"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.editors","text":"","title":"editors"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.howpublished","text":"","title":"howpublished"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.institution","text":"","title":"institution"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.journal","text":"","title":"journal"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.key","text":"","title":"key"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.month","text":"","title":"month"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.note","text":"","title":"note"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.number","text":"","title":"number"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.organization","text":"","title":"organization"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.pages","text":"","title":"pages"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.publisher","text":"","title":"publisher"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.school","text":"","title":"school"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.series","text":"","title":"series"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.title","text":"","title":"title"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.url","text":"","title":"url"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.volume","text":"","title":"volume"},{"location":"api_reference/models/references/#optimade.models.references.ReferenceResourceAttributes.year","text":"","title":"year"},{"location":"api_reference/models/responses/","text":"responses \u00b6 EntryInfoResponse \u00b6 Source code in optimade/models/responses.py 57 58 59 60 class EntryInfoResponse ( Success ): data : EntryInfoResource = StrictField ( ... , description = \"OPTIMADE information for an entry endpoint.\" ) data : EntryInfoResource = StrictField ( Ellipsis , description = 'OPTIMADE information for an entry endpoint.' ) class-attribute \u00b6 EntryResponseMany \u00b6 Source code in optimade/models/responses.py 76 77 78 79 80 81 82 class EntryResponseMany ( Success ): data : Union [ List [ EntryResource ], List [ Dict [ str , Any ]]] = Field ( ... , uniqueItems = True ) included : Optional [ Union [ List [ EntryResource ], List [ Dict [ str , Any ]]]] = Field ( None , uniqueItems = True ) data : Union [ List [ EntryResource ], List [ Dict [ str , Any ]]] = Field ( Ellipsis , uniqueItems = True ) class-attribute \u00b6 included : Optional [ Union [ List [ EntryResource ], List [ Dict [ str , Any ]]]] = Field ( None , uniqueItems = True ) class-attribute \u00b6 EntryResponseOne \u00b6 Source code in optimade/models/responses.py 69 70 71 72 73 class EntryResponseOne ( Success ): data : Union [ EntryResource , Dict [ str , Any ], None ] = Field ( ... ) included : Optional [ Union [ List [ EntryResource ], List [ Dict [ str , Any ]]]] = Field ( None , uniqueItems = True ) data : Union [ EntryResource , Dict [ str , Any ], None ] = Field ( Ellipsis ) class-attribute \u00b6 included : Optional [ Union [ List [ EntryResource ], List [ Dict [ str , Any ]]]] = Field ( None , uniqueItems = True ) class-attribute \u00b6 ErrorResponse \u00b6 errors MUST be present and data MUST be skipped Source code in optimade/models/responses.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class ErrorResponse ( Response ): \"\"\"errors MUST be present and data MUST be skipped\"\"\" meta : ResponseMeta = StrictField ( ... , description = \"A meta object containing non-standard information.\" ) errors : List [ OptimadeError ] = StrictField ( ... , description = \"A list of OPTIMADE-specific JSON API error objects, where the field detail MUST be present.\" , uniqueItems = True , ) @root_validator ( pre = True ) def data_must_be_skipped ( cls , values ): if \"data\" in values : raise ValueError ( \"data MUST be skipped for failures reporting errors.\" ) return values errors : List [ OptimadeError ] = StrictField ( Ellipsis , description = 'A list of OPTIMADE-specific JSON API error objects, where the field detail MUST be present.' , uniqueItems = True ) class-attribute \u00b6 meta : ResponseMeta = StrictField ( Ellipsis , description = 'A meta object containing non-standard information.' ) class-attribute \u00b6 data_must_be_skipped ( values ) \u00b6 Source code in optimade/models/responses.py 44 45 46 47 48 @root_validator ( pre = True ) def data_must_be_skipped ( cls , values ): if \"data\" in values : raise ValueError ( \"data MUST be skipped for failures reporting errors.\" ) return values IndexInfoResponse \u00b6 Source code in optimade/models/responses.py 51 52 53 54 class IndexInfoResponse ( Success ): data : IndexInfoResource = StrictField ( ... , description = \"Index meta-database /info data.\" ) data : IndexInfoResource = StrictField ( Ellipsis , description = 'Index meta-database /info data.' ) class-attribute \u00b6 InfoResponse \u00b6 Source code in optimade/models/responses.py 63 64 65 66 class InfoResponse ( Success ): data : BaseInfoResource = StrictField ( ... , description = \"The implementations /info data.\" ) data : BaseInfoResource = StrictField ( Ellipsis , description = 'The implementations /info data.' ) class-attribute \u00b6 LinksResponse \u00b6 Source code in optimade/models/responses.py 85 86 87 88 89 90 class LinksResponse ( EntryResponseMany ): data : Union [ List [ LinksResource ], List [ Dict [ str , Any ]]] = StrictField ( ... , description = \"List of unique OPTIMADE links resource objects.\" , uniqueItems = True , ) data : Union [ List [ LinksResource ], List [ Dict [ str , Any ]]] = StrictField ( Ellipsis , description = 'List of unique OPTIMADE links resource objects.' , uniqueItems = True ) class-attribute \u00b6 ReferenceResponseMany \u00b6 Source code in optimade/models/responses.py 113 114 115 116 117 118 class ReferenceResponseMany ( EntryResponseMany ): data : Union [ List [ ReferenceResource ], List [ Dict [ str , Any ]]] = StrictField ( ... , description = \"List of unique OPTIMADE references entry resource objects.\" , uniqueItems = True , ) data : Union [ List [ ReferenceResource ], List [ Dict [ str , Any ]]] = StrictField ( Ellipsis , description = 'List of unique OPTIMADE references entry resource objects.' , uniqueItems = True ) class-attribute \u00b6 ReferenceResponseOne \u00b6 Source code in optimade/models/responses.py 107 108 109 110 class ReferenceResponseOne ( EntryResponseOne ): data : Union [ ReferenceResource , Dict [ str , Any ], None ] = StrictField ( ... , description = \"A single references entry resource.\" ) data : Union [ ReferenceResource , Dict [ str , Any ], None ] = StrictField ( Ellipsis , description = 'A single references entry resource.' ) class-attribute \u00b6 StructureResponseMany \u00b6 Source code in optimade/models/responses.py 99 100 101 102 103 104 class StructureResponseMany ( EntryResponseMany ): data : Union [ List [ StructureResource ], List [ Dict [ str , Any ]]] = StrictField ( ... , description = \"List of unique OPTIMADE structures entry resource objects.\" , uniqueItems = True , ) data : Union [ List [ StructureResource ], List [ Dict [ str , Any ]]] = StrictField ( Ellipsis , description = 'List of unique OPTIMADE structures entry resource objects.' , uniqueItems = True ) class-attribute \u00b6 StructureResponseOne \u00b6 Source code in optimade/models/responses.py 93 94 95 96 class StructureResponseOne ( EntryResponseOne ): data : Union [ StructureResource , Dict [ str , Any ], None ] = StrictField ( ... , description = \"A single structures entry resource.\" ) data : Union [ StructureResource , Dict [ str , Any ], None ] = StrictField ( Ellipsis , description = 'A single structures entry resource.' ) class-attribute \u00b6","title":"responses"},{"location":"api_reference/models/responses/#responses","text":"","title":"responses"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryInfoResponse","text":"Source code in optimade/models/responses.py 57 58 59 60 class EntryInfoResponse ( Success ): data : EntryInfoResource = StrictField ( ... , description = \"OPTIMADE information for an entry endpoint.\" )","title":"EntryInfoResponse"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryInfoResponse.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryResponseMany","text":"Source code in optimade/models/responses.py 76 77 78 79 80 81 82 class EntryResponseMany ( Success ): data : Union [ List [ EntryResource ], List [ Dict [ str , Any ]]] = Field ( ... , uniqueItems = True ) included : Optional [ Union [ List [ EntryResource ], List [ Dict [ str , Any ]]]] = Field ( None , uniqueItems = True )","title":"EntryResponseMany"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryResponseMany.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryResponseMany.included","text":"","title":"included"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryResponseOne","text":"Source code in optimade/models/responses.py 69 70 71 72 73 class EntryResponseOne ( Success ): data : Union [ EntryResource , Dict [ str , Any ], None ] = Field ( ... ) included : Optional [ Union [ List [ EntryResource ], List [ Dict [ str , Any ]]]] = Field ( None , uniqueItems = True )","title":"EntryResponseOne"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryResponseOne.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.EntryResponseOne.included","text":"","title":"included"},{"location":"api_reference/models/responses/#optimade.models.responses.ErrorResponse","text":"errors MUST be present and data MUST be skipped Source code in optimade/models/responses.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class ErrorResponse ( Response ): \"\"\"errors MUST be present and data MUST be skipped\"\"\" meta : ResponseMeta = StrictField ( ... , description = \"A meta object containing non-standard information.\" ) errors : List [ OptimadeError ] = StrictField ( ... , description = \"A list of OPTIMADE-specific JSON API error objects, where the field detail MUST be present.\" , uniqueItems = True , ) @root_validator ( pre = True ) def data_must_be_skipped ( cls , values ): if \"data\" in values : raise ValueError ( \"data MUST be skipped for failures reporting errors.\" ) return values","title":"ErrorResponse"},{"location":"api_reference/models/responses/#optimade.models.responses.ErrorResponse.errors","text":"","title":"errors"},{"location":"api_reference/models/responses/#optimade.models.responses.ErrorResponse.meta","text":"","title":"meta"},{"location":"api_reference/models/responses/#optimade.models.responses.ErrorResponse.data_must_be_skipped","text":"Source code in optimade/models/responses.py 44 45 46 47 48 @root_validator ( pre = True ) def data_must_be_skipped ( cls , values ): if \"data\" in values : raise ValueError ( \"data MUST be skipped for failures reporting errors.\" ) return values","title":"data_must_be_skipped()"},{"location":"api_reference/models/responses/#optimade.models.responses.IndexInfoResponse","text":"Source code in optimade/models/responses.py 51 52 53 54 class IndexInfoResponse ( Success ): data : IndexInfoResource = StrictField ( ... , description = \"Index meta-database /info data.\" )","title":"IndexInfoResponse"},{"location":"api_reference/models/responses/#optimade.models.responses.IndexInfoResponse.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.InfoResponse","text":"Source code in optimade/models/responses.py 63 64 65 66 class InfoResponse ( Success ): data : BaseInfoResource = StrictField ( ... , description = \"The implementations /info data.\" )","title":"InfoResponse"},{"location":"api_reference/models/responses/#optimade.models.responses.InfoResponse.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.LinksResponse","text":"Source code in optimade/models/responses.py 85 86 87 88 89 90 class LinksResponse ( EntryResponseMany ): data : Union [ List [ LinksResource ], List [ Dict [ str , Any ]]] = StrictField ( ... , description = \"List of unique OPTIMADE links resource objects.\" , uniqueItems = True , )","title":"LinksResponse"},{"location":"api_reference/models/responses/#optimade.models.responses.LinksResponse.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.ReferenceResponseMany","text":"Source code in optimade/models/responses.py 113 114 115 116 117 118 class ReferenceResponseMany ( EntryResponseMany ): data : Union [ List [ ReferenceResource ], List [ Dict [ str , Any ]]] = StrictField ( ... , description = \"List of unique OPTIMADE references entry resource objects.\" , uniqueItems = True , )","title":"ReferenceResponseMany"},{"location":"api_reference/models/responses/#optimade.models.responses.ReferenceResponseMany.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.ReferenceResponseOne","text":"Source code in optimade/models/responses.py 107 108 109 110 class ReferenceResponseOne ( EntryResponseOne ): data : Union [ ReferenceResource , Dict [ str , Any ], None ] = StrictField ( ... , description = \"A single references entry resource.\" )","title":"ReferenceResponseOne"},{"location":"api_reference/models/responses/#optimade.models.responses.ReferenceResponseOne.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.StructureResponseMany","text":"Source code in optimade/models/responses.py 99 100 101 102 103 104 class StructureResponseMany ( EntryResponseMany ): data : Union [ List [ StructureResource ], List [ Dict [ str , Any ]]] = StrictField ( ... , description = \"List of unique OPTIMADE structures entry resource objects.\" , uniqueItems = True , )","title":"StructureResponseMany"},{"location":"api_reference/models/responses/#optimade.models.responses.StructureResponseMany.data","text":"","title":"data"},{"location":"api_reference/models/responses/#optimade.models.responses.StructureResponseOne","text":"Source code in optimade/models/responses.py 93 94 95 96 class StructureResponseOne ( EntryResponseOne ): data : Union [ StructureResource , Dict [ str , Any ], None ] = StrictField ( ... , description = \"A single structures entry resource.\" )","title":"StructureResponseOne"},{"location":"api_reference/models/responses/#optimade.models.responses.StructureResponseOne.data","text":"","title":"data"},{"location":"api_reference/models/structures/","text":"structures \u00b6 CORRELATED_STRUCTURE_FIELDS = ({ 'dimension_types' , 'nperiodic_dimensions' }, { 'cartesian_site_positions' , 'species_at_sites' }, { 'nsites' , 'cartesian_site_positions' }, { 'species_at_sites' , 'species' }) module-attribute \u00b6 EPS = 2 ** - 23 module-attribute \u00b6 EXTENDED_CHEMICAL_SYMBOLS = set ( CHEMICAL_SYMBOLS + EXTRA_SYMBOLS ) module-attribute \u00b6 Vector3D = conlist ( float , min_items = 3 , max_items = 3 ) module-attribute \u00b6 Vector3D_unknown = conlist ( Union [ float , None ], min_items = 3 , max_items = 3 ) module-attribute \u00b6 Assembly \u00b6 A description of groups of sites that are statistically correlated. Examples (for each entry of the assemblies list): {\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]} : the first site and the second site never occur at the same time in the unit cell. Statistically, 30 % of the times the first site is present, while 70 % of the times the second site is present. {\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]} : the second and third site are either present together or not present; they form the first group of atoms for this assembly. The second group is formed by the fourth site. Sites of the first group (the second and the third) are never present at the same time as the fourth site. 30 % of times sites 1 and 2 are present (and site 3 is absent); 70 % of times site 3 is present (and sites 1 and 2 are absent). Source code in optimade/models/structures.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 class Assembly ( BaseModel ): \"\"\"A description of groups of sites that are statistically correlated. - **Examples** (for each entry of the assemblies list): - `{\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]}`: the first site and the second site never occur at the same time in the unit cell. Statistically, 30 % of the times the first site is present, while 70 % of the times the second site is present. - `{\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]}`: the second and third site are either present together or not present; they form the first group of atoms for this assembly. The second group is formed by the fourth site. Sites of the first group (the second and the third) are never present at the same time as the fourth site. 30 % of times sites 1 and 2 are present (and site 3 is absent); 70 % of times site 3 is present (and sites 1 and 2 are absent). \"\"\" sites_in_groups : List [ List [ int ]] = OptimadeField ( ... , description = \"\"\"Index of the sites (0-based) that belong to each group for each assembly. - **Examples**: - `[[1], [2]]`: two groups, one with the second site, one with the third. - `[[1,2], [3]]`: one group with the second and third site, one with the fourth.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) group_probabilities : List [ float ] = OptimadeField ( ... , description = \"\"\"Statistical probability of each group. It MUST have the same length as `sites_in_groups`. It SHOULD sum to one. See below for examples of how to specify the probability of the occurrence of a vacancy. The possible reasons for the values not to sum to one are the same as already specified above for the `concentration` of each `species`.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) @validator ( \"sites_in_groups\" ) def validate_sites_in_groups ( cls , v ): sites = [] for group in v : sites . extend ( group ) if len ( set ( sites )) != len ( sites ): raise ValueError ( f \"A site MUST NOT appear in more than one group. Given value: { v } \" ) return v @validator ( \"group_probabilities\" ) def check_self_consistency ( cls , v , values ): if len ( v ) != len ( values . get ( \"sites_in_groups\" , [])): raise ValueError ( f \"sites_in_groups and group_probabilities MUST be of same length, \" f \"but are { len ( values . get ( 'sites_in_groups' , [])) } and { len ( v ) } , respectively\" ) return v group_probabilities : List [ float ] = OptimadeField ( Ellipsis , description = 'Statistical probability of each group. It MUST have the same length as `sites_in_groups`. \\n It SHOULD sum to one. \\n See below for examples of how to specify the probability of the occurrence of a vacancy. \\n The possible reasons for the values not to sum to one are the same as already specified above for the `concentration` of each `species`.' , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 sites_in_groups : List [ List [ int ]] = OptimadeField ( Ellipsis , description = 'Index of the sites (0-based) that belong to each group for each assembly. \\n\\n - **Examples**: \\n - `[[1], [2]]`: two groups, one with the second site, one with the third. \\n - `[[1,2], [3]]`: one group with the second and third site, one with the fourth.' , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 check_self_consistency ( v , values ) \u00b6 Source code in optimade/models/structures.py 247 248 249 250 251 252 253 254 @validator ( \"group_probabilities\" ) def check_self_consistency ( cls , v , values ): if len ( v ) != len ( values . get ( \"sites_in_groups\" , [])): raise ValueError ( f \"sites_in_groups and group_probabilities MUST be of same length, \" f \"but are { len ( values . get ( 'sites_in_groups' , [])) } and { len ( v ) } , respectively\" ) return v validate_sites_in_groups ( v ) \u00b6 Source code in optimade/models/structures.py 236 237 238 239 240 241 242 243 244 245 @validator ( \"sites_in_groups\" ) def validate_sites_in_groups ( cls , v ): sites = [] for group in v : sites . extend ( group ) if len ( set ( sites )) != len ( sites ): raise ValueError ( f \"A site MUST NOT appear in more than one group. Given value: { v } \" ) return v Periodicity \u00b6 Integer enumeration of dimension_types values Source code in optimade/models/structures.py 46 47 48 49 50 class Periodicity ( IntEnum ): \"\"\"Integer enumeration of dimension_types values\"\"\" APERIODIC = 0 PERIODIC = 1 APERIODIC = 0 class-attribute \u00b6 PERIODIC = 1 class-attribute \u00b6 Species \u00b6 A list describing the species of the sites of this structure. Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). Examples : [ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ] : any site with this species is occupied by a Ti atom. [ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ] : any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. [ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ] : any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. [ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ] : any site with this species is occupied by a carbon isotope with mass 12. [ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ] : any site with this species is occupied by a carbon isotope with mass 13. [ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ] : any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms. Source code in optimade/models/structures.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 class Species ( BaseModel ): \"\"\"A list describing the species of the sites of this structure. Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). - **Examples**: - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ]`: any site with this species is occupied by a Ti atom. - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ]`: any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. - `[ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ]`: any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. - `[ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ]`: any site with this species is occupied by a carbon isotope with mass 12. - `[ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ]`: any site with this species is occupied by a carbon isotope with mass 13. - `[ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ]`: any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms. \"\"\" name : str = OptimadeField ( ... , description = \"\"\"Gives the name of the species; the **name** value MUST be unique in the `species` list.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) chemical_symbols : List [ str ] = OptimadeField ( ... , description = \"\"\"MUST be a list of strings of all chemical elements composing this species. Each item of the list MUST be one of the following: - a valid chemical-element symbol, or - the special value `\"X\"` to represent a non-chemical element, or - the special value `\"vacancy\"` to represent that this site has a non-zero probability of having a vacancy (the respective probability is indicated in the `concentration` list, see below). If any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element, the correct flag MUST be set in the list `structure_features`.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) concentration : List [ float ] = OptimadeField ( ... , description = \"\"\"MUST be a list of floats, with same length as `chemical_symbols`. The numbers represent the relative concentration of the corresponding chemical symbol in this species. The numbers SHOULD sum to one. Cases in which the numbers do not sum to one typically fall only in the following two categories: - Numerical errors when representing float numbers in fixed precision, e.g. for two chemical symbols with concentrations `1/3` and `2/3`, the concentration might look something like `[0.33333333333, 0.66666666666]`. If the client is aware that the sum is not one because of numerical precision, it can renormalize the values so that the sum is exactly one. - Experimental errors in the data present in the database. In this case, it is the responsibility of the client to decide how to process the data. Note that concentrations are uncorrelated between different site (even of the same species).\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) mass : Optional [ List [ float ]] = OptimadeField ( None , description = \"\"\"If present MUST be a list of floats expressed in a.m.u. Elements denoting vacancies MUST have masses equal to 0.\"\"\" , unit = \"a.m.u.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) original_name : Optional [ str ] = OptimadeField ( None , description = \"\"\"Can be any valid Unicode string, and SHOULD contain (if specified) the name of the species that is used internally in the source database. Note: With regards to \"source database\", we refer to the immediate source being queried via the OPTIMADE API implementation.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) attached : Optional [ List [ str ]] = OptimadeField ( None , description = \"\"\"If provided MUST be a list of length 1 or more of strings of chemical symbols for the elements attached to this site, or \"X\" for a non-chemical element.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) nattached : Optional [ List [ int ]] = OptimadeField ( None , description = \"\"\"If provided MUST be a list of length 1 or more of integers indicating the number of attached atoms of the kind specified in the value of the :field:`attached` key.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) @validator ( \"chemical_symbols\" , each_item = True ) def validate_chemical_symbols ( cls , v ): if v not in EXTENDED_CHEMICAL_SYMBOLS : raise ValueError ( f ' { v !r} MUST be an element symbol, e.g., \"C\", \"He\", or a special symbol from { EXTRA_SYMBOLS } .' ) return v @validator ( \"concentration\" , \"mass\" ) def validate_concentration_and_mass ( cls , v , values , field ): if not v : return v if values . get ( \"chemical_symbols\" ): if len ( v ) != len ( values [ \"chemical_symbols\" ]): raise ValueError ( f \"Length of concentration ( { len ( v ) } ) MUST equal length of chemical_symbols \" f \"( { len ( values . get ( 'chemical_symbols' , [])) } )\" ) return v raise ValueError ( f \"Could not validate { field . name !r} as 'chemical_symbols' is missing/invalid.\" ) @validator ( \"attached\" , \"nattached\" ) def validate_minimum_list_length ( cls , v ): if v is not None and len ( v ) < 1 : raise ValueError ( f \"The list's length MUST be 1 or more, instead it was found to be { len ( v ) } \" ) return v @root_validator def attached_nattached_mutually_exclusive ( cls , values ): attached , nattached = ( values . get ( \"attached\" , None ), values . get ( \"nattached\" , None ), ) if ( attached is None and nattached is not None ) or ( attached is not None and nattached is None ): raise ValueError ( f \"Either both or none of attached ( { attached } ) and nattached ( { nattached } ) MUST be set.\" ) if ( attached is not None and nattached is not None and len ( attached ) != len ( nattached ) ): raise ValueError ( f \"attached ( { attached } ) and nattached ( { nattached } ) MUST be lists of equal length.\" ) return values attached : Optional [ List [ str ]] = OptimadeField ( None , description = 'If provided MUST be a list of length 1 or more of strings of chemical symbols for the elements attached to this site, or \"X\" for a non-chemical element.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 chemical_symbols : List [ str ] = OptimadeField ( Ellipsis , description = 'MUST be a list of strings of all chemical elements composing this species. Each item of the list MUST be one of the following: \\n\\n - a valid chemical-element symbol, or \\n - the special value `\"X\"` to represent a non-chemical element, or \\n - the special value `\"vacancy\"` to represent that this site has a non-zero probability of having a vacancy (the respective probability is indicated in the `concentration` list, see below). \\n\\n If any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element, the correct flag MUST be set in the list `structure_features`.' , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 concentration : List [ float ] = OptimadeField ( Ellipsis , description = 'MUST be a list of floats, with same length as `chemical_symbols`. The numbers represent the relative concentration of the corresponding chemical symbol in this species. The numbers SHOULD sum to one. Cases in which the numbers do not sum to one typically fall only in the following two categories: \\n\\n - Numerical errors when representing float numbers in fixed precision, e.g. for two chemical symbols with concentrations `1/3` and `2/3`, the concentration might look something like `[0.33333333333, 0.66666666666]`. If the client is aware that the sum is not one because of numerical precision, it can renormalize the values so that the sum is exactly one. \\n - Experimental errors in the data present in the database. In this case, it is the responsibility of the client to decide how to process the data. \\n\\n Note that concentrations are uncorrelated between different site (even of the same species).' , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 mass : Optional [ List [ float ]] = OptimadeField ( None , description = 'If present MUST be a list of floats expressed in a.m.u. \\n Elements denoting vacancies MUST have masses equal to 0.' , unit = 'a.m.u.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 name : str = OptimadeField ( Ellipsis , description = 'Gives the name of the species; the **name** value MUST be unique in the `species` list.' , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 nattached : Optional [ List [ int ]] = OptimadeField ( None , description = 'If provided MUST be a list of length 1 or more of integers indicating the number of attached atoms of the kind specified in the value of the :field:`attached` key.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 original_name : Optional [ str ] = OptimadeField ( None , description = 'Can be any valid Unicode string, and SHOULD contain (if specified) the name of the species that is used internally in the source database. \\n\\n Note: With regards to \"source database\", we refer to the immediate source being queried via the OPTIMADE API implementation.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 attached_nattached_mutually_exclusive ( values ) \u00b6 Source code in optimade/models/structures.py 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @root_validator def attached_nattached_mutually_exclusive ( cls , values ): attached , nattached = ( values . get ( \"attached\" , None ), values . get ( \"nattached\" , None ), ) if ( attached is None and nattached is not None ) or ( attached is not None and nattached is None ): raise ValueError ( f \"Either both or none of attached ( { attached } ) and nattached ( { nattached } ) MUST be set.\" ) if ( attached is not None and nattached is not None and len ( attached ) != len ( nattached ) ): raise ValueError ( f \"attached ( { attached } ) and nattached ( { nattached } ) MUST be lists of equal length.\" ) return values validate_chemical_symbols ( v ) \u00b6 Source code in optimade/models/structures.py 146 147 148 149 150 151 152 @validator ( \"chemical_symbols\" , each_item = True ) def validate_chemical_symbols ( cls , v ): if v not in EXTENDED_CHEMICAL_SYMBOLS : raise ValueError ( f ' { v !r} MUST be an element symbol, e.g., \"C\", \"He\", or a special symbol from { EXTRA_SYMBOLS } .' ) return v validate_concentration_and_mass ( v , values , field ) \u00b6 Source code in optimade/models/structures.py 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 @validator ( \"concentration\" , \"mass\" ) def validate_concentration_and_mass ( cls , v , values , field ): if not v : return v if values . get ( \"chemical_symbols\" ): if len ( v ) != len ( values [ \"chemical_symbols\" ]): raise ValueError ( f \"Length of concentration ( { len ( v ) } ) MUST equal length of chemical_symbols \" f \"( { len ( values . get ( 'chemical_symbols' , [])) } )\" ) return v raise ValueError ( f \"Could not validate { field . name !r} as 'chemical_symbols' is missing/invalid.\" ) validate_minimum_list_length ( v ) \u00b6 Source code in optimade/models/structures.py 170 171 172 173 174 175 176 @validator ( \"attached\" , \"nattached\" ) def validate_minimum_list_length ( cls , v ): if v is not None and len ( v ) < 1 : raise ValueError ( f \"The list's length MUST be 1 or more, instead it was found to be { len ( v ) } \" ) return v StructureFeatures \u00b6 Enumeration of structure_features values Source code in optimade/models/structures.py 53 54 55 56 57 58 59 class StructureFeatures ( Enum ): \"\"\"Enumeration of structure_features values\"\"\" DISORDER = \"disorder\" IMPLICIT_ATOMS = \"implicit_atoms\" SITE_ATTACHMENTS = \"site_attachments\" ASSEMBLIES = \"assemblies\" ASSEMBLIES = 'assemblies' class-attribute \u00b6 DISORDER = 'disorder' class-attribute \u00b6 IMPLICIT_ATOMS = 'implicit_atoms' class-attribute \u00b6 SITE_ATTACHMENTS = 'site_attachments' class-attribute \u00b6 StructureResource \u00b6 Representing a structure. Source code in optimade/models/structures.py 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 class StructureResource ( EntryResource ): \"\"\"Representing a structure.\"\"\" type : str = StrictField ( \"structures\" , description = \"\"\"The name of the type of an entry. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - MUST be an existing entry type. - The entry of type `<type>` and ID `<id>` MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. - **Examples**: - `\"structures\"`\"\"\" , regex = \"^structures$\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) attributes : StructureResourceAttributes attributes : StructureResourceAttributes class-attribute \u00b6 type : str = StrictField ( 'structures' , description = 'The name of the type of an entry. \\n\\n - **Type**: string. \\n\\n - **Requirements/Conventions**: \\n - **Support**: MUST be supported by all implementations, MUST NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - **Response**: REQUIRED in the response. \\n - MUST be an existing entry type. \\n - The entry of type `<type>` and ID `<id>` MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. \\n\\n - **Examples**: \\n - `\"structures\"`' , regex = '^structures$' , support = SupportLevel . MUST , queryable = SupportLevel . MUST ) class-attribute \u00b6 StructureResourceAttributes \u00b6 This class contains the Field for the attributes used to represent a structure, e.g. unit cell, atoms, positions. Source code in optimade/models/structures.py 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 class StructureResourceAttributes ( EntryResourceAttributes ): \"\"\"This class contains the Field for the attributes used to represent a structure, e.g. unit cell, atoms, positions.\"\"\" elements : Optional [ List [ str ]] = OptimadeField ( ... , description = \"\"\"The chemical symbols of the different elements present in the structure. - **Type**: list of strings. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - The strings are the chemical symbols, i.e., either a single uppercase letter or an uppercase letter followed by a number of lowercase letters. - The order MUST be alphabetical. - MUST refer to the same elements in the same order, and therefore be of the same length, as `elements_ratios`, if the latter is provided. - Note: This property SHOULD NOT contain the string \"X\" to indicate non-chemical elements or \"vacancy\" to indicate vacancies (in contrast to the field `chemical_symbols` for the `species` property). - **Examples**: - `[\"Si\"]` - `[\"Al\",\"O\",\"Si\"]` - **Query examples**: - A filter that matches all records of structures that contain Si, Al **and** O, and possibly other elements: `elements HAS ALL \"Si\", \"Al\", \"O\"`. - To match structures with exactly these three elements, use `elements HAS ALL \"Si\", \"Al\", \"O\" AND elements LENGTH 3`. - Note: length queries on this property can be equivalently formulated by filtering on the `nelements`_ property directly.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) nelements : Optional [ int ] = OptimadeField ( ... , description = \"\"\"Number of different elements in the structure as an integer. - **Type**: integer - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - MUST be equal to the lengths of the list properties `elements` and `elements_ratios`, if they are provided. - **Examples**: - `3` - **Querying**: - Note: queries on this property can equivalently be formulated using `elements LENGTH`. - A filter that matches structures that have exactly 4 elements: `nelements=4`. - A filter that matches structures that have between 2 and 7 elements: `nelements>=2 AND nelements<=7`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) elements_ratios : Optional [ List [ float ]] = OptimadeField ( ... , description = \"\"\"Relative proportions of different elements in the structure. - **Type**: list of floats - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - Composed by the proportions of elements in the structure as a list of floating point numbers. - The sum of the numbers MUST be 1.0 (within floating point accuracy) - MUST refer to the same elements in the same order, and therefore be of the same length, as `elements`, if the latter is provided. - **Examples**: - `[1.0]` - `[0.3333333333333333, 0.2222222222222222, 0.4444444444444444]` - **Query examples**: - Note: Useful filters can be formulated using the set operator syntax for correlated values. However, since the values are floating point values, the use of equality comparisons is generally inadvisable. - OPTIONAL: a filter that matches structures where approximately 1/3 of the atoms in the structure are the element Al is: `elements:elements_ratios HAS ALL \"Al\":>0.3333, \"Al\":<0.3334`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) chemical_formula_descriptive : Optional [ str ] = OptimadeField ( ... , description = \"\"\"The chemical formula for a structure as a string in a form chosen by the API implementation. - **Type**: string - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - The chemical formula is given as a string consisting of properly capitalized element symbols followed by integers or decimal numbers, balanced parentheses, square, and curly brackets `(`,`)`, `[`,`]`, `{`, `}`, commas, the `+`, `-`, `:` and `=` symbols. The parentheses are allowed to be followed by a number. Spaces are allowed anywhere except within chemical symbols. The order of elements and any groupings indicated by parentheses or brackets are chosen freely by the API implementation. - The string SHOULD be arithmetically consistent with the element ratios in the `chemical_formula_reduced` property. - It is RECOMMENDED, but not mandatory, that symbols, parentheses and brackets, if used, are used with the meanings prescribed by [IUPAC's Nomenclature of Organic Chemistry](https://www.qmul.ac.uk/sbcs/iupac/bibliog/blue.html). - **Examples**: - `\"(H2O)2 Na\"` - `\"NaCl\"` - `\"CaCO3\"` - `\"CCaO3\"` - `\"(CH3)3N+ - [CH2]2-OH = Me3N+ - CH2 - CH2OH\"` - **Query examples**: - Note: the free-form nature of this property is likely to make queries on it across different databases inconsistent. - A filter that matches an exactly given formula: `chemical_formula_descriptive=\"(H2O)2 Na\"`. - A filter that does a partial match: `chemical_formula_descriptive CONTAINS \"H2O\"`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) chemical_formula_reduced : Optional [ str ] = OptimadeField ( ... , description = \"\"\"The reduced chemical formula for a structure as a string with element symbols and integer chemical proportion numbers. The proportion number MUST be omitted if it is 1. - **Type**: string - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property. However, support for filters using partial string matching with this property is OPTIONAL (i.e., BEGINS WITH, ENDS WITH, and CONTAINS). Intricate queries on formula components are instead suggested to be formulated using set-type filter operators on the multi valued `elements` and `elements_ratios` properties. - Element symbols MUST have proper capitalization (e.g., `\"Si\"`, not `\"SI\"` for \"silicon\"). - Elements MUST be placed in alphabetical order, followed by their integer chemical proportion number. - For structures with no partial occupation, the chemical proportion numbers are the smallest integers for which the chemical proportion is exactly correct. - For structures with partial occupation, the chemical proportion numbers are integers that within reasonable approximation indicate the correct chemical proportions. The precise details of how to perform the rounding is chosen by the API implementation. - No spaces or separators are allowed. - **Examples**: - `\"H2NaO\"` - `\"ClNa\"` - `\"CCaO3\"` - **Query examples**: - A filter that matches an exactly given formula is `chemical_formula_reduced=\"H2NaO\"`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , regex = CHEMICAL_FORMULA_REGEXP , ) chemical_formula_hill : Optional [ str ] = OptimadeField ( None , description = \"\"\"The chemical formula for a structure in [Hill form](https://dx.doi.org/10.1021/ja02046a005) with element symbols followed by integer chemical proportion numbers. The proportion number MUST be omitted if it is 1. - **Type**: string - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, only a subset of the filter features MAY be supported. - The overall scale factor of the chemical proportions is chosen such that the resulting values are integers that indicate the most chemically relevant unit of which the system is composed. For example, if the structure is a repeating unit cell with four hydrogens and four oxygens that represents two hydroperoxide molecules, `chemical_formula_hill` is `\"H2O2\"` (i.e., not `\"HO\"`, nor `\"H4O4\"`). - If the chemical insight needed to ascribe a Hill formula to the system is not present, the property MUST be handled as unset. - Element symbols MUST have proper capitalization (e.g., `\"Si\"`, not `\"SI\"` for \"silicon\"). - Elements MUST be placed in [Hill order](https://dx.doi.org/10.1021/ja02046a005), followed by their integer chemical proportion number. Hill order means: if carbon is present, it is placed first, and if also present, hydrogen is placed second. After that, all other elements are ordered alphabetically. If carbon is not present, all elements are ordered alphabetically. - If the system has sites with partial occupation and the total occupations of each element do not all sum up to integers, then the Hill formula SHOULD be handled as unset. - No spaces or separators are allowed. - **Examples**: - `\"H2O2\"` - **Query examples**: - A filter that matches an exactly given formula is `chemical_formula_hill=\"H2O2\"`.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , regex = CHEMICAL_FORMULA_REGEXP , ) chemical_formula_anonymous : Optional [ str ] = OptimadeField ( ... , description = \"\"\"The anonymous formula is the `chemical_formula_reduced`, but where the elements are instead first ordered by their chemical proportion number, and then, in order left to right, replaced by anonymous symbols A, B, C, ..., Z, Aa, Ba, ..., Za, Ab, Bb, ... and so on. - **Type**: string - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property. However, support for filters using partial string matching with this property is OPTIONAL (i.e., BEGINS WITH, ENDS WITH, and CONTAINS). - **Examples**: - `\"A2B\"` - `\"A42B42C16D12E10F9G5\"` - **Querying**: - A filter that matches an exactly given formula is `chemical_formula_anonymous=\"A2B\"`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , regex = CHEMICAL_FORMULA_REGEXP , ) dimension_types : Optional [ conlist ( Periodicity , min_items = 3 , max_items = 3 ) ] = OptimadeField ( None , title = \"Dimension Types\" , description = \"\"\"List of three integers. For each of the three directions indicated by the three lattice vectors (see property `lattice_vectors`), this list indicates if the direction is periodic (value `1`) or non-periodic (value `0`). Note: the elements in this list each refer to the direction of the corresponding entry in `lattice_vectors` and *not* the Cartesian x, y, z directions. - **Type**: list of integers. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. - MUST be a list of length 3. - Each integer element MUST assume only the value 0 or 1. - **Examples**: - For a molecule: `[0, 0, 0]` - For a wire along the direction specified by the third lattice vector: `[0, 0, 1]` - For a 2D surface/slab, periodic on the plane defined by the first and third lattice vectors: `[1, 0, 1]` - For a bulk 3D system: `[1, 1, 1]`\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) nperiodic_dimensions : Optional [ int ] = OptimadeField ( ... , description = \"\"\"An integer specifying the number of periodic dimensions in the structure, equivalent to the number of non-zero entries in `dimension_types`. - **Type**: integer - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - The integer value MUST be between 0 and 3 inclusive and MUST be equal to the sum of the items in the `dimension_types` property. - This property only reflects the treatment of the lattice vectors provided for the structure, and not any physical interpretation of the dimensionality of its contents. - **Examples**: - `2` should be indicated in cases where `dimension_types` is any of `[1, 1, 0]`, `[1, 0, 1]`, `[0, 1, 1]`. - **Query examples**: - Match only structures with exactly 3 periodic dimensions: `nperiodic_dimensions=3` - Match all structures with 2 or fewer periodic dimensions: `nperiodic_dimensions<=2`\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) lattice_vectors : Optional [ conlist ( Vector3D_unknown , min_items = 3 , max_items = 3 ) ] = OptimadeField ( None , description = \"\"\"The three lattice vectors in Cartesian coordinates, in \u00e5ngstr\u00f6m (\u00c5). - **Type**: list of list of floats or unknown values. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - MUST be a list of three vectors *a*, *b*, and *c*, where each of the vectors MUST BE a list of the vector's coordinates along the x, y, and z Cartesian coordinates. (Therefore, the first index runs over the three lattice vectors and the second index runs over the x, y, z Cartesian coordinates). - For databases that do not define an absolute Cartesian system (e.g., only defining the length and angles between vectors), the first lattice vector SHOULD be set along *x* and the second on the *xy*-plane. - MUST always contain three vectors of three coordinates each, independently of the elements of property `dimension_types`. The vectors SHOULD by convention be chosen so the determinant of the `lattice_vectors` matrix is different from zero. The vectors in the non-periodic directions have no significance beyond fulfilling these requirements. - The coordinates of the lattice vectors of non-periodic dimensions (i.e., those dimensions for which `dimension_types` is `0`) MAY be given as a list of all `null` values. If a lattice vector contains the value `null`, all coordinates of that lattice vector MUST be `null`. - **Examples**: - `[[4.0,0.0,0.0],[0.0,4.0,0.0],[0.0,1.0,4.0]]` represents a cell, where the first vector is `(4, 0, 0)`, i.e., a vector aligned along the `x` axis of length 4 \u00c5; the second vector is `(0, 4, 0)`; and the third vector is `(0, 1, 4)`.\"\"\" , unit = \"\u00c5\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) cartesian_site_positions : Optional [ List [ Vector3D ]] = OptimadeField ( ... , description = \"\"\"Cartesian positions of each site in the structure. A site is usually used to describe positions of atoms; what atoms can be encountered at a given site is conveyed by the `species_at_sites` property, and the species themselves are described in the `species` property. - **Type**: list of list of floats - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - It MUST be a list of length equal to the number of sites in the structure, where every element is a list of the three Cartesian coordinates of a site expressed as float values in the unit angstrom (\u00c5). - An entry MAY have multiple sites at the same Cartesian position (for a relevant use of this, see e.g., the property `assemblies`). - **Examples**: - `[[0,0,0],[0,0,2]]` indicates a structure with two sites, one sitting at the origin and one along the (positive) *z*-axis, 2 \u00c5 away from the origin.\"\"\" , unit = \"\u00c5\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) nsites : Optional [ int ] = OptimadeField ( ... , description = \"\"\"An integer specifying the length of the `cartesian_site_positions` property. - **Type**: integer - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Examples**: - `42` - **Query examples**: - Match only structures with exactly 4 sites: `nsites=4` - Match structures that have between 2 and 7 sites: `nsites>=2 AND nsites<=7`\"\"\" , queryable = SupportLevel . MUST , support = SupportLevel . SHOULD , ) species : Optional [ List [ Species ]] = OptimadeField ( ... , description = \"\"\"A list describing the species of the sites of this structure. Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). - **Type**: list of dictionary with keys: - `name`: string (REQUIRED) - `chemical_symbols`: list of strings (REQUIRED) - `concentration`: list of float (REQUIRED) - `attached`: list of strings (REQUIRED) - `nattached`: list of integers (OPTIONAL) - `mass`: list of floats (OPTIONAL) - `original_name`: string (OPTIONAL). - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - Each list member MUST be a dictionary with the following keys: - **name**: REQUIRED; gives the name of the species; the **name** value MUST be unique in the `species` list; - **chemical_symbols**: REQUIRED; MUST be a list of strings of all chemical elements composing this species. Each item of the list MUST be one of the following: - a valid chemical-element symbol, or - the special value `\"X\"` to represent a non-chemical element, or - the special value `\"vacancy\"` to represent that this site has a non-zero probability of having a vacancy (the respective probability is indicated in the `concentration` list, see below). If any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element, the correct flag MUST be set in the list `structure_features`. - **concentration**: REQUIRED; MUST be a list of floats, with same length as `chemical_symbols`. The numbers represent the relative concentration of the corresponding chemical symbol in this species. The numbers SHOULD sum to one. Cases in which the numbers do not sum to one typically fall only in the following two categories: - Numerical errors when representing float numbers in fixed precision, e.g. for two chemical symbols with concentrations `1/3` and `2/3`, the concentration might look something like `[0.33333333333, 0.66666666666]`. If the client is aware that the sum is not one because of numerical precision, it can renormalize the values so that the sum is exactly one. - Experimental errors in the data present in the database. In this case, it is the responsibility of the client to decide how to process the data. Note that concentrations are uncorrelated between different sites (even of the same species). - **attached**: OPTIONAL; if provided MUST be a list of length 1 or more of strings of chemical symbols for the elements attached to this site, or \"X\" for a non-chemical element. - **nattached**: OPTIONAL; if provided MUST be a list of length 1 or more of integers indicating the number of attached atoms of the kind specified in the value of the `attached` key. The implementation MUST include either both or none of the `attached` and `nattached` keys, and if they are provided, they MUST be of the same length. Furthermore, if they are provided, the `structure_features` property MUST include the string `site_attachments`. - **mass**: OPTIONAL. If present MUST be a list of floats, with the same length as `chemical_symbols`, providing element masses expressed in a.m.u. Elements denoting vacancies MUST have masses equal to 0. - **original_name**: OPTIONAL. Can be any valid Unicode string, and SHOULD contain (if specified) the name of the species that is used internally in the source database. Note: With regards to \"source database\", we refer to the immediate source being queried via the OPTIMADE API implementation. The main use of this field is for source databases that use species names, containing characters that are not allowed (see description of the list property `species_at_sites`). - For systems that have only species formed by a single chemical symbol, and that have at most one species per chemical symbol, SHOULD use the chemical symbol as species name (e.g., `\"Ti\"` for titanium, `\"O\"` for oxygen, etc.) However, note that this is OPTIONAL, and client implementations MUST NOT assume that the key corresponds to a chemical symbol, nor assume that if the species name is a valid chemical symbol, that it represents a species with that chemical symbol. This means that a species `{\"name\": \"C\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]}` is valid and represents a titanium species (and *not* a carbon species). - It is NOT RECOMMENDED that a structure includes species that do not have at least one corresponding site. - **Examples**: - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ]`: any site with this species is occupied by a Ti atom. - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ]`: any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. - `[ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ]`: any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. - `[ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ]`: any site with this species is occupied by a carbon isotope with mass 12. - `[ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ]`: any site with this species is occupied by a carbon isotope with mass 13. - `[ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ]`: any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) species_at_sites : Optional [ List [ str ]] = OptimadeField ( ... , description = \"\"\"Name of the species at each site (where values for sites are specified with the same order of the property `cartesian_site_positions`). The properties of the species are found in the property `species`. - **Type**: list of strings. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - MUST have length equal to the number of sites in the structure (first dimension of the list property `cartesian_site_positions`). - Each species name mentioned in the `species_at_sites` list MUST be described in the list property `species` (i.e. for each value in the `species_at_sites` list there MUST exist exactly one dictionary in the `species` list with the `name` attribute equal to the corresponding `species_at_sites` value). - Each site MUST be associated only to a single species. **Note**: However, species can represent mixtures of atoms, and multiple species MAY be defined for the same chemical element. This latter case is useful when different atoms of the same type need to be grouped or distinguished, for instance in simulation codes to assign different initial spin states. - **Examples**: - `[\"Ti\",\"O2\"]` indicates that the first site is hosting a species labeled `\"Ti\"` and the second a species labeled `\"O2\"`. - `[\"Ac\", \"Ac\", \"Ag\", \"Ir\"]` indicating the first two sites contains the `\"Ac\"` species, while the third and fourth sites contain the `\"Ag\"` and `\"Ir\"` species, respectively.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) assemblies : Optional [ List [ Assembly ]] = OptimadeField ( None , description = \"\"\"A description of groups of sites that are statistically correlated. - **Type**: list of dictionary with keys: - `sites_in_groups`: list of list of integers (REQUIRED) - `group_probabilities`: list of floats (REQUIRED) - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - The property SHOULD be `null` for entries that have no partial occupancies. - If present, the correct flag MUST be set in the list `structure_features`. - Client implementations MUST check its presence (as its presence changes the interpretation of the structure). - If present, it MUST be a list of dictionaries, each of which represents an assembly and MUST have the following two keys: - **sites_in_groups**: Index of the sites (0-based) that belong to each group for each assembly. Example: `[[1], [2]]`: two groups, one with the second site, one with the third. Example: `[[1,2], [3]]`: one group with the second and third site, one with the fourth. - **group_probabilities**: Statistical probability of each group. It MUST have the same length as `sites_in_groups`. It SHOULD sum to one. See below for examples of how to specify the probability of the occurrence of a vacancy. The possible reasons for the values not to sum to one are the same as already specified above for the `concentration` of each `species`. - If a site is not present in any group, it means that it is present with 100 % probability (as if no assembly was specified). - A site MUST NOT appear in more than one group. - **Examples** (for each entry of the assemblies list): - `{\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]}`: the first site and the second site never occur at the same time in the unit cell. Statistically, 30 % o f the times the first site is present, while 70 % o f the times the second site is present. - `{\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]}`: the second and third site are either present together or not present; they form the first group of atoms for this assembly. The second group is formed by the fourth site. Sites of the first group (the second and the third) are never present at the same time as the fourth site. 30 % o f times sites 1 and 2 are present (and site 3 is absent); 70 % o f times site 3 is present (and sites 1 and 2 are absent). - **Notes**: - Assemblies are essential to represent, for instance, the situation where an atom can statistically occupy two different positions (sites). - By defining groups, it is possible to represent, e.g., the case where a functional molecule (and not just one atom) is either present or absent (or the case where it it is present in two conformations) - Considerations on virtual alloys and on vacancies: In the special case of a virtual alloy, these specifications allow two different, equivalent ways of specifying them. For instance, for a site at the origin with 30 % probability of being occupied by Si, 50 % probability of being occupied by Ge, and 20 % o f being a vacancy, the following two representations are possible: - Using a single species: ```json { \"cartesian_site_positions\": [[0,0,0]], \"species_at_sites\": [\"SiGe-vac\"], \"species\": [ { \"name\": \"SiGe-vac\", \"chemical_symbols\": [\"Si\", \"Ge\", \"vacancy\"], \"concentration\": [0.3, 0.5, 0.2] } ] // ... } ``` - Using multiple species and the assemblies: ```json { \"cartesian_site_positions\": [ [0,0,0], [0,0,0], [0,0,0] ], \"species_at_sites\": [\"Si\", \"Ge\", \"vac\"], \"species\": [ { \"name\": \"Si\", \"chemical_symbols\": [\"Si\"], \"concentration\": [1.0] }, { \"name\": \"Ge\", \"chemical_symbols\": [\"Ge\"], \"concentration\": [1.0] }, { \"name\": \"vac\", \"chemical_symbols\": [\"vacancy\"], \"concentration\": [1.0] } ], \"assemblies\": [ { \"sites_in_groups\": [ [0], [1], [2] ], \"group_probabilities\": [0.3, 0.5, 0.2] } ] // ... } ``` - It is up to the database provider to decide which representation to use, typically depending on the internal format in which the structure is stored. However, given a structure identified by a unique ID, the API implementation MUST always provide the same representation for it. - The probabilities of occurrence of different assemblies are uncorrelated. So, for instance in the following case with two assemblies: ```json { \"assemblies\": [ { \"sites_in_groups\": [ [0], [1] ], \"group_probabilities\": [0.2, 0.8], }, { \"sites_in_groups\": [ [2], [3] ], \"group_probabilities\": [0.3, 0.7] } ] } ``` Site 0 is present with a probability of 20 % a nd site 1 with a probability of 80 %. These two sites are correlated (either site 0 or 1 is present). Similarly, site 2 is present with a probability of 30 % a nd site 3 with a probability of 70 %. These two sites are correlated (either site 2 or 3 is present). However, the presence or absence of sites 0 and 1 is not correlated with the presence or absence of sites 2 and 3 (in the specific example, the pair of sites (0, 2) can occur with 0.2*0.3 = 6 % probability; the pair (0, 3) with 0.2*0.7 = 14 % probability; the pair (1, 2) with 0.8*0.3 = 24 % probability; and the pair (1, 3) with 0.8*0.7 = 56 % probability).\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) structure_features : List [ StructureFeatures ] = OptimadeField ( ... , title = \"Structure Features\" , description = \"\"\"A list of strings that flag which special features are used by the structure. - **Type**: list of strings - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property. Filters on the list MUST support all mandatory HAS-type queries. Filter operators for comparisons on the string components MUST support equality, support for other comparison operators are OPTIONAL. - MUST be an empty list if no special features are used. - MUST be sorted alphabetically. - If a special feature listed below is used, the list MUST contain the corresponding string. - If a special feature listed below is not used, the list MUST NOT contain the corresponding string. - **List of strings used to indicate special structure features**: - `disorder`: this flag MUST be present if any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element. - `implicit_atoms`: this flag MUST be present if the structure contains atoms that are not assigned to sites via the property `species_at_sites` (e.g., because their positions are unknown). When this flag is present, the properties related to the chemical formula will likely not match the type and count of atoms represented by the `species_at_sites`, `species` and `assemblies` properties. - `site_attachments`: this flag MUST be present if any one entry in the `species` list includes `attached` and `nattached`. - `assemblies`: this flag MUST be present if the property `assemblies` is present. - **Examples**: A structure having implicit atoms and using assemblies: `[\"assemblies\", \"implicit_atoms\"]`\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) class Config : def schema_extra ( schema , model ): \"\"\"Two things need to be added to the schema: 1. Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, `dimension_types` and `lattice_vectors`, are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. 2. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be `nullable` according to the OpenAPI definition. \"\"\" schema [ \"required\" ] . insert ( 7 , \"dimension_types\" ) schema [ \"required\" ] . insert ( 9 , \"lattice_vectors\" ) nullable_props = ( prop for prop in schema [ \"required\" ] if schema [ \"properties\" ][ prop ] . get ( \"x-optimade-support\" ) == SupportLevel . SHOULD ) for prop in nullable_props : schema [ \"properties\" ][ prop ][ \"nullable\" ] = True @root_validator ( pre = True ) def warn_on_missing_correlated_fields ( cls , values ): \"\"\"Emit warnings if a field takes a null value when a value was expected based on the value/nullity of another field. \"\"\" accumulated_warnings = [] for field_set in CORRELATED_STRUCTURE_FIELDS : missing_fields = { f for f in field_set if values . get ( f ) is None } if missing_fields and len ( missing_fields ) != len ( field_set ): accumulated_warnings += [ f \"Structure with values { values } is missing fields { missing_fields } which are required if { field_set - missing_fields } are present.\" ] for warn in accumulated_warnings : warnings . warn ( warn , MissingExpectedField ) return values @validator ( \"chemical_formula_reduced\" , \"chemical_formula_hill\" ) def check_ordered_formula ( cls , v , field ): if v is None : return v elements = re . findall ( r \"[A-Z][a-z]?\" , v ) expected_elements = sorted ( elements ) if field . name == \"chemical_formula_hill\" : # Make sure C is first (and H is second, if present along with C). if \"C\" in expected_elements : expected_elements = sorted ( expected_elements , key = lambda elem : { \"C\" : \"0\" , \"H\" : \"1\" } . get ( elem , elem ), ) if any ( elem not in CHEMICAL_SYMBOLS for elem in elements ): raise ValueError ( f \"Cannot use unknown chemical symbols { [ elem for elem in elements if elem not in CHEMICAL_SYMBOLS ] } in { field . name !r} \" ) if expected_elements != elements : order = \"Hill\" if field . name == \"chemical_formula_hill\" else \"alphabetical\" raise ValueError ( f \"Elements in { field . name !r} must appear in { order } order: { expected_elements } not { elements } .\" ) return v @validator ( \"chemical_formula_anonymous\" ) def check_anonymous_formula ( cls , v ): if v is None : return v elements = tuple ( re . findall ( r \"[A-Z][a-z]*\" , v )) numbers = re . split ( r \"[A-Z][a-z]*\" , v )[ 1 :] numbers = [ int ( i ) if i else 1 for i in numbers ] expected_labels = ANONYMOUS_ELEMENTS [: len ( elements )] expected_numbers = sorted ( numbers , reverse = True ) if expected_numbers != numbers : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong order: elements with highest proportion should appear first: { numbers } vs expected { expected_numbers } \" ) if elements != expected_labels : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong labels: { elements } vs expected { expected_labels } .\" ) return v @validator ( \"chemical_formula_anonymous\" , \"chemical_formula_reduced\" ) def check_reduced_formulae ( cls , value , field ): if value is None : return value numbers = [ n . strip () or 1 for n in re . split ( r \"[A-Z][a-z]*\" , value )] # Need to remove leading 1 from split and convert to ints numbers = [ int ( n ) for n in numbers [ 1 :]] if sys . version_info [ 1 ] >= 9 : gcd = math . gcd ( * numbers ) else : gcd = reduce ( math . gcd , numbers ) if gcd != 1 : raise ValueError ( f \" { field . name } { value !r} is not properly reduced: greatest common divisor was { gcd } , expected 1.\" ) return value @validator ( \"elements\" , each_item = True ) def element_must_be_chemical_symbol ( cls , v ): if v not in CHEMICAL_SYMBOLS : raise ValueError ( f \"Only chemical symbols are allowed, you passed: { v } \" ) return v @validator ( \"elements\" ) def elements_must_be_alphabetical ( cls , v ): if v is None : return v if sorted ( v ) != v : raise ValueError ( f \"elements must be sorted alphabetically, but is: { v } \" ) return v @validator ( \"elements_ratios\" ) def ratios_must_sum_to_one ( cls , v ): if v is None : return v if abs ( sum ( v ) - 1 ) > EPS : raise ValueError ( f \"elements_ratios MUST sum to 1 within (at least single precision) floating point accuracy. It sums to: { sum ( v ) } \" ) return v @validator ( \"nperiodic_dimensions\" ) def check_periodic_dimensions ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ) and v != sum ( values . get ( \"dimension_types\" )): raise ValueError ( f \"nperiodic_dimensions ( { v } ) does not match expected value of { sum ( values [ 'dimension_types' ]) } \" f \"from dimension_types ( { values [ 'dimension_types' ] } )\" ) return v @validator ( \"lattice_vectors\" , always = True ) def required_if_dimension_types_has_one ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ): for dim_type , vector in zip ( values . get ( \"dimension_types\" , ( None ,) * 3 ), v ): if None in vector and dim_type == Periodicity . PERIODIC . value : raise ValueError ( f \"Null entries in lattice vectors are only permitted when the corresponding dimension type is { Periodicity . APERIODIC . value } . \" f \"Here: dimension_types = { tuple ( getattr ( _ , 'value' , None ) for _ in values . get ( 'dimension_types' , [])) } , lattice_vectors = { v } \" ) return v @validator ( \"lattice_vectors\" ) def null_values_for_whole_vector ( cls , v ): if v is None : return v for vector in v : if None in vector and any (( isinstance ( _ , float ) for _ in vector )): raise ValueError ( f \"A lattice vector MUST be either all `null` or all numbers (vector: { vector } , all vectors: { v } )\" ) return v @validator ( \"nsites\" ) def validate_nsites ( cls , v , values ): if v is None : return v if values . get ( \"cartesian_site_positions\" ) and v != len ( values . get ( \"cartesian_site_positions\" , []) ): raise ValueError ( f \"nsites (value: { v } ) MUST equal length of cartesian_site_positions \" f \"(value: { len ( values . get ( 'cartesian_site_positions' , [])) } )\" ) return v @validator ( \"species_at_sites\" ) def validate_species_at_sites ( cls , v , values ): if v is None : return v if values . get ( \"nsites\" ) and len ( v ) != values . get ( \"nsites\" ): raise ValueError ( f \"Number of species_at_sites (value: { len ( v ) } ) MUST equal number of sites \" f \"(value: { values . get ( 'nsites' , 'Not specified' ) } )\" ) if values . get ( \"species\" ): all_species_names = { getattr ( _ , \"name\" , None ) for _ in values . get ( \"species\" , [{}]) } all_species_names -= { None } for value in v : if value not in all_species_names : raise ValueError ( \"species_at_sites MUST be represented by a species' name, \" f \"but { value } was not found in the list of species names: { all_species_names } \" ) return v @validator ( \"species\" ) def validate_species ( cls , v ): if v is None : return v all_species = [ _ . name for _ in v ] unique_species = set ( all_species ) if len ( all_species ) != len ( unique_species ): raise ValueError ( f \"Species MUST be unique based on their 'name'. Found species names: { all_species } \" ) return v @validator ( \"structure_features\" , always = True ) def validate_structure_features ( cls , v , values ): if [ StructureFeatures ( value ) for value in sorted (( _ . value for _ in v ))] != v : raise ValueError ( f \"structure_features MUST be sorted alphabetically, given value: { v } \" ) # assemblies if values . get ( \"assemblies\" ) is not None : if StructureFeatures . ASSEMBLIES not in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST be present, since the property of the same name is present\" ) elif StructureFeatures . ASSEMBLIES in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST NOT be present, \" \"since the property of the same name is not present\" ) if values . get ( \"species\" ): # disorder for species in values . get ( \"species\" , []): if len ( species . chemical_symbols ) > 1 : if StructureFeatures . DISORDER not in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST be present when any one entry in species \" \"has a chemical_symbols list greater than one element\" ) break else : if StructureFeatures . DISORDER in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST NOT be present, since all species' chemical_symbols \" \"lists are equal to or less than one element\" ) # site_attachments for species in values . get ( \"species\" , []): # There is no need to also test \"nattached\", # since a Species validator makes sure either both are present or both are None. if getattr ( species , \"attached\" , None ) is not None : if StructureFeatures . SITE_ATTACHMENTS not in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST be present when any one entry \" \"in species includes attached and nattached\" ) break else : if StructureFeatures . SITE_ATTACHMENTS in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST NOT be present, since no species includes \" \"the attached and nattached fields\" ) # implicit_atoms species_names = [ _ . name for _ in values . get ( \"species\" , [])] for name in species_names : if values . get ( \"species_at_sites\" ) is not None and name not in values . get ( \"species_at_sites\" , []): if StructureFeatures . IMPLICIT_ATOMS not in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST be present when any one entry in species \" \"is not represented in species_at_sites\" ) break else : if StructureFeatures . IMPLICIT_ATOMS in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST NOT be present, since all species are \" \"represented in species_at_sites\" ) return v assemblies : Optional [ List [ Assembly ]] = OptimadeField ( None , description = 'A description of groups of sites that are statistically correlated. \\n\\n - **Type**: list of dictionary with keys: \\n - `sites_in_groups`: list of list of integers (REQUIRED) \\n - `group_probabilities`: list of floats (REQUIRED) \\n\\n - **Requirements/Conventions**: \\n - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n If supported, filters MAY support only a subset of comparison operators. \\n - The property SHOULD be `null` for entries that have no partial occupancies. \\n - If present, the correct flag MUST be set in the list `structure_features`. \\n - Client implementations MUST check its presence (as its presence changes the interpretation of the structure). \\n - If present, it MUST be a list of dictionaries, each of which represents an assembly and MUST have the following two keys: \\n - **sites_in_groups**: Index of the sites (0-based) that belong to each group for each assembly. \\n\\n Example: `[[1], [2]]`: two groups, one with the second site, one with the third. \\n Example: `[[1,2], [3]]`: one group with the second and third site, one with the fourth. \\n\\n - **group_probabilities**: Statistical probability of each group. It MUST have the same length as `sites_in_groups`. \\n It SHOULD sum to one. \\n See below for examples of how to specify the probability of the occurrence of a vacancy. \\n The possible reasons for the values not to sum to one are the same as already specified above for the `concentration` of each `species`. \\n\\n - If a site is not present in any group, it means that it is present with 100 % probability (as if no assembly was specified). \\n - A site MUST NOT appear in more than one group. \\n\\n - **Examples** (for each entry of the assemblies list): \\n - `{\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]}`: the first site and the second site never occur at the same time in the unit cell. \\n Statistically, 30 % o f the times the first site is present, while 70 % o f the times the second site is present. \\n - `{\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]}`: the second and third site are either present together or not present; they form the first group of atoms for this assembly. \\n The second group is formed by the fourth site. \\n Sites of the first group (the second and the third) are never present at the same time as the fourth site. \\n 30 % o f times sites 1 and 2 are present (and site 3 is absent); 70 % o f times site 3 is present (and sites 1 and 2 are absent). \\n\\n - **Notes**: \\n - Assemblies are essential to represent, for instance, the situation where an atom can statistically occupy two different positions (sites). \\n\\n - By defining groups, it is possible to represent, e.g., the case where a functional molecule (and not just one atom) is either present or absent (or the case where it it is present in two conformations) \\n\\n - Considerations on virtual alloys and on vacancies: In the special case of a virtual alloy, these specifications allow two different, equivalent ways of specifying them. \\n For instance, for a site at the origin with 30 % probability of being occupied by Si, 50 % probability of being occupied by Ge, and 20 % o f being a vacancy, the following two representations are possible: \\n\\n - Using a single species: \\n ```json \\n { \\n \"cartesian_site_positions\": [[0,0,0]], \\n \"species_at_sites\": [\"SiGe-vac\"], \\n \"species\": [ \\n { \\n \"name\": \"SiGe-vac\", \\n \"chemical_symbols\": [\"Si\", \"Ge\", \"vacancy\"], \\n \"concentration\": [0.3, 0.5, 0.2] \\n } \\n ] \\n // ... \\n } \\n ``` \\n\\n - Using multiple species and the assemblies: \\n ```json \\n { \\n \"cartesian_site_positions\": [ [0,0,0], [0,0,0], [0,0,0] ], \\n \"species_at_sites\": [\"Si\", \"Ge\", \"vac\"], \\n \"species\": [ \\n { \"name\": \"Si\", \"chemical_symbols\": [\"Si\"], \"concentration\": [1.0] }, \\n { \"name\": \"Ge\", \"chemical_symbols\": [\"Ge\"], \"concentration\": [1.0] }, \\n { \"name\": \"vac\", \"chemical_symbols\": [\"vacancy\"], \"concentration\": [1.0] } \\n ], \\n \"assemblies\": [ \\n { \\n \"sites_in_groups\": [ [0], [1], [2] ], \\n \"group_probabilities\": [0.3, 0.5, 0.2] \\n } \\n ] \\n // ... \\n } \\n ``` \\n\\n - It is up to the database provider to decide which representation to use, typically depending on the internal format in which the structure is stored. \\n However, given a structure identified by a unique ID, the API implementation MUST always provide the same representation for it. \\n\\n - The probabilities of occurrence of different assemblies are uncorrelated. \\n So, for instance in the following case with two assemblies: \\n ```json \\n { \\n \"assemblies\": [ \\n { \\n \"sites_in_groups\": [ [0], [1] ], \\n \"group_probabilities\": [0.2, 0.8], \\n }, \\n { \\n \"sites_in_groups\": [ [2], [3] ], \\n \"group_probabilities\": [0.3, 0.7] \\n } \\n ] \\n } \\n ``` \\n\\n Site 0 is present with a probability of 20 % a nd site 1 with a probability of 80 %. These two sites are correlated (either site 0 or 1 is present). Similarly, site 2 is present with a probability of 30 % a nd site 3 with a probability of 70 %. \\n These two sites are correlated (either site 2 or 3 is present). \\n However, the presence or absence of sites 0 and 1 is not correlated with the presence or absence of sites 2 and 3 (in the specific example, the pair of sites (0, 2) can occur with 0.2*0.3 = 6 % probability; the pair (0, 3) with 0.2*0.7 = 14 % probability; the pair (1, 2) with 0.8*0.3 = 24 % probability; and the pair (1, 3) with 0.8*0.7 = 56 % probability).' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 cartesian_site_positions : Optional [ List [ Vector3D ]] = OptimadeField ( Ellipsis , description = 'Cartesian positions of each site in the structure. \\n A site is usually used to describe positions of atoms; what atoms can be encountered at a given site is conveyed by the `species_at_sites` property, and the species themselves are described in the `species` property. \\n\\n - **Type**: list of list of floats \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n If supported, filters MAY support only a subset of comparison operators. \\n - It MUST be a list of length equal to the number of sites in the structure, where every element is a list of the three Cartesian coordinates of a site expressed as float values in the unit angstrom (\u00c5). \\n - An entry MAY have multiple sites at the same Cartesian position (for a relevant use of this, see e.g., the property `assemblies`). \\n\\n - **Examples**: \\n - `[[0,0,0],[0,0,2]]` indicates a structure with two sites, one sitting at the origin and one along the (positive) *z*-axis, 2 \u00c5 away from the origin.' , unit = '\u00c5' , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 chemical_formula_anonymous : Optional [ str ] = OptimadeField ( Ellipsis , description = 'The anonymous formula is the `chemical_formula_reduced`, but where the elements are instead first ordered by their chemical proportion number, and then, in order left to right, replaced by anonymous symbols A, B, C, ..., Z, Aa, Ba, ..., Za, Ab, Bb, ... and so on. \\n\\n - **Type**: string \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property. \\n However, support for filters using partial string matching with this property is OPTIONAL (i.e., BEGINS WITH, ENDS WITH, and CONTAINS). \\n\\n - **Examples**: \\n - `\"A2B\"` \\n - `\"A42B42C16D12E10F9G5\"` \\n\\n - **Querying**: \\n - A filter that matches an exactly given formula is `chemical_formula_anonymous=\"A2B\"`.' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , regex = CHEMICAL_FORMULA_REGEXP ) class-attribute \u00b6 chemical_formula_descriptive : Optional [ str ] = OptimadeField ( Ellipsis , description = 'The chemical formula for a structure as a string in a form chosen by the API implementation. \\n\\n - **Type**: string \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - The chemical formula is given as a string consisting of properly capitalized element symbols followed by integers or decimal numbers, balanced parentheses, square, and curly brackets `(`,`)`, `[`,`]`, `{`, `}`, commas, the `+`, `-`, `:` and `=` symbols. The parentheses are allowed to be followed by a number. Spaces are allowed anywhere except within chemical symbols. The order of elements and any groupings indicated by parentheses or brackets are chosen freely by the API implementation. \\n - The string SHOULD be arithmetically consistent with the element ratios in the `chemical_formula_reduced` property. \\n - It is RECOMMENDED, but not mandatory, that symbols, parentheses and brackets, if used, are used with the meanings prescribed by [IUPAC \\' s Nomenclature of Organic Chemistry](https://www.qmul.ac.uk/sbcs/iupac/bibliog/blue.html). \\n\\n - **Examples**: \\n - `\"(H2O)2 Na\"` \\n - `\"NaCl\"` \\n - `\"CaCO3\"` \\n - `\"CCaO3\"` \\n - `\"(CH3)3N+ - [CH2]2-OH = Me3N+ - CH2 - CH2OH\"` \\n\\n - **Query examples**: \\n - Note: the free-form nature of this property is likely to make queries on it across different databases inconsistent. \\n - A filter that matches an exactly given formula: `chemical_formula_descriptive=\"(H2O)2 Na\"`. \\n - A filter that does a partial match: `chemical_formula_descriptive CONTAINS \"H2O\"`.' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST ) class-attribute \u00b6 chemical_formula_hill : Optional [ str ] = OptimadeField ( None , description = 'The chemical formula for a structure in [Hill form](https://dx.doi.org/10.1021/ja02046a005) with element symbols followed by integer chemical proportion numbers. The proportion number MUST be omitted if it is 1. \\n\\n - **Type**: string \\n\\n - **Requirements/Conventions**: \\n - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n If supported, only a subset of the filter features MAY be supported. \\n - The overall scale factor of the chemical proportions is chosen such that the resulting values are integers that indicate the most chemically relevant unit of which the system is composed. \\n For example, if the structure is a repeating unit cell with four hydrogens and four oxygens that represents two hydroperoxide molecules, `chemical_formula_hill` is `\"H2O2\"` (i.e., not `\"HO\"`, nor `\"H4O4\"`). \\n - If the chemical insight needed to ascribe a Hill formula to the system is not present, the property MUST be handled as unset. \\n - Element symbols MUST have proper capitalization (e.g., `\"Si\"`, not `\"SI\"` for \"silicon\"). \\n - Elements MUST be placed in [Hill order](https://dx.doi.org/10.1021/ja02046a005), followed by their integer chemical proportion number. \\n Hill order means: if carbon is present, it is placed first, and if also present, hydrogen is placed second. \\n After that, all other elements are ordered alphabetically. \\n If carbon is not present, all elements are ordered alphabetically. \\n - If the system has sites with partial occupation and the total occupations of each element do not all sum up to integers, then the Hill formula SHOULD be handled as unset. \\n - No spaces or separators are allowed. \\n\\n - **Examples**: \\n - `\"H2O2\"` \\n\\n - **Query examples**: \\n - A filter that matches an exactly given formula is `chemical_formula_hill=\"H2O2\"`.' , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , regex = CHEMICAL_FORMULA_REGEXP ) class-attribute \u00b6 chemical_formula_reduced : Optional [ str ] = OptimadeField ( Ellipsis , description = 'The reduced chemical formula for a structure as a string with element symbols and integer chemical proportion numbers. \\n The proportion number MUST be omitted if it is 1. \\n\\n - **Type**: string \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property. \\n However, support for filters using partial string matching with this property is OPTIONAL (i.e., BEGINS WITH, ENDS WITH, and CONTAINS). \\n Intricate queries on formula components are instead suggested to be formulated using set-type filter operators on the multi valued `elements` and `elements_ratios` properties. \\n - Element symbols MUST have proper capitalization (e.g., `\"Si\"`, not `\"SI\"` for \"silicon\"). \\n - Elements MUST be placed in alphabetical order, followed by their integer chemical proportion number. \\n - For structures with no partial occupation, the chemical proportion numbers are the smallest integers for which the chemical proportion is exactly correct. \\n - For structures with partial occupation, the chemical proportion numbers are integers that within reasonable approximation indicate the correct chemical proportions. The precise details of how to perform the rounding is chosen by the API implementation. \\n - No spaces or separators are allowed. \\n\\n - **Examples**: \\n - `\"H2NaO\"` \\n - `\"ClNa\"` \\n - `\"CCaO3\"` \\n\\n - **Query examples**: \\n - A filter that matches an exactly given formula is `chemical_formula_reduced=\"H2NaO\"`.' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , regex = CHEMICAL_FORMULA_REGEXP ) class-attribute \u00b6 dimension_types : Optional [ conlist ( Periodicity , min_items = 3 , max_items = 3 )] = OptimadeField ( None , title = 'Dimension Types' , description = 'List of three integers. \\n For each of the three directions indicated by the three lattice vectors (see property `lattice_vectors`), this list indicates if the direction is periodic (value `1`) or non-periodic (value `0`). \\n Note: the elements in this list each refer to the direction of the corresponding entry in `lattice_vectors` and *not* the Cartesian x, y, z directions. \\n\\n - **Type**: list of integers. \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n - MUST be a list of length 3. \\n - Each integer element MUST assume only the value 0 or 1. \\n\\n - **Examples**: \\n - For a molecule: `[0, 0, 0]` \\n - For a wire along the direction specified by the third lattice vector: `[0, 0, 1]` \\n - For a 2D surface/slab, periodic on the plane defined by the first and third lattice vectors: `[1, 0, 1]` \\n - For a bulk 3D system: `[1, 1, 1]`' , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 elements : Optional [ List [ str ]] = OptimadeField ( Ellipsis , description = 'The chemical symbols of the different elements present in the structure. \\n\\n - **Type**: list of strings. \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - The strings are the chemical symbols, i.e., either a single uppercase letter or an uppercase letter followed by a number of lowercase letters. \\n - The order MUST be alphabetical. \\n - MUST refer to the same elements in the same order, and therefore be of the same length, as `elements_ratios`, if the latter is provided. \\n - Note: This property SHOULD NOT contain the string \"X\" to indicate non-chemical elements or \"vacancy\" to indicate vacancies (in contrast to the field `chemical_symbols` for the `species` property). \\n\\n - **Examples**: \\n - `[\"Si\"]` \\n - `[\"Al\",\"O\",\"Si\"]` \\n\\n - **Query examples**: \\n - A filter that matches all records of structures that contain Si, Al **and** O, and possibly other elements: `elements HAS ALL \"Si\", \"Al\", \"O\"`. \\n - To match structures with exactly these three elements, use `elements HAS ALL \"Si\", \"Al\", \"O\" AND elements LENGTH 3`. \\n - Note: length queries on this property can be equivalently formulated by filtering on the `nelements`_ property directly.' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST ) class-attribute \u00b6 elements_ratios : Optional [ List [ float ]] = OptimadeField ( Ellipsis , description = 'Relative proportions of different elements in the structure. \\n\\n - **Type**: list of floats \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - Composed by the proportions of elements in the structure as a list of floating point numbers. \\n - The sum of the numbers MUST be 1.0 (within floating point accuracy) \\n - MUST refer to the same elements in the same order, and therefore be of the same length, as `elements`, if the latter is provided. \\n\\n - **Examples**: \\n - `[1.0]` \\n - `[0.3333333333333333, 0.2222222222222222, 0.4444444444444444]` \\n\\n - **Query examples**: \\n - Note: Useful filters can be formulated using the set operator syntax for correlated values. \\n However, since the values are floating point values, the use of equality comparisons is generally inadvisable. \\n - OPTIONAL: a filter that matches structures where approximately 1/3 of the atoms in the structure are the element Al is: `elements:elements_ratios HAS ALL \"Al\":>0.3333, \"Al\":<0.3334`.' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST ) class-attribute \u00b6 lattice_vectors : Optional [ conlist ( Vector3D_unknown , min_items = 3 , max_items = 3 )] = OptimadeField ( None , description = \"The three lattice vectors in Cartesian coordinates, in \u00e5ngstr\u00f6m (\u00c5). \\n\\n - **Type**: list of list of floats or unknown values. \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n If supported, filters MAY support only a subset of comparison operators. \\n - MUST be a list of three vectors *a*, *b*, and *c*, where each of the vectors MUST BE a list of the vector's coordinates along the x, y, and z Cartesian coordinates. \\n (Therefore, the first index runs over the three lattice vectors and the second index runs over the x, y, z Cartesian coordinates). \\n - For databases that do not define an absolute Cartesian system (e.g., only defining the length and angles between vectors), the first lattice vector SHOULD be set along *x* and the second on the *xy*-plane. \\n - MUST always contain three vectors of three coordinates each, independently of the elements of property `dimension_types`. \\n The vectors SHOULD by convention be chosen so the determinant of the `lattice_vectors` matrix is different from zero. \\n The vectors in the non-periodic directions have no significance beyond fulfilling these requirements. \\n - The coordinates of the lattice vectors of non-periodic dimensions (i.e., those dimensions for which `dimension_types` is `0`) MAY be given as a list of all `null` values. \\n If a lattice vector contains the value `null`, all coordinates of that lattice vector MUST be `null`. \\n\\n - **Examples**: \\n - `[[4.0,0.0,0.0],[0.0,4.0,0.0],[0.0,1.0,4.0]]` represents a cell, where the first vector is `(4, 0, 0)`, i.e., a vector aligned along the `x` axis of length 4 \u00c5; the second vector is `(0, 4, 0)`; and the third vector is `(0, 1, 4)`.\" , unit = '\u00c5' , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 nelements : Optional [ int ] = OptimadeField ( Ellipsis , description = 'Number of different elements in the structure as an integer. \\n\\n - **Type**: integer \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - MUST be equal to the lengths of the list properties `elements` and `elements_ratios`, if they are provided. \\n\\n - **Examples**: \\n - `3` \\n\\n - **Querying**: \\n - Note: queries on this property can equivalently be formulated using `elements LENGTH`. \\n - A filter that matches structures that have exactly 4 elements: `nelements=4`. \\n - A filter that matches structures that have between 2 and 7 elements: `nelements>=2 AND nelements<=7`.' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST ) class-attribute \u00b6 nperiodic_dimensions : Optional [ int ] = OptimadeField ( Ellipsis , description = 'An integer specifying the number of periodic dimensions in the structure, equivalent to the number of non-zero entries in `dimension_types`. \\n\\n - **Type**: integer \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n - The integer value MUST be between 0 and 3 inclusive and MUST be equal to the sum of the items in the `dimension_types` property. \\n - This property only reflects the treatment of the lattice vectors provided for the structure, and not any physical interpretation of the dimensionality of its contents. \\n\\n - **Examples**: \\n - `2` should be indicated in cases where `dimension_types` is any of `[1, 1, 0]`, `[1, 0, 1]`, `[0, 1, 1]`. \\n\\n - **Query examples**: \\n - Match only structures with exactly 3 periodic dimensions: `nperiodic_dimensions=3` \\n - Match all structures with 2 or fewer periodic dimensions: `nperiodic_dimensions<=2`' , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST ) class-attribute \u00b6 nsites : Optional [ int ] = OptimadeField ( Ellipsis , description = 'An integer specifying the length of the `cartesian_site_positions` property. \\n\\n - **Type**: integer \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: MUST be a queryable property with support for all mandatory filter features. \\n\\n - **Examples**: \\n - `42` \\n\\n - **Query examples**: \\n - Match only structures with exactly 4 sites: `nsites=4` \\n - Match structures that have between 2 and 7 sites: `nsites>=2 AND nsites<=7`' , queryable = SupportLevel . MUST , support = SupportLevel . SHOULD ) class-attribute \u00b6 species : Optional [ List [ Species ]] = OptimadeField ( Ellipsis , description = 'A list describing the species of the sites of this structure. \\n Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). \\n\\n - **Type**: list of dictionary with keys: \\n - `name`: string (REQUIRED) \\n - `chemical_symbols`: list of strings (REQUIRED) \\n - `concentration`: list of float (REQUIRED) \\n - `attached`: list of strings (REQUIRED) \\n - `nattached`: list of integers (OPTIONAL) \\n - `mass`: list of floats (OPTIONAL) \\n - `original_name`: string (OPTIONAL). \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n If supported, filters MAY support only a subset of comparison operators. \\n - Each list member MUST be a dictionary with the following keys: \\n - **name**: REQUIRED; gives the name of the species; the **name** value MUST be unique in the `species` list; \\n - **chemical_symbols**: REQUIRED; MUST be a list of strings of all chemical elements composing this species. \\n Each item of the list MUST be one of the following: \\n - a valid chemical-element symbol, or \\n - the special value `\"X\"` to represent a non-chemical element, or \\n - the special value `\"vacancy\"` to represent that this site has a non-zero probability of having a vacancy (the respective probability is indicated in the `concentration` list, see below). \\n\\n If any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element, the correct flag MUST be set in the list `structure_features`. \\n\\n - **concentration**: REQUIRED; MUST be a list of floats, with same length as `chemical_symbols`. \\n The numbers represent the relative concentration of the corresponding chemical symbol in this species. \\n The numbers SHOULD sum to one. Cases in which the numbers do not sum to one typically fall only in the following two categories: \\n\\n - Numerical errors when representing float numbers in fixed precision, e.g. for two chemical symbols with concentrations `1/3` and `2/3`, the concentration might look something like `[0.33333333333, 0.66666666666]`. If the client is aware that the sum is not one because of numerical precision, it can renormalize the values so that the sum is exactly one. \\n - Experimental errors in the data present in the database. In this case, it is the responsibility of the client to decide how to process the data. \\n\\n Note that concentrations are uncorrelated between different sites (even of the same species). \\n\\n - **attached**: OPTIONAL; if provided MUST be a list of length 1 or more of strings of chemical symbols for the elements attached to this site, or \"X\" for a non-chemical element. \\n\\n - **nattached**: OPTIONAL; if provided MUST be a list of length 1 or more of integers indicating the number of attached atoms of the kind specified in the value of the `attached` key. \\n\\n The implementation MUST include either both or none of the `attached` and `nattached` keys, and if they are provided, they MUST be of the same length. \\n Furthermore, if they are provided, the `structure_features` property MUST include the string `site_attachments`. \\n\\n - **mass**: OPTIONAL. If present MUST be a list of floats, with the same length as `chemical_symbols`, providing element masses expressed in a.m.u. \\n Elements denoting vacancies MUST have masses equal to 0. \\n\\n - **original_name**: OPTIONAL. Can be any valid Unicode string, and SHOULD contain (if specified) the name of the species that is used internally in the source database. \\n\\n Note: With regards to \"source database\", we refer to the immediate source being queried via the OPTIMADE API implementation. \\n\\n The main use of this field is for source databases that use species names, containing characters that are not allowed (see description of the list property `species_at_sites`). \\n\\n - For systems that have only species formed by a single chemical symbol, and that have at most one species per chemical symbol, SHOULD use the chemical symbol as species name (e.g., `\"Ti\"` for titanium, `\"O\"` for oxygen, etc.) \\n However, note that this is OPTIONAL, and client implementations MUST NOT assume that the key corresponds to a chemical symbol, nor assume that if the species name is a valid chemical symbol, that it represents a species with that chemical symbol. \\n This means that a species `{\"name\": \"C\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]}` is valid and represents a titanium species (and *not* a carbon species). \\n - It is NOT RECOMMENDED that a structure includes species that do not have at least one corresponding site. \\n\\n - **Examples**: \\n - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ]`: any site with this species is occupied by a Ti atom. \\n - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ]`: any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. \\n - `[ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ]`: any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. \\n - `[ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ]`: any site with this species is occupied by a carbon isotope with mass 12. \\n - `[ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ]`: any site with this species is occupied by a carbon isotope with mass 13. \\n - `[ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ]`: any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms.' , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 species_at_sites : Optional [ List [ str ]] = OptimadeField ( Ellipsis , description = 'Name of the species at each site (where values for sites are specified with the same order of the property `cartesian_site_positions`). \\n The properties of the species are found in the property `species`. \\n\\n - **Type**: list of strings. \\n\\n - **Requirements/Conventions**: \\n - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. \\n - **Query**: Support for queries on this property is OPTIONAL. \\n If supported, filters MAY support only a subset of comparison operators. \\n - MUST have length equal to the number of sites in the structure (first dimension of the list property `cartesian_site_positions`). \\n - Each species name mentioned in the `species_at_sites` list MUST be described in the list property `species` (i.e. for each value in the `species_at_sites` list there MUST exist exactly one dictionary in the `species` list with the `name` attribute equal to the corresponding `species_at_sites` value). \\n - Each site MUST be associated only to a single species. \\n **Note**: However, species can represent mixtures of atoms, and multiple species MAY be defined for the same chemical element. \\n This latter case is useful when different atoms of the same type need to be grouped or distinguished, for instance in simulation codes to assign different initial spin states. \\n\\n - **Examples**: \\n - `[\"Ti\",\"O2\"]` indicates that the first site is hosting a species labeled `\"Ti\"` and the second a species labeled `\"O2\"`. \\n - `[\"Ac\", \"Ac\", \"Ag\", \"Ir\"]` indicating the first two sites contains the `\"Ac\"` species, while the third and fourth sites contain the `\"Ag\"` and `\"Ir\"` species, respectively.' , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL ) class-attribute \u00b6 structure_features : List [ StructureFeatures ] = OptimadeField ( Ellipsis , title = 'Structure Features' , description = 'A list of strings that flag which special features are used by the structure. \\n\\n - **Type**: list of strings \\n\\n - **Requirements/Conventions**: \\n - **Support**: MUST be supported by all implementations, MUST NOT be `null`. \\n - **Query**: MUST be a queryable property. \\n Filters on the list MUST support all mandatory HAS-type queries. \\n Filter operators for comparisons on the string components MUST support equality, support for other comparison operators are OPTIONAL. \\n - MUST be an empty list if no special features are used. \\n - MUST be sorted alphabetically. \\n - If a special feature listed below is used, the list MUST contain the corresponding string. \\n - If a special feature listed below is not used, the list MUST NOT contain the corresponding string. \\n - **List of strings used to indicate special structure features**: \\n - `disorder`: this flag MUST be present if any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element. \\n - `implicit_atoms`: this flag MUST be present if the structure contains atoms that are not assigned to sites via the property `species_at_sites` (e.g., because their positions are unknown). \\n When this flag is present, the properties related to the chemical formula will likely not match the type and count of atoms represented by the `species_at_sites`, `species` and `assemblies` properties. \\n - `site_attachments`: this flag MUST be present if any one entry in the `species` list includes `attached` and `nattached`. \\n - `assemblies`: this flag MUST be present if the property `assemblies` is present. \\n\\n - **Examples**: A structure having implicit atoms and using assemblies: `[\"assemblies\", \"implicit_atoms\"]`' , support = SupportLevel . MUST , queryable = SupportLevel . MUST ) class-attribute \u00b6 Config \u00b6 Source code in optimade/models/structures.py 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 class Config : def schema_extra ( schema , model ): \"\"\"Two things need to be added to the schema: 1. Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, `dimension_types` and `lattice_vectors`, are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. 2. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be `nullable` according to the OpenAPI definition. \"\"\" schema [ \"required\" ] . insert ( 7 , \"dimension_types\" ) schema [ \"required\" ] . insert ( 9 , \"lattice_vectors\" ) nullable_props = ( prop for prop in schema [ \"required\" ] if schema [ \"properties\" ][ prop ] . get ( \"x-optimade-support\" ) == SupportLevel . SHOULD ) for prop in nullable_props : schema [ \"properties\" ][ prop ][ \"nullable\" ] = True schema_extra ( schema , model ) \u00b6 Two things need to be added to the schema: Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, dimension_types and lattice_vectors , are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be nullable according to the OpenAPI definition. Source code in optimade/models/structures.py 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 def schema_extra ( schema , model ): \"\"\"Two things need to be added to the schema: 1. Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, `dimension_types` and `lattice_vectors`, are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. 2. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be `nullable` according to the OpenAPI definition. \"\"\" schema [ \"required\" ] . insert ( 7 , \"dimension_types\" ) schema [ \"required\" ] . insert ( 9 , \"lattice_vectors\" ) nullable_props = ( prop for prop in schema [ \"required\" ] if schema [ \"properties\" ][ prop ] . get ( \"x-optimade-support\" ) == SupportLevel . SHOULD ) for prop in nullable_props : schema [ \"properties\" ][ prop ][ \"nullable\" ] = True check_anonymous_formula ( v ) \u00b6 Source code in optimade/models/structures.py 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 @validator ( \"chemical_formula_anonymous\" ) def check_anonymous_formula ( cls , v ): if v is None : return v elements = tuple ( re . findall ( r \"[A-Z][a-z]*\" , v )) numbers = re . split ( r \"[A-Z][a-z]*\" , v )[ 1 :] numbers = [ int ( i ) if i else 1 for i in numbers ] expected_labels = ANONYMOUS_ELEMENTS [: len ( elements )] expected_numbers = sorted ( numbers , reverse = True ) if expected_numbers != numbers : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong order: elements with highest proportion should appear first: { numbers } vs expected { expected_numbers } \" ) if elements != expected_labels : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong labels: { elements } vs expected { expected_labels } .\" ) return v check_ordered_formula ( v , field ) \u00b6 Source code in optimade/models/structures.py 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 @validator ( \"chemical_formula_reduced\" , \"chemical_formula_hill\" ) def check_ordered_formula ( cls , v , field ): if v is None : return v elements = re . findall ( r \"[A-Z][a-z]?\" , v ) expected_elements = sorted ( elements ) if field . name == \"chemical_formula_hill\" : # Make sure C is first (and H is second, if present along with C). if \"C\" in expected_elements : expected_elements = sorted ( expected_elements , key = lambda elem : { \"C\" : \"0\" , \"H\" : \"1\" } . get ( elem , elem ), ) if any ( elem not in CHEMICAL_SYMBOLS for elem in elements ): raise ValueError ( f \"Cannot use unknown chemical symbols { [ elem for elem in elements if elem not in CHEMICAL_SYMBOLS ] } in { field . name !r} \" ) if expected_elements != elements : order = \"Hill\" if field . name == \"chemical_formula_hill\" else \"alphabetical\" raise ValueError ( f \"Elements in { field . name !r} must appear in { order } order: { expected_elements } not { elements } .\" ) return v check_periodic_dimensions ( v , values ) \u00b6 Source code in optimade/models/structures.py 940 941 942 943 944 945 946 947 948 949 950 951 @validator ( \"nperiodic_dimensions\" ) def check_periodic_dimensions ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ) and v != sum ( values . get ( \"dimension_types\" )): raise ValueError ( f \"nperiodic_dimensions ( { v } ) does not match expected value of { sum ( values [ 'dimension_types' ]) } \" f \"from dimension_types ( { values [ 'dimension_types' ] } )\" ) return v check_reduced_formulae ( value , field ) \u00b6 Source code in optimade/models/structures.py 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 @validator ( \"chemical_formula_anonymous\" , \"chemical_formula_reduced\" ) def check_reduced_formulae ( cls , value , field ): if value is None : return value numbers = [ n . strip () or 1 for n in re . split ( r \"[A-Z][a-z]*\" , value )] # Need to remove leading 1 from split and convert to ints numbers = [ int ( n ) for n in numbers [ 1 :]] if sys . version_info [ 1 ] >= 9 : gcd = math . gcd ( * numbers ) else : gcd = reduce ( math . gcd , numbers ) if gcd != 1 : raise ValueError ( f \" { field . name } { value !r} is not properly reduced: greatest common divisor was { gcd } , expected 1.\" ) return value element_must_be_chemical_symbol ( v ) \u00b6 Source code in optimade/models/structures.py 914 915 916 917 918 @validator ( \"elements\" , each_item = True ) def element_must_be_chemical_symbol ( cls , v ): if v not in CHEMICAL_SYMBOLS : raise ValueError ( f \"Only chemical symbols are allowed, you passed: { v } \" ) return v elements_must_be_alphabetical ( v ) \u00b6 Source code in optimade/models/structures.py 920 921 922 923 924 925 926 927 @validator ( \"elements\" ) def elements_must_be_alphabetical ( cls , v ): if v is None : return v if sorted ( v ) != v : raise ValueError ( f \"elements must be sorted alphabetically, but is: { v } \" ) return v null_values_for_whole_vector ( v ) \u00b6 Source code in optimade/models/structures.py 968 969 970 971 972 973 974 975 976 977 978 @validator ( \"lattice_vectors\" ) def null_values_for_whole_vector ( cls , v ): if v is None : return v for vector in v : if None in vector and any (( isinstance ( _ , float ) for _ in vector )): raise ValueError ( f \"A lattice vector MUST be either all `null` or all numbers (vector: { vector } , all vectors: { v } )\" ) return v ratios_must_sum_to_one ( v ) \u00b6 Source code in optimade/models/structures.py 929 930 931 932 933 934 935 936 937 938 @validator ( \"elements_ratios\" ) def ratios_must_sum_to_one ( cls , v ): if v is None : return v if abs ( sum ( v ) - 1 ) > EPS : raise ValueError ( f \"elements_ratios MUST sum to 1 within (at least single precision) floating point accuracy. It sums to: { sum ( v ) } \" ) return v required_if_dimension_types_has_one ( v , values ) \u00b6 Source code in optimade/models/structures.py 953 954 955 956 957 958 959 960 961 962 963 964 965 966 @validator ( \"lattice_vectors\" , always = True ) def required_if_dimension_types_has_one ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ): for dim_type , vector in zip ( values . get ( \"dimension_types\" , ( None ,) * 3 ), v ): if None in vector and dim_type == Periodicity . PERIODIC . value : raise ValueError ( f \"Null entries in lattice vectors are only permitted when the corresponding dimension type is { Periodicity . APERIODIC . value } . \" f \"Here: dimension_types = { tuple ( getattr ( _ , 'value' , None ) for _ in values . get ( 'dimension_types' , [])) } , lattice_vectors = { v } \" ) return v validate_nsites ( v , values ) \u00b6 Source code in optimade/models/structures.py 980 981 982 983 984 985 986 987 988 989 990 991 992 @validator ( \"nsites\" ) def validate_nsites ( cls , v , values ): if v is None : return v if values . get ( \"cartesian_site_positions\" ) and v != len ( values . get ( \"cartesian_site_positions\" , []) ): raise ValueError ( f \"nsites (value: { v } ) MUST equal length of cartesian_site_positions \" f \"(value: { len ( values . get ( 'cartesian_site_positions' , [])) } )\" ) return v validate_species ( v ) \u00b6 Source code in optimade/models/structures.py 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 @validator ( \"species\" ) def validate_species ( cls , v ): if v is None : return v all_species = [ _ . name for _ in v ] unique_species = set ( all_species ) if len ( all_species ) != len ( unique_species ): raise ValueError ( f \"Species MUST be unique based on their 'name'. Found species names: { all_species } \" ) return v validate_species_at_sites ( v , values ) \u00b6 Source code in optimade/models/structures.py 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 @validator ( \"species_at_sites\" ) def validate_species_at_sites ( cls , v , values ): if v is None : return v if values . get ( \"nsites\" ) and len ( v ) != values . get ( \"nsites\" ): raise ValueError ( f \"Number of species_at_sites (value: { len ( v ) } ) MUST equal number of sites \" f \"(value: { values . get ( 'nsites' , 'Not specified' ) } )\" ) if values . get ( \"species\" ): all_species_names = { getattr ( _ , \"name\" , None ) for _ in values . get ( \"species\" , [{}]) } all_species_names -= { None } for value in v : if value not in all_species_names : raise ValueError ( \"species_at_sites MUST be represented by a species' name, \" f \"but { value } was not found in the list of species names: { all_species_names } \" ) return v validate_structure_features ( v , values ) \u00b6 Source code in optimade/models/structures.py 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 @validator ( \"structure_features\" , always = True ) def validate_structure_features ( cls , v , values ): if [ StructureFeatures ( value ) for value in sorted (( _ . value for _ in v ))] != v : raise ValueError ( f \"structure_features MUST be sorted alphabetically, given value: { v } \" ) # assemblies if values . get ( \"assemblies\" ) is not None : if StructureFeatures . ASSEMBLIES not in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST be present, since the property of the same name is present\" ) elif StructureFeatures . ASSEMBLIES in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST NOT be present, \" \"since the property of the same name is not present\" ) if values . get ( \"species\" ): # disorder for species in values . get ( \"species\" , []): if len ( species . chemical_symbols ) > 1 : if StructureFeatures . DISORDER not in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST be present when any one entry in species \" \"has a chemical_symbols list greater than one element\" ) break else : if StructureFeatures . DISORDER in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST NOT be present, since all species' chemical_symbols \" \"lists are equal to or less than one element\" ) # site_attachments for species in values . get ( \"species\" , []): # There is no need to also test \"nattached\", # since a Species validator makes sure either both are present or both are None. if getattr ( species , \"attached\" , None ) is not None : if StructureFeatures . SITE_ATTACHMENTS not in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST be present when any one entry \" \"in species includes attached and nattached\" ) break else : if StructureFeatures . SITE_ATTACHMENTS in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST NOT be present, since no species includes \" \"the attached and nattached fields\" ) # implicit_atoms species_names = [ _ . name for _ in values . get ( \"species\" , [])] for name in species_names : if values . get ( \"species_at_sites\" ) is not None and name not in values . get ( \"species_at_sites\" , []): if StructureFeatures . IMPLICIT_ATOMS not in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST be present when any one entry in species \" \"is not represented in species_at_sites\" ) break else : if StructureFeatures . IMPLICIT_ATOMS in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST NOT be present, since all species are \" \"represented in species_at_sites\" ) return v warn_on_missing_correlated_fields ( values ) \u00b6 Emit warnings if a field takes a null value when a value was expected based on the value/nullity of another field. Source code in optimade/models/structures.py 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 @root_validator ( pre = True ) def warn_on_missing_correlated_fields ( cls , values ): \"\"\"Emit warnings if a field takes a null value when a value was expected based on the value/nullity of another field. \"\"\" accumulated_warnings = [] for field_set in CORRELATED_STRUCTURE_FIELDS : missing_fields = { f for f in field_set if values . get ( f ) is None } if missing_fields and len ( missing_fields ) != len ( field_set ): accumulated_warnings += [ f \"Structure with values { values } is missing fields { missing_fields } which are required if { field_set - missing_fields } are present.\" ] for warn in accumulated_warnings : warnings . warn ( warn , MissingExpectedField ) return values","title":"structures"},{"location":"api_reference/models/structures/#structures","text":"","title":"structures"},{"location":"api_reference/models/structures/#optimade.models.structures.CORRELATED_STRUCTURE_FIELDS","text":"","title":"CORRELATED_STRUCTURE_FIELDS"},{"location":"api_reference/models/structures/#optimade.models.structures.EPS","text":"","title":"EPS"},{"location":"api_reference/models/structures/#optimade.models.structures.EXTENDED_CHEMICAL_SYMBOLS","text":"","title":"EXTENDED_CHEMICAL_SYMBOLS"},{"location":"api_reference/models/structures/#optimade.models.structures.Vector3D","text":"","title":"Vector3D"},{"location":"api_reference/models/structures/#optimade.models.structures.Vector3D_unknown","text":"","title":"Vector3D_unknown"},{"location":"api_reference/models/structures/#optimade.models.structures.Assembly","text":"A description of groups of sites that are statistically correlated. Examples (for each entry of the assemblies list): {\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]} : the first site and the second site never occur at the same time in the unit cell. Statistically, 30 % of the times the first site is present, while 70 % of the times the second site is present. {\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]} : the second and third site are either present together or not present; they form the first group of atoms for this assembly. The second group is formed by the fourth site. Sites of the first group (the second and the third) are never present at the same time as the fourth site. 30 % of times sites 1 and 2 are present (and site 3 is absent); 70 % of times site 3 is present (and sites 1 and 2 are absent). Source code in optimade/models/structures.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 class Assembly ( BaseModel ): \"\"\"A description of groups of sites that are statistically correlated. - **Examples** (for each entry of the assemblies list): - `{\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]}`: the first site and the second site never occur at the same time in the unit cell. Statistically, 30 % of the times the first site is present, while 70 % of the times the second site is present. - `{\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]}`: the second and third site are either present together or not present; they form the first group of atoms for this assembly. The second group is formed by the fourth site. Sites of the first group (the second and the third) are never present at the same time as the fourth site. 30 % of times sites 1 and 2 are present (and site 3 is absent); 70 % of times site 3 is present (and sites 1 and 2 are absent). \"\"\" sites_in_groups : List [ List [ int ]] = OptimadeField ( ... , description = \"\"\"Index of the sites (0-based) that belong to each group for each assembly. - **Examples**: - `[[1], [2]]`: two groups, one with the second site, one with the third. - `[[1,2], [3]]`: one group with the second and third site, one with the fourth.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) group_probabilities : List [ float ] = OptimadeField ( ... , description = \"\"\"Statistical probability of each group. It MUST have the same length as `sites_in_groups`. It SHOULD sum to one. See below for examples of how to specify the probability of the occurrence of a vacancy. The possible reasons for the values not to sum to one are the same as already specified above for the `concentration` of each `species`.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) @validator ( \"sites_in_groups\" ) def validate_sites_in_groups ( cls , v ): sites = [] for group in v : sites . extend ( group ) if len ( set ( sites )) != len ( sites ): raise ValueError ( f \"A site MUST NOT appear in more than one group. Given value: { v } \" ) return v @validator ( \"group_probabilities\" ) def check_self_consistency ( cls , v , values ): if len ( v ) != len ( values . get ( \"sites_in_groups\" , [])): raise ValueError ( f \"sites_in_groups and group_probabilities MUST be of same length, \" f \"but are { len ( values . get ( 'sites_in_groups' , [])) } and { len ( v ) } , respectively\" ) return v","title":"Assembly"},{"location":"api_reference/models/structures/#optimade.models.structures.Assembly.group_probabilities","text":"","title":"group_probabilities"},{"location":"api_reference/models/structures/#optimade.models.structures.Assembly.sites_in_groups","text":"","title":"sites_in_groups"},{"location":"api_reference/models/structures/#optimade.models.structures.Assembly.check_self_consistency","text":"Source code in optimade/models/structures.py 247 248 249 250 251 252 253 254 @validator ( \"group_probabilities\" ) def check_self_consistency ( cls , v , values ): if len ( v ) != len ( values . get ( \"sites_in_groups\" , [])): raise ValueError ( f \"sites_in_groups and group_probabilities MUST be of same length, \" f \"but are { len ( values . get ( 'sites_in_groups' , [])) } and { len ( v ) } , respectively\" ) return v","title":"check_self_consistency()"},{"location":"api_reference/models/structures/#optimade.models.structures.Assembly.validate_sites_in_groups","text":"Source code in optimade/models/structures.py 236 237 238 239 240 241 242 243 244 245 @validator ( \"sites_in_groups\" ) def validate_sites_in_groups ( cls , v ): sites = [] for group in v : sites . extend ( group ) if len ( set ( sites )) != len ( sites ): raise ValueError ( f \"A site MUST NOT appear in more than one group. Given value: { v } \" ) return v","title":"validate_sites_in_groups()"},{"location":"api_reference/models/structures/#optimade.models.structures.Periodicity","text":"Integer enumeration of dimension_types values Source code in optimade/models/structures.py 46 47 48 49 50 class Periodicity ( IntEnum ): \"\"\"Integer enumeration of dimension_types values\"\"\" APERIODIC = 0 PERIODIC = 1","title":"Periodicity"},{"location":"api_reference/models/structures/#optimade.models.structures.Periodicity.APERIODIC","text":"","title":"APERIODIC"},{"location":"api_reference/models/structures/#optimade.models.structures.Periodicity.PERIODIC","text":"","title":"PERIODIC"},{"location":"api_reference/models/structures/#optimade.models.structures.Species","text":"A list describing the species of the sites of this structure. Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). Examples : [ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ] : any site with this species is occupied by a Ti atom. [ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ] : any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. [ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ] : any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. [ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ] : any site with this species is occupied by a carbon isotope with mass 12. [ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ] : any site with this species is occupied by a carbon isotope with mass 13. [ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ] : any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms. Source code in optimade/models/structures.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 class Species ( BaseModel ): \"\"\"A list describing the species of the sites of this structure. Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). - **Examples**: - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ]`: any site with this species is occupied by a Ti atom. - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ]`: any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. - `[ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ]`: any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. - `[ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ]`: any site with this species is occupied by a carbon isotope with mass 12. - `[ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ]`: any site with this species is occupied by a carbon isotope with mass 13. - `[ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ]`: any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms. \"\"\" name : str = OptimadeField ( ... , description = \"\"\"Gives the name of the species; the **name** value MUST be unique in the `species` list.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) chemical_symbols : List [ str ] = OptimadeField ( ... , description = \"\"\"MUST be a list of strings of all chemical elements composing this species. Each item of the list MUST be one of the following: - a valid chemical-element symbol, or - the special value `\"X\"` to represent a non-chemical element, or - the special value `\"vacancy\"` to represent that this site has a non-zero probability of having a vacancy (the respective probability is indicated in the `concentration` list, see below). If any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element, the correct flag MUST be set in the list `structure_features`.\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) concentration : List [ float ] = OptimadeField ( ... , description = \"\"\"MUST be a list of floats, with same length as `chemical_symbols`. The numbers represent the relative concentration of the corresponding chemical symbol in this species. The numbers SHOULD sum to one. Cases in which the numbers do not sum to one typically fall only in the following two categories: - Numerical errors when representing float numbers in fixed precision, e.g. for two chemical symbols with concentrations `1/3` and `2/3`, the concentration might look something like `[0.33333333333, 0.66666666666]`. If the client is aware that the sum is not one because of numerical precision, it can renormalize the values so that the sum is exactly one. - Experimental errors in the data present in the database. In this case, it is the responsibility of the client to decide how to process the data. Note that concentrations are uncorrelated between different site (even of the same species).\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . OPTIONAL , ) mass : Optional [ List [ float ]] = OptimadeField ( None , description = \"\"\"If present MUST be a list of floats expressed in a.m.u. Elements denoting vacancies MUST have masses equal to 0.\"\"\" , unit = \"a.m.u.\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) original_name : Optional [ str ] = OptimadeField ( None , description = \"\"\"Can be any valid Unicode string, and SHOULD contain (if specified) the name of the species that is used internally in the source database. Note: With regards to \"source database\", we refer to the immediate source being queried via the OPTIMADE API implementation.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) attached : Optional [ List [ str ]] = OptimadeField ( None , description = \"\"\"If provided MUST be a list of length 1 or more of strings of chemical symbols for the elements attached to this site, or \"X\" for a non-chemical element.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) nattached : Optional [ List [ int ]] = OptimadeField ( None , description = \"\"\"If provided MUST be a list of length 1 or more of integers indicating the number of attached atoms of the kind specified in the value of the :field:`attached` key.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) @validator ( \"chemical_symbols\" , each_item = True ) def validate_chemical_symbols ( cls , v ): if v not in EXTENDED_CHEMICAL_SYMBOLS : raise ValueError ( f ' { v !r} MUST be an element symbol, e.g., \"C\", \"He\", or a special symbol from { EXTRA_SYMBOLS } .' ) return v @validator ( \"concentration\" , \"mass\" ) def validate_concentration_and_mass ( cls , v , values , field ): if not v : return v if values . get ( \"chemical_symbols\" ): if len ( v ) != len ( values [ \"chemical_symbols\" ]): raise ValueError ( f \"Length of concentration ( { len ( v ) } ) MUST equal length of chemical_symbols \" f \"( { len ( values . get ( 'chemical_symbols' , [])) } )\" ) return v raise ValueError ( f \"Could not validate { field . name !r} as 'chemical_symbols' is missing/invalid.\" ) @validator ( \"attached\" , \"nattached\" ) def validate_minimum_list_length ( cls , v ): if v is not None and len ( v ) < 1 : raise ValueError ( f \"The list's length MUST be 1 or more, instead it was found to be { len ( v ) } \" ) return v @root_validator def attached_nattached_mutually_exclusive ( cls , values ): attached , nattached = ( values . get ( \"attached\" , None ), values . get ( \"nattached\" , None ), ) if ( attached is None and nattached is not None ) or ( attached is not None and nattached is None ): raise ValueError ( f \"Either both or none of attached ( { attached } ) and nattached ( { nattached } ) MUST be set.\" ) if ( attached is not None and nattached is not None and len ( attached ) != len ( nattached ) ): raise ValueError ( f \"attached ( { attached } ) and nattached ( { nattached } ) MUST be lists of equal length.\" ) return values","title":"Species"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.attached","text":"","title":"attached"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.chemical_symbols","text":"","title":"chemical_symbols"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.concentration","text":"","title":"concentration"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.mass","text":"","title":"mass"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.name","text":"","title":"name"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.nattached","text":"","title":"nattached"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.original_name","text":"","title":"original_name"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.attached_nattached_mutually_exclusive","text":"Source code in optimade/models/structures.py 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @root_validator def attached_nattached_mutually_exclusive ( cls , values ): attached , nattached = ( values . get ( \"attached\" , None ), values . get ( \"nattached\" , None ), ) if ( attached is None and nattached is not None ) or ( attached is not None and nattached is None ): raise ValueError ( f \"Either both or none of attached ( { attached } ) and nattached ( { nattached } ) MUST be set.\" ) if ( attached is not None and nattached is not None and len ( attached ) != len ( nattached ) ): raise ValueError ( f \"attached ( { attached } ) and nattached ( { nattached } ) MUST be lists of equal length.\" ) return values","title":"attached_nattached_mutually_exclusive()"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.validate_chemical_symbols","text":"Source code in optimade/models/structures.py 146 147 148 149 150 151 152 @validator ( \"chemical_symbols\" , each_item = True ) def validate_chemical_symbols ( cls , v ): if v not in EXTENDED_CHEMICAL_SYMBOLS : raise ValueError ( f ' { v !r} MUST be an element symbol, e.g., \"C\", \"He\", or a special symbol from { EXTRA_SYMBOLS } .' ) return v","title":"validate_chemical_symbols()"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.validate_concentration_and_mass","text":"Source code in optimade/models/structures.py 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 @validator ( \"concentration\" , \"mass\" ) def validate_concentration_and_mass ( cls , v , values , field ): if not v : return v if values . get ( \"chemical_symbols\" ): if len ( v ) != len ( values [ \"chemical_symbols\" ]): raise ValueError ( f \"Length of concentration ( { len ( v ) } ) MUST equal length of chemical_symbols \" f \"( { len ( values . get ( 'chemical_symbols' , [])) } )\" ) return v raise ValueError ( f \"Could not validate { field . name !r} as 'chemical_symbols' is missing/invalid.\" )","title":"validate_concentration_and_mass()"},{"location":"api_reference/models/structures/#optimade.models.structures.Species.validate_minimum_list_length","text":"Source code in optimade/models/structures.py 170 171 172 173 174 175 176 @validator ( \"attached\" , \"nattached\" ) def validate_minimum_list_length ( cls , v ): if v is not None and len ( v ) < 1 : raise ValueError ( f \"The list's length MUST be 1 or more, instead it was found to be { len ( v ) } \" ) return v","title":"validate_minimum_list_length()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureFeatures","text":"Enumeration of structure_features values Source code in optimade/models/structures.py 53 54 55 56 57 58 59 class StructureFeatures ( Enum ): \"\"\"Enumeration of structure_features values\"\"\" DISORDER = \"disorder\" IMPLICIT_ATOMS = \"implicit_atoms\" SITE_ATTACHMENTS = \"site_attachments\" ASSEMBLIES = \"assemblies\"","title":"StructureFeatures"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureFeatures.ASSEMBLIES","text":"","title":"ASSEMBLIES"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureFeatures.DISORDER","text":"","title":"DISORDER"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureFeatures.IMPLICIT_ATOMS","text":"","title":"IMPLICIT_ATOMS"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureFeatures.SITE_ATTACHMENTS","text":"","title":"SITE_ATTACHMENTS"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResource","text":"Representing a structure. Source code in optimade/models/structures.py 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 class StructureResource ( EntryResource ): \"\"\"Representing a structure.\"\"\" type : str = StrictField ( \"structures\" , description = \"\"\"The name of the type of an entry. - **Type**: string. - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Response**: REQUIRED in the response. - MUST be an existing entry type. - The entry of type `<type>` and ID `<id>` MUST be returned in response to a request for `/<type>/<id>` under the versioned base URL. - **Examples**: - `\"structures\"`\"\"\" , regex = \"^structures$\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) attributes : StructureResourceAttributes","title":"StructureResource"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResource.attributes","text":"","title":"attributes"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResource.type","text":"","title":"type"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes","text":"This class contains the Field for the attributes used to represent a structure, e.g. unit cell, atoms, positions. Source code in optimade/models/structures.py 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 class StructureResourceAttributes ( EntryResourceAttributes ): \"\"\"This class contains the Field for the attributes used to represent a structure, e.g. unit cell, atoms, positions.\"\"\" elements : Optional [ List [ str ]] = OptimadeField ( ... , description = \"\"\"The chemical symbols of the different elements present in the structure. - **Type**: list of strings. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - The strings are the chemical symbols, i.e., either a single uppercase letter or an uppercase letter followed by a number of lowercase letters. - The order MUST be alphabetical. - MUST refer to the same elements in the same order, and therefore be of the same length, as `elements_ratios`, if the latter is provided. - Note: This property SHOULD NOT contain the string \"X\" to indicate non-chemical elements or \"vacancy\" to indicate vacancies (in contrast to the field `chemical_symbols` for the `species` property). - **Examples**: - `[\"Si\"]` - `[\"Al\",\"O\",\"Si\"]` - **Query examples**: - A filter that matches all records of structures that contain Si, Al **and** O, and possibly other elements: `elements HAS ALL \"Si\", \"Al\", \"O\"`. - To match structures with exactly these three elements, use `elements HAS ALL \"Si\", \"Al\", \"O\" AND elements LENGTH 3`. - Note: length queries on this property can be equivalently formulated by filtering on the `nelements`_ property directly.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) nelements : Optional [ int ] = OptimadeField ( ... , description = \"\"\"Number of different elements in the structure as an integer. - **Type**: integer - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - MUST be equal to the lengths of the list properties `elements` and `elements_ratios`, if they are provided. - **Examples**: - `3` - **Querying**: - Note: queries on this property can equivalently be formulated using `elements LENGTH`. - A filter that matches structures that have exactly 4 elements: `nelements=4`. - A filter that matches structures that have between 2 and 7 elements: `nelements>=2 AND nelements<=7`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) elements_ratios : Optional [ List [ float ]] = OptimadeField ( ... , description = \"\"\"Relative proportions of different elements in the structure. - **Type**: list of floats - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - Composed by the proportions of elements in the structure as a list of floating point numbers. - The sum of the numbers MUST be 1.0 (within floating point accuracy) - MUST refer to the same elements in the same order, and therefore be of the same length, as `elements`, if the latter is provided. - **Examples**: - `[1.0]` - `[0.3333333333333333, 0.2222222222222222, 0.4444444444444444]` - **Query examples**: - Note: Useful filters can be formulated using the set operator syntax for correlated values. However, since the values are floating point values, the use of equality comparisons is generally inadvisable. - OPTIONAL: a filter that matches structures where approximately 1/3 of the atoms in the structure are the element Al is: `elements:elements_ratios HAS ALL \"Al\":>0.3333, \"Al\":<0.3334`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) chemical_formula_descriptive : Optional [ str ] = OptimadeField ( ... , description = \"\"\"The chemical formula for a structure as a string in a form chosen by the API implementation. - **Type**: string - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - The chemical formula is given as a string consisting of properly capitalized element symbols followed by integers or decimal numbers, balanced parentheses, square, and curly brackets `(`,`)`, `[`,`]`, `{`, `}`, commas, the `+`, `-`, `:` and `=` symbols. The parentheses are allowed to be followed by a number. Spaces are allowed anywhere except within chemical symbols. The order of elements and any groupings indicated by parentheses or brackets are chosen freely by the API implementation. - The string SHOULD be arithmetically consistent with the element ratios in the `chemical_formula_reduced` property. - It is RECOMMENDED, but not mandatory, that symbols, parentheses and brackets, if used, are used with the meanings prescribed by [IUPAC's Nomenclature of Organic Chemistry](https://www.qmul.ac.uk/sbcs/iupac/bibliog/blue.html). - **Examples**: - `\"(H2O)2 Na\"` - `\"NaCl\"` - `\"CaCO3\"` - `\"CCaO3\"` - `\"(CH3)3N+ - [CH2]2-OH = Me3N+ - CH2 - CH2OH\"` - **Query examples**: - Note: the free-form nature of this property is likely to make queries on it across different databases inconsistent. - A filter that matches an exactly given formula: `chemical_formula_descriptive=\"(H2O)2 Na\"`. - A filter that does a partial match: `chemical_formula_descriptive CONTAINS \"H2O\"`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) chemical_formula_reduced : Optional [ str ] = OptimadeField ( ... , description = \"\"\"The reduced chemical formula for a structure as a string with element symbols and integer chemical proportion numbers. The proportion number MUST be omitted if it is 1. - **Type**: string - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property. However, support for filters using partial string matching with this property is OPTIONAL (i.e., BEGINS WITH, ENDS WITH, and CONTAINS). Intricate queries on formula components are instead suggested to be formulated using set-type filter operators on the multi valued `elements` and `elements_ratios` properties. - Element symbols MUST have proper capitalization (e.g., `\"Si\"`, not `\"SI\"` for \"silicon\"). - Elements MUST be placed in alphabetical order, followed by their integer chemical proportion number. - For structures with no partial occupation, the chemical proportion numbers are the smallest integers for which the chemical proportion is exactly correct. - For structures with partial occupation, the chemical proportion numbers are integers that within reasonable approximation indicate the correct chemical proportions. The precise details of how to perform the rounding is chosen by the API implementation. - No spaces or separators are allowed. - **Examples**: - `\"H2NaO\"` - `\"ClNa\"` - `\"CCaO3\"` - **Query examples**: - A filter that matches an exactly given formula is `chemical_formula_reduced=\"H2NaO\"`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , regex = CHEMICAL_FORMULA_REGEXP , ) chemical_formula_hill : Optional [ str ] = OptimadeField ( None , description = \"\"\"The chemical formula for a structure in [Hill form](https://dx.doi.org/10.1021/ja02046a005) with element symbols followed by integer chemical proportion numbers. The proportion number MUST be omitted if it is 1. - **Type**: string - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, only a subset of the filter features MAY be supported. - The overall scale factor of the chemical proportions is chosen such that the resulting values are integers that indicate the most chemically relevant unit of which the system is composed. For example, if the structure is a repeating unit cell with four hydrogens and four oxygens that represents two hydroperoxide molecules, `chemical_formula_hill` is `\"H2O2\"` (i.e., not `\"HO\"`, nor `\"H4O4\"`). - If the chemical insight needed to ascribe a Hill formula to the system is not present, the property MUST be handled as unset. - Element symbols MUST have proper capitalization (e.g., `\"Si\"`, not `\"SI\"` for \"silicon\"). - Elements MUST be placed in [Hill order](https://dx.doi.org/10.1021/ja02046a005), followed by their integer chemical proportion number. Hill order means: if carbon is present, it is placed first, and if also present, hydrogen is placed second. After that, all other elements are ordered alphabetically. If carbon is not present, all elements are ordered alphabetically. - If the system has sites with partial occupation and the total occupations of each element do not all sum up to integers, then the Hill formula SHOULD be handled as unset. - No spaces or separators are allowed. - **Examples**: - `\"H2O2\"` - **Query examples**: - A filter that matches an exactly given formula is `chemical_formula_hill=\"H2O2\"`.\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , regex = CHEMICAL_FORMULA_REGEXP , ) chemical_formula_anonymous : Optional [ str ] = OptimadeField ( ... , description = \"\"\"The anonymous formula is the `chemical_formula_reduced`, but where the elements are instead first ordered by their chemical proportion number, and then, in order left to right, replaced by anonymous symbols A, B, C, ..., Z, Aa, Ba, ..., Za, Ab, Bb, ... and so on. - **Type**: string - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property. However, support for filters using partial string matching with this property is OPTIONAL (i.e., BEGINS WITH, ENDS WITH, and CONTAINS). - **Examples**: - `\"A2B\"` - `\"A42B42C16D12E10F9G5\"` - **Querying**: - A filter that matches an exactly given formula is `chemical_formula_anonymous=\"A2B\"`.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , regex = CHEMICAL_FORMULA_REGEXP , ) dimension_types : Optional [ conlist ( Periodicity , min_items = 3 , max_items = 3 ) ] = OptimadeField ( None , title = \"Dimension Types\" , description = \"\"\"List of three integers. For each of the three directions indicated by the three lattice vectors (see property `lattice_vectors`), this list indicates if the direction is periodic (value `1`) or non-periodic (value `0`). Note: the elements in this list each refer to the direction of the corresponding entry in `lattice_vectors` and *not* the Cartesian x, y, z directions. - **Type**: list of integers. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. - MUST be a list of length 3. - Each integer element MUST assume only the value 0 or 1. - **Examples**: - For a molecule: `[0, 0, 0]` - For a wire along the direction specified by the third lattice vector: `[0, 0, 1]` - For a 2D surface/slab, periodic on the plane defined by the first and third lattice vectors: `[1, 0, 1]` - For a bulk 3D system: `[1, 1, 1]`\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) nperiodic_dimensions : Optional [ int ] = OptimadeField ( ... , description = \"\"\"An integer specifying the number of periodic dimensions in the structure, equivalent to the number of non-zero entries in `dimension_types`. - **Type**: integer - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - The integer value MUST be between 0 and 3 inclusive and MUST be equal to the sum of the items in the `dimension_types` property. - This property only reflects the treatment of the lattice vectors provided for the structure, and not any physical interpretation of the dimensionality of its contents. - **Examples**: - `2` should be indicated in cases where `dimension_types` is any of `[1, 1, 0]`, `[1, 0, 1]`, `[0, 1, 1]`. - **Query examples**: - Match only structures with exactly 3 periodic dimensions: `nperiodic_dimensions=3` - Match all structures with 2 or fewer periodic dimensions: `nperiodic_dimensions<=2`\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . MUST , ) lattice_vectors : Optional [ conlist ( Vector3D_unknown , min_items = 3 , max_items = 3 ) ] = OptimadeField ( None , description = \"\"\"The three lattice vectors in Cartesian coordinates, in \u00e5ngstr\u00f6m (\u00c5). - **Type**: list of list of floats or unknown values. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - MUST be a list of three vectors *a*, *b*, and *c*, where each of the vectors MUST BE a list of the vector's coordinates along the x, y, and z Cartesian coordinates. (Therefore, the first index runs over the three lattice vectors and the second index runs over the x, y, z Cartesian coordinates). - For databases that do not define an absolute Cartesian system (e.g., only defining the length and angles between vectors), the first lattice vector SHOULD be set along *x* and the second on the *xy*-plane. - MUST always contain three vectors of three coordinates each, independently of the elements of property `dimension_types`. The vectors SHOULD by convention be chosen so the determinant of the `lattice_vectors` matrix is different from zero. The vectors in the non-periodic directions have no significance beyond fulfilling these requirements. - The coordinates of the lattice vectors of non-periodic dimensions (i.e., those dimensions for which `dimension_types` is `0`) MAY be given as a list of all `null` values. If a lattice vector contains the value `null`, all coordinates of that lattice vector MUST be `null`. - **Examples**: - `[[4.0,0.0,0.0],[0.0,4.0,0.0],[0.0,1.0,4.0]]` represents a cell, where the first vector is `(4, 0, 0)`, i.e., a vector aligned along the `x` axis of length 4 \u00c5; the second vector is `(0, 4, 0)`; and the third vector is `(0, 1, 4)`.\"\"\" , unit = \"\u00c5\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) cartesian_site_positions : Optional [ List [ Vector3D ]] = OptimadeField ( ... , description = \"\"\"Cartesian positions of each site in the structure. A site is usually used to describe positions of atoms; what atoms can be encountered at a given site is conveyed by the `species_at_sites` property, and the species themselves are described in the `species` property. - **Type**: list of list of floats - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - It MUST be a list of length equal to the number of sites in the structure, where every element is a list of the three Cartesian coordinates of a site expressed as float values in the unit angstrom (\u00c5). - An entry MAY have multiple sites at the same Cartesian position (for a relevant use of this, see e.g., the property `assemblies`). - **Examples**: - `[[0,0,0],[0,0,2]]` indicates a structure with two sites, one sitting at the origin and one along the (positive) *z*-axis, 2 \u00c5 away from the origin.\"\"\" , unit = \"\u00c5\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) nsites : Optional [ int ] = OptimadeField ( ... , description = \"\"\"An integer specifying the length of the `cartesian_site_positions` property. - **Type**: integer - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: MUST be a queryable property with support for all mandatory filter features. - **Examples**: - `42` - **Query examples**: - Match only structures with exactly 4 sites: `nsites=4` - Match structures that have between 2 and 7 sites: `nsites>=2 AND nsites<=7`\"\"\" , queryable = SupportLevel . MUST , support = SupportLevel . SHOULD , ) species : Optional [ List [ Species ]] = OptimadeField ( ... , description = \"\"\"A list describing the species of the sites of this structure. Species can represent pure chemical elements, virtual-crystal atoms representing a statistical occupation of a given site by multiple chemical elements, and/or a location to which there are attached atoms, i.e., atoms whose precise location are unknown beyond that they are attached to that position (frequently used to indicate hydrogen atoms attached to another element, e.g., a carbon with three attached hydrogens might represent a methyl group, -CH3). - **Type**: list of dictionary with keys: - `name`: string (REQUIRED) - `chemical_symbols`: list of strings (REQUIRED) - `concentration`: list of float (REQUIRED) - `attached`: list of strings (REQUIRED) - `nattached`: list of integers (OPTIONAL) - `mass`: list of floats (OPTIONAL) - `original_name`: string (OPTIONAL). - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - Each list member MUST be a dictionary with the following keys: - **name**: REQUIRED; gives the name of the species; the **name** value MUST be unique in the `species` list; - **chemical_symbols**: REQUIRED; MUST be a list of strings of all chemical elements composing this species. Each item of the list MUST be one of the following: - a valid chemical-element symbol, or - the special value `\"X\"` to represent a non-chemical element, or - the special value `\"vacancy\"` to represent that this site has a non-zero probability of having a vacancy (the respective probability is indicated in the `concentration` list, see below). If any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element, the correct flag MUST be set in the list `structure_features`. - **concentration**: REQUIRED; MUST be a list of floats, with same length as `chemical_symbols`. The numbers represent the relative concentration of the corresponding chemical symbol in this species. The numbers SHOULD sum to one. Cases in which the numbers do not sum to one typically fall only in the following two categories: - Numerical errors when representing float numbers in fixed precision, e.g. for two chemical symbols with concentrations `1/3` and `2/3`, the concentration might look something like `[0.33333333333, 0.66666666666]`. If the client is aware that the sum is not one because of numerical precision, it can renormalize the values so that the sum is exactly one. - Experimental errors in the data present in the database. In this case, it is the responsibility of the client to decide how to process the data. Note that concentrations are uncorrelated between different sites (even of the same species). - **attached**: OPTIONAL; if provided MUST be a list of length 1 or more of strings of chemical symbols for the elements attached to this site, or \"X\" for a non-chemical element. - **nattached**: OPTIONAL; if provided MUST be a list of length 1 or more of integers indicating the number of attached atoms of the kind specified in the value of the `attached` key. The implementation MUST include either both or none of the `attached` and `nattached` keys, and if they are provided, they MUST be of the same length. Furthermore, if they are provided, the `structure_features` property MUST include the string `site_attachments`. - **mass**: OPTIONAL. If present MUST be a list of floats, with the same length as `chemical_symbols`, providing element masses expressed in a.m.u. Elements denoting vacancies MUST have masses equal to 0. - **original_name**: OPTIONAL. Can be any valid Unicode string, and SHOULD contain (if specified) the name of the species that is used internally in the source database. Note: With regards to \"source database\", we refer to the immediate source being queried via the OPTIMADE API implementation. The main use of this field is for source databases that use species names, containing characters that are not allowed (see description of the list property `species_at_sites`). - For systems that have only species formed by a single chemical symbol, and that have at most one species per chemical symbol, SHOULD use the chemical symbol as species name (e.g., `\"Ti\"` for titanium, `\"O\"` for oxygen, etc.) However, note that this is OPTIONAL, and client implementations MUST NOT assume that the key corresponds to a chemical symbol, nor assume that if the species name is a valid chemical symbol, that it represents a species with that chemical symbol. This means that a species `{\"name\": \"C\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]}` is valid and represents a titanium species (and *not* a carbon species). - It is NOT RECOMMENDED that a structure includes species that do not have at least one corresponding site. - **Examples**: - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\"], \"concentration\": [1.0]} ]`: any site with this species is occupied by a Ti atom. - `[ {\"name\": \"Ti\", \"chemical_symbols\": [\"Ti\", \"vacancy\"], \"concentration\": [0.9, 0.1]} ]`: any site with this species is occupied by a Ti atom with 90 % probability, and has a vacancy with 10 % probability. - `[ {\"name\": \"BaCa\", \"chemical_symbols\": [\"vacancy\", \"Ba\", \"Ca\"], \"concentration\": [0.05, 0.45, 0.5], \"mass\": [0.0, 137.327, 40.078]} ]`: any site with this species is occupied by a Ba atom with 45 % probability, a Ca atom with 50 % probability, and by a vacancy with 5 % probability. The mass of this site is (on average) 88.5 a.m.u. - `[ {\"name\": \"C12\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [12.0]} ]`: any site with this species is occupied by a carbon isotope with mass 12. - `[ {\"name\": \"C13\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"mass\": [13.0]} ]`: any site with this species is occupied by a carbon isotope with mass 13. - `[ {\"name\": \"CH3\", \"chemical_symbols\": [\"C\"], \"concentration\": [1.0], \"attached\": [\"H\"], \"nattached\": [3]} ]`: any site with this species is occupied by a methyl group, -CH3, which is represented without specifying precise positions of the hydrogen atoms.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) species_at_sites : Optional [ List [ str ]] = OptimadeField ( ... , description = \"\"\"Name of the species at each site (where values for sites are specified with the same order of the property `cartesian_site_positions`). The properties of the species are found in the property `species`. - **Type**: list of strings. - **Requirements/Conventions**: - **Support**: SHOULD be supported by all implementations, i.e., SHOULD NOT be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - MUST have length equal to the number of sites in the structure (first dimension of the list property `cartesian_site_positions`). - Each species name mentioned in the `species_at_sites` list MUST be described in the list property `species` (i.e. for each value in the `species_at_sites` list there MUST exist exactly one dictionary in the `species` list with the `name` attribute equal to the corresponding `species_at_sites` value). - Each site MUST be associated only to a single species. **Note**: However, species can represent mixtures of atoms, and multiple species MAY be defined for the same chemical element. This latter case is useful when different atoms of the same type need to be grouped or distinguished, for instance in simulation codes to assign different initial spin states. - **Examples**: - `[\"Ti\",\"O2\"]` indicates that the first site is hosting a species labeled `\"Ti\"` and the second a species labeled `\"O2\"`. - `[\"Ac\", \"Ac\", \"Ag\", \"Ir\"]` indicating the first two sites contains the `\"Ac\"` species, while the third and fourth sites contain the `\"Ag\"` and `\"Ir\"` species, respectively.\"\"\" , support = SupportLevel . SHOULD , queryable = SupportLevel . OPTIONAL , ) assemblies : Optional [ List [ Assembly ]] = OptimadeField ( None , description = \"\"\"A description of groups of sites that are statistically correlated. - **Type**: list of dictionary with keys: - `sites_in_groups`: list of list of integers (REQUIRED) - `group_probabilities`: list of floats (REQUIRED) - **Requirements/Conventions**: - **Support**: OPTIONAL support in implementations, i.e., MAY be `null`. - **Query**: Support for queries on this property is OPTIONAL. If supported, filters MAY support only a subset of comparison operators. - The property SHOULD be `null` for entries that have no partial occupancies. - If present, the correct flag MUST be set in the list `structure_features`. - Client implementations MUST check its presence (as its presence changes the interpretation of the structure). - If present, it MUST be a list of dictionaries, each of which represents an assembly and MUST have the following two keys: - **sites_in_groups**: Index of the sites (0-based) that belong to each group for each assembly. Example: `[[1], [2]]`: two groups, one with the second site, one with the third. Example: `[[1,2], [3]]`: one group with the second and third site, one with the fourth. - **group_probabilities**: Statistical probability of each group. It MUST have the same length as `sites_in_groups`. It SHOULD sum to one. See below for examples of how to specify the probability of the occurrence of a vacancy. The possible reasons for the values not to sum to one are the same as already specified above for the `concentration` of each `species`. - If a site is not present in any group, it means that it is present with 100 % probability (as if no assembly was specified). - A site MUST NOT appear in more than one group. - **Examples** (for each entry of the assemblies list): - `{\"sites_in_groups\": [[0], [1]], \"group_probabilities: [0.3, 0.7]}`: the first site and the second site never occur at the same time in the unit cell. Statistically, 30 % o f the times the first site is present, while 70 % o f the times the second site is present. - `{\"sites_in_groups\": [[1,2], [3]], \"group_probabilities: [0.3, 0.7]}`: the second and third site are either present together or not present; they form the first group of atoms for this assembly. The second group is formed by the fourth site. Sites of the first group (the second and the third) are never present at the same time as the fourth site. 30 % o f times sites 1 and 2 are present (and site 3 is absent); 70 % o f times site 3 is present (and sites 1 and 2 are absent). - **Notes**: - Assemblies are essential to represent, for instance, the situation where an atom can statistically occupy two different positions (sites). - By defining groups, it is possible to represent, e.g., the case where a functional molecule (and not just one atom) is either present or absent (or the case where it it is present in two conformations) - Considerations on virtual alloys and on vacancies: In the special case of a virtual alloy, these specifications allow two different, equivalent ways of specifying them. For instance, for a site at the origin with 30 % probability of being occupied by Si, 50 % probability of being occupied by Ge, and 20 % o f being a vacancy, the following two representations are possible: - Using a single species: ```json { \"cartesian_site_positions\": [[0,0,0]], \"species_at_sites\": [\"SiGe-vac\"], \"species\": [ { \"name\": \"SiGe-vac\", \"chemical_symbols\": [\"Si\", \"Ge\", \"vacancy\"], \"concentration\": [0.3, 0.5, 0.2] } ] // ... } ``` - Using multiple species and the assemblies: ```json { \"cartesian_site_positions\": [ [0,0,0], [0,0,0], [0,0,0] ], \"species_at_sites\": [\"Si\", \"Ge\", \"vac\"], \"species\": [ { \"name\": \"Si\", \"chemical_symbols\": [\"Si\"], \"concentration\": [1.0] }, { \"name\": \"Ge\", \"chemical_symbols\": [\"Ge\"], \"concentration\": [1.0] }, { \"name\": \"vac\", \"chemical_symbols\": [\"vacancy\"], \"concentration\": [1.0] } ], \"assemblies\": [ { \"sites_in_groups\": [ [0], [1], [2] ], \"group_probabilities\": [0.3, 0.5, 0.2] } ] // ... } ``` - It is up to the database provider to decide which representation to use, typically depending on the internal format in which the structure is stored. However, given a structure identified by a unique ID, the API implementation MUST always provide the same representation for it. - The probabilities of occurrence of different assemblies are uncorrelated. So, for instance in the following case with two assemblies: ```json { \"assemblies\": [ { \"sites_in_groups\": [ [0], [1] ], \"group_probabilities\": [0.2, 0.8], }, { \"sites_in_groups\": [ [2], [3] ], \"group_probabilities\": [0.3, 0.7] } ] } ``` Site 0 is present with a probability of 20 % a nd site 1 with a probability of 80 %. These two sites are correlated (either site 0 or 1 is present). Similarly, site 2 is present with a probability of 30 % a nd site 3 with a probability of 70 %. These two sites are correlated (either site 2 or 3 is present). However, the presence or absence of sites 0 and 1 is not correlated with the presence or absence of sites 2 and 3 (in the specific example, the pair of sites (0, 2) can occur with 0.2*0.3 = 6 % probability; the pair (0, 3) with 0.2*0.7 = 14 % probability; the pair (1, 2) with 0.8*0.3 = 24 % probability; and the pair (1, 3) with 0.8*0.7 = 56 % probability).\"\"\" , support = SupportLevel . OPTIONAL , queryable = SupportLevel . OPTIONAL , ) structure_features : List [ StructureFeatures ] = OptimadeField ( ... , title = \"Structure Features\" , description = \"\"\"A list of strings that flag which special features are used by the structure. - **Type**: list of strings - **Requirements/Conventions**: - **Support**: MUST be supported by all implementations, MUST NOT be `null`. - **Query**: MUST be a queryable property. Filters on the list MUST support all mandatory HAS-type queries. Filter operators for comparisons on the string components MUST support equality, support for other comparison operators are OPTIONAL. - MUST be an empty list if no special features are used. - MUST be sorted alphabetically. - If a special feature listed below is used, the list MUST contain the corresponding string. - If a special feature listed below is not used, the list MUST NOT contain the corresponding string. - **List of strings used to indicate special structure features**: - `disorder`: this flag MUST be present if any one entry in the `species` list has a `chemical_symbols` list that is longer than 1 element. - `implicit_atoms`: this flag MUST be present if the structure contains atoms that are not assigned to sites via the property `species_at_sites` (e.g., because their positions are unknown). When this flag is present, the properties related to the chemical formula will likely not match the type and count of atoms represented by the `species_at_sites`, `species` and `assemblies` properties. - `site_attachments`: this flag MUST be present if any one entry in the `species` list includes `attached` and `nattached`. - `assemblies`: this flag MUST be present if the property `assemblies` is present. - **Examples**: A structure having implicit atoms and using assemblies: `[\"assemblies\", \"implicit_atoms\"]`\"\"\" , support = SupportLevel . MUST , queryable = SupportLevel . MUST , ) class Config : def schema_extra ( schema , model ): \"\"\"Two things need to be added to the schema: 1. Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, `dimension_types` and `lattice_vectors`, are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. 2. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be `nullable` according to the OpenAPI definition. \"\"\" schema [ \"required\" ] . insert ( 7 , \"dimension_types\" ) schema [ \"required\" ] . insert ( 9 , \"lattice_vectors\" ) nullable_props = ( prop for prop in schema [ \"required\" ] if schema [ \"properties\" ][ prop ] . get ( \"x-optimade-support\" ) == SupportLevel . SHOULD ) for prop in nullable_props : schema [ \"properties\" ][ prop ][ \"nullable\" ] = True @root_validator ( pre = True ) def warn_on_missing_correlated_fields ( cls , values ): \"\"\"Emit warnings if a field takes a null value when a value was expected based on the value/nullity of another field. \"\"\" accumulated_warnings = [] for field_set in CORRELATED_STRUCTURE_FIELDS : missing_fields = { f for f in field_set if values . get ( f ) is None } if missing_fields and len ( missing_fields ) != len ( field_set ): accumulated_warnings += [ f \"Structure with values { values } is missing fields { missing_fields } which are required if { field_set - missing_fields } are present.\" ] for warn in accumulated_warnings : warnings . warn ( warn , MissingExpectedField ) return values @validator ( \"chemical_formula_reduced\" , \"chemical_formula_hill\" ) def check_ordered_formula ( cls , v , field ): if v is None : return v elements = re . findall ( r \"[A-Z][a-z]?\" , v ) expected_elements = sorted ( elements ) if field . name == \"chemical_formula_hill\" : # Make sure C is first (and H is second, if present along with C). if \"C\" in expected_elements : expected_elements = sorted ( expected_elements , key = lambda elem : { \"C\" : \"0\" , \"H\" : \"1\" } . get ( elem , elem ), ) if any ( elem not in CHEMICAL_SYMBOLS for elem in elements ): raise ValueError ( f \"Cannot use unknown chemical symbols { [ elem for elem in elements if elem not in CHEMICAL_SYMBOLS ] } in { field . name !r} \" ) if expected_elements != elements : order = \"Hill\" if field . name == \"chemical_formula_hill\" else \"alphabetical\" raise ValueError ( f \"Elements in { field . name !r} must appear in { order } order: { expected_elements } not { elements } .\" ) return v @validator ( \"chemical_formula_anonymous\" ) def check_anonymous_formula ( cls , v ): if v is None : return v elements = tuple ( re . findall ( r \"[A-Z][a-z]*\" , v )) numbers = re . split ( r \"[A-Z][a-z]*\" , v )[ 1 :] numbers = [ int ( i ) if i else 1 for i in numbers ] expected_labels = ANONYMOUS_ELEMENTS [: len ( elements )] expected_numbers = sorted ( numbers , reverse = True ) if expected_numbers != numbers : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong order: elements with highest proportion should appear first: { numbers } vs expected { expected_numbers } \" ) if elements != expected_labels : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong labels: { elements } vs expected { expected_labels } .\" ) return v @validator ( \"chemical_formula_anonymous\" , \"chemical_formula_reduced\" ) def check_reduced_formulae ( cls , value , field ): if value is None : return value numbers = [ n . strip () or 1 for n in re . split ( r \"[A-Z][a-z]*\" , value )] # Need to remove leading 1 from split and convert to ints numbers = [ int ( n ) for n in numbers [ 1 :]] if sys . version_info [ 1 ] >= 9 : gcd = math . gcd ( * numbers ) else : gcd = reduce ( math . gcd , numbers ) if gcd != 1 : raise ValueError ( f \" { field . name } { value !r} is not properly reduced: greatest common divisor was { gcd } , expected 1.\" ) return value @validator ( \"elements\" , each_item = True ) def element_must_be_chemical_symbol ( cls , v ): if v not in CHEMICAL_SYMBOLS : raise ValueError ( f \"Only chemical symbols are allowed, you passed: { v } \" ) return v @validator ( \"elements\" ) def elements_must_be_alphabetical ( cls , v ): if v is None : return v if sorted ( v ) != v : raise ValueError ( f \"elements must be sorted alphabetically, but is: { v } \" ) return v @validator ( \"elements_ratios\" ) def ratios_must_sum_to_one ( cls , v ): if v is None : return v if abs ( sum ( v ) - 1 ) > EPS : raise ValueError ( f \"elements_ratios MUST sum to 1 within (at least single precision) floating point accuracy. It sums to: { sum ( v ) } \" ) return v @validator ( \"nperiodic_dimensions\" ) def check_periodic_dimensions ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ) and v != sum ( values . get ( \"dimension_types\" )): raise ValueError ( f \"nperiodic_dimensions ( { v } ) does not match expected value of { sum ( values [ 'dimension_types' ]) } \" f \"from dimension_types ( { values [ 'dimension_types' ] } )\" ) return v @validator ( \"lattice_vectors\" , always = True ) def required_if_dimension_types_has_one ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ): for dim_type , vector in zip ( values . get ( \"dimension_types\" , ( None ,) * 3 ), v ): if None in vector and dim_type == Periodicity . PERIODIC . value : raise ValueError ( f \"Null entries in lattice vectors are only permitted when the corresponding dimension type is { Periodicity . APERIODIC . value } . \" f \"Here: dimension_types = { tuple ( getattr ( _ , 'value' , None ) for _ in values . get ( 'dimension_types' , [])) } , lattice_vectors = { v } \" ) return v @validator ( \"lattice_vectors\" ) def null_values_for_whole_vector ( cls , v ): if v is None : return v for vector in v : if None in vector and any (( isinstance ( _ , float ) for _ in vector )): raise ValueError ( f \"A lattice vector MUST be either all `null` or all numbers (vector: { vector } , all vectors: { v } )\" ) return v @validator ( \"nsites\" ) def validate_nsites ( cls , v , values ): if v is None : return v if values . get ( \"cartesian_site_positions\" ) and v != len ( values . get ( \"cartesian_site_positions\" , []) ): raise ValueError ( f \"nsites (value: { v } ) MUST equal length of cartesian_site_positions \" f \"(value: { len ( values . get ( 'cartesian_site_positions' , [])) } )\" ) return v @validator ( \"species_at_sites\" ) def validate_species_at_sites ( cls , v , values ): if v is None : return v if values . get ( \"nsites\" ) and len ( v ) != values . get ( \"nsites\" ): raise ValueError ( f \"Number of species_at_sites (value: { len ( v ) } ) MUST equal number of sites \" f \"(value: { values . get ( 'nsites' , 'Not specified' ) } )\" ) if values . get ( \"species\" ): all_species_names = { getattr ( _ , \"name\" , None ) for _ in values . get ( \"species\" , [{}]) } all_species_names -= { None } for value in v : if value not in all_species_names : raise ValueError ( \"species_at_sites MUST be represented by a species' name, \" f \"but { value } was not found in the list of species names: { all_species_names } \" ) return v @validator ( \"species\" ) def validate_species ( cls , v ): if v is None : return v all_species = [ _ . name for _ in v ] unique_species = set ( all_species ) if len ( all_species ) != len ( unique_species ): raise ValueError ( f \"Species MUST be unique based on their 'name'. Found species names: { all_species } \" ) return v @validator ( \"structure_features\" , always = True ) def validate_structure_features ( cls , v , values ): if [ StructureFeatures ( value ) for value in sorted (( _ . value for _ in v ))] != v : raise ValueError ( f \"structure_features MUST be sorted alphabetically, given value: { v } \" ) # assemblies if values . get ( \"assemblies\" ) is not None : if StructureFeatures . ASSEMBLIES not in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST be present, since the property of the same name is present\" ) elif StructureFeatures . ASSEMBLIES in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST NOT be present, \" \"since the property of the same name is not present\" ) if values . get ( \"species\" ): # disorder for species in values . get ( \"species\" , []): if len ( species . chemical_symbols ) > 1 : if StructureFeatures . DISORDER not in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST be present when any one entry in species \" \"has a chemical_symbols list greater than one element\" ) break else : if StructureFeatures . DISORDER in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST NOT be present, since all species' chemical_symbols \" \"lists are equal to or less than one element\" ) # site_attachments for species in values . get ( \"species\" , []): # There is no need to also test \"nattached\", # since a Species validator makes sure either both are present or both are None. if getattr ( species , \"attached\" , None ) is not None : if StructureFeatures . SITE_ATTACHMENTS not in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST be present when any one entry \" \"in species includes attached and nattached\" ) break else : if StructureFeatures . SITE_ATTACHMENTS in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST NOT be present, since no species includes \" \"the attached and nattached fields\" ) # implicit_atoms species_names = [ _ . name for _ in values . get ( \"species\" , [])] for name in species_names : if values . get ( \"species_at_sites\" ) is not None and name not in values . get ( \"species_at_sites\" , []): if StructureFeatures . IMPLICIT_ATOMS not in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST be present when any one entry in species \" \"is not represented in species_at_sites\" ) break else : if StructureFeatures . IMPLICIT_ATOMS in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST NOT be present, since all species are \" \"represented in species_at_sites\" ) return v","title":"StructureResourceAttributes"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.assemblies","text":"","title":"assemblies"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.cartesian_site_positions","text":"","title":"cartesian_site_positions"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.chemical_formula_anonymous","text":"","title":"chemical_formula_anonymous"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.chemical_formula_descriptive","text":"","title":"chemical_formula_descriptive"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.chemical_formula_hill","text":"","title":"chemical_formula_hill"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.chemical_formula_reduced","text":"","title":"chemical_formula_reduced"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.dimension_types","text":"","title":"dimension_types"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.elements","text":"","title":"elements"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.elements_ratios","text":"","title":"elements_ratios"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.lattice_vectors","text":"","title":"lattice_vectors"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.nelements","text":"","title":"nelements"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.nperiodic_dimensions","text":"","title":"nperiodic_dimensions"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.nsites","text":"","title":"nsites"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.species","text":"","title":"species"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.species_at_sites","text":"","title":"species_at_sites"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.structure_features","text":"","title":"structure_features"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.Config","text":"Source code in optimade/models/structures.py 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 class Config : def schema_extra ( schema , model ): \"\"\"Two things need to be added to the schema: 1. Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, `dimension_types` and `lattice_vectors`, are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. 2. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be `nullable` according to the OpenAPI definition. \"\"\" schema [ \"required\" ] . insert ( 7 , \"dimension_types\" ) schema [ \"required\" ] . insert ( 9 , \"lattice_vectors\" ) nullable_props = ( prop for prop in schema [ \"required\" ] if schema [ \"properties\" ][ prop ] . get ( \"x-optimade-support\" ) == SupportLevel . SHOULD ) for prop in nullable_props : schema [ \"properties\" ][ prop ][ \"nullable\" ] = True","title":"Config"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.Config.schema_extra","text":"Two things need to be added to the schema: Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, dimension_types and lattice_vectors , are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be nullable according to the OpenAPI definition. Source code in optimade/models/structures.py 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 def schema_extra ( schema , model ): \"\"\"Two things need to be added to the schema: 1. Constrained types in pydantic do not currently play nicely with \"Required Optional\" fields, i.e. fields must be specified but can be null. The two contrained list fields, `dimension_types` and `lattice_vectors`, are OPTIMADE 'SHOULD' fields, which means that they are allowed to be null. 2. All OPTIMADE 'SHOULD' fields are allowed to be null, so we manually set them to be `nullable` according to the OpenAPI definition. \"\"\" schema [ \"required\" ] . insert ( 7 , \"dimension_types\" ) schema [ \"required\" ] . insert ( 9 , \"lattice_vectors\" ) nullable_props = ( prop for prop in schema [ \"required\" ] if schema [ \"properties\" ][ prop ] . get ( \"x-optimade-support\" ) == SupportLevel . SHOULD ) for prop in nullable_props : schema [ \"properties\" ][ prop ][ \"nullable\" ] = True","title":"schema_extra()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.check_anonymous_formula","text":"Source code in optimade/models/structures.py 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 @validator ( \"chemical_formula_anonymous\" ) def check_anonymous_formula ( cls , v ): if v is None : return v elements = tuple ( re . findall ( r \"[A-Z][a-z]*\" , v )) numbers = re . split ( r \"[A-Z][a-z]*\" , v )[ 1 :] numbers = [ int ( i ) if i else 1 for i in numbers ] expected_labels = ANONYMOUS_ELEMENTS [: len ( elements )] expected_numbers = sorted ( numbers , reverse = True ) if expected_numbers != numbers : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong order: elements with highest proportion should appear first: { numbers } vs expected { expected_numbers } \" ) if elements != expected_labels : raise ValueError ( f \"'chemical_formula_anonymous' { v } has wrong labels: { elements } vs expected { expected_labels } .\" ) return v","title":"check_anonymous_formula()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.check_ordered_formula","text":"Source code in optimade/models/structures.py 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 @validator ( \"chemical_formula_reduced\" , \"chemical_formula_hill\" ) def check_ordered_formula ( cls , v , field ): if v is None : return v elements = re . findall ( r \"[A-Z][a-z]?\" , v ) expected_elements = sorted ( elements ) if field . name == \"chemical_formula_hill\" : # Make sure C is first (and H is second, if present along with C). if \"C\" in expected_elements : expected_elements = sorted ( expected_elements , key = lambda elem : { \"C\" : \"0\" , \"H\" : \"1\" } . get ( elem , elem ), ) if any ( elem not in CHEMICAL_SYMBOLS for elem in elements ): raise ValueError ( f \"Cannot use unknown chemical symbols { [ elem for elem in elements if elem not in CHEMICAL_SYMBOLS ] } in { field . name !r} \" ) if expected_elements != elements : order = \"Hill\" if field . name == \"chemical_formula_hill\" else \"alphabetical\" raise ValueError ( f \"Elements in { field . name !r} must appear in { order } order: { expected_elements } not { elements } .\" ) return v","title":"check_ordered_formula()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.check_periodic_dimensions","text":"Source code in optimade/models/structures.py 940 941 942 943 944 945 946 947 948 949 950 951 @validator ( \"nperiodic_dimensions\" ) def check_periodic_dimensions ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ) and v != sum ( values . get ( \"dimension_types\" )): raise ValueError ( f \"nperiodic_dimensions ( { v } ) does not match expected value of { sum ( values [ 'dimension_types' ]) } \" f \"from dimension_types ( { values [ 'dimension_types' ] } )\" ) return v","title":"check_periodic_dimensions()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.check_reduced_formulae","text":"Source code in optimade/models/structures.py 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 @validator ( \"chemical_formula_anonymous\" , \"chemical_formula_reduced\" ) def check_reduced_formulae ( cls , value , field ): if value is None : return value numbers = [ n . strip () or 1 for n in re . split ( r \"[A-Z][a-z]*\" , value )] # Need to remove leading 1 from split and convert to ints numbers = [ int ( n ) for n in numbers [ 1 :]] if sys . version_info [ 1 ] >= 9 : gcd = math . gcd ( * numbers ) else : gcd = reduce ( math . gcd , numbers ) if gcd != 1 : raise ValueError ( f \" { field . name } { value !r} is not properly reduced: greatest common divisor was { gcd } , expected 1.\" ) return value","title":"check_reduced_formulae()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.element_must_be_chemical_symbol","text":"Source code in optimade/models/structures.py 914 915 916 917 918 @validator ( \"elements\" , each_item = True ) def element_must_be_chemical_symbol ( cls , v ): if v not in CHEMICAL_SYMBOLS : raise ValueError ( f \"Only chemical symbols are allowed, you passed: { v } \" ) return v","title":"element_must_be_chemical_symbol()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.elements_must_be_alphabetical","text":"Source code in optimade/models/structures.py 920 921 922 923 924 925 926 927 @validator ( \"elements\" ) def elements_must_be_alphabetical ( cls , v ): if v is None : return v if sorted ( v ) != v : raise ValueError ( f \"elements must be sorted alphabetically, but is: { v } \" ) return v","title":"elements_must_be_alphabetical()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.null_values_for_whole_vector","text":"Source code in optimade/models/structures.py 968 969 970 971 972 973 974 975 976 977 978 @validator ( \"lattice_vectors\" ) def null_values_for_whole_vector ( cls , v ): if v is None : return v for vector in v : if None in vector and any (( isinstance ( _ , float ) for _ in vector )): raise ValueError ( f \"A lattice vector MUST be either all `null` or all numbers (vector: { vector } , all vectors: { v } )\" ) return v","title":"null_values_for_whole_vector()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.ratios_must_sum_to_one","text":"Source code in optimade/models/structures.py 929 930 931 932 933 934 935 936 937 938 @validator ( \"elements_ratios\" ) def ratios_must_sum_to_one ( cls , v ): if v is None : return v if abs ( sum ( v ) - 1 ) > EPS : raise ValueError ( f \"elements_ratios MUST sum to 1 within (at least single precision) floating point accuracy. It sums to: { sum ( v ) } \" ) return v","title":"ratios_must_sum_to_one()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.required_if_dimension_types_has_one","text":"Source code in optimade/models/structures.py 953 954 955 956 957 958 959 960 961 962 963 964 965 966 @validator ( \"lattice_vectors\" , always = True ) def required_if_dimension_types_has_one ( cls , v , values ): if v is None : return v if values . get ( \"dimension_types\" ): for dim_type , vector in zip ( values . get ( \"dimension_types\" , ( None ,) * 3 ), v ): if None in vector and dim_type == Periodicity . PERIODIC . value : raise ValueError ( f \"Null entries in lattice vectors are only permitted when the corresponding dimension type is { Periodicity . APERIODIC . value } . \" f \"Here: dimension_types = { tuple ( getattr ( _ , 'value' , None ) for _ in values . get ( 'dimension_types' , [])) } , lattice_vectors = { v } \" ) return v","title":"required_if_dimension_types_has_one()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.validate_nsites","text":"Source code in optimade/models/structures.py 980 981 982 983 984 985 986 987 988 989 990 991 992 @validator ( \"nsites\" ) def validate_nsites ( cls , v , values ): if v is None : return v if values . get ( \"cartesian_site_positions\" ) and v != len ( values . get ( \"cartesian_site_positions\" , []) ): raise ValueError ( f \"nsites (value: { v } ) MUST equal length of cartesian_site_positions \" f \"(value: { len ( values . get ( 'cartesian_site_positions' , [])) } )\" ) return v","title":"validate_nsites()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.validate_species","text":"Source code in optimade/models/structures.py 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 @validator ( \"species\" ) def validate_species ( cls , v ): if v is None : return v all_species = [ _ . name for _ in v ] unique_species = set ( all_species ) if len ( all_species ) != len ( unique_species ): raise ValueError ( f \"Species MUST be unique based on their 'name'. Found species names: { all_species } \" ) return v","title":"validate_species()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.validate_species_at_sites","text":"Source code in optimade/models/structures.py 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 @validator ( \"species_at_sites\" ) def validate_species_at_sites ( cls , v , values ): if v is None : return v if values . get ( \"nsites\" ) and len ( v ) != values . get ( \"nsites\" ): raise ValueError ( f \"Number of species_at_sites (value: { len ( v ) } ) MUST equal number of sites \" f \"(value: { values . get ( 'nsites' , 'Not specified' ) } )\" ) if values . get ( \"species\" ): all_species_names = { getattr ( _ , \"name\" , None ) for _ in values . get ( \"species\" , [{}]) } all_species_names -= { None } for value in v : if value not in all_species_names : raise ValueError ( \"species_at_sites MUST be represented by a species' name, \" f \"but { value } was not found in the list of species names: { all_species_names } \" ) return v","title":"validate_species_at_sites()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.validate_structure_features","text":"Source code in optimade/models/structures.py 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 @validator ( \"structure_features\" , always = True ) def validate_structure_features ( cls , v , values ): if [ StructureFeatures ( value ) for value in sorted (( _ . value for _ in v ))] != v : raise ValueError ( f \"structure_features MUST be sorted alphabetically, given value: { v } \" ) # assemblies if values . get ( \"assemblies\" ) is not None : if StructureFeatures . ASSEMBLIES not in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST be present, since the property of the same name is present\" ) elif StructureFeatures . ASSEMBLIES in v : raise ValueError ( f \" { StructureFeatures . ASSEMBLIES . value } MUST NOT be present, \" \"since the property of the same name is not present\" ) if values . get ( \"species\" ): # disorder for species in values . get ( \"species\" , []): if len ( species . chemical_symbols ) > 1 : if StructureFeatures . DISORDER not in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST be present when any one entry in species \" \"has a chemical_symbols list greater than one element\" ) break else : if StructureFeatures . DISORDER in v : raise ValueError ( f \" { StructureFeatures . DISORDER . value } MUST NOT be present, since all species' chemical_symbols \" \"lists are equal to or less than one element\" ) # site_attachments for species in values . get ( \"species\" , []): # There is no need to also test \"nattached\", # since a Species validator makes sure either both are present or both are None. if getattr ( species , \"attached\" , None ) is not None : if StructureFeatures . SITE_ATTACHMENTS not in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST be present when any one entry \" \"in species includes attached and nattached\" ) break else : if StructureFeatures . SITE_ATTACHMENTS in v : raise ValueError ( f \" { StructureFeatures . SITE_ATTACHMENTS . value } MUST NOT be present, since no species includes \" \"the attached and nattached fields\" ) # implicit_atoms species_names = [ _ . name for _ in values . get ( \"species\" , [])] for name in species_names : if values . get ( \"species_at_sites\" ) is not None and name not in values . get ( \"species_at_sites\" , []): if StructureFeatures . IMPLICIT_ATOMS not in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST be present when any one entry in species \" \"is not represented in species_at_sites\" ) break else : if StructureFeatures . IMPLICIT_ATOMS in v : raise ValueError ( f \" { StructureFeatures . IMPLICIT_ATOMS . value } MUST NOT be present, since all species are \" \"represented in species_at_sites\" ) return v","title":"validate_structure_features()"},{"location":"api_reference/models/structures/#optimade.models.structures.StructureResourceAttributes.warn_on_missing_correlated_fields","text":"Emit warnings if a field takes a null value when a value was expected based on the value/nullity of another field. Source code in optimade/models/structures.py 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 @root_validator ( pre = True ) def warn_on_missing_correlated_fields ( cls , values ): \"\"\"Emit warnings if a field takes a null value when a value was expected based on the value/nullity of another field. \"\"\" accumulated_warnings = [] for field_set in CORRELATED_STRUCTURE_FIELDS : missing_fields = { f for f in field_set if values . get ( f ) is None } if missing_fields and len ( missing_fields ) != len ( field_set ): accumulated_warnings += [ f \"Structure with values { values } is missing fields { missing_fields } which are required if { field_set - missing_fields } are present.\" ] for warn in accumulated_warnings : warnings . warn ( warn , MissingExpectedField ) return values","title":"warn_on_missing_correlated_fields()"},{"location":"api_reference/models/utils/","text":"utils \u00b6 ANONYMOUS_ELEMENTS = tuple ( itertools . islice ( anonymous_element_generator (), 150 )) module-attribute \u00b6 Returns the first 150 values of the anonymous element generator. ATOMIC_NUMBERS = {} module-attribute \u00b6 CHEMICAL_FORMULA_REGEXP = '^([A-Z][a-z]?([2-9]|[1-9] \\\\ d+)?)+$' module-attribute \u00b6 CHEMICAL_SYMBOLS = [ 'H' , 'He' , 'Li' , 'Be' , 'B' , 'C' , 'N' , 'O' , 'F' , 'Ne' , 'Na' , 'Mg' , 'Al' , 'Si' , 'P' , 'S' , 'Cl' , 'Ar' , 'K' , 'Ca' , 'Sc' , 'Ti' , 'V' , 'Cr' , 'Mn' , 'Fe' , 'Co' , 'Ni' , 'Cu' , 'Zn' , 'Ga' , 'Ge' , 'As' , 'Se' , 'Br' , 'Kr' , 'Rb' , 'Sr' , 'Y' , 'Zr' , 'Nb' , 'Mo' , 'Tc' , 'Ru' , 'Rh' , 'Pd' , 'Ag' , 'Cd' , 'In' , 'Sn' , 'Sb' , 'Te' , 'I' , 'Xe' , 'Cs' , 'Ba' , 'La' , 'Ce' , 'Pr' , 'Nd' , 'Pm' , 'Sm' , 'Eu' , 'Gd' , 'Tb' , 'Dy' , 'Ho' , 'Er' , 'Tm' , 'Yb' , 'Lu' , 'Hf' , 'Ta' , 'W' , 'Re' , 'Os' , 'Ir' , 'Pt' , 'Au' , 'Hg' , 'Tl' , 'Pb' , 'Bi' , 'Po' , 'At' , 'Rn' , 'Fr' , 'Ra' , 'Ac' , 'Th' , 'Pa' , 'U' , 'Np' , 'Pu' , 'Am' , 'Cm' , 'Bk' , 'Cf' , 'Es' , 'Fm' , 'Md' , 'No' , 'Lr' , 'Rf' , 'Db' , 'Sg' , 'Bh' , 'Hs' , 'Mt' , 'Ds' , 'Rg' , 'Cn' , 'Nh' , 'Fl' , 'Mc' , 'Lv' , 'Ts' , 'Og' ] module-attribute \u00b6 EXTRA_SYMBOLS = [ 'X' , 'vacancy' ] module-attribute \u00b6 OPTIMADE_SCHEMA_EXTENSION_KEYS = [ 'support' , 'queryable' , 'unit' , 'sortable' ] module-attribute \u00b6 OPTIMADE_SCHEMA_EXTENSION_PREFIX = 'x-optimade-' module-attribute \u00b6 SemanticVersion \u00b6 A custom type for a semantic version, using the recommended semver regexp from https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string. Source code in optimade/models/utils.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 class SemanticVersion ( str ): \"\"\"A custom type for a semantic version, using the recommended semver regexp from https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string. \"\"\" regex = re . compile ( r \"^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$\" ) @classmethod def __get_validators__ ( cls ): yield cls . validate @classmethod def __modify_schema__ ( cls , field_schema ): field_schema . update ( pattern = cls . regex . pattern , example = [ \"0.10.1\" , \"1.0.0-rc.2\" , \"1.2.3-rc.5+develop\" ], ) @classmethod def validate ( cls , v : str ): if not cls . regex . match ( v ): raise ValueError ( f \"Unable to validate the version string { v !r} as a semantic version (expected <major>.<minor>.<patch>).\" \"See https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string for more information.\" ) return v @property def _match ( self ): \"\"\"The result of the regex match.\"\"\" return self . regex . match ( self ) @property def major ( self ) -> int : \"\"\"The major version number.\"\"\" return int ( self . _match . group ( 1 )) @property def minor ( self ) -> int : \"\"\"The minor version number.\"\"\" return int ( self . _match . group ( 2 )) @property def patch ( self ) -> int : \"\"\"The patch version number.\"\"\" return int ( self . _match . group ( 3 )) @property def prerelease ( self ) -> str : \"\"\"The pre-release tag.\"\"\" return self . _match . group ( 4 ) @property def build_metadata ( self ) -> str : \"\"\"The build metadata.\"\"\" return self . _match . group ( 5 ) @property def base_version ( self ) -> str : \"\"\"The base version string without patch and metadata info.\"\"\" return f \" { self . major } . { self . minor } . { self . patch } \" regex = re . compile ( '^(0|[1-9] \\\\ d*) \\\\ .(0|[1-9] \\\\ d*) \\\\ .(0|[1-9] \\\\ d*)(?:-((?:0|[1-9] \\\\ d*| \\\\ d*[a-zA-Z-][0-9a-zA-Z-]*)(?: \\\\ .(?:0|[1-9] \\\\ d*| \\\\ d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?: \\\\ +([0-9a-zA-Z-]+(?: \\\\ .[0-9a-zA-Z-]+)*))?$' ) class-attribute \u00b6 __get_validators__ () classmethod \u00b6 Source code in optimade/models/utils.py 163 164 165 @classmethod def __get_validators__ ( cls ): yield cls . validate __modify_schema__ ( field_schema ) classmethod \u00b6 Source code in optimade/models/utils.py 167 168 169 170 171 172 @classmethod def __modify_schema__ ( cls , field_schema ): field_schema . update ( pattern = cls . regex . pattern , example = [ \"0.10.1\" , \"1.0.0-rc.2\" , \"1.2.3-rc.5+develop\" ], ) base_version () property \u00b6 The base version string without patch and metadata info. Source code in optimade/models/utils.py 214 215 216 217 @property def base_version ( self ) -> str : \"\"\"The base version string without patch and metadata info.\"\"\" return f \" { self . major } . { self . minor } . { self . patch } \" build_metadata () property \u00b6 The build metadata. Source code in optimade/models/utils.py 209 210 211 212 @property def build_metadata ( self ) -> str : \"\"\"The build metadata.\"\"\" return self . _match . group ( 5 ) major () property \u00b6 The major version number. Source code in optimade/models/utils.py 189 190 191 192 @property def major ( self ) -> int : \"\"\"The major version number.\"\"\" return int ( self . _match . group ( 1 )) minor () property \u00b6 The minor version number. Source code in optimade/models/utils.py 194 195 196 197 @property def minor ( self ) -> int : \"\"\"The minor version number.\"\"\" return int ( self . _match . group ( 2 )) patch () property \u00b6 The patch version number. Source code in optimade/models/utils.py 199 200 201 202 @property def patch ( self ) -> int : \"\"\"The patch version number.\"\"\" return int ( self . _match . group ( 3 )) prerelease () property \u00b6 The pre-release tag. Source code in optimade/models/utils.py 204 205 206 207 @property def prerelease ( self ) -> str : \"\"\"The pre-release tag.\"\"\" return self . _match . group ( 4 ) validate ( v ) classmethod \u00b6 Source code in optimade/models/utils.py 174 175 176 177 178 179 180 181 182 @classmethod def validate ( cls , v : str ): if not cls . regex . match ( v ): raise ValueError ( f \"Unable to validate the version string { v !r} as a semantic version (expected <major>.<minor>.<patch>).\" \"See https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string for more information.\" ) return v StrictFieldInfo \u00b6 Wraps the standard pydantic FieldInfo in order to prefix any custom keys from StrictField . Source code in optimade/models/utils.py 37 38 39 40 41 42 43 44 45 46 47 48 49 class StrictFieldInfo ( FieldInfo ): \"\"\"Wraps the standard pydantic `FieldInfo` in order to prefix any custom keys from `StrictField`. \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) for key in OPTIMADE_SCHEMA_EXTENSION_KEYS : if key in self . extra : self . extra [ f \" { OPTIMADE_SCHEMA_EXTENSION_PREFIX }{ key } \" ] = self . extra . pop ( key ) __init__ ( * args , ** kwargs ) \u00b6 Source code in optimade/models/utils.py 43 44 45 46 47 48 49 def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) for key in OPTIMADE_SCHEMA_EXTENSION_KEYS : if key in self . extra : self . extra [ f \" { OPTIMADE_SCHEMA_EXTENSION_PREFIX }{ key } \" ] = self . extra . pop ( key ) SupportLevel \u00b6 OPTIMADE property/field support levels Source code in optimade/models/utils.py 29 30 31 32 33 34 class SupportLevel ( Enum ): \"\"\"OPTIMADE property/field support levels\"\"\" MUST = \"must\" SHOULD = \"should\" OPTIONAL = \"optional\" MUST = 'must' class-attribute \u00b6 OPTIONAL = 'optional' class-attribute \u00b6 SHOULD = 'should' class-attribute \u00b6 OptimadeField ( * args , support = None , queryable = None , unit = None , ** kwargs ) \u00b6 A wrapper around pydantic.Field that adds OPTIMADE-specific field paramters queryable , support and unit , indicating the corresponding support level in the specification and the physical unit of the field. Parameters: Name Type Description Default support Optional [ SupportLevel ] The support level of the field itself, i.e. whether the field can be null or omitted by an implementation. None queryable Optional [ SupportLevel ] The support level corresponding to the queryablility of this field. None unit Optional [ str ] A string describing the unit of the field. None Returns: Type Description Field The pydantic field with extra validation provided by StrictField . Source code in optimade/models/utils.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def OptimadeField ( * args , support : Optional [ SupportLevel ] = None , queryable : Optional [ SupportLevel ] = None , unit : Optional [ str ] = None , ** kwargs , ) -> Field : \"\"\"A wrapper around `pydantic.Field` that adds OPTIMADE-specific field paramters `queryable`, `support` and `unit`, indicating the corresponding support level in the specification and the physical unit of the field. Arguments: support: The support level of the field itself, i.e. whether the field can be null or omitted by an implementation. queryable: The support level corresponding to the queryablility of this field. unit: A string describing the unit of the field. Returns: The pydantic field with extra validation provided by [`StrictField`][optimade.models.utils.StrictField]. \"\"\" # Collect non-null keyword arguments to add to the Field schema if unit is not None : kwargs [ \"unit\" ] = unit if queryable is not None : if isinstance ( queryable , str ): queryable = SupportLevel ( queryable . lower ()) kwargs [ \"queryable\" ] = queryable if support is not None : if isinstance ( support , str ): support = SupportLevel ( support . lower ()) kwargs [ \"support\" ] = support return StrictField ( * args , ** kwargs ) StrictField ( * args , description = None , ** kwargs ) \u00b6 A wrapper around pydantic.Field that does the following: Forbids any \"extra\" keys that would be passed to pydantic.Field , except those used elsewhere to modify the schema in-place, e.g. \"uniqueItems\", \"pattern\" and those added by OptimadeField, e.g. \"unit\", \"queryable\" and \"sortable\". Emits a warning when no description is provided. Parameters: Name Type Description Default *args Any Positional arguments passed through to Field . () description str The description of the Field ; if this is not specified then a UserWarning will be emitted. None **kwargs Any Extra keyword arguments to be passed to Field . {} Raises: Type Description RuntimeError If **kwargs contains a key not found in the function signature of Field , or in the extensions used by models in this package (see above). Returns: Type Description StrictFieldInfo The pydantic Field . Source code in optimade/models/utils.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def StrictField ( * args : \"Any\" , description : str = None , ** kwargs : \"Any\" , ) -> StrictFieldInfo : \"\"\"A wrapper around `pydantic.Field` that does the following: - Forbids any \"extra\" keys that would be passed to `pydantic.Field`, except those used elsewhere to modify the schema in-place, e.g. \"uniqueItems\", \"pattern\" and those added by OptimadeField, e.g. \"unit\", \"queryable\" and \"sortable\". - Emits a warning when no description is provided. Arguments: *args: Positional arguments passed through to `Field`. description: The description of the `Field`; if this is not specified then a `UserWarning` will be emitted. **kwargs: Extra keyword arguments to be passed to `Field`. Raises: RuntimeError: If `**kwargs` contains a key not found in the function signature of `Field`, or in the extensions used by models in this package (see above). Returns: The pydantic `Field`. \"\"\" allowed_keys = [ \"pattern\" , \"uniqueItems\" , \"nullable\" , ] + OPTIMADE_SCHEMA_EXTENSION_KEYS _banned = [ k for k in kwargs if k not in set ( _PYDANTIC_FIELD_KWARGS + allowed_keys )] if _banned : raise RuntimeError ( f \"Not creating StrictField( { args } , { kwargs } ) with forbidden keywords { _banned } .\" ) if description is not None : kwargs [ \"description\" ] = description if description is None : warnings . warn ( f \"No description provided for StrictField specified by { args } , { kwargs } .\" ) return StrictPydanticField ( * args , ** kwargs ) StrictPydanticField ( * args , ** kwargs ) \u00b6 Wrapper for Field that uses StrictFieldInfo instead of the pydantic FieldInfo . Source code in optimade/models/utils.py 52 53 54 55 56 57 58 def StrictPydanticField ( * args , ** kwargs ): \"\"\"Wrapper for `Field` that uses `StrictFieldInfo` instead of the pydantic `FieldInfo`. \"\"\" field_info = StrictFieldInfo ( * args , ** kwargs ) field_info . _validate () return field_info anonymous_element_generator () \u00b6 Generator that yields the next symbol in the A, B, Aa, ... Az naming scheme. Source code in optimade/models/utils.py 220 221 222 223 224 225 226 227 228 def anonymous_element_generator (): \"\"\"Generator that yields the next symbol in the A, B, Aa, ... Az naming scheme.\"\"\" from string import ascii_lowercase for size in itertools . count ( 1 ): for s in itertools . product ( ascii_lowercase , repeat = size ): s = list ( s ) s [ 0 ] = s [ 0 ] . upper () yield \"\" . join ( s )","title":"utils"},{"location":"api_reference/models/utils/#utils","text":"","title":"utils"},{"location":"api_reference/models/utils/#optimade.models.utils.ANONYMOUS_ELEMENTS","text":"Returns the first 150 values of the anonymous element generator.","title":"ANONYMOUS_ELEMENTS"},{"location":"api_reference/models/utils/#optimade.models.utils.ATOMIC_NUMBERS","text":"","title":"ATOMIC_NUMBERS"},{"location":"api_reference/models/utils/#optimade.models.utils.CHEMICAL_FORMULA_REGEXP","text":"","title":"CHEMICAL_FORMULA_REGEXP"},{"location":"api_reference/models/utils/#optimade.models.utils.CHEMICAL_SYMBOLS","text":"","title":"CHEMICAL_SYMBOLS"},{"location":"api_reference/models/utils/#optimade.models.utils.EXTRA_SYMBOLS","text":"","title":"EXTRA_SYMBOLS"},{"location":"api_reference/models/utils/#optimade.models.utils.OPTIMADE_SCHEMA_EXTENSION_KEYS","text":"","title":"OPTIMADE_SCHEMA_EXTENSION_KEYS"},{"location":"api_reference/models/utils/#optimade.models.utils.OPTIMADE_SCHEMA_EXTENSION_PREFIX","text":"","title":"OPTIMADE_SCHEMA_EXTENSION_PREFIX"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion","text":"A custom type for a semantic version, using the recommended semver regexp from https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string. Source code in optimade/models/utils.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 class SemanticVersion ( str ): \"\"\"A custom type for a semantic version, using the recommended semver regexp from https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string. \"\"\" regex = re . compile ( r \"^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$\" ) @classmethod def __get_validators__ ( cls ): yield cls . validate @classmethod def __modify_schema__ ( cls , field_schema ): field_schema . update ( pattern = cls . regex . pattern , example = [ \"0.10.1\" , \"1.0.0-rc.2\" , \"1.2.3-rc.5+develop\" ], ) @classmethod def validate ( cls , v : str ): if not cls . regex . match ( v ): raise ValueError ( f \"Unable to validate the version string { v !r} as a semantic version (expected <major>.<minor>.<patch>).\" \"See https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string for more information.\" ) return v @property def _match ( self ): \"\"\"The result of the regex match.\"\"\" return self . regex . match ( self ) @property def major ( self ) -> int : \"\"\"The major version number.\"\"\" return int ( self . _match . group ( 1 )) @property def minor ( self ) -> int : \"\"\"The minor version number.\"\"\" return int ( self . _match . group ( 2 )) @property def patch ( self ) -> int : \"\"\"The patch version number.\"\"\" return int ( self . _match . group ( 3 )) @property def prerelease ( self ) -> str : \"\"\"The pre-release tag.\"\"\" return self . _match . group ( 4 ) @property def build_metadata ( self ) -> str : \"\"\"The build metadata.\"\"\" return self . _match . group ( 5 ) @property def base_version ( self ) -> str : \"\"\"The base version string without patch and metadata info.\"\"\" return f \" { self . major } . { self . minor } . { self . patch } \"","title":"SemanticVersion"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.regex","text":"","title":"regex"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.__get_validators__","text":"Source code in optimade/models/utils.py 163 164 165 @classmethod def __get_validators__ ( cls ): yield cls . validate","title":"__get_validators__()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.__modify_schema__","text":"Source code in optimade/models/utils.py 167 168 169 170 171 172 @classmethod def __modify_schema__ ( cls , field_schema ): field_schema . update ( pattern = cls . regex . pattern , example = [ \"0.10.1\" , \"1.0.0-rc.2\" , \"1.2.3-rc.5+develop\" ], )","title":"__modify_schema__()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.base_version","text":"The base version string without patch and metadata info. Source code in optimade/models/utils.py 214 215 216 217 @property def base_version ( self ) -> str : \"\"\"The base version string without patch and metadata info.\"\"\" return f \" { self . major } . { self . minor } . { self . patch } \"","title":"base_version()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.build_metadata","text":"The build metadata. Source code in optimade/models/utils.py 209 210 211 212 @property def build_metadata ( self ) -> str : \"\"\"The build metadata.\"\"\" return self . _match . group ( 5 )","title":"build_metadata()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.major","text":"The major version number. Source code in optimade/models/utils.py 189 190 191 192 @property def major ( self ) -> int : \"\"\"The major version number.\"\"\" return int ( self . _match . group ( 1 ))","title":"major()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.minor","text":"The minor version number. Source code in optimade/models/utils.py 194 195 196 197 @property def minor ( self ) -> int : \"\"\"The minor version number.\"\"\" return int ( self . _match . group ( 2 ))","title":"minor()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.patch","text":"The patch version number. Source code in optimade/models/utils.py 199 200 201 202 @property def patch ( self ) -> int : \"\"\"The patch version number.\"\"\" return int ( self . _match . group ( 3 ))","title":"patch()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.prerelease","text":"The pre-release tag. Source code in optimade/models/utils.py 204 205 206 207 @property def prerelease ( self ) -> str : \"\"\"The pre-release tag.\"\"\" return self . _match . group ( 4 )","title":"prerelease()"},{"location":"api_reference/models/utils/#optimade.models.utils.SemanticVersion.validate","text":"Source code in optimade/models/utils.py 174 175 176 177 178 179 180 181 182 @classmethod def validate ( cls , v : str ): if not cls . regex . match ( v ): raise ValueError ( f \"Unable to validate the version string { v !r} as a semantic version (expected <major>.<minor>.<patch>).\" \"See https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string for more information.\" ) return v","title":"validate()"},{"location":"api_reference/models/utils/#optimade.models.utils.StrictFieldInfo","text":"Wraps the standard pydantic FieldInfo in order to prefix any custom keys from StrictField . Source code in optimade/models/utils.py 37 38 39 40 41 42 43 44 45 46 47 48 49 class StrictFieldInfo ( FieldInfo ): \"\"\"Wraps the standard pydantic `FieldInfo` in order to prefix any custom keys from `StrictField`. \"\"\" def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) for key in OPTIMADE_SCHEMA_EXTENSION_KEYS : if key in self . extra : self . extra [ f \" { OPTIMADE_SCHEMA_EXTENSION_PREFIX }{ key } \" ] = self . extra . pop ( key )","title":"StrictFieldInfo"},{"location":"api_reference/models/utils/#optimade.models.utils.StrictFieldInfo.__init__","text":"Source code in optimade/models/utils.py 43 44 45 46 47 48 49 def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) for key in OPTIMADE_SCHEMA_EXTENSION_KEYS : if key in self . extra : self . extra [ f \" { OPTIMADE_SCHEMA_EXTENSION_PREFIX }{ key } \" ] = self . extra . pop ( key )","title":"__init__()"},{"location":"api_reference/models/utils/#optimade.models.utils.SupportLevel","text":"OPTIMADE property/field support levels Source code in optimade/models/utils.py 29 30 31 32 33 34 class SupportLevel ( Enum ): \"\"\"OPTIMADE property/field support levels\"\"\" MUST = \"must\" SHOULD = \"should\" OPTIONAL = \"optional\"","title":"SupportLevel"},{"location":"api_reference/models/utils/#optimade.models.utils.SupportLevel.MUST","text":"","title":"MUST"},{"location":"api_reference/models/utils/#optimade.models.utils.SupportLevel.OPTIONAL","text":"","title":"OPTIONAL"},{"location":"api_reference/models/utils/#optimade.models.utils.SupportLevel.SHOULD","text":"","title":"SHOULD"},{"location":"api_reference/models/utils/#optimade.models.utils.OptimadeField","text":"A wrapper around pydantic.Field that adds OPTIMADE-specific field paramters queryable , support and unit , indicating the corresponding support level in the specification and the physical unit of the field. Parameters: Name Type Description Default support Optional [ SupportLevel ] The support level of the field itself, i.e. whether the field can be null or omitted by an implementation. None queryable Optional [ SupportLevel ] The support level corresponding to the queryablility of this field. None unit Optional [ str ] A string describing the unit of the field. None Returns: Type Description Field The pydantic field with extra validation provided by StrictField . Source code in optimade/models/utils.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def OptimadeField ( * args , support : Optional [ SupportLevel ] = None , queryable : Optional [ SupportLevel ] = None , unit : Optional [ str ] = None , ** kwargs , ) -> Field : \"\"\"A wrapper around `pydantic.Field` that adds OPTIMADE-specific field paramters `queryable`, `support` and `unit`, indicating the corresponding support level in the specification and the physical unit of the field. Arguments: support: The support level of the field itself, i.e. whether the field can be null or omitted by an implementation. queryable: The support level corresponding to the queryablility of this field. unit: A string describing the unit of the field. Returns: The pydantic field with extra validation provided by [`StrictField`][optimade.models.utils.StrictField]. \"\"\" # Collect non-null keyword arguments to add to the Field schema if unit is not None : kwargs [ \"unit\" ] = unit if queryable is not None : if isinstance ( queryable , str ): queryable = SupportLevel ( queryable . lower ()) kwargs [ \"queryable\" ] = queryable if support is not None : if isinstance ( support , str ): support = SupportLevel ( support . lower ()) kwargs [ \"support\" ] = support return StrictField ( * args , ** kwargs )","title":"OptimadeField()"},{"location":"api_reference/models/utils/#optimade.models.utils.StrictField","text":"A wrapper around pydantic.Field that does the following: Forbids any \"extra\" keys that would be passed to pydantic.Field , except those used elsewhere to modify the schema in-place, e.g. \"uniqueItems\", \"pattern\" and those added by OptimadeField, e.g. \"unit\", \"queryable\" and \"sortable\". Emits a warning when no description is provided. Parameters: Name Type Description Default *args Any Positional arguments passed through to Field . () description str The description of the Field ; if this is not specified then a UserWarning will be emitted. None **kwargs Any Extra keyword arguments to be passed to Field . {} Raises: Type Description RuntimeError If **kwargs contains a key not found in the function signature of Field , or in the extensions used by models in this package (see above). Returns: Type Description StrictFieldInfo The pydantic Field . Source code in optimade/models/utils.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def StrictField ( * args : \"Any\" , description : str = None , ** kwargs : \"Any\" , ) -> StrictFieldInfo : \"\"\"A wrapper around `pydantic.Field` that does the following: - Forbids any \"extra\" keys that would be passed to `pydantic.Field`, except those used elsewhere to modify the schema in-place, e.g. \"uniqueItems\", \"pattern\" and those added by OptimadeField, e.g. \"unit\", \"queryable\" and \"sortable\". - Emits a warning when no description is provided. Arguments: *args: Positional arguments passed through to `Field`. description: The description of the `Field`; if this is not specified then a `UserWarning` will be emitted. **kwargs: Extra keyword arguments to be passed to `Field`. Raises: RuntimeError: If `**kwargs` contains a key not found in the function signature of `Field`, or in the extensions used by models in this package (see above). Returns: The pydantic `Field`. \"\"\" allowed_keys = [ \"pattern\" , \"uniqueItems\" , \"nullable\" , ] + OPTIMADE_SCHEMA_EXTENSION_KEYS _banned = [ k for k in kwargs if k not in set ( _PYDANTIC_FIELD_KWARGS + allowed_keys )] if _banned : raise RuntimeError ( f \"Not creating StrictField( { args } , { kwargs } ) with forbidden keywords { _banned } .\" ) if description is not None : kwargs [ \"description\" ] = description if description is None : warnings . warn ( f \"No description provided for StrictField specified by { args } , { kwargs } .\" ) return StrictPydanticField ( * args , ** kwargs )","title":"StrictField()"},{"location":"api_reference/models/utils/#optimade.models.utils.StrictPydanticField","text":"Wrapper for Field that uses StrictFieldInfo instead of the pydantic FieldInfo . Source code in optimade/models/utils.py 52 53 54 55 56 57 58 def StrictPydanticField ( * args , ** kwargs ): \"\"\"Wrapper for `Field` that uses `StrictFieldInfo` instead of the pydantic `FieldInfo`. \"\"\" field_info = StrictFieldInfo ( * args , ** kwargs ) field_info . _validate () return field_info","title":"StrictPydanticField()"},{"location":"api_reference/models/utils/#optimade.models.utils.anonymous_element_generator","text":"Generator that yields the next symbol in the A, B, Aa, ... Az naming scheme. Source code in optimade/models/utils.py 220 221 222 223 224 225 226 227 228 def anonymous_element_generator (): \"\"\"Generator that yields the next symbol in the A, B, Aa, ... Az naming scheme.\"\"\" from string import ascii_lowercase for size in itertools . count ( 1 ): for s in itertools . product ( ascii_lowercase , repeat = size ): s = list ( s ) s [ 0 ] = s [ 0 ] . upper () yield \"\" . join ( s )","title":"anonymous_element_generator()"},{"location":"api_reference/server/config/","text":"config \u00b6 CONFIG : ServerConfig = ServerConfig () module-attribute \u00b6 This singleton loads the config from a hierarchy of sources (see customise_sources ) and makes it importable in the server code. DEFAULT_CONFIG_FILE_PATH : str = str ( Path . home () . joinpath ( '.optimade.json' )) module-attribute \u00b6 Default configuration file path. This variable is used as the fallback value if the environment variable OPTIMADE_CONFIG_FILE is not set. Note It is set to: pathlib.Path.home()/.optimade.json For Unix-based systems (Linux) this will be equivalent to ~/.optimade.json . LogLevel \u00b6 Replication of logging LogLevels notset debug info warning error critical Source code in optimade/server/config.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class LogLevel ( Enum ): \"\"\"Replication of logging LogLevels - `notset` - `debug` - `info` - `warning` - `error` - `critical` \"\"\" NOTSET = \"notset\" DEBUG = \"debug\" INFO = \"info\" WARNING = \"warning\" ERROR = \"error\" CRITICAL = \"critical\" CRITICAL = 'critical' class-attribute \u00b6 DEBUG = 'debug' class-attribute \u00b6 ERROR = 'error' class-attribute \u00b6 INFO = 'info' class-attribute \u00b6 NOTSET = 'notset' class-attribute \u00b6 WARNING = 'warning' class-attribute \u00b6 ServerConfig \u00b6 This class stores server config parameters in a way that can be easily extended for new config file types. Source code in optimade/server/config.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 class ServerConfig ( BaseSettings ): \"\"\"This class stores server config parameters in a way that can be easily extended for new config file types. \"\"\" debug : bool = Field ( False , description = \"Turns on Debug Mode for the OPTIMADE Server implementation\" , ) insert_test_data : bool = Field ( True , description = ( \"Insert test data into each collection on server initialisation. If true, the \" \"configured backend will be populated with test data on server start. Should be \" \"disabled for production usage.\" ), ) use_real_mongo : Optional [ bool ] = Field ( None , description = \"DEPRECATED: force usage of MongoDB over any other backend.\" ) database_backend : SupportedBackend = Field ( SupportedBackend . MONGOMOCK , description = \"Which database backend to use out of the supported backends.\" , ) elastic_hosts : Optional [ List [ Dict ]] = Field ( None , description = \"Host settings to pass through to the `Elasticsearch` class.\" ) mongo_database : str = Field ( \"optimade\" , description = \"Mongo database for collection data\" ) mongo_uri : str = Field ( \"localhost:27017\" , description = \"URI for the Mongo server\" ) links_collection : str = Field ( \"links\" , description = \"Mongo collection name for /links endpoint resources\" ) references_collection : str = Field ( \"references\" , description = \"Mongo collection name for /references endpoint resources\" , ) structures_collection : str = Field ( \"structures\" , description = \"Mongo collection name for /structures endpoint resources\" , ) page_limit : int = Field ( 20 , description = \"Default number of resources per page\" ) page_limit_max : int = Field ( 500 , description = \"Max allowed number of resources per page\" ) default_db : str = Field ( \"test_server\" , description = ( \"ID of /links endpoint resource for the chosen default OPTIMADE implementation (only \" \"relevant for the index meta-database)\" ), ) root_path : Optional [ str ] = Field ( None , description = ( \"Sets the FastAPI app `root_path` parameter. This can be used to serve the API under a\" \" path prefix behind a proxy or as a sub-application of another FastAPI app. See \" \"https://fastapi.tiangolo.com/advanced/sub-applications/#technical-details-root_path \" \"for details.\" ), ) base_url : Optional [ str ] = Field ( None , description = \"Base URL for this implementation\" ) implementation : Implementation = Field ( Implementation ( name = \"OPTIMADE Python Tools\" , version = __version__ , source_url = \"https://github.com/Materials-Consortia/optimade-python-tools\" , maintainer = { \"email\" : \"dev@optimade.org\" }, issue_tracker = \"https://github.com/Materials-Consortia/optimade-python-tools/issues\" , ), description = \"Introspective information about this OPTIMADE implementation\" , ) index_base_url : Optional [ AnyHttpUrl ] = Field ( None , description = \"An optional link to the base URL for the index meta-database of the provider.\" , ) provider : Provider = Field ( Provider ( prefix = \"exmpl\" , name = \"Example provider\" , description = \"Provider used for examples, not to be assigned to a real database\" , homepage = \"https://example.com\" , ), description = \"General information about the provider of this OPTIMADE implementation\" , ) provider_fields : Dict [ Literal [ \"links\" , \"references\" , \"structures\" ], List [ Union [ str , Dict [ Literal [ \"name\" , \"type\" , \"unit\" , \"description\" ], str ]]], ] = Field ( {}, description = ( \"A list of additional fields to be served with the provider's prefix attached, \" \"broken down by endpoint.\" ), ) aliases : Dict [ Literal [ \"links\" , \"references\" , \"structures\" ], Dict [ str , str ]] = Field ( {}, description = ( \"A mapping between field names in the database with their corresponding OPTIMADE field\" \" names, broken down by endpoint.\" ), ) length_aliases : Dict [ Literal [ \"links\" , \"references\" , \"structures\" ], Dict [ str , str ] ] = Field ( {}, description = ( \"A mapping between a list property (or otherwise) and an integer property that defines\" \" the length of that list, for example elements -> nelements. The standard aliases are\" \" applied first, so this dictionary must refer to the API fields, not the database \" \"fields.\" ), ) index_links_path : Path = Field ( Path ( __file__ ) . parent . joinpath ( \"index_links.json\" ), description = ( \"Absolute path to a JSON file containing the MongoDB collecton of links entries \" \"(documents) to serve under the /links endpoint of the index meta-database. \" \"NB! As suggested in the previous sentence, these will only be served when using a \" \"MongoDB-based backend.\" ), ) schema_url : Optional [ Union [ str , AnyHttpUrl ]] = Field ( f \"https://schemas.optimade.org/openapi/v { __api_version__ } /optimade.json\" , description = ( \"A URL that will be provided in the `meta->schema` field for every response\" ), ) index_schema_url : Optional [ Union [ str , AnyHttpUrl ]] = Field ( f \"https://schemas.optimade.org/openapi/v { __api_version__ } /optimade_index.json\" , description = ( \"A URL that will be provided in the `meta->schema` field for every response from the index meta-database.\" ), ) log_level : LogLevel = Field ( LogLevel . INFO , description = \"Logging level for the OPTIMADE server.\" ) log_dir : Path = Field ( Path ( \"/var/log/optimade/\" ), description = \"Folder in which log files will be saved.\" , ) validate_query_parameters : Optional [ bool ] = Field ( True , description = \"If True, the server will check whether the query parameters given in the request are correct.\" , ) @validator ( \"implementation\" , pre = True ) def set_implementation_version ( cls , v ): \"\"\"Set defaults and modify bypassed value(s)\"\"\" res = { \"version\" : __version__ } res . update ( v ) return res @root_validator ( pre = True ) def use_real_mongo_override ( cls , values ): \"\"\"Overrides the `database_backend` setting with MongoDB and raises a deprecation warning. \"\"\" use_real_mongo = values . pop ( \"use_real_mongo\" , None ) if use_real_mongo is not None : warnings . warn ( \"'use_real_mongo' is deprecated, please set the appropriate 'database_backend' \" \"instead.\" , DeprecationWarning , ) if use_real_mongo : values [ \"database_backend\" ] = SupportedBackend . MONGODB return values class Config : \"\"\" This is a pydantic model Config object that modifies the behaviour of ServerConfig by adding a prefix to the environment variables that override config file values. It has nothing to do with the OPTIMADE config. \"\"\" env_prefix = \"optimade_\" extra = \"allow\" env_file_encoding = \"utf-8\" @classmethod def customise_sources ( cls , init_settings : SettingsSourceCallable , env_settings : SettingsSourceCallable , file_secret_settings : SettingsSourceCallable , ) -> Tuple [ SettingsSourceCallable , ... ]: \"\"\" **Priority of config settings sources**: 1. Passed arguments upon initialization of [`ServerConfig`][optimade.server.config.ServerConfig]. 2. Environment variables, matching the syntax: `\"OPTIMADE_\"` or `\"optimade_\"` + `<config_name>`, e.g., `OPTIMADE_LOG_LEVEL=debug` or `optimade_log_dir=~/logs_dir/optimade/`. 3. Configuration file (JSON/YAML) taken from: 1. Environment variable `OPTIMADE_CONFIG_FILE`. 2. Default location (see [DEFAULT_CONFIG_FILE_PATH][optimade.server.config.DEFAULT_CONFIG_FILE_PATH]). 4. Settings from secret file (see [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#secret-support) for more information). \"\"\" return ( init_settings , env_settings , config_file_settings , file_secret_settings , ) aliases : Dict [ Literal [ links , references , structures ], Dict [ str , str ]] = Field ({}, description = 'A mapping between field names in the database with their corresponding OPTIMADE field names, broken down by endpoint.' ) class-attribute \u00b6 base_url : Optional [ str ] = Field ( None , description = 'Base URL for this implementation' ) class-attribute \u00b6 database_backend : SupportedBackend = Field ( SupportedBackend . MONGOMOCK , description = 'Which database backend to use out of the supported backends.' ) class-attribute \u00b6 debug : bool = Field ( False , description = 'Turns on Debug Mode for the OPTIMADE Server implementation' ) class-attribute \u00b6 default_db : str = Field ( 'test_server' , description = 'ID of /links endpoint resource for the chosen default OPTIMADE implementation (only relevant for the index meta-database)' ) class-attribute \u00b6 elastic_hosts : Optional [ List [ Dict ]] = Field ( None , description = 'Host settings to pass through to the `Elasticsearch` class.' ) class-attribute \u00b6 implementation : Implementation = Field ( Implementation ( name = 'OPTIMADE Python Tools' , version = __version__ , source_url = 'https://github.com/Materials-Consortia/optimade-python-tools' , maintainer = { 'email' : 'dev@optimade.org' }, issue_tracker = 'https://github.com/Materials-Consortia/optimade-python-tools/issues' ), description = 'Introspective information about this OPTIMADE implementation' ) class-attribute \u00b6 index_base_url : Optional [ AnyHttpUrl ] = Field ( None , description = 'An optional link to the base URL for the index meta-database of the provider.' ) class-attribute \u00b6 index_links_path : Path = Field ( Path ( __file__ ) . parent . joinpath ( 'index_links.json' ), description = 'Absolute path to a JSON file containing the MongoDB collecton of links entries (documents) to serve under the /links endpoint of the index meta-database. NB! As suggested in the previous sentence, these will only be served when using a MongoDB-based backend.' ) class-attribute \u00b6 index_schema_url : Optional [ Union [ str , AnyHttpUrl ]] = Field ( f 'https://schemas.optimade.org/openapi/v { __api_version__ } /optimade_index.json' , description = 'A URL that will be provided in the `meta->schema` field for every response from the index meta-database.' ) class-attribute \u00b6 insert_test_data : bool = Field ( True , description = 'Insert test data into each collection on server initialisation. If true, the configured backend will be populated with test data on server start. Should be disabled for production usage.' ) class-attribute \u00b6 length_aliases : Dict [ Literal [ links , references , structures ], Dict [ str , str ]] = Field ({}, description = 'A mapping between a list property (or otherwise) and an integer property that defines the length of that list, for example elements -> nelements. The standard aliases are applied first, so this dictionary must refer to the API fields, not the database fields.' ) class-attribute \u00b6 links_collection : str = Field ( 'links' , description = 'Mongo collection name for /links endpoint resources' ) class-attribute \u00b6 log_dir : Path = Field ( Path ( '/var/log/optimade/' ), description = 'Folder in which log files will be saved.' ) class-attribute \u00b6 log_level : LogLevel = Field ( LogLevel . INFO , description = 'Logging level for the OPTIMADE server.' ) class-attribute \u00b6 mongo_database : str = Field ( 'optimade' , description = 'Mongo database for collection data' ) class-attribute \u00b6 mongo_uri : str = Field ( 'localhost:27017' , description = 'URI for the Mongo server' ) class-attribute \u00b6 page_limit : int = Field ( 20 , description = 'Default number of resources per page' ) class-attribute \u00b6 page_limit_max : int = Field ( 500 , description = 'Max allowed number of resources per page' ) class-attribute \u00b6 provider : Provider = Field ( Provider ( prefix = 'exmpl' , name = 'Example provider' , description = 'Provider used for examples, not to be assigned to a real database' , homepage = 'https://example.com' ), description = 'General information about the provider of this OPTIMADE implementation' ) class-attribute \u00b6 provider_fields : Dict [ Literal [ links , references , structures ], List [ Union [ str , Dict [ Literal [ name , type , unit , description ], str ]]]] = Field ({}, description = \"A list of additional fields to be served with the provider's prefix attached, broken down by endpoint.\" ) class-attribute \u00b6 references_collection : str = Field ( 'references' , description = 'Mongo collection name for /references endpoint resources' ) class-attribute \u00b6 root_path : Optional [ str ] = Field ( None , description = 'Sets the FastAPI app `root_path` parameter. This can be used to serve the API under a path prefix behind a proxy or as a sub-application of another FastAPI app. See https://fastapi.tiangolo.com/advanced/sub-applications/#technical-details-root_path for details.' ) class-attribute \u00b6 schema_url : Optional [ Union [ str , AnyHttpUrl ]] = Field ( f 'https://schemas.optimade.org/openapi/v { __api_version__ } /optimade.json' , description = 'A URL that will be provided in the `meta->schema` field for every response' ) class-attribute \u00b6 structures_collection : str = Field ( 'structures' , description = 'Mongo collection name for /structures endpoint resources' ) class-attribute \u00b6 use_real_mongo : Optional [ bool ] = Field ( None , description = 'DEPRECATED: force usage of MongoDB over any other backend.' ) class-attribute \u00b6 validate_query_parameters : Optional [ bool ] = Field ( True , description = 'If True, the server will check whether the query parameters given in the request are correct.' ) class-attribute \u00b6 Config \u00b6 This is a pydantic model Config object that modifies the behaviour of ServerConfig by adding a prefix to the environment variables that override config file values. It has nothing to do with the OPTIMADE config. Source code in optimade/server/config.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 class Config : \"\"\" This is a pydantic model Config object that modifies the behaviour of ServerConfig by adding a prefix to the environment variables that override config file values. It has nothing to do with the OPTIMADE config. \"\"\" env_prefix = \"optimade_\" extra = \"allow\" env_file_encoding = \"utf-8\" @classmethod def customise_sources ( cls , init_settings : SettingsSourceCallable , env_settings : SettingsSourceCallable , file_secret_settings : SettingsSourceCallable , ) -> Tuple [ SettingsSourceCallable , ... ]: \"\"\" **Priority of config settings sources**: 1. Passed arguments upon initialization of [`ServerConfig`][optimade.server.config.ServerConfig]. 2. Environment variables, matching the syntax: `\"OPTIMADE_\"` or `\"optimade_\"` + `<config_name>`, e.g., `OPTIMADE_LOG_LEVEL=debug` or `optimade_log_dir=~/logs_dir/optimade/`. 3. Configuration file (JSON/YAML) taken from: 1. Environment variable `OPTIMADE_CONFIG_FILE`. 2. Default location (see [DEFAULT_CONFIG_FILE_PATH][optimade.server.config.DEFAULT_CONFIG_FILE_PATH]). 4. Settings from secret file (see [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#secret-support) for more information). \"\"\" return ( init_settings , env_settings , config_file_settings , file_secret_settings , ) env_file_encoding = 'utf-8' class-attribute \u00b6 env_prefix = 'optimade_' class-attribute \u00b6 extra = 'allow' class-attribute \u00b6 customise_sources ( init_settings , env_settings , file_secret_settings ) classmethod \u00b6 Priority of config settings sources : Passed arguments upon initialization of ServerConfig . Environment variables, matching the syntax: \"OPTIMADE_\" or \"optimade_\" + <config_name> , e.g., OPTIMADE_LOG_LEVEL=debug or optimade_log_dir=~/logs_dir/optimade/ . Configuration file (JSON/YAML) taken from: Environment variable OPTIMADE_CONFIG_FILE . Default location (see DEFAULT_CONFIG_FILE_PATH ). Settings from secret file (see pydantic documentation for more information). Source code in optimade/server/config.py 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 @classmethod def customise_sources ( cls , init_settings : SettingsSourceCallable , env_settings : SettingsSourceCallable , file_secret_settings : SettingsSourceCallable , ) -> Tuple [ SettingsSourceCallable , ... ]: \"\"\" **Priority of config settings sources**: 1. Passed arguments upon initialization of [`ServerConfig`][optimade.server.config.ServerConfig]. 2. Environment variables, matching the syntax: `\"OPTIMADE_\"` or `\"optimade_\"` + `<config_name>`, e.g., `OPTIMADE_LOG_LEVEL=debug` or `optimade_log_dir=~/logs_dir/optimade/`. 3. Configuration file (JSON/YAML) taken from: 1. Environment variable `OPTIMADE_CONFIG_FILE`. 2. Default location (see [DEFAULT_CONFIG_FILE_PATH][optimade.server.config.DEFAULT_CONFIG_FILE_PATH]). 4. Settings from secret file (see [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#secret-support) for more information). \"\"\" return ( init_settings , env_settings , config_file_settings , file_secret_settings , ) set_implementation_version ( v ) \u00b6 Set defaults and modify bypassed value(s) Source code in optimade/server/config.py 289 290 291 292 293 294 @validator ( \"implementation\" , pre = True ) def set_implementation_version ( cls , v ): \"\"\"Set defaults and modify bypassed value(s)\"\"\" res = { \"version\" : __version__ } res . update ( v ) return res use_real_mongo_override ( values ) \u00b6 Overrides the database_backend setting with MongoDB and raises a deprecation warning. Source code in optimade/server/config.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 @root_validator ( pre = True ) def use_real_mongo_override ( cls , values ): \"\"\"Overrides the `database_backend` setting with MongoDB and raises a deprecation warning. \"\"\" use_real_mongo = values . pop ( \"use_real_mongo\" , None ) if use_real_mongo is not None : warnings . warn ( \"'use_real_mongo' is deprecated, please set the appropriate 'database_backend' \" \"instead.\" , DeprecationWarning , ) if use_real_mongo : values [ \"database_backend\" ] = SupportedBackend . MONGODB return values SupportedBackend \u00b6 Enumeration of supported database backends elastic : Elasticsearch . mongodb : MongoDB . mongomock : Also MongoDB, but instead of using the pymongo driver to connect to a live Mongo database instance, this will use the mongomock driver, creating an in-memory database, which is mainly used for testing. Source code in optimade/server/config.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class SupportedBackend ( Enum ): \"\"\"Enumeration of supported database backends - `elastic`: [Elasticsearch](https://www.elastic.co/). - `mongodb`: [MongoDB](https://www.mongodb.com/). - `mongomock`: Also MongoDB, but instead of using the [`pymongo`](https://pymongo.readthedocs.io/) driver to connect to a live Mongo database instance, this will use the [`mongomock`](https://github.com/mongomock/mongomock) driver, creating an in-memory database, which is mainly used for testing. \"\"\" ELASTIC = \"elastic\" MONGODB = \"mongodb\" MONGOMOCK = \"mongomock\" ELASTIC = 'elastic' class-attribute \u00b6 MONGODB = 'mongodb' class-attribute \u00b6 MONGOMOCK = 'mongomock' class-attribute \u00b6 config_file_settings ( settings ) \u00b6 Configuration file settings source. Based on the example in the pydantic documentation , this function loads ServerConfig settings from a configuration file. The file must be of either type JSON or YML/YAML. Parameters: Name Type Description Default settings BaseSettings The pydantic.BaseSettings class using this function as a pydantic.SettingsSourceCallable . required Returns: Type Description Dict [ str , Any ] Dictionary of settings as read from a file. Source code in optimade/server/config.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def config_file_settings ( settings : BaseSettings ) -> Dict [ str , Any ]: \"\"\"Configuration file settings source. Based on the example in the [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#adding-sources), this function loads ServerConfig settings from a configuration file. The file must be of either type JSON or YML/YAML. Parameters: settings: The `pydantic.BaseSettings` class using this function as a `pydantic.SettingsSourceCallable`. Returns: Dictionary of settings as read from a file. \"\"\" import json import os import yaml encoding = settings . __config__ . env_file_encoding config_file = Path ( os . getenv ( \"OPTIMADE_CONFIG_FILE\" , DEFAULT_CONFIG_FILE_PATH )) res = {} if config_file . is_file (): config_file_content = config_file . read_text ( encoding = encoding ) try : res = json . loads ( config_file_content ) except json . JSONDecodeError as json_exc : try : # This can essentially also load JSON files, as JSON is a subset of YAML v1, # but I suspect it is not as rigorous res = yaml . safe_load ( config_file_content ) except yaml . YAMLError as yaml_exc : warnings . warn ( f \"Unable to parse config file { config_file } as JSON or YAML, using the \" \"default settings instead.. \\n \" f \"Errors: \\n JSON: \\n { json_exc } . \\n\\n YAML: \\n { yaml_exc } \" ) else : warnings . warn ( f \"Unable to find config file at { config_file } , using the default settings instead.\" ) if res is None : # This can happen if the yaml loading doesn't succeed properly, e.g., if the file is empty. warnings . warn ( \"Unable to load any settings from {config_file} , using the default settings instead.\" ) res = {} return res","title":"config"},{"location":"api_reference/server/config/#config","text":"","title":"config"},{"location":"api_reference/server/config/#optimade.server.config.CONFIG","text":"This singleton loads the config from a hierarchy of sources (see customise_sources ) and makes it importable in the server code.","title":"CONFIG"},{"location":"api_reference/server/config/#optimade.server.config.DEFAULT_CONFIG_FILE_PATH","text":"Default configuration file path. This variable is used as the fallback value if the environment variable OPTIMADE_CONFIG_FILE is not set. Note It is set to: pathlib.Path.home()/.optimade.json For Unix-based systems (Linux) this will be equivalent to ~/.optimade.json .","title":"DEFAULT_CONFIG_FILE_PATH"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel","text":"Replication of logging LogLevels notset debug info warning error critical Source code in optimade/server/config.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 class LogLevel ( Enum ): \"\"\"Replication of logging LogLevels - `notset` - `debug` - `info` - `warning` - `error` - `critical` \"\"\" NOTSET = \"notset\" DEBUG = \"debug\" INFO = \"info\" WARNING = \"warning\" ERROR = \"error\" CRITICAL = \"critical\"","title":"LogLevel"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel.CRITICAL","text":"","title":"CRITICAL"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel.DEBUG","text":"","title":"DEBUG"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel.ERROR","text":"","title":"ERROR"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel.INFO","text":"","title":"INFO"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel.NOTSET","text":"","title":"NOTSET"},{"location":"api_reference/server/config/#optimade.server.config.LogLevel.WARNING","text":"","title":"WARNING"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig","text":"This class stores server config parameters in a way that can be easily extended for new config file types. Source code in optimade/server/config.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 class ServerConfig ( BaseSettings ): \"\"\"This class stores server config parameters in a way that can be easily extended for new config file types. \"\"\" debug : bool = Field ( False , description = \"Turns on Debug Mode for the OPTIMADE Server implementation\" , ) insert_test_data : bool = Field ( True , description = ( \"Insert test data into each collection on server initialisation. If true, the \" \"configured backend will be populated with test data on server start. Should be \" \"disabled for production usage.\" ), ) use_real_mongo : Optional [ bool ] = Field ( None , description = \"DEPRECATED: force usage of MongoDB over any other backend.\" ) database_backend : SupportedBackend = Field ( SupportedBackend . MONGOMOCK , description = \"Which database backend to use out of the supported backends.\" , ) elastic_hosts : Optional [ List [ Dict ]] = Field ( None , description = \"Host settings to pass through to the `Elasticsearch` class.\" ) mongo_database : str = Field ( \"optimade\" , description = \"Mongo database for collection data\" ) mongo_uri : str = Field ( \"localhost:27017\" , description = \"URI for the Mongo server\" ) links_collection : str = Field ( \"links\" , description = \"Mongo collection name for /links endpoint resources\" ) references_collection : str = Field ( \"references\" , description = \"Mongo collection name for /references endpoint resources\" , ) structures_collection : str = Field ( \"structures\" , description = \"Mongo collection name for /structures endpoint resources\" , ) page_limit : int = Field ( 20 , description = \"Default number of resources per page\" ) page_limit_max : int = Field ( 500 , description = \"Max allowed number of resources per page\" ) default_db : str = Field ( \"test_server\" , description = ( \"ID of /links endpoint resource for the chosen default OPTIMADE implementation (only \" \"relevant for the index meta-database)\" ), ) root_path : Optional [ str ] = Field ( None , description = ( \"Sets the FastAPI app `root_path` parameter. This can be used to serve the API under a\" \" path prefix behind a proxy or as a sub-application of another FastAPI app. See \" \"https://fastapi.tiangolo.com/advanced/sub-applications/#technical-details-root_path \" \"for details.\" ), ) base_url : Optional [ str ] = Field ( None , description = \"Base URL for this implementation\" ) implementation : Implementation = Field ( Implementation ( name = \"OPTIMADE Python Tools\" , version = __version__ , source_url = \"https://github.com/Materials-Consortia/optimade-python-tools\" , maintainer = { \"email\" : \"dev@optimade.org\" }, issue_tracker = \"https://github.com/Materials-Consortia/optimade-python-tools/issues\" , ), description = \"Introspective information about this OPTIMADE implementation\" , ) index_base_url : Optional [ AnyHttpUrl ] = Field ( None , description = \"An optional link to the base URL for the index meta-database of the provider.\" , ) provider : Provider = Field ( Provider ( prefix = \"exmpl\" , name = \"Example provider\" , description = \"Provider used for examples, not to be assigned to a real database\" , homepage = \"https://example.com\" , ), description = \"General information about the provider of this OPTIMADE implementation\" , ) provider_fields : Dict [ Literal [ \"links\" , \"references\" , \"structures\" ], List [ Union [ str , Dict [ Literal [ \"name\" , \"type\" , \"unit\" , \"description\" ], str ]]], ] = Field ( {}, description = ( \"A list of additional fields to be served with the provider's prefix attached, \" \"broken down by endpoint.\" ), ) aliases : Dict [ Literal [ \"links\" , \"references\" , \"structures\" ], Dict [ str , str ]] = Field ( {}, description = ( \"A mapping between field names in the database with their corresponding OPTIMADE field\" \" names, broken down by endpoint.\" ), ) length_aliases : Dict [ Literal [ \"links\" , \"references\" , \"structures\" ], Dict [ str , str ] ] = Field ( {}, description = ( \"A mapping between a list property (or otherwise) and an integer property that defines\" \" the length of that list, for example elements -> nelements. The standard aliases are\" \" applied first, so this dictionary must refer to the API fields, not the database \" \"fields.\" ), ) index_links_path : Path = Field ( Path ( __file__ ) . parent . joinpath ( \"index_links.json\" ), description = ( \"Absolute path to a JSON file containing the MongoDB collecton of links entries \" \"(documents) to serve under the /links endpoint of the index meta-database. \" \"NB! As suggested in the previous sentence, these will only be served when using a \" \"MongoDB-based backend.\" ), ) schema_url : Optional [ Union [ str , AnyHttpUrl ]] = Field ( f \"https://schemas.optimade.org/openapi/v { __api_version__ } /optimade.json\" , description = ( \"A URL that will be provided in the `meta->schema` field for every response\" ), ) index_schema_url : Optional [ Union [ str , AnyHttpUrl ]] = Field ( f \"https://schemas.optimade.org/openapi/v { __api_version__ } /optimade_index.json\" , description = ( \"A URL that will be provided in the `meta->schema` field for every response from the index meta-database.\" ), ) log_level : LogLevel = Field ( LogLevel . INFO , description = \"Logging level for the OPTIMADE server.\" ) log_dir : Path = Field ( Path ( \"/var/log/optimade/\" ), description = \"Folder in which log files will be saved.\" , ) validate_query_parameters : Optional [ bool ] = Field ( True , description = \"If True, the server will check whether the query parameters given in the request are correct.\" , ) @validator ( \"implementation\" , pre = True ) def set_implementation_version ( cls , v ): \"\"\"Set defaults and modify bypassed value(s)\"\"\" res = { \"version\" : __version__ } res . update ( v ) return res @root_validator ( pre = True ) def use_real_mongo_override ( cls , values ): \"\"\"Overrides the `database_backend` setting with MongoDB and raises a deprecation warning. \"\"\" use_real_mongo = values . pop ( \"use_real_mongo\" , None ) if use_real_mongo is not None : warnings . warn ( \"'use_real_mongo' is deprecated, please set the appropriate 'database_backend' \" \"instead.\" , DeprecationWarning , ) if use_real_mongo : values [ \"database_backend\" ] = SupportedBackend . MONGODB return values class Config : \"\"\" This is a pydantic model Config object that modifies the behaviour of ServerConfig by adding a prefix to the environment variables that override config file values. It has nothing to do with the OPTIMADE config. \"\"\" env_prefix = \"optimade_\" extra = \"allow\" env_file_encoding = \"utf-8\" @classmethod def customise_sources ( cls , init_settings : SettingsSourceCallable , env_settings : SettingsSourceCallable , file_secret_settings : SettingsSourceCallable , ) -> Tuple [ SettingsSourceCallable , ... ]: \"\"\" **Priority of config settings sources**: 1. Passed arguments upon initialization of [`ServerConfig`][optimade.server.config.ServerConfig]. 2. Environment variables, matching the syntax: `\"OPTIMADE_\"` or `\"optimade_\"` + `<config_name>`, e.g., `OPTIMADE_LOG_LEVEL=debug` or `optimade_log_dir=~/logs_dir/optimade/`. 3. Configuration file (JSON/YAML) taken from: 1. Environment variable `OPTIMADE_CONFIG_FILE`. 2. Default location (see [DEFAULT_CONFIG_FILE_PATH][optimade.server.config.DEFAULT_CONFIG_FILE_PATH]). 4. Settings from secret file (see [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#secret-support) for more information). \"\"\" return ( init_settings , env_settings , config_file_settings , file_secret_settings , )","title":"ServerConfig"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.aliases","text":"","title":"aliases"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.base_url","text":"","title":"base_url"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.database_backend","text":"","title":"database_backend"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.debug","text":"","title":"debug"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.default_db","text":"","title":"default_db"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.elastic_hosts","text":"","title":"elastic_hosts"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.implementation","text":"","title":"implementation"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.index_base_url","text":"","title":"index_base_url"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.index_links_path","text":"","title":"index_links_path"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.index_schema_url","text":"","title":"index_schema_url"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.insert_test_data","text":"","title":"insert_test_data"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.length_aliases","text":"","title":"length_aliases"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.links_collection","text":"","title":"links_collection"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.log_dir","text":"","title":"log_dir"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.log_level","text":"","title":"log_level"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.mongo_database","text":"","title":"mongo_database"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.mongo_uri","text":"","title":"mongo_uri"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.page_limit","text":"","title":"page_limit"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.page_limit_max","text":"","title":"page_limit_max"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.provider","text":"","title":"provider"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.provider_fields","text":"","title":"provider_fields"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.references_collection","text":"","title":"references_collection"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.root_path","text":"","title":"root_path"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.schema_url","text":"","title":"schema_url"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.structures_collection","text":"","title":"structures_collection"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.use_real_mongo","text":"","title":"use_real_mongo"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.validate_query_parameters","text":"","title":"validate_query_parameters"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.Config","text":"This is a pydantic model Config object that modifies the behaviour of ServerConfig by adding a prefix to the environment variables that override config file values. It has nothing to do with the OPTIMADE config. Source code in optimade/server/config.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 class Config : \"\"\" This is a pydantic model Config object that modifies the behaviour of ServerConfig by adding a prefix to the environment variables that override config file values. It has nothing to do with the OPTIMADE config. \"\"\" env_prefix = \"optimade_\" extra = \"allow\" env_file_encoding = \"utf-8\" @classmethod def customise_sources ( cls , init_settings : SettingsSourceCallable , env_settings : SettingsSourceCallable , file_secret_settings : SettingsSourceCallable , ) -> Tuple [ SettingsSourceCallable , ... ]: \"\"\" **Priority of config settings sources**: 1. Passed arguments upon initialization of [`ServerConfig`][optimade.server.config.ServerConfig]. 2. Environment variables, matching the syntax: `\"OPTIMADE_\"` or `\"optimade_\"` + `<config_name>`, e.g., `OPTIMADE_LOG_LEVEL=debug` or `optimade_log_dir=~/logs_dir/optimade/`. 3. Configuration file (JSON/YAML) taken from: 1. Environment variable `OPTIMADE_CONFIG_FILE`. 2. Default location (see [DEFAULT_CONFIG_FILE_PATH][optimade.server.config.DEFAULT_CONFIG_FILE_PATH]). 4. Settings from secret file (see [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#secret-support) for more information). \"\"\" return ( init_settings , env_settings , config_file_settings , file_secret_settings , )","title":"Config"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.Config.env_file_encoding","text":"","title":"env_file_encoding"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.Config.env_prefix","text":"","title":"env_prefix"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.Config.extra","text":"","title":"extra"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.Config.customise_sources","text":"Priority of config settings sources : Passed arguments upon initialization of ServerConfig . Environment variables, matching the syntax: \"OPTIMADE_\" or \"optimade_\" + <config_name> , e.g., OPTIMADE_LOG_LEVEL=debug or optimade_log_dir=~/logs_dir/optimade/ . Configuration file (JSON/YAML) taken from: Environment variable OPTIMADE_CONFIG_FILE . Default location (see DEFAULT_CONFIG_FILE_PATH ). Settings from secret file (see pydantic documentation for more information). Source code in optimade/server/config.py 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 @classmethod def customise_sources ( cls , init_settings : SettingsSourceCallable , env_settings : SettingsSourceCallable , file_secret_settings : SettingsSourceCallable , ) -> Tuple [ SettingsSourceCallable , ... ]: \"\"\" **Priority of config settings sources**: 1. Passed arguments upon initialization of [`ServerConfig`][optimade.server.config.ServerConfig]. 2. Environment variables, matching the syntax: `\"OPTIMADE_\"` or `\"optimade_\"` + `<config_name>`, e.g., `OPTIMADE_LOG_LEVEL=debug` or `optimade_log_dir=~/logs_dir/optimade/`. 3. Configuration file (JSON/YAML) taken from: 1. Environment variable `OPTIMADE_CONFIG_FILE`. 2. Default location (see [DEFAULT_CONFIG_FILE_PATH][optimade.server.config.DEFAULT_CONFIG_FILE_PATH]). 4. Settings from secret file (see [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#secret-support) for more information). \"\"\" return ( init_settings , env_settings , config_file_settings , file_secret_settings , )","title":"customise_sources()"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.set_implementation_version","text":"Set defaults and modify bypassed value(s) Source code in optimade/server/config.py 289 290 291 292 293 294 @validator ( \"implementation\" , pre = True ) def set_implementation_version ( cls , v ): \"\"\"Set defaults and modify bypassed value(s)\"\"\" res = { \"version\" : __version__ } res . update ( v ) return res","title":"set_implementation_version()"},{"location":"api_reference/server/config/#optimade.server.config.ServerConfig.use_real_mongo_override","text":"Overrides the database_backend setting with MongoDB and raises a deprecation warning. Source code in optimade/server/config.py 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 @root_validator ( pre = True ) def use_real_mongo_override ( cls , values ): \"\"\"Overrides the `database_backend` setting with MongoDB and raises a deprecation warning. \"\"\" use_real_mongo = values . pop ( \"use_real_mongo\" , None ) if use_real_mongo is not None : warnings . warn ( \"'use_real_mongo' is deprecated, please set the appropriate 'database_backend' \" \"instead.\" , DeprecationWarning , ) if use_real_mongo : values [ \"database_backend\" ] = SupportedBackend . MONGODB return values","title":"use_real_mongo_override()"},{"location":"api_reference/server/config/#optimade.server.config.SupportedBackend","text":"Enumeration of supported database backends elastic : Elasticsearch . mongodb : MongoDB . mongomock : Also MongoDB, but instead of using the pymongo driver to connect to a live Mongo database instance, this will use the mongomock driver, creating an in-memory database, which is mainly used for testing. Source code in optimade/server/config.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class SupportedBackend ( Enum ): \"\"\"Enumeration of supported database backends - `elastic`: [Elasticsearch](https://www.elastic.co/). - `mongodb`: [MongoDB](https://www.mongodb.com/). - `mongomock`: Also MongoDB, but instead of using the [`pymongo`](https://pymongo.readthedocs.io/) driver to connect to a live Mongo database instance, this will use the [`mongomock`](https://github.com/mongomock/mongomock) driver, creating an in-memory database, which is mainly used for testing. \"\"\" ELASTIC = \"elastic\" MONGODB = \"mongodb\" MONGOMOCK = \"mongomock\"","title":"SupportedBackend"},{"location":"api_reference/server/config/#optimade.server.config.SupportedBackend.ELASTIC","text":"","title":"ELASTIC"},{"location":"api_reference/server/config/#optimade.server.config.SupportedBackend.MONGODB","text":"","title":"MONGODB"},{"location":"api_reference/server/config/#optimade.server.config.SupportedBackend.MONGOMOCK","text":"","title":"MONGOMOCK"},{"location":"api_reference/server/config/#optimade.server.config.config_file_settings","text":"Configuration file settings source. Based on the example in the pydantic documentation , this function loads ServerConfig settings from a configuration file. The file must be of either type JSON or YML/YAML. Parameters: Name Type Description Default settings BaseSettings The pydantic.BaseSettings class using this function as a pydantic.SettingsSourceCallable . required Returns: Type Description Dict [ str , Any ] Dictionary of settings as read from a file. Source code in optimade/server/config.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def config_file_settings ( settings : BaseSettings ) -> Dict [ str , Any ]: \"\"\"Configuration file settings source. Based on the example in the [pydantic documentation](https://pydantic-docs.helpmanual.io/usage/settings/#adding-sources), this function loads ServerConfig settings from a configuration file. The file must be of either type JSON or YML/YAML. Parameters: settings: The `pydantic.BaseSettings` class using this function as a `pydantic.SettingsSourceCallable`. Returns: Dictionary of settings as read from a file. \"\"\" import json import os import yaml encoding = settings . __config__ . env_file_encoding config_file = Path ( os . getenv ( \"OPTIMADE_CONFIG_FILE\" , DEFAULT_CONFIG_FILE_PATH )) res = {} if config_file . is_file (): config_file_content = config_file . read_text ( encoding = encoding ) try : res = json . loads ( config_file_content ) except json . JSONDecodeError as json_exc : try : # This can essentially also load JSON files, as JSON is a subset of YAML v1, # but I suspect it is not as rigorous res = yaml . safe_load ( config_file_content ) except yaml . YAMLError as yaml_exc : warnings . warn ( f \"Unable to parse config file { config_file } as JSON or YAML, using the \" \"default settings instead.. \\n \" f \"Errors: \\n JSON: \\n { json_exc } . \\n\\n YAML: \\n { yaml_exc } \" ) else : warnings . warn ( f \"Unable to find config file at { config_file } , using the default settings instead.\" ) if res is None : # This can happen if the yaml loading doesn't succeed properly, e.g., if the file is empty. warnings . warn ( \"Unable to load any settings from {config_file} , using the default settings instead.\" ) res = {} return res","title":"config_file_settings()"},{"location":"api_reference/server/exception_handlers/","text":"exception_handlers \u00b6 OPTIMADE_EXCEPTIONS : Tuple [ Exception , Callable [[ Request , Exception ], JSONAPIResponse ]] = (( StarletteHTTPException , http_exception_handler ), ( RequestValidationError , request_validation_exception_handler ), ( ValidationError , validation_exception_handler ), ( VisitError , grammar_not_implemented_handler ), ( NotImplementedError , not_implemented_handler ), ( Exception , general_exception_handler )) module-attribute \u00b6 A tuple of all pairs of exceptions and handler functions that allow for appropriate responses to be returned in certain scenarios according to the OPTIMADE specification. To use these in FastAPI app code: from fastapi import FastAPI app = FastAPI () for exception , handler in OPTIMADE_EXCEPTIONS : app . add_exception_handler ( exception , handler ) general_exception ( request , exc , status_code = 500 , errors = None ) \u00b6 Handle an exception Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc Exception The exception being raised. required status_code int The returned HTTP status code for the error response. 500 errors List [ OptimadeError ] List of error resources as defined in the OPTIMADE specification . None Returns: Type Description JSONAPIResponse A JSON HTTP response based on ErrorResponse . Source code in optimade/server/exception_handlers.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def general_exception ( request : Request , exc : Exception , status_code : int = 500 , # A status_code in `exc` will take precedence errors : List [ OptimadeError ] = None , ) -> JSONAPIResponse : \"\"\"Handle an exception Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. status_code: The returned HTTP status code for the error response. errors: List of error resources as defined in [the OPTIMADE specification](https://github.com/Materials-Consortia/OPTIMADE/blob/develop/optimade.rst#json-response-schema-common-fields). Returns: A JSON HTTP response based on [`ErrorResponse`][optimade.models.responses.ErrorResponse]. \"\"\" debug_info = {} if CONFIG . debug : tb = \"\" . join ( traceback . format_exception ( type ( exc ), value = exc , tb = exc . __traceback__ ) ) LOGGER . error ( \"Traceback: \\n %s \" , tb ) debug_info [ f \"_ { CONFIG . provider . prefix } _traceback\" ] = tb try : http_response_code = int ( exc . status_code ) except AttributeError : http_response_code = int ( status_code ) try : title = str ( exc . title ) except AttributeError : title = str ( exc . __class__ . __name__ ) try : detail = str ( exc . detail ) except AttributeError : detail = str ( exc ) if errors is None : errors = [ OptimadeError ( detail = detail , status = http_response_code , title = title )] response = ErrorResponse ( meta = meta_values ( url = request . url , data_returned = 0 , data_available = 0 , more_data_available = False , schema = CONFIG . schema_url , ** debug_info , ), errors = errors , ) return JSONAPIResponse ( status_code = http_response_code , content = jsonable_encoder ( response , exclude_unset = True ), ) general_exception_handler ( request , exc ) \u00b6 Catch all Python Exceptions not handled by other exception handlers Pass-through directly to general_exception() . Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc Exception The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def general_exception_handler ( request : Request , exc : Exception ) -> JSONAPIResponse : \"\"\"Catch all Python Exceptions not handled by other exception handlers Pass-through directly to [`general_exception()`][optimade.server.exception_handlers.general_exception]. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" return general_exception ( request , exc ) grammar_not_implemented_handler ( request , exc ) \u00b6 Handle an error raised by Lark during filter transformation All errors raised during filter transformation are wrapped in the Lark VisitError . According to the OPTIMADE specification, these errors are repurposed to be 501 NotImplementedErrors. For special exceptions, like BadRequest , we pass-through to general_exception() , since they should not return a 501 NotImplementedError. Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc VisitError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def grammar_not_implemented_handler ( request : Request , exc : VisitError ) -> JSONAPIResponse : \"\"\"Handle an error raised by Lark during filter transformation All errors raised during filter transformation are wrapped in the Lark `VisitError`. According to the OPTIMADE specification, these errors are repurposed to be 501 NotImplementedErrors. For special exceptions, like [`BadRequest`][optimade.server.exceptions.BadRequest], we pass-through to [`general_exception()`][optimade.server.exception_handlers.general_exception], since they should not return a 501 NotImplementedError. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" pass_through_exceptions = ( BadRequest ,) orig_exc = getattr ( exc , \"orig_exc\" , None ) if isinstance ( orig_exc , pass_through_exceptions ): return general_exception ( request , orig_exc ) rule = getattr ( exc . obj , \"data\" , getattr ( exc . obj , \"type\" , str ( exc ))) status = 501 title = \"NotImplementedError\" detail = ( f \"Error trying to process rule ' { rule } '\" if not str ( exc . orig_exc ) else str ( exc . orig_exc ) ) error = OptimadeError ( detail = detail , status = status , title = title ) return general_exception ( request , exc , status_code = status , errors = [ error ]) http_exception_handler ( request , exc ) \u00b6 Handle a general HTTP Exception from Starlette Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc StarletteHTTPException The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def http_exception_handler ( request : Request , exc : StarletteHTTPException ) -> JSONAPIResponse : \"\"\"Handle a general HTTP Exception from Starlette Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" return general_exception ( request , exc ) not_implemented_handler ( request , exc ) \u00b6 Handle a standard NotImplementedError Python exception Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc NotImplementedError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def not_implemented_handler ( request : Request , exc : NotImplementedError ) -> JSONAPIResponse : \"\"\"Handle a standard NotImplementedError Python exception Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" status = 501 title = \"NotImplementedError\" detail = str ( exc ) error = OptimadeError ( detail = detail , status = status , title = title ) return general_exception ( request , exc , status_code = status , errors = [ error ]) request_validation_exception_handler ( request , exc ) \u00b6 Handle a request validation error from FastAPI RequestValidationError is a specialization of a general pydantic ValidationError . Pass-through directly to general_exception() . Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc RequestValidationError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def request_validation_exception_handler ( request : Request , exc : RequestValidationError ) -> JSONAPIResponse : \"\"\"Handle a request validation error from FastAPI `RequestValidationError` is a specialization of a general pydantic `ValidationError`. Pass-through directly to [`general_exception()`][optimade.server.exception_handlers.general_exception]. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" return general_exception ( request , exc ) validation_exception_handler ( request , exc ) \u00b6 Handle a general pydantic validation error The pydantic ValidationError usually contains a list of errors, this function extracts them and wraps them in the OPTIMADE specific error resource. Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc ValidationError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def validation_exception_handler ( request : Request , exc : ValidationError ) -> JSONAPIResponse : \"\"\"Handle a general pydantic validation error The pydantic `ValidationError` usually contains a list of errors, this function extracts them and wraps them in the OPTIMADE specific error resource. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" status = 500 title = \"ValidationError\" errors = set () for error in exc . errors (): pointer = \"/\" + \"/\" . join ([ str ( _ ) for _ in error [ \"loc\" ]]) source = ErrorSource ( pointer = pointer ) code = error [ \"type\" ] detail = error [ \"msg\" ] errors . add ( OptimadeError ( detail = detail , status = status , title = title , source = source , code = code ) ) return general_exception ( request , exc , status_code = status , errors = list ( errors ))","title":"exception_handlers"},{"location":"api_reference/server/exception_handlers/#exception_handlers","text":"","title":"exception_handlers"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.OPTIMADE_EXCEPTIONS","text":"A tuple of all pairs of exceptions and handler functions that allow for appropriate responses to be returned in certain scenarios according to the OPTIMADE specification. To use these in FastAPI app code: from fastapi import FastAPI app = FastAPI () for exception , handler in OPTIMADE_EXCEPTIONS : app . add_exception_handler ( exception , handler )","title":"OPTIMADE_EXCEPTIONS"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.general_exception","text":"Handle an exception Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc Exception The exception being raised. required status_code int The returned HTTP status code for the error response. 500 errors List [ OptimadeError ] List of error resources as defined in the OPTIMADE specification . None Returns: Type Description JSONAPIResponse A JSON HTTP response based on ErrorResponse . Source code in optimade/server/exception_handlers.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def general_exception ( request : Request , exc : Exception , status_code : int = 500 , # A status_code in `exc` will take precedence errors : List [ OptimadeError ] = None , ) -> JSONAPIResponse : \"\"\"Handle an exception Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. status_code: The returned HTTP status code for the error response. errors: List of error resources as defined in [the OPTIMADE specification](https://github.com/Materials-Consortia/OPTIMADE/blob/develop/optimade.rst#json-response-schema-common-fields). Returns: A JSON HTTP response based on [`ErrorResponse`][optimade.models.responses.ErrorResponse]. \"\"\" debug_info = {} if CONFIG . debug : tb = \"\" . join ( traceback . format_exception ( type ( exc ), value = exc , tb = exc . __traceback__ ) ) LOGGER . error ( \"Traceback: \\n %s \" , tb ) debug_info [ f \"_ { CONFIG . provider . prefix } _traceback\" ] = tb try : http_response_code = int ( exc . status_code ) except AttributeError : http_response_code = int ( status_code ) try : title = str ( exc . title ) except AttributeError : title = str ( exc . __class__ . __name__ ) try : detail = str ( exc . detail ) except AttributeError : detail = str ( exc ) if errors is None : errors = [ OptimadeError ( detail = detail , status = http_response_code , title = title )] response = ErrorResponse ( meta = meta_values ( url = request . url , data_returned = 0 , data_available = 0 , more_data_available = False , schema = CONFIG . schema_url , ** debug_info , ), errors = errors , ) return JSONAPIResponse ( status_code = http_response_code , content = jsonable_encoder ( response , exclude_unset = True ), )","title":"general_exception()"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.general_exception_handler","text":"Catch all Python Exceptions not handled by other exception handlers Pass-through directly to general_exception() . Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc Exception The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 208 209 210 211 212 213 214 215 216 217 218 219 220 221 def general_exception_handler ( request : Request , exc : Exception ) -> JSONAPIResponse : \"\"\"Catch all Python Exceptions not handled by other exception handlers Pass-through directly to [`general_exception()`][optimade.server.exception_handlers.general_exception]. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" return general_exception ( request , exc )","title":"general_exception_handler()"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.grammar_not_implemented_handler","text":"Handle an error raised by Lark during filter transformation All errors raised during filter transformation are wrapped in the Lark VisitError . According to the OPTIMADE specification, these errors are repurposed to be 501 NotImplementedErrors. For special exceptions, like BadRequest , we pass-through to general_exception() , since they should not return a 501 NotImplementedError. Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc VisitError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def grammar_not_implemented_handler ( request : Request , exc : VisitError ) -> JSONAPIResponse : \"\"\"Handle an error raised by Lark during filter transformation All errors raised during filter transformation are wrapped in the Lark `VisitError`. According to the OPTIMADE specification, these errors are repurposed to be 501 NotImplementedErrors. For special exceptions, like [`BadRequest`][optimade.server.exceptions.BadRequest], we pass-through to [`general_exception()`][optimade.server.exception_handlers.general_exception], since they should not return a 501 NotImplementedError. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" pass_through_exceptions = ( BadRequest ,) orig_exc = getattr ( exc , \"orig_exc\" , None ) if isinstance ( orig_exc , pass_through_exceptions ): return general_exception ( request , orig_exc ) rule = getattr ( exc . obj , \"data\" , getattr ( exc . obj , \"type\" , str ( exc ))) status = 501 title = \"NotImplementedError\" detail = ( f \"Error trying to process rule ' { rule } '\" if not str ( exc . orig_exc ) else str ( exc . orig_exc ) ) error = OptimadeError ( detail = detail , status = status , title = title ) return general_exception ( request , exc , status_code = status , errors = [ error ])","title":"grammar_not_implemented_handler()"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.http_exception_handler","text":"Handle a general HTTP Exception from Starlette Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc StarletteHTTPException The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def http_exception_handler ( request : Request , exc : StarletteHTTPException ) -> JSONAPIResponse : \"\"\"Handle a general HTTP Exception from Starlette Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" return general_exception ( request , exc )","title":"http_exception_handler()"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.not_implemented_handler","text":"Handle a standard NotImplementedError Python exception Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc NotImplementedError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def not_implemented_handler ( request : Request , exc : NotImplementedError ) -> JSONAPIResponse : \"\"\"Handle a standard NotImplementedError Python exception Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" status = 501 title = \"NotImplementedError\" detail = str ( exc ) error = OptimadeError ( detail = detail , status = status , title = title ) return general_exception ( request , exc , status_code = status , errors = [ error ])","title":"not_implemented_handler()"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.request_validation_exception_handler","text":"Handle a request validation error from FastAPI RequestValidationError is a specialization of a general pydantic ValidationError . Pass-through directly to general_exception() . Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc RequestValidationError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def request_validation_exception_handler ( request : Request , exc : RequestValidationError ) -> JSONAPIResponse : \"\"\"Handle a request validation error from FastAPI `RequestValidationError` is a specialization of a general pydantic `ValidationError`. Pass-through directly to [`general_exception()`][optimade.server.exception_handlers.general_exception]. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" return general_exception ( request , exc )","title":"request_validation_exception_handler()"},{"location":"api_reference/server/exception_handlers/#optimade.server.exception_handlers.validation_exception_handler","text":"Handle a general pydantic validation error The pydantic ValidationError usually contains a list of errors, this function extracts them and wraps them in the OPTIMADE specific error resource. Parameters: Name Type Description Default request Request The HTTP request resulting in the exception being raised. required exc ValidationError The exception being raised. required Returns: Type Description JSONAPIResponse A JSON HTTP response through general_exception() . Source code in optimade/server/exception_handlers.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def validation_exception_handler ( request : Request , exc : ValidationError ) -> JSONAPIResponse : \"\"\"Handle a general pydantic validation error The pydantic `ValidationError` usually contains a list of errors, this function extracts them and wraps them in the OPTIMADE specific error resource. Parameters: request: The HTTP request resulting in the exception being raised. exc: The exception being raised. Returns: A JSON HTTP response through [`general_exception()`][optimade.server.exception_handlers.general_exception]. \"\"\" status = 500 title = \"ValidationError\" errors = set () for error in exc . errors (): pointer = \"/\" + \"/\" . join ([ str ( _ ) for _ in error [ \"loc\" ]]) source = ErrorSource ( pointer = pointer ) code = error [ \"type\" ] detail = error [ \"msg\" ] errors . add ( OptimadeError ( detail = detail , status = status , title = title , source = source , code = code ) ) return general_exception ( request , exc , status_code = status , errors = list ( errors ))","title":"validation_exception_handler()"},{"location":"api_reference/server/exceptions/","text":"exceptions \u00b6 BadRequest \u00b6 400 Bad Request Source code in optimade/server/exceptions.py 44 45 46 47 48 class BadRequest ( HTTPException ): \"\"\"400 Bad Request\"\"\" status_code : int = 400 title : str = \"Bad Request\" Forbidden \u00b6 403 Forbidden Source code in optimade/server/exceptions.py 58 59 60 61 62 class Forbidden ( HTTPException ): \"\"\"403 Forbidden\"\"\" status_code : int = 403 title : str = \"Forbidden\" HTTPException \u00b6 This abstract class makes it easier to subclass FastAPI's HTTPException with new status codes. It can also be useful when testing requires a string representation of an exception that contains the HTTPException detail string, rather than the standard Python exception message. Attributes: Name Type Description status_code int The HTTP status code accompanying this exception. title str A descriptive title for this exception. Source code in optimade/server/exceptions.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class HTTPException ( FastAPIHTTPException , ABC ): \"\"\"This abstract class makes it easier to subclass FastAPI's HTTPException with new status codes. It can also be useful when testing requires a string representation of an exception that contains the HTTPException detail string, rather than the standard Python exception message. Attributes: status_code: The HTTP status code accompanying this exception. title: A descriptive title for this exception. \"\"\" status_code : int = None title : str def __init__ ( self , detail : str = None , headers : dict = None ) -> None : if self . status_code is None : raise AttributeError ( \"HTTPException class {self.__class__.__name__} is missing required `status_code` attribute.\" ) super () . __init__ ( status_code = self . status_code , detail = detail , headers = headers ) def __str__ ( self ) -> str : return self . detail if self . detail is not None else self . __repr__ () InternalServerError \u00b6 500 Internal Server Error Source code in optimade/server/exceptions.py 79 80 81 82 83 class InternalServerError ( HTTPException ): \"\"\"500 Internal Server Error\"\"\" status_code : int = 500 title : str = \"Internal Server Error\" NotFound \u00b6 404 Not Found Source code in optimade/server/exceptions.py 65 66 67 68 69 class NotFound ( HTTPException ): \"\"\"404 Not Found\"\"\" status_code : int = 404 title : str = \"Not Found\" NotImplementedResponse \u00b6 501 Not Implemented Source code in optimade/server/exceptions.py 86 87 88 89 90 class NotImplementedResponse ( HTTPException ): \"\"\"501 Not Implemented\"\"\" status_code : int = 501 title : str = \"Not Implemented\" UnprocessableEntity \u00b6 422 Unprocessable Entity Source code in optimade/server/exceptions.py 72 73 74 75 76 class UnprocessableEntity ( HTTPException ): \"\"\"422 Unprocessable Entity\"\"\" status_code : int = 422 title : str = \"Unprocessable Entity\" VersionNotSupported \u00b6 553 Version Not Supported Source code in optimade/server/exceptions.py 51 52 53 54 55 class VersionNotSupported ( HTTPException ): \"\"\"553 Version Not Supported\"\"\" status_code : int = 553 title : str = \"Version Not Supported\"","title":"exceptions"},{"location":"api_reference/server/exceptions/#exceptions","text":"","title":"exceptions"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.BadRequest","text":"400 Bad Request Source code in optimade/server/exceptions.py 44 45 46 47 48 class BadRequest ( HTTPException ): \"\"\"400 Bad Request\"\"\" status_code : int = 400 title : str = \"Bad Request\"","title":"BadRequest"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.Forbidden","text":"403 Forbidden Source code in optimade/server/exceptions.py 58 59 60 61 62 class Forbidden ( HTTPException ): \"\"\"403 Forbidden\"\"\" status_code : int = 403 title : str = \"Forbidden\"","title":"Forbidden"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.HTTPException","text":"This abstract class makes it easier to subclass FastAPI's HTTPException with new status codes. It can also be useful when testing requires a string representation of an exception that contains the HTTPException detail string, rather than the standard Python exception message. Attributes: Name Type Description status_code int The HTTP status code accompanying this exception. title str A descriptive title for this exception. Source code in optimade/server/exceptions.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class HTTPException ( FastAPIHTTPException , ABC ): \"\"\"This abstract class makes it easier to subclass FastAPI's HTTPException with new status codes. It can also be useful when testing requires a string representation of an exception that contains the HTTPException detail string, rather than the standard Python exception message. Attributes: status_code: The HTTP status code accompanying this exception. title: A descriptive title for this exception. \"\"\" status_code : int = None title : str def __init__ ( self , detail : str = None , headers : dict = None ) -> None : if self . status_code is None : raise AttributeError ( \"HTTPException class {self.__class__.__name__} is missing required `status_code` attribute.\" ) super () . __init__ ( status_code = self . status_code , detail = detail , headers = headers ) def __str__ ( self ) -> str : return self . detail if self . detail is not None else self . __repr__ ()","title":"HTTPException"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.InternalServerError","text":"500 Internal Server Error Source code in optimade/server/exceptions.py 79 80 81 82 83 class InternalServerError ( HTTPException ): \"\"\"500 Internal Server Error\"\"\" status_code : int = 500 title : str = \"Internal Server Error\"","title":"InternalServerError"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.NotFound","text":"404 Not Found Source code in optimade/server/exceptions.py 65 66 67 68 69 class NotFound ( HTTPException ): \"\"\"404 Not Found\"\"\" status_code : int = 404 title : str = \"Not Found\"","title":"NotFound"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.NotImplementedResponse","text":"501 Not Implemented Source code in optimade/server/exceptions.py 86 87 88 89 90 class NotImplementedResponse ( HTTPException ): \"\"\"501 Not Implemented\"\"\" status_code : int = 501 title : str = \"Not Implemented\"","title":"NotImplementedResponse"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.UnprocessableEntity","text":"422 Unprocessable Entity Source code in optimade/server/exceptions.py 72 73 74 75 76 class UnprocessableEntity ( HTTPException ): \"\"\"422 Unprocessable Entity\"\"\" status_code : int = 422 title : str = \"Unprocessable Entity\"","title":"UnprocessableEntity"},{"location":"api_reference/server/exceptions/#optimade.server.exceptions.VersionNotSupported","text":"553 Version Not Supported Source code in optimade/server/exceptions.py 51 52 53 54 55 class VersionNotSupported ( HTTPException ): \"\"\"553 Version Not Supported\"\"\" status_code : int = 553 title : str = \"Version Not Supported\"","title":"VersionNotSupported"},{"location":"api_reference/server/logger/","text":"logger \u00b6 Logging to both file and terminal","title":"logger"},{"location":"api_reference/server/logger/#logger","text":"Logging to both file and terminal","title":"logger"},{"location":"api_reference/server/main/","text":"main \u00b6 The OPTIMADE server The server is based on MongoDB, using either pymongo or mongomock . This is an example implementation with example data. To implement your own server see the documentation at https://optimade.org/optimade-python-tools. add_major_version_base_url ( app ) \u00b6 Add mandatory vMajor endpoints, i.e. all except versions. Source code in optimade/server/main.py 110 111 112 113 def add_major_version_base_url ( app : FastAPI ): \"\"\"Add mandatory vMajor endpoints, i.e. all except versions.\"\"\" for endpoint in ( info , links , references , structures , landing ): app . include_router ( endpoint . router , prefix = BASE_URL_PREFIXES [ \"major\" ]) add_optional_versioned_base_urls ( app ) \u00b6 Add the following OPTIONAL prefixes/base URLs to server: /vMajor.Minor /vMajor.Minor.Patch Source code in optimade/server/main.py 116 117 118 119 120 121 122 123 124 125 def add_optional_versioned_base_urls ( app : FastAPI ): \"\"\"Add the following OPTIONAL prefixes/base URLs to server: ``` /vMajor.Minor /vMajor.Minor.Patch ``` \"\"\" for version in ( \"minor\" , \"patch\" ): for endpoint in ( info , links , references , structures , landing ): app . include_router ( endpoint . router , prefix = BASE_URL_PREFIXES [ version ])","title":"main"},{"location":"api_reference/server/main/#main","text":"The OPTIMADE server The server is based on MongoDB, using either pymongo or mongomock . This is an example implementation with example data. To implement your own server see the documentation at https://optimade.org/optimade-python-tools.","title":"main"},{"location":"api_reference/server/main/#optimade.server.main.add_major_version_base_url","text":"Add mandatory vMajor endpoints, i.e. all except versions. Source code in optimade/server/main.py 110 111 112 113 def add_major_version_base_url ( app : FastAPI ): \"\"\"Add mandatory vMajor endpoints, i.e. all except versions.\"\"\" for endpoint in ( info , links , references , structures , landing ): app . include_router ( endpoint . router , prefix = BASE_URL_PREFIXES [ \"major\" ])","title":"add_major_version_base_url()"},{"location":"api_reference/server/main/#optimade.server.main.add_optional_versioned_base_urls","text":"Add the following OPTIONAL prefixes/base URLs to server: /vMajor.Minor /vMajor.Minor.Patch Source code in optimade/server/main.py 116 117 118 119 120 121 122 123 124 125 def add_optional_versioned_base_urls ( app : FastAPI ): \"\"\"Add the following OPTIONAL prefixes/base URLs to server: ``` /vMajor.Minor /vMajor.Minor.Patch ``` \"\"\" for version in ( \"minor\" , \"patch\" ): for endpoint in ( info , links , references , structures , landing ): app . include_router ( endpoint . router , prefix = BASE_URL_PREFIXES [ version ])","title":"add_optional_versioned_base_urls()"},{"location":"api_reference/server/main_index/","text":"main_index \u00b6 The OPTIMADE Index Meta-Database server The server is based on MongoDB, using either pymongo or mongomock . This is an example implementation with example data. To implement your own index meta-database server see the documentation at https://optimade.org/optimade-python-tools. add_major_version_base_url ( app ) \u00b6 Add mandatory endpoints to /vMAJOR base URL. Source code in optimade/server/main_index.py 116 117 118 119 def add_major_version_base_url ( app : FastAPI ): \"\"\"Add mandatory endpoints to `/vMAJOR` base URL.\"\"\" for endpoint in ( index_info , links ): app . include_router ( endpoint . router , prefix = BASE_URL_PREFIXES [ \"major\" ]) add_optional_versioned_base_urls ( app ) \u00b6 Add the following OPTIONAL prefixes/base URLs to server: /vMajor.Minor /vMajor.Minor.Patch Source code in optimade/server/main_index.py 122 123 124 125 126 127 128 129 130 131 def add_optional_versioned_base_urls ( app : FastAPI ): \"\"\"Add the following OPTIONAL prefixes/base URLs to server: ``` /vMajor.Minor /vMajor.Minor.Patch ``` \"\"\" for version in ( \"minor\" , \"patch\" ): app . include_router ( index_info . router , prefix = BASE_URL_PREFIXES [ version ]) app . include_router ( links . router , prefix = BASE_URL_PREFIXES [ version ])","title":"main_index"},{"location":"api_reference/server/main_index/#main_index","text":"The OPTIMADE Index Meta-Database server The server is based on MongoDB, using either pymongo or mongomock . This is an example implementation with example data. To implement your own index meta-database server see the documentation at https://optimade.org/optimade-python-tools.","title":"main_index"},{"location":"api_reference/server/main_index/#optimade.server.main_index.add_major_version_base_url","text":"Add mandatory endpoints to /vMAJOR base URL. Source code in optimade/server/main_index.py 116 117 118 119 def add_major_version_base_url ( app : FastAPI ): \"\"\"Add mandatory endpoints to `/vMAJOR` base URL.\"\"\" for endpoint in ( index_info , links ): app . include_router ( endpoint . router , prefix = BASE_URL_PREFIXES [ \"major\" ])","title":"add_major_version_base_url()"},{"location":"api_reference/server/main_index/#optimade.server.main_index.add_optional_versioned_base_urls","text":"Add the following OPTIONAL prefixes/base URLs to server: /vMajor.Minor /vMajor.Minor.Patch Source code in optimade/server/main_index.py 122 123 124 125 126 127 128 129 130 131 def add_optional_versioned_base_urls ( app : FastAPI ): \"\"\"Add the following OPTIONAL prefixes/base URLs to server: ``` /vMajor.Minor /vMajor.Minor.Patch ``` \"\"\" for version in ( \"minor\" , \"patch\" ): app . include_router ( index_info . router , prefix = BASE_URL_PREFIXES [ version ]) app . include_router ( links . router , prefix = BASE_URL_PREFIXES [ version ])","title":"add_optional_versioned_base_urls()"},{"location":"api_reference/server/middleware/","text":"middleware \u00b6 Custom ASGI app middleware. These middleware are based on Starlette 's BaseHTTPMiddleware . See the specific Starlette documentation page for more information on it's middleware implementation. OPTIMADE_MIDDLEWARE : Tuple [ BaseHTTPMiddleware ] = ( EnsureQueryParamIntegrity , CheckWronglyVersionedBaseUrls , HandleApiHint , AddWarnings ) module-attribute \u00b6 A tuple of all the middleware classes that implement certain required features of the OPTIMADE specification, e.g. warnings and URL versioning. Note The order in which middleware is added to an application matters. As discussed in the docstring of AddWarnings , this middleware is the final entry to this list so that it is the first to be applied by the server. Any other middleware should therefore be added before iterating through this variable. This is the opposite way around to the example in the Starlette documentation which initialises the application with a pre-built middleware list in the reverse order to OPTIMADE_MIDDLEWARE . To use this variable in FastAPI app code after initialisation: from fastapi import FastAPI app = FastAPI () for middleware in OPTIMADE_MIDDLEWARE : app . add_middleware ( middleware ) Alternatively, to use this variable on initialisation: from fastapi import FastAPI from starlette.middleware import Middleware app = FastAPI ( ... , middleware = [ Middleware ( m ) for m in reversed ( OPTIMADE_MIDDLEWARE )] ) AddWarnings \u00b6 Add OptimadeWarning s to the response. All sub-classes of OptimadeWarning will also be added to the response's meta.warnings list. By overriding the warnings.showwarning() function with the showwarning method , all usages of warnings.warn() will result in the regular printing of the warning message to stderr , but also its addition to an in-memory list of warnings. This middleware will, after the URL request has been handled, add the list of accumulated warnings to the JSON response under the meta.warnings field. To make sure the last part happens correctly and a Starlette StreamingResponse is returned, as is expected from a BaseHTTPMiddleware sub-class, one is instantiated with the updated Content-Length header, as well as making sure the response's body content is actually streamable, by breaking it down into chunks of the original response's chunk size. Important It is recommended to add this middleware as the last one to your application. This is to ensure it is invoked first , updating warnings.showwarning() and catching all warnings that should be added to the response. This can be achieved by applying AddWarnings after all other middleware with the .add_middleware() method, or by initialising the app with a middleware list in which AddWarnings appears first . More information can be found in the docstring of OPTIMADE_MIDDLEWARE . Attributes: Name Type Description _warnings List [ Warnings ] List of Warnings added through usages of warnings.warn() via showwarning . Source code in optimade/server/middleware.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 class AddWarnings ( BaseHTTPMiddleware ): \"\"\" Add [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning]s to the response. All sub-classes of [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] will also be added to the response's [`meta.warnings`][optimade.models.optimade_json.ResponseMeta.warnings] list. By overriding the `warnings.showwarning()` function with the [`showwarning` method][optimade.server.middleware.AddWarnings.showwarning], all usages of `warnings.warn()` will result in the regular printing of the warning message to `stderr`, but also its addition to an in-memory list of warnings. This middleware will, after the URL request has been handled, add the list of accumulated warnings to the JSON response under the [`meta.warnings`][optimade.models.optimade_json.ResponseMeta.warnings] field. To make sure the last part happens correctly and a Starlette `StreamingResponse` is returned, as is expected from a `BaseHTTPMiddleware` sub-class, one is instantiated with the updated `Content-Length` header, as well as making sure the response's body content is actually streamable, by breaking it down into chunks of the original response's chunk size. !!! warning \"Important\" It is **recommended** to add this middleware as the _last one_ to your application. This is to ensure it is invoked _first_, updating `warnings.showwarning()` and catching all warnings that should be added to the response. This can be achieved by applying `AddWarnings` _after_ all other middleware with the `.add_middleware()` method, or by initialising the app with a middleware list in which `AddWarnings` appears _first_. More information can be found in the docstring of [`OPTIMADE_MIDDLEWARE`][optimade.server.middleware.OPTIMADE_MIDDLEWARE]. Attributes: _warnings (List[Warnings]): List of [`Warnings`][optimade.models.optimade_json.Warnings] added through usages of `warnings.warn()` via [`showwarning`][optimade.server.middleware.AddWarnings.showwarning]. \"\"\" def showwarning ( self , message : Warning , category : Type [ Warning ], filename : str , lineno : int , file : Optional [ IO ] = None , line : Optional [ str ] = None , ) -> None : \"\"\" Hook to write a warning to a file using the built-in `warnings` lib. In [the documentation](https://docs.python.org/3/library/warnings.html) for the built-in `warnings` library, there are a few recommended ways of customizing the printing of warning messages. This method can override the `warnings.showwarning` function, which is called as part of the `warnings` library's workflow to print warning messages, e.g., when using `warnings.warn()`. Originally, it prints warning messages to `stderr`. This method will also print warning messages to `stderr` by calling `warnings._showwarning_orig()` or `warnings._showwarnmsg_impl()`. The first function will be called if the issued warning is not recognized as an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning]. This is equivalent to \"standard behaviour\". The second function will be called _after_ an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] has been handled. An [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] will be translated into an OPTIMADE Warnings JSON object in accordance with [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#json-response-schema-common-fields). This process is similar to the [Exception handlers][optimade.server.exception_handlers]. Parameters: message: The `Warning` object to show and possibly handle. category: `Warning` type being warned about. This amounts to `type(message)`. filename: Name of the file, where the warning was issued. lineno: Line number in the file, where the warning was issued. file: A file-like object to which the warning should be written. line: Source content of the line that issued the warning. \"\"\" assert isinstance ( message , Warning ), \"'message' is expected to be a Warning or subclass thereof.\" if not isinstance ( message , OptimadeWarning ): # If the Warning is not an OptimadeWarning or subclass thereof, # use the regular 'showwarning' function. warnings . _showwarning_orig ( message , category , filename , lineno , file , line ) return # Format warning try : title = str ( message . title ) except AttributeError : title = str ( message . __class__ . __name__ ) try : detail = str ( message . detail ) except AttributeError : detail = str ( message ) if CONFIG . debug : if line is None : # All this is taken directly from the warnings library. # See 'warnings._formatwarnmsg_impl()' for the original code. try : import linecache line = linecache . getline ( filename , lineno ) except Exception : # When a warning is logged during Python shutdown, linecache # and the import machinery don't work anymore line = None linecache = None meta = { \"filename\" : filename , \"lineno\" : lineno , } if line : meta [ \"line\" ] = line . strip () if CONFIG . debug : new_warning = Warnings ( title = title , detail = detail , meta = meta ) else : new_warning = Warnings ( title = title , detail = detail ) # Add new warning to self._warnings self . _warnings . append ( new_warning . dict ( exclude_unset = True )) # Show warning message as normal in sys.stderr warnings . _showwarnmsg_impl ( warnings . WarningMessage ( message , category , filename , lineno , file , line ) ) @staticmethod def chunk_it_up ( content : str , chunk_size : int ) -> Generator : \"\"\"Return generator for string in chunks of size `chunk_size`. Parameters: content: String-content to separate into chunks. chunk_size: The size of the chunks, i.e. the length of the string-chunks. Returns: A Python generator to be converted later to an `asyncio` generator. \"\"\" if chunk_size <= 0 : chunk_size = 1 return ( content [ i : chunk_size + i ] for i in range ( 0 , len ( content ), chunk_size )) async def dispatch ( self , request : Request , call_next ): self . _warnings = [] warnings . simplefilter ( action = \"default\" , category = OptimadeWarning ) warnings . showwarning = self . showwarning response = await call_next ( request ) status = response . status_code headers = response . headers media_type = response . media_type background = response . background charset = response . charset body = b \"\" first_run = True async for chunk in response . body_iterator : if first_run : first_run = False chunk_size = len ( chunk ) if not isinstance ( chunk , bytes ): chunk = chunk . encode ( charset ) body += chunk body = body . decode ( charset ) if self . _warnings : response = json . loads ( body ) response . get ( \"meta\" , {})[ \"warnings\" ] = self . _warnings body = json . dumps ( response ) if \"content-length\" in headers : headers [ \"content-length\" ] = str ( len ( body )) response = StreamingResponse ( content = self . chunk_it_up ( body , chunk_size ), status_code = status , headers = headers , media_type = media_type , background = background , ) return response chunk_it_up ( content , chunk_size ) staticmethod \u00b6 Return generator for string in chunks of size chunk_size . Parameters: Name Type Description Default content str String-content to separate into chunks. required chunk_size int The size of the chunks, i.e. the length of the string-chunks. required Returns: Type Description Generator A Python generator to be converted later to an asyncio generator. Source code in optimade/server/middleware.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 @staticmethod def chunk_it_up ( content : str , chunk_size : int ) -> Generator : \"\"\"Return generator for string in chunks of size `chunk_size`. Parameters: content: String-content to separate into chunks. chunk_size: The size of the chunks, i.e. the length of the string-chunks. Returns: A Python generator to be converted later to an `asyncio` generator. \"\"\" if chunk_size <= 0 : chunk_size = 1 return ( content [ i : chunk_size + i ] for i in range ( 0 , len ( content ), chunk_size )) showwarning ( message , category , filename , lineno , file = None , line = None ) \u00b6 Hook to write a warning to a file using the built-in warnings lib. In the documentation for the built-in warnings library, there are a few recommended ways of customizing the printing of warning messages. This method can override the warnings.showwarning function, which is called as part of the warnings library's workflow to print warning messages, e.g., when using warnings.warn() . Originally, it prints warning messages to stderr . This method will also print warning messages to stderr by calling warnings._showwarning_orig() or warnings._showwarnmsg_impl() . The first function will be called if the issued warning is not recognized as an OptimadeWarning . This is equivalent to \"standard behaviour\". The second function will be called after an OptimadeWarning has been handled. An OptimadeWarning will be translated into an OPTIMADE Warnings JSON object in accordance with the specification . This process is similar to the Exception handlers . Parameters: Name Type Description Default message Warning The Warning object to show and possibly handle. required category Type [ Warning ] Warning type being warned about. This amounts to type(message) . required filename str Name of the file, where the warning was issued. required lineno int Line number in the file, where the warning was issued. required file Optional [ IO ] A file-like object to which the warning should be written. None line Optional [ str ] Source content of the line that issued the warning. None Source code in optimade/server/middleware.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def showwarning ( self , message : Warning , category : Type [ Warning ], filename : str , lineno : int , file : Optional [ IO ] = None , line : Optional [ str ] = None , ) -> None : \"\"\" Hook to write a warning to a file using the built-in `warnings` lib. In [the documentation](https://docs.python.org/3/library/warnings.html) for the built-in `warnings` library, there are a few recommended ways of customizing the printing of warning messages. This method can override the `warnings.showwarning` function, which is called as part of the `warnings` library's workflow to print warning messages, e.g., when using `warnings.warn()`. Originally, it prints warning messages to `stderr`. This method will also print warning messages to `stderr` by calling `warnings._showwarning_orig()` or `warnings._showwarnmsg_impl()`. The first function will be called if the issued warning is not recognized as an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning]. This is equivalent to \"standard behaviour\". The second function will be called _after_ an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] has been handled. An [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] will be translated into an OPTIMADE Warnings JSON object in accordance with [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#json-response-schema-common-fields). This process is similar to the [Exception handlers][optimade.server.exception_handlers]. Parameters: message: The `Warning` object to show and possibly handle. category: `Warning` type being warned about. This amounts to `type(message)`. filename: Name of the file, where the warning was issued. lineno: Line number in the file, where the warning was issued. file: A file-like object to which the warning should be written. line: Source content of the line that issued the warning. \"\"\" assert isinstance ( message , Warning ), \"'message' is expected to be a Warning or subclass thereof.\" if not isinstance ( message , OptimadeWarning ): # If the Warning is not an OptimadeWarning or subclass thereof, # use the regular 'showwarning' function. warnings . _showwarning_orig ( message , category , filename , lineno , file , line ) return # Format warning try : title = str ( message . title ) except AttributeError : title = str ( message . __class__ . __name__ ) try : detail = str ( message . detail ) except AttributeError : detail = str ( message ) if CONFIG . debug : if line is None : # All this is taken directly from the warnings library. # See 'warnings._formatwarnmsg_impl()' for the original code. try : import linecache line = linecache . getline ( filename , lineno ) except Exception : # When a warning is logged during Python shutdown, linecache # and the import machinery don't work anymore line = None linecache = None meta = { \"filename\" : filename , \"lineno\" : lineno , } if line : meta [ \"line\" ] = line . strip () if CONFIG . debug : new_warning = Warnings ( title = title , detail = detail , meta = meta ) else : new_warning = Warnings ( title = title , detail = detail ) # Add new warning to self._warnings self . _warnings . append ( new_warning . dict ( exclude_unset = True )) # Show warning message as normal in sys.stderr warnings . _showwarnmsg_impl ( warnings . WarningMessage ( message , category , filename , lineno , file , line ) ) CheckWronglyVersionedBaseUrls \u00b6 If a non-supported versioned base URL is supplied return 553 Version Not Supported . Source code in optimade/server/middleware.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class CheckWronglyVersionedBaseUrls ( BaseHTTPMiddleware ): \"\"\"If a non-supported versioned base URL is supplied return `553 Version Not Supported`.\"\"\" @staticmethod def check_url ( url : StarletteURL ): \"\"\"Check URL path for versioned part. Parameters: url: A complete urllib-parsed raw URL. Raises: VersionNotSupported: If the URL represents an OPTIMADE versioned base URL and the version part is not supported by the implementation. \"\"\" base_url = get_base_url ( url ) optimade_path = f \" { url . scheme } :// { url . netloc }{ url . path } \" [ len ( base_url ) :] match = re . match ( r \"^(?P<version>/v[0-9]+(\\.[0-9]+){0,2}).*\" , optimade_path ) if match is not None : if match . group ( \"version\" ) not in BASE_URL_PREFIXES . values (): raise VersionNotSupported ( detail = ( f \"The parsed versioned base URL { match . group ( 'version' ) !r} from \" f \" { url } is not supported by this implementation. \" f \"Supported versioned base URLs are: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) async def dispatch ( self , request : Request , call_next ): if request . url . path : self . check_url ( request . url ) response = await call_next ( request ) return response check_url ( url ) staticmethod \u00b6 Check URL path for versioned part. Parameters: Name Type Description Default url StarletteURL A complete urllib-parsed raw URL. required Raises: Type Description VersionNotSupported If the URL represents an OPTIMADE versioned base URL and the version part is not supported by the implementation. Source code in optimade/server/middleware.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @staticmethod def check_url ( url : StarletteURL ): \"\"\"Check URL path for versioned part. Parameters: url: A complete urllib-parsed raw URL. Raises: VersionNotSupported: If the URL represents an OPTIMADE versioned base URL and the version part is not supported by the implementation. \"\"\" base_url = get_base_url ( url ) optimade_path = f \" { url . scheme } :// { url . netloc }{ url . path } \" [ len ( base_url ) :] match = re . match ( r \"^(?P<version>/v[0-9]+(\\.[0-9]+){0,2}).*\" , optimade_path ) if match is not None : if match . group ( \"version\" ) not in BASE_URL_PREFIXES . values (): raise VersionNotSupported ( detail = ( f \"The parsed versioned base URL { match . group ( 'version' ) !r} from \" f \" { url } is not supported by this implementation. \" f \"Supported versioned base URLs are: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) EnsureQueryParamIntegrity \u00b6 Ensure all query parameters are followed by an equal sign ( = ). Source code in optimade/server/middleware.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class EnsureQueryParamIntegrity ( BaseHTTPMiddleware ): \"\"\"Ensure all query parameters are followed by an equal sign (`=`).\"\"\" @staticmethod def check_url ( url_query : str ) -> set : \"\"\"Check parsed URL query part for parameters not followed by `=`. URL query parameters are considered to be split by ampersand (`&`) and semi-colon (`;`). Parameters: url_query: The raw urllib-parsed query part. Raises: BadRequest: If a query parameter does not come with a value. Returns: The set of individual query parameters and their values. This is mainly for testing and not actually neeeded by the middleware, since if the URL exhibits an invalid query part a `400 Bad Request` response will be returned. \"\"\" queries_amp = set ( url_query . split ( \"&\" )) queries = set () for query in queries_amp : queries . update ( set ( query . split ( \";\" ))) for query in queries : if \"=\" not in query and query != \"\" : raise BadRequest ( detail = \"A query parameter without an equal sign (=) is not supported by this server\" ) return queries # Useful for testing async def dispatch ( self , request : Request , call_next ): parsed_url = urllib . parse . urlsplit ( str ( request . url )) if parsed_url . query : self . check_url ( parsed_url . query ) response = await call_next ( request ) return response check_url ( url_query ) staticmethod \u00b6 Check parsed URL query part for parameters not followed by = . URL query parameters are considered to be split by ampersand ( & ) and semi-colon ( ; ). Parameters: Name Type Description Default url_query str The raw urllib-parsed query part. required Raises: Type Description BadRequest If a query parameter does not come with a value. Returns: Type Description set The set of individual query parameters and their values. set This is mainly for testing and not actually neeeded by the middleware, set since if the URL exhibits an invalid query part a 400 Bad Request set response will be returned. Source code in optimade/server/middleware.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @staticmethod def check_url ( url_query : str ) -> set : \"\"\"Check parsed URL query part for parameters not followed by `=`. URL query parameters are considered to be split by ampersand (`&`) and semi-colon (`;`). Parameters: url_query: The raw urllib-parsed query part. Raises: BadRequest: If a query parameter does not come with a value. Returns: The set of individual query parameters and their values. This is mainly for testing and not actually neeeded by the middleware, since if the URL exhibits an invalid query part a `400 Bad Request` response will be returned. \"\"\" queries_amp = set ( url_query . split ( \"&\" )) queries = set () for query in queries_amp : queries . update ( set ( query . split ( \";\" ))) for query in queries : if \"=\" not in query and query != \"\" : raise BadRequest ( detail = \"A query parameter without an equal sign (=) is not supported by this server\" ) return queries # Useful for testing HandleApiHint \u00b6 Handle api_hint query parameter. Source code in optimade/server/middleware.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class HandleApiHint ( BaseHTTPMiddleware ): \"\"\"Handle `api_hint` query parameter.\"\"\" @staticmethod def handle_api_hint ( api_hint : List [ str ]) -> Union [ None , str ]: \"\"\"Handle `api_hint` parameter value. There are several scenarios that can play out, when handling the `api_hint` query parameter: If several `api_hint` query parameters have been used, or a \"standard\" JSON list (`,`-separated value) has been supplied, a warning will be added to the response and the `api_hint` query parameter will not be applied. If the passed value does not comply with the rules set out in [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation), a warning will be added to the response and the `api_hint` query parameter will not be applied. If the value is part of the implementation's accepted versioned base URLs, it will be returned as is. If the value represents a major version that is newer than what is supported by the implementation, a `553 Version Not Supported` response will be returned, as is stated by [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation). On the other hand, if the value represents a major version equal to or lower than the implementation's supported major version, then the implementation's supported major version will be returned and tried for the request. Parameters: api_hint: The urllib-parsed query parameter value for `api_hint`. Raises: VersionNotSupported: If the requested major version is newer than the supported major version of the implementation. Returns: Either a valid `api_hint` value or `None`. \"\"\" # Try to split by `,` if value is provided once, but in JSON-type \"list\" format _api_hint = [] for value in api_hint : values = value . split ( \",\" ) _api_hint . extend ( values ) api_hint = _api_hint if len ( api_hint ) > 1 : warnings . warn ( TooManyValues ( detail = \"`api_hint` should only be supplied once, with a single value.\" ) ) return None api_hint = f \"/ { api_hint [ 0 ] } \" if re . match ( r \"^/v[0-9]+(\\.[0-9]+)?$\" , api_hint ) is None : warnings . warn ( FieldValueNotRecognized ( detail = f \" { api_hint [ 1 :] !r} is not recognized as a valid `api_hint` value.\" ) ) return None if api_hint in BASE_URL_PREFIXES . values (): return api_hint major_api_hint = int ( re . findall ( r \"/v([0-9]+)\" , api_hint )[ 0 ]) major_implementation = int ( BASE_URL_PREFIXES [ \"major\" ][ len ( \"/v\" ) :]) if major_api_hint > major_implementation : # Let's not try to handle a request for a newer major version raise VersionNotSupported ( detail = ( f \"The provided `api_hint` ( { api_hint [ 1 :] !r} ) is not supported by this implementation. \" f \"Supported versions include: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) if major_api_hint <= major_implementation : # If less than: # Use the current implementation in hope that it can still handle older requests # # If equal: # Go to /v<MAJOR>, since this should point to the latest available return BASE_URL_PREFIXES [ \"major\" ] @staticmethod def is_versioned_base_url ( url : str ) -> bool : \"\"\"Determine whether a request is for a versioned base URL. First, simply check whether a `/vMAJOR(.MINOR.PATCH)` part exists in the URL. If not, return `False`, else, remove unversioned base URL from the URL and check again. Return `bool` of final result. Parameters: url: The full URL to check. Returns: Whether or not the full URL represents an OPTIMADE versioned base URL. \"\"\" if not re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url ): return False base_url = get_base_url ( url ) return bool ( re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url [ len ( base_url ) :])) async def dispatch ( self , request : Request , call_next ): parsed_query = urllib . parse . parse_qs ( request . url . query , keep_blank_values = True ) if \"api_hint\" in parsed_query : if self . is_versioned_base_url ( str ( request . url )): warnings . warn ( QueryParamNotUsed ( detail = ( \"`api_hint` provided with value {:s} ' {:s} ' for a versioned base URL. \" \"In accordance with the specification, this will not be handled by \" \"the implementation.\" . format ( \"s\" if len ( parsed_query [ \"api_hint\" ]) > 1 else \"\" , \"', '\" . join ( parsed_query [ \"api_hint\" ]), ) ) ) ) else : from optimade.server.routers.utils import get_base_url version_path = self . handle_api_hint ( parsed_query [ \"api_hint\" ]) if version_path : base_url = get_base_url ( request . url ) new_request = ( f \" { base_url }{ version_path }{ str ( request . url )[ len ( base_url ):] } \" ) url = urllib . parse . urlsplit ( new_request ) parsed_query = urllib . parse . parse_qsl ( url . query , keep_blank_values = True ) parsed_query = \"&\" . join ( [ f \" { key } = { value } \" for key , value in parsed_query if key != \"api_hint\" ] ) return RedirectResponse ( request . url . replace ( path = url . path , query = parsed_query ), headers = request . headers , ) # This is the non-URL changing solution: # # scope = request.scope # scope[\"path\"] = path # request = Request(scope=scope, receive=request.receive, send=request._send) response = await call_next ( request ) return response handle_api_hint ( api_hint ) staticmethod \u00b6 Handle api_hint parameter value. There are several scenarios that can play out, when handling the api_hint query parameter: If several api_hint query parameters have been used, or a \"standard\" JSON list ( , -separated value) has been supplied, a warning will be added to the response and the api_hint query parameter will not be applied. If the passed value does not comply with the rules set out in the specification , a warning will be added to the response and the api_hint query parameter will not be applied. If the value is part of the implementation's accepted versioned base URLs, it will be returned as is. If the value represents a major version that is newer than what is supported by the implementation, a 553 Version Not Supported response will be returned, as is stated by the specification . On the other hand, if the value represents a major version equal to or lower than the implementation's supported major version, then the implementation's supported major version will be returned and tried for the request. Parameters: Name Type Description Default api_hint List [ str ] The urllib-parsed query parameter value for api_hint . required Raises: Type Description VersionNotSupported If the requested major version is newer than the supported major version of the implementation. Returns: Type Description Union [None, str ] Either a valid api_hint value or None . Source code in optimade/server/middleware.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @staticmethod def handle_api_hint ( api_hint : List [ str ]) -> Union [ None , str ]: \"\"\"Handle `api_hint` parameter value. There are several scenarios that can play out, when handling the `api_hint` query parameter: If several `api_hint` query parameters have been used, or a \"standard\" JSON list (`,`-separated value) has been supplied, a warning will be added to the response and the `api_hint` query parameter will not be applied. If the passed value does not comply with the rules set out in [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation), a warning will be added to the response and the `api_hint` query parameter will not be applied. If the value is part of the implementation's accepted versioned base URLs, it will be returned as is. If the value represents a major version that is newer than what is supported by the implementation, a `553 Version Not Supported` response will be returned, as is stated by [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation). On the other hand, if the value represents a major version equal to or lower than the implementation's supported major version, then the implementation's supported major version will be returned and tried for the request. Parameters: api_hint: The urllib-parsed query parameter value for `api_hint`. Raises: VersionNotSupported: If the requested major version is newer than the supported major version of the implementation. Returns: Either a valid `api_hint` value or `None`. \"\"\" # Try to split by `,` if value is provided once, but in JSON-type \"list\" format _api_hint = [] for value in api_hint : values = value . split ( \",\" ) _api_hint . extend ( values ) api_hint = _api_hint if len ( api_hint ) > 1 : warnings . warn ( TooManyValues ( detail = \"`api_hint` should only be supplied once, with a single value.\" ) ) return None api_hint = f \"/ { api_hint [ 0 ] } \" if re . match ( r \"^/v[0-9]+(\\.[0-9]+)?$\" , api_hint ) is None : warnings . warn ( FieldValueNotRecognized ( detail = f \" { api_hint [ 1 :] !r} is not recognized as a valid `api_hint` value.\" ) ) return None if api_hint in BASE_URL_PREFIXES . values (): return api_hint major_api_hint = int ( re . findall ( r \"/v([0-9]+)\" , api_hint )[ 0 ]) major_implementation = int ( BASE_URL_PREFIXES [ \"major\" ][ len ( \"/v\" ) :]) if major_api_hint > major_implementation : # Let's not try to handle a request for a newer major version raise VersionNotSupported ( detail = ( f \"The provided `api_hint` ( { api_hint [ 1 :] !r} ) is not supported by this implementation. \" f \"Supported versions include: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) if major_api_hint <= major_implementation : # If less than: # Use the current implementation in hope that it can still handle older requests # # If equal: # Go to /v<MAJOR>, since this should point to the latest available return BASE_URL_PREFIXES [ \"major\" ] is_versioned_base_url ( url ) staticmethod \u00b6 Determine whether a request is for a versioned base URL. First, simply check whether a /vMAJOR(.MINOR.PATCH) part exists in the URL. If not, return False , else, remove unversioned base URL from the URL and check again. Return bool of final result. Parameters: Name Type Description Default url str The full URL to check. required Returns: Type Description bool Whether or not the full URL represents an OPTIMADE versioned base URL. Source code in optimade/server/middleware.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 @staticmethod def is_versioned_base_url ( url : str ) -> bool : \"\"\"Determine whether a request is for a versioned base URL. First, simply check whether a `/vMAJOR(.MINOR.PATCH)` part exists in the URL. If not, return `False`, else, remove unversioned base URL from the URL and check again. Return `bool` of final result. Parameters: url: The full URL to check. Returns: Whether or not the full URL represents an OPTIMADE versioned base URL. \"\"\" if not re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url ): return False base_url = get_base_url ( url ) return bool ( re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url [ len ( base_url ) :]))","title":"middleware"},{"location":"api_reference/server/middleware/#middleware","text":"Custom ASGI app middleware. These middleware are based on Starlette 's BaseHTTPMiddleware . See the specific Starlette documentation page for more information on it's middleware implementation.","title":"middleware"},{"location":"api_reference/server/middleware/#optimade.server.middleware.OPTIMADE_MIDDLEWARE","text":"A tuple of all the middleware classes that implement certain required features of the OPTIMADE specification, e.g. warnings and URL versioning. Note The order in which middleware is added to an application matters. As discussed in the docstring of AddWarnings , this middleware is the final entry to this list so that it is the first to be applied by the server. Any other middleware should therefore be added before iterating through this variable. This is the opposite way around to the example in the Starlette documentation which initialises the application with a pre-built middleware list in the reverse order to OPTIMADE_MIDDLEWARE . To use this variable in FastAPI app code after initialisation: from fastapi import FastAPI app = FastAPI () for middleware in OPTIMADE_MIDDLEWARE : app . add_middleware ( middleware ) Alternatively, to use this variable on initialisation: from fastapi import FastAPI from starlette.middleware import Middleware app = FastAPI ( ... , middleware = [ Middleware ( m ) for m in reversed ( OPTIMADE_MIDDLEWARE )] )","title":"OPTIMADE_MIDDLEWARE"},{"location":"api_reference/server/middleware/#optimade.server.middleware.AddWarnings","text":"Add OptimadeWarning s to the response. All sub-classes of OptimadeWarning will also be added to the response's meta.warnings list. By overriding the warnings.showwarning() function with the showwarning method , all usages of warnings.warn() will result in the regular printing of the warning message to stderr , but also its addition to an in-memory list of warnings. This middleware will, after the URL request has been handled, add the list of accumulated warnings to the JSON response under the meta.warnings field. To make sure the last part happens correctly and a Starlette StreamingResponse is returned, as is expected from a BaseHTTPMiddleware sub-class, one is instantiated with the updated Content-Length header, as well as making sure the response's body content is actually streamable, by breaking it down into chunks of the original response's chunk size. Important It is recommended to add this middleware as the last one to your application. This is to ensure it is invoked first , updating warnings.showwarning() and catching all warnings that should be added to the response. This can be achieved by applying AddWarnings after all other middleware with the .add_middleware() method, or by initialising the app with a middleware list in which AddWarnings appears first . More information can be found in the docstring of OPTIMADE_MIDDLEWARE . Attributes: Name Type Description _warnings List [ Warnings ] List of Warnings added through usages of warnings.warn() via showwarning . Source code in optimade/server/middleware.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 class AddWarnings ( BaseHTTPMiddleware ): \"\"\" Add [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning]s to the response. All sub-classes of [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] will also be added to the response's [`meta.warnings`][optimade.models.optimade_json.ResponseMeta.warnings] list. By overriding the `warnings.showwarning()` function with the [`showwarning` method][optimade.server.middleware.AddWarnings.showwarning], all usages of `warnings.warn()` will result in the regular printing of the warning message to `stderr`, but also its addition to an in-memory list of warnings. This middleware will, after the URL request has been handled, add the list of accumulated warnings to the JSON response under the [`meta.warnings`][optimade.models.optimade_json.ResponseMeta.warnings] field. To make sure the last part happens correctly and a Starlette `StreamingResponse` is returned, as is expected from a `BaseHTTPMiddleware` sub-class, one is instantiated with the updated `Content-Length` header, as well as making sure the response's body content is actually streamable, by breaking it down into chunks of the original response's chunk size. !!! warning \"Important\" It is **recommended** to add this middleware as the _last one_ to your application. This is to ensure it is invoked _first_, updating `warnings.showwarning()` and catching all warnings that should be added to the response. This can be achieved by applying `AddWarnings` _after_ all other middleware with the `.add_middleware()` method, or by initialising the app with a middleware list in which `AddWarnings` appears _first_. More information can be found in the docstring of [`OPTIMADE_MIDDLEWARE`][optimade.server.middleware.OPTIMADE_MIDDLEWARE]. Attributes: _warnings (List[Warnings]): List of [`Warnings`][optimade.models.optimade_json.Warnings] added through usages of `warnings.warn()` via [`showwarning`][optimade.server.middleware.AddWarnings.showwarning]. \"\"\" def showwarning ( self , message : Warning , category : Type [ Warning ], filename : str , lineno : int , file : Optional [ IO ] = None , line : Optional [ str ] = None , ) -> None : \"\"\" Hook to write a warning to a file using the built-in `warnings` lib. In [the documentation](https://docs.python.org/3/library/warnings.html) for the built-in `warnings` library, there are a few recommended ways of customizing the printing of warning messages. This method can override the `warnings.showwarning` function, which is called as part of the `warnings` library's workflow to print warning messages, e.g., when using `warnings.warn()`. Originally, it prints warning messages to `stderr`. This method will also print warning messages to `stderr` by calling `warnings._showwarning_orig()` or `warnings._showwarnmsg_impl()`. The first function will be called if the issued warning is not recognized as an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning]. This is equivalent to \"standard behaviour\". The second function will be called _after_ an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] has been handled. An [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] will be translated into an OPTIMADE Warnings JSON object in accordance with [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#json-response-schema-common-fields). This process is similar to the [Exception handlers][optimade.server.exception_handlers]. Parameters: message: The `Warning` object to show and possibly handle. category: `Warning` type being warned about. This amounts to `type(message)`. filename: Name of the file, where the warning was issued. lineno: Line number in the file, where the warning was issued. file: A file-like object to which the warning should be written. line: Source content of the line that issued the warning. \"\"\" assert isinstance ( message , Warning ), \"'message' is expected to be a Warning or subclass thereof.\" if not isinstance ( message , OptimadeWarning ): # If the Warning is not an OptimadeWarning or subclass thereof, # use the regular 'showwarning' function. warnings . _showwarning_orig ( message , category , filename , lineno , file , line ) return # Format warning try : title = str ( message . title ) except AttributeError : title = str ( message . __class__ . __name__ ) try : detail = str ( message . detail ) except AttributeError : detail = str ( message ) if CONFIG . debug : if line is None : # All this is taken directly from the warnings library. # See 'warnings._formatwarnmsg_impl()' for the original code. try : import linecache line = linecache . getline ( filename , lineno ) except Exception : # When a warning is logged during Python shutdown, linecache # and the import machinery don't work anymore line = None linecache = None meta = { \"filename\" : filename , \"lineno\" : lineno , } if line : meta [ \"line\" ] = line . strip () if CONFIG . debug : new_warning = Warnings ( title = title , detail = detail , meta = meta ) else : new_warning = Warnings ( title = title , detail = detail ) # Add new warning to self._warnings self . _warnings . append ( new_warning . dict ( exclude_unset = True )) # Show warning message as normal in sys.stderr warnings . _showwarnmsg_impl ( warnings . WarningMessage ( message , category , filename , lineno , file , line ) ) @staticmethod def chunk_it_up ( content : str , chunk_size : int ) -> Generator : \"\"\"Return generator for string in chunks of size `chunk_size`. Parameters: content: String-content to separate into chunks. chunk_size: The size of the chunks, i.e. the length of the string-chunks. Returns: A Python generator to be converted later to an `asyncio` generator. \"\"\" if chunk_size <= 0 : chunk_size = 1 return ( content [ i : chunk_size + i ] for i in range ( 0 , len ( content ), chunk_size )) async def dispatch ( self , request : Request , call_next ): self . _warnings = [] warnings . simplefilter ( action = \"default\" , category = OptimadeWarning ) warnings . showwarning = self . showwarning response = await call_next ( request ) status = response . status_code headers = response . headers media_type = response . media_type background = response . background charset = response . charset body = b \"\" first_run = True async for chunk in response . body_iterator : if first_run : first_run = False chunk_size = len ( chunk ) if not isinstance ( chunk , bytes ): chunk = chunk . encode ( charset ) body += chunk body = body . decode ( charset ) if self . _warnings : response = json . loads ( body ) response . get ( \"meta\" , {})[ \"warnings\" ] = self . _warnings body = json . dumps ( response ) if \"content-length\" in headers : headers [ \"content-length\" ] = str ( len ( body )) response = StreamingResponse ( content = self . chunk_it_up ( body , chunk_size ), status_code = status , headers = headers , media_type = media_type , background = background , ) return response","title":"AddWarnings"},{"location":"api_reference/server/middleware/#optimade.server.middleware.AddWarnings.chunk_it_up","text":"Return generator for string in chunks of size chunk_size . Parameters: Name Type Description Default content str String-content to separate into chunks. required chunk_size int The size of the chunks, i.e. the length of the string-chunks. required Returns: Type Description Generator A Python generator to be converted later to an asyncio generator. Source code in optimade/server/middleware.py 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 @staticmethod def chunk_it_up ( content : str , chunk_size : int ) -> Generator : \"\"\"Return generator for string in chunks of size `chunk_size`. Parameters: content: String-content to separate into chunks. chunk_size: The size of the chunks, i.e. the length of the string-chunks. Returns: A Python generator to be converted later to an `asyncio` generator. \"\"\" if chunk_size <= 0 : chunk_size = 1 return ( content [ i : chunk_size + i ] for i in range ( 0 , len ( content ), chunk_size ))","title":"chunk_it_up()"},{"location":"api_reference/server/middleware/#optimade.server.middleware.AddWarnings.showwarning","text":"Hook to write a warning to a file using the built-in warnings lib. In the documentation for the built-in warnings library, there are a few recommended ways of customizing the printing of warning messages. This method can override the warnings.showwarning function, which is called as part of the warnings library's workflow to print warning messages, e.g., when using warnings.warn() . Originally, it prints warning messages to stderr . This method will also print warning messages to stderr by calling warnings._showwarning_orig() or warnings._showwarnmsg_impl() . The first function will be called if the issued warning is not recognized as an OptimadeWarning . This is equivalent to \"standard behaviour\". The second function will be called after an OptimadeWarning has been handled. An OptimadeWarning will be translated into an OPTIMADE Warnings JSON object in accordance with the specification . This process is similar to the Exception handlers . Parameters: Name Type Description Default message Warning The Warning object to show and possibly handle. required category Type [ Warning ] Warning type being warned about. This amounts to type(message) . required filename str Name of the file, where the warning was issued. required lineno int Line number in the file, where the warning was issued. required file Optional [ IO ] A file-like object to which the warning should be written. None line Optional [ str ] Source content of the line that issued the warning. None Source code in optimade/server/middleware.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 def showwarning ( self , message : Warning , category : Type [ Warning ], filename : str , lineno : int , file : Optional [ IO ] = None , line : Optional [ str ] = None , ) -> None : \"\"\" Hook to write a warning to a file using the built-in `warnings` lib. In [the documentation](https://docs.python.org/3/library/warnings.html) for the built-in `warnings` library, there are a few recommended ways of customizing the printing of warning messages. This method can override the `warnings.showwarning` function, which is called as part of the `warnings` library's workflow to print warning messages, e.g., when using `warnings.warn()`. Originally, it prints warning messages to `stderr`. This method will also print warning messages to `stderr` by calling `warnings._showwarning_orig()` or `warnings._showwarnmsg_impl()`. The first function will be called if the issued warning is not recognized as an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning]. This is equivalent to \"standard behaviour\". The second function will be called _after_ an [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] has been handled. An [`OptimadeWarning`][optimade.server.warnings.OptimadeWarning] will be translated into an OPTIMADE Warnings JSON object in accordance with [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#json-response-schema-common-fields). This process is similar to the [Exception handlers][optimade.server.exception_handlers]. Parameters: message: The `Warning` object to show and possibly handle. category: `Warning` type being warned about. This amounts to `type(message)`. filename: Name of the file, where the warning was issued. lineno: Line number in the file, where the warning was issued. file: A file-like object to which the warning should be written. line: Source content of the line that issued the warning. \"\"\" assert isinstance ( message , Warning ), \"'message' is expected to be a Warning or subclass thereof.\" if not isinstance ( message , OptimadeWarning ): # If the Warning is not an OptimadeWarning or subclass thereof, # use the regular 'showwarning' function. warnings . _showwarning_orig ( message , category , filename , lineno , file , line ) return # Format warning try : title = str ( message . title ) except AttributeError : title = str ( message . __class__ . __name__ ) try : detail = str ( message . detail ) except AttributeError : detail = str ( message ) if CONFIG . debug : if line is None : # All this is taken directly from the warnings library. # See 'warnings._formatwarnmsg_impl()' for the original code. try : import linecache line = linecache . getline ( filename , lineno ) except Exception : # When a warning is logged during Python shutdown, linecache # and the import machinery don't work anymore line = None linecache = None meta = { \"filename\" : filename , \"lineno\" : lineno , } if line : meta [ \"line\" ] = line . strip () if CONFIG . debug : new_warning = Warnings ( title = title , detail = detail , meta = meta ) else : new_warning = Warnings ( title = title , detail = detail ) # Add new warning to self._warnings self . _warnings . append ( new_warning . dict ( exclude_unset = True )) # Show warning message as normal in sys.stderr warnings . _showwarnmsg_impl ( warnings . WarningMessage ( message , category , filename , lineno , file , line ) )","title":"showwarning()"},{"location":"api_reference/server/middleware/#optimade.server.middleware.CheckWronglyVersionedBaseUrls","text":"If a non-supported versioned base URL is supplied return 553 Version Not Supported . Source code in optimade/server/middleware.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class CheckWronglyVersionedBaseUrls ( BaseHTTPMiddleware ): \"\"\"If a non-supported versioned base URL is supplied return `553 Version Not Supported`.\"\"\" @staticmethod def check_url ( url : StarletteURL ): \"\"\"Check URL path for versioned part. Parameters: url: A complete urllib-parsed raw URL. Raises: VersionNotSupported: If the URL represents an OPTIMADE versioned base URL and the version part is not supported by the implementation. \"\"\" base_url = get_base_url ( url ) optimade_path = f \" { url . scheme } :// { url . netloc }{ url . path } \" [ len ( base_url ) :] match = re . match ( r \"^(?P<version>/v[0-9]+(\\.[0-9]+){0,2}).*\" , optimade_path ) if match is not None : if match . group ( \"version\" ) not in BASE_URL_PREFIXES . values (): raise VersionNotSupported ( detail = ( f \"The parsed versioned base URL { match . group ( 'version' ) !r} from \" f \" { url } is not supported by this implementation. \" f \"Supported versioned base URLs are: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) async def dispatch ( self , request : Request , call_next ): if request . url . path : self . check_url ( request . url ) response = await call_next ( request ) return response","title":"CheckWronglyVersionedBaseUrls"},{"location":"api_reference/server/middleware/#optimade.server.middleware.CheckWronglyVersionedBaseUrls.check_url","text":"Check URL path for versioned part. Parameters: Name Type Description Default url StarletteURL A complete urllib-parsed raw URL. required Raises: Type Description VersionNotSupported If the URL represents an OPTIMADE versioned base URL and the version part is not supported by the implementation. Source code in optimade/server/middleware.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 @staticmethod def check_url ( url : StarletteURL ): \"\"\"Check URL path for versioned part. Parameters: url: A complete urllib-parsed raw URL. Raises: VersionNotSupported: If the URL represents an OPTIMADE versioned base URL and the version part is not supported by the implementation. \"\"\" base_url = get_base_url ( url ) optimade_path = f \" { url . scheme } :// { url . netloc }{ url . path } \" [ len ( base_url ) :] match = re . match ( r \"^(?P<version>/v[0-9]+(\\.[0-9]+){0,2}).*\" , optimade_path ) if match is not None : if match . group ( \"version\" ) not in BASE_URL_PREFIXES . values (): raise VersionNotSupported ( detail = ( f \"The parsed versioned base URL { match . group ( 'version' ) !r} from \" f \" { url } is not supported by this implementation. \" f \"Supported versioned base URLs are: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) )","title":"check_url()"},{"location":"api_reference/server/middleware/#optimade.server.middleware.EnsureQueryParamIntegrity","text":"Ensure all query parameters are followed by an equal sign ( = ). Source code in optimade/server/middleware.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class EnsureQueryParamIntegrity ( BaseHTTPMiddleware ): \"\"\"Ensure all query parameters are followed by an equal sign (`=`).\"\"\" @staticmethod def check_url ( url_query : str ) -> set : \"\"\"Check parsed URL query part for parameters not followed by `=`. URL query parameters are considered to be split by ampersand (`&`) and semi-colon (`;`). Parameters: url_query: The raw urllib-parsed query part. Raises: BadRequest: If a query parameter does not come with a value. Returns: The set of individual query parameters and their values. This is mainly for testing and not actually neeeded by the middleware, since if the URL exhibits an invalid query part a `400 Bad Request` response will be returned. \"\"\" queries_amp = set ( url_query . split ( \"&\" )) queries = set () for query in queries_amp : queries . update ( set ( query . split ( \";\" ))) for query in queries : if \"=\" not in query and query != \"\" : raise BadRequest ( detail = \"A query parameter without an equal sign (=) is not supported by this server\" ) return queries # Useful for testing async def dispatch ( self , request : Request , call_next ): parsed_url = urllib . parse . urlsplit ( str ( request . url )) if parsed_url . query : self . check_url ( parsed_url . query ) response = await call_next ( request ) return response","title":"EnsureQueryParamIntegrity"},{"location":"api_reference/server/middleware/#optimade.server.middleware.EnsureQueryParamIntegrity.check_url","text":"Check parsed URL query part for parameters not followed by = . URL query parameters are considered to be split by ampersand ( & ) and semi-colon ( ; ). Parameters: Name Type Description Default url_query str The raw urllib-parsed query part. required Raises: Type Description BadRequest If a query parameter does not come with a value. Returns: Type Description set The set of individual query parameters and their values. set This is mainly for testing and not actually neeeded by the middleware, set since if the URL exhibits an invalid query part a 400 Bad Request set response will be returned. Source code in optimade/server/middleware.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @staticmethod def check_url ( url_query : str ) -> set : \"\"\"Check parsed URL query part for parameters not followed by `=`. URL query parameters are considered to be split by ampersand (`&`) and semi-colon (`;`). Parameters: url_query: The raw urllib-parsed query part. Raises: BadRequest: If a query parameter does not come with a value. Returns: The set of individual query parameters and their values. This is mainly for testing and not actually neeeded by the middleware, since if the URL exhibits an invalid query part a `400 Bad Request` response will be returned. \"\"\" queries_amp = set ( url_query . split ( \"&\" )) queries = set () for query in queries_amp : queries . update ( set ( query . split ( \";\" ))) for query in queries : if \"=\" not in query and query != \"\" : raise BadRequest ( detail = \"A query parameter without an equal sign (=) is not supported by this server\" ) return queries # Useful for testing","title":"check_url()"},{"location":"api_reference/server/middleware/#optimade.server.middleware.HandleApiHint","text":"Handle api_hint query parameter. Source code in optimade/server/middleware.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class HandleApiHint ( BaseHTTPMiddleware ): \"\"\"Handle `api_hint` query parameter.\"\"\" @staticmethod def handle_api_hint ( api_hint : List [ str ]) -> Union [ None , str ]: \"\"\"Handle `api_hint` parameter value. There are several scenarios that can play out, when handling the `api_hint` query parameter: If several `api_hint` query parameters have been used, or a \"standard\" JSON list (`,`-separated value) has been supplied, a warning will be added to the response and the `api_hint` query parameter will not be applied. If the passed value does not comply with the rules set out in [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation), a warning will be added to the response and the `api_hint` query parameter will not be applied. If the value is part of the implementation's accepted versioned base URLs, it will be returned as is. If the value represents a major version that is newer than what is supported by the implementation, a `553 Version Not Supported` response will be returned, as is stated by [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation). On the other hand, if the value represents a major version equal to or lower than the implementation's supported major version, then the implementation's supported major version will be returned and tried for the request. Parameters: api_hint: The urllib-parsed query parameter value for `api_hint`. Raises: VersionNotSupported: If the requested major version is newer than the supported major version of the implementation. Returns: Either a valid `api_hint` value or `None`. \"\"\" # Try to split by `,` if value is provided once, but in JSON-type \"list\" format _api_hint = [] for value in api_hint : values = value . split ( \",\" ) _api_hint . extend ( values ) api_hint = _api_hint if len ( api_hint ) > 1 : warnings . warn ( TooManyValues ( detail = \"`api_hint` should only be supplied once, with a single value.\" ) ) return None api_hint = f \"/ { api_hint [ 0 ] } \" if re . match ( r \"^/v[0-9]+(\\.[0-9]+)?$\" , api_hint ) is None : warnings . warn ( FieldValueNotRecognized ( detail = f \" { api_hint [ 1 :] !r} is not recognized as a valid `api_hint` value.\" ) ) return None if api_hint in BASE_URL_PREFIXES . values (): return api_hint major_api_hint = int ( re . findall ( r \"/v([0-9]+)\" , api_hint )[ 0 ]) major_implementation = int ( BASE_URL_PREFIXES [ \"major\" ][ len ( \"/v\" ) :]) if major_api_hint > major_implementation : # Let's not try to handle a request for a newer major version raise VersionNotSupported ( detail = ( f \"The provided `api_hint` ( { api_hint [ 1 :] !r} ) is not supported by this implementation. \" f \"Supported versions include: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) if major_api_hint <= major_implementation : # If less than: # Use the current implementation in hope that it can still handle older requests # # If equal: # Go to /v<MAJOR>, since this should point to the latest available return BASE_URL_PREFIXES [ \"major\" ] @staticmethod def is_versioned_base_url ( url : str ) -> bool : \"\"\"Determine whether a request is for a versioned base URL. First, simply check whether a `/vMAJOR(.MINOR.PATCH)` part exists in the URL. If not, return `False`, else, remove unversioned base URL from the URL and check again. Return `bool` of final result. Parameters: url: The full URL to check. Returns: Whether or not the full URL represents an OPTIMADE versioned base URL. \"\"\" if not re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url ): return False base_url = get_base_url ( url ) return bool ( re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url [ len ( base_url ) :])) async def dispatch ( self , request : Request , call_next ): parsed_query = urllib . parse . parse_qs ( request . url . query , keep_blank_values = True ) if \"api_hint\" in parsed_query : if self . is_versioned_base_url ( str ( request . url )): warnings . warn ( QueryParamNotUsed ( detail = ( \"`api_hint` provided with value {:s} ' {:s} ' for a versioned base URL. \" \"In accordance with the specification, this will not be handled by \" \"the implementation.\" . format ( \"s\" if len ( parsed_query [ \"api_hint\" ]) > 1 else \"\" , \"', '\" . join ( parsed_query [ \"api_hint\" ]), ) ) ) ) else : from optimade.server.routers.utils import get_base_url version_path = self . handle_api_hint ( parsed_query [ \"api_hint\" ]) if version_path : base_url = get_base_url ( request . url ) new_request = ( f \" { base_url }{ version_path }{ str ( request . url )[ len ( base_url ):] } \" ) url = urllib . parse . urlsplit ( new_request ) parsed_query = urllib . parse . parse_qsl ( url . query , keep_blank_values = True ) parsed_query = \"&\" . join ( [ f \" { key } = { value } \" for key , value in parsed_query if key != \"api_hint\" ] ) return RedirectResponse ( request . url . replace ( path = url . path , query = parsed_query ), headers = request . headers , ) # This is the non-URL changing solution: # # scope = request.scope # scope[\"path\"] = path # request = Request(scope=scope, receive=request.receive, send=request._send) response = await call_next ( request ) return response","title":"HandleApiHint"},{"location":"api_reference/server/middleware/#optimade.server.middleware.HandleApiHint.handle_api_hint","text":"Handle api_hint parameter value. There are several scenarios that can play out, when handling the api_hint query parameter: If several api_hint query parameters have been used, or a \"standard\" JSON list ( , -separated value) has been supplied, a warning will be added to the response and the api_hint query parameter will not be applied. If the passed value does not comply with the rules set out in the specification , a warning will be added to the response and the api_hint query parameter will not be applied. If the value is part of the implementation's accepted versioned base URLs, it will be returned as is. If the value represents a major version that is newer than what is supported by the implementation, a 553 Version Not Supported response will be returned, as is stated by the specification . On the other hand, if the value represents a major version equal to or lower than the implementation's supported major version, then the implementation's supported major version will be returned and tried for the request. Parameters: Name Type Description Default api_hint List [ str ] The urllib-parsed query parameter value for api_hint . required Raises: Type Description VersionNotSupported If the requested major version is newer than the supported major version of the implementation. Returns: Type Description Union [None, str ] Either a valid api_hint value or None . Source code in optimade/server/middleware.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 @staticmethod def handle_api_hint ( api_hint : List [ str ]) -> Union [ None , str ]: \"\"\"Handle `api_hint` parameter value. There are several scenarios that can play out, when handling the `api_hint` query parameter: If several `api_hint` query parameters have been used, or a \"standard\" JSON list (`,`-separated value) has been supplied, a warning will be added to the response and the `api_hint` query parameter will not be applied. If the passed value does not comply with the rules set out in [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation), a warning will be added to the response and the `api_hint` query parameter will not be applied. If the value is part of the implementation's accepted versioned base URLs, it will be returned as is. If the value represents a major version that is newer than what is supported by the implementation, a `553 Version Not Supported` response will be returned, as is stated by [the specification](https://github.com/Materials-Consortia/OPTIMADE/blob/v1.0.0/optimade.rst#version-negotiation). On the other hand, if the value represents a major version equal to or lower than the implementation's supported major version, then the implementation's supported major version will be returned and tried for the request. Parameters: api_hint: The urllib-parsed query parameter value for `api_hint`. Raises: VersionNotSupported: If the requested major version is newer than the supported major version of the implementation. Returns: Either a valid `api_hint` value or `None`. \"\"\" # Try to split by `,` if value is provided once, but in JSON-type \"list\" format _api_hint = [] for value in api_hint : values = value . split ( \",\" ) _api_hint . extend ( values ) api_hint = _api_hint if len ( api_hint ) > 1 : warnings . warn ( TooManyValues ( detail = \"`api_hint` should only be supplied once, with a single value.\" ) ) return None api_hint = f \"/ { api_hint [ 0 ] } \" if re . match ( r \"^/v[0-9]+(\\.[0-9]+)?$\" , api_hint ) is None : warnings . warn ( FieldValueNotRecognized ( detail = f \" { api_hint [ 1 :] !r} is not recognized as a valid `api_hint` value.\" ) ) return None if api_hint in BASE_URL_PREFIXES . values (): return api_hint major_api_hint = int ( re . findall ( r \"/v([0-9]+)\" , api_hint )[ 0 ]) major_implementation = int ( BASE_URL_PREFIXES [ \"major\" ][ len ( \"/v\" ) :]) if major_api_hint > major_implementation : # Let's not try to handle a request for a newer major version raise VersionNotSupported ( detail = ( f \"The provided `api_hint` ( { api_hint [ 1 :] !r} ) is not supported by this implementation. \" f \"Supported versions include: { ', ' . join ( BASE_URL_PREFIXES . values ()) } \" ) ) if major_api_hint <= major_implementation : # If less than: # Use the current implementation in hope that it can still handle older requests # # If equal: # Go to /v<MAJOR>, since this should point to the latest available return BASE_URL_PREFIXES [ \"major\" ]","title":"handle_api_hint()"},{"location":"api_reference/server/middleware/#optimade.server.middleware.HandleApiHint.is_versioned_base_url","text":"Determine whether a request is for a versioned base URL. First, simply check whether a /vMAJOR(.MINOR.PATCH) part exists in the URL. If not, return False , else, remove unversioned base URL from the URL and check again. Return bool of final result. Parameters: Name Type Description Default url str The full URL to check. required Returns: Type Description bool Whether or not the full URL represents an OPTIMADE versioned base URL. Source code in optimade/server/middleware.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 @staticmethod def is_versioned_base_url ( url : str ) -> bool : \"\"\"Determine whether a request is for a versioned base URL. First, simply check whether a `/vMAJOR(.MINOR.PATCH)` part exists in the URL. If not, return `False`, else, remove unversioned base URL from the URL and check again. Return `bool` of final result. Parameters: url: The full URL to check. Returns: Whether or not the full URL represents an OPTIMADE versioned base URL. \"\"\" if not re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url ): return False base_url = get_base_url ( url ) return bool ( re . findall ( r \"(/v[0-9]+(\\.[0-9]+){0,2})\" , url [ len ( base_url ) :]))","title":"is_versioned_base_url()"},{"location":"api_reference/server/query_params/","text":"query_params \u00b6 BaseQueryParams \u00b6 A base class for query parameters that provides validation via the check_params method. Attributes: Name Type Description unsupported_params List [ str ] Any string parameter listed here will raise a warning when passed to the check_params methods. Useful for disabling optional OPTIMADE query parameters that are not implemented by the server, e.g., cursor-based pagination. Source code in optimade/server/query_params.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BaseQueryParams ( ABC ): \"\"\"A base class for query parameters that provides validation via the `check_params` method. Attributes: unsupported_params: Any string parameter listed here will raise a warning when passed to the check_params methods. Useful for disabling optional OPTIMADE query parameters that are not implemented by the server, e.g., cursor-based pagination. \"\"\" unsupported_params : List [ str ] = [] def check_params ( self , query_params : Iterable [ str ]) -> None : \"\"\"This method checks whether all the query parameters that are specified in the URL string are implemented in the relevant `*QueryParams` class. This method handles four cases: * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, and it is not prefixed with a known provider prefix, then a `BadRequest` is raised. * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with a known provider prefix, then the parameter is silently ignored * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with an unknown provider prefix, then a `UnknownProviderQueryParameter` warning is emitted. * If a query parameter is passed that is on the `unsupported_params` list for the inherited class, then a `QueryParamNotUsed` warning is emitted. Arguments: query_params: An iterable of the request's string query parameters. Raises: `BadRequest`: if the query parameter was not found in the relevant class, or if it does not have a valid prefix. \"\"\" if not getattr ( CONFIG , \"validate_query_parameters\" , False ): return errors = [] warnings = [] unsupported_warnings = [] for param in query_params : if param in self . unsupported_params : unsupported_warnings . append ( param ) if not hasattr ( self , param ): split_param = param . split ( \"_\" ) if param . startswith ( \"_\" ) and len ( split_param ) > 2 : prefix = split_param [ 1 ] if prefix in BaseResourceMapper . SUPPORTED_PREFIXES : errors . append ( param ) elif prefix not in BaseResourceMapper . KNOWN_PROVIDER_PREFIXES : warnings . append ( param ) else : errors . append ( param ) if warnings : warn ( f \"The query parameter(s) ' { warnings } ' are unrecognised and have been ignored.\" , UnknownProviderQueryParameter , ) if unsupported_warnings : warn ( f \"The query parameter(s) ' { unsupported_warnings } ' are not supported by this server and have been ignored.\" , QueryParamNotUsed , ) if errors : raise BadRequest ( f \"The query parameter(s) ' { errors } ' are not recognised by this endpoint.\" ) check_params ( query_params ) \u00b6 This method checks whether all the query parameters that are specified in the URL string are implemented in the relevant *QueryParams class. This method handles four cases: If a query parameter is passed that is not defined in the relevant *QueryParams class, and it is not prefixed with a known provider prefix, then a BadRequest is raised. If a query parameter is passed that is not defined in the relevant *QueryParams class, that is prefixed with a known provider prefix, then the parameter is silently ignored If a query parameter is passed that is not defined in the relevant *QueryParams class, that is prefixed with an unknown provider prefix, then a UnknownProviderQueryParameter warning is emitted. If a query parameter is passed that is on the unsupported_params list for the inherited class, then a QueryParamNotUsed warning is emitted. Parameters: Name Type Description Default query_params Iterable [ str ] An iterable of the request's string query parameters. required Raises: Type Description `BadRequest` if the query parameter was not found in the relevant class, or if it does not have a valid prefix. Source code in optimade/server/query_params.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def check_params ( self , query_params : Iterable [ str ]) -> None : \"\"\"This method checks whether all the query parameters that are specified in the URL string are implemented in the relevant `*QueryParams` class. This method handles four cases: * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, and it is not prefixed with a known provider prefix, then a `BadRequest` is raised. * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with a known provider prefix, then the parameter is silently ignored * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with an unknown provider prefix, then a `UnknownProviderQueryParameter` warning is emitted. * If a query parameter is passed that is on the `unsupported_params` list for the inherited class, then a `QueryParamNotUsed` warning is emitted. Arguments: query_params: An iterable of the request's string query parameters. Raises: `BadRequest`: if the query parameter was not found in the relevant class, or if it does not have a valid prefix. \"\"\" if not getattr ( CONFIG , \"validate_query_parameters\" , False ): return errors = [] warnings = [] unsupported_warnings = [] for param in query_params : if param in self . unsupported_params : unsupported_warnings . append ( param ) if not hasattr ( self , param ): split_param = param . split ( \"_\" ) if param . startswith ( \"_\" ) and len ( split_param ) > 2 : prefix = split_param [ 1 ] if prefix in BaseResourceMapper . SUPPORTED_PREFIXES : errors . append ( param ) elif prefix not in BaseResourceMapper . KNOWN_PROVIDER_PREFIXES : warnings . append ( param ) else : errors . append ( param ) if warnings : warn ( f \"The query parameter(s) ' { warnings } ' are unrecognised and have been ignored.\" , UnknownProviderQueryParameter , ) if unsupported_warnings : warn ( f \"The query parameter(s) ' { unsupported_warnings } ' are not supported by this server and have been ignored.\" , QueryParamNotUsed , ) if errors : raise BadRequest ( f \"The query parameter(s) ' { errors } ' are not recognised by this endpoint.\" ) EntryListingQueryParams \u00b6 Common query params for all Entry listing endpoints. Attributes: Name Type Description filter str A filter string, in the format described in section API Filtering Format Specification of the specification. response_format str The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. Example : http://example.com/v1/structures?response_format=xml email_address EmailStr An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. Example : http://example.com/v1/structures?email_address=user@example.com response_fields str A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. Example : http://example.com/v1/structures?response_fields=last_modified,nsites sort str If supporting sortable queries, an implementation MUST use the sort query parameter with format as specified by JSON API 1.0 . An implementation MAY support multiple sort fields for a single query. If it does, it again MUST conform to the JSON API 1.0 specification. If an implementation supports sorting for an entry listing endpoint, then the /info/<entries> endpoint MUST include, for each field name <fieldname> in its data.properties.<fieldname> response value that can be used for sorting, the key sortable with value true . If a field name under an entry listing endpoint supporting sorting cannot be used for sorting, the server MUST either leave out the sortable key or set it equal to false for the specific field name. The set of field names, with sortable equal to true are allowed to be used in the \"sort fields\" list according to its definition in the JSON API 1.0 specification. The field sortable is in addition to each property description and other OPTIONAL fields. An example is shown in the section Entry Listing Info Endpoints. page_limit int Sets a numerical limit on the number of entries returned. See JSON API 1.0 . The API implementation MUST return no more than the number specified. It MAY return fewer. The database MAY have a maximum limit and not accept larger numbers (in which case an error code -- 403 Forbidden -- MUST be returned). The default limit value is up to the API implementation to decide. Example : http://example.com/optimade/v1/structures?page_limit=100 page_offset int RECOMMENDED for use with offset-based pagination: using page_offset and page_limit is RECOMMENDED. Example : Skip 50 structures and fetch up to 100: /structures?page_offset=50&page_limit=100 . page_number int RECOMMENDED for use with page-based pagination: using page_number and page_limit is RECOMMENDED. It is RECOMMENDED that the first page has number 1, i.e., that page_number is 1-based. Example : Fetch page 2 of up to 50 structures per page: /structures?page_number=2&page_limit=50 . page_cursor int RECOMMENDED for use with cursor-based pagination: using page_cursor and page_limit is RECOMMENDED. page_above int RECOMMENDED for use with value-based pagination: using page_above / page_below and page_limit is RECOMMENDED. Example : Fetch up to 100 structures above sort-field value 4000 (in this example, server chooses to fetch results sorted by increasing id , so page_above value refers to an id value): /structures?page_above=4000&page_limit=100 . page_below int RECOMMENDED for use with value-based pagination: using page_above / page_below and page_limit is RECOMMENDED. include str A server MAY implement the JSON API concept of returning compound documents by utilizing the include query parameter as specified by JSON API 1.0 . All related resource objects MUST be returned as part of an array value for the top-level included field, see the section JSON Response Schema: Common Fields. The value of include MUST be a comma-separated list of \"relationship paths\", as defined in the JSON API . If relationship paths are not supported, or a server is unable to identify a relationship path a 400 Bad Request response MUST be made. The default value for include is references . This means references entries MUST always be included under the top-level field included as default, since a server assumes if include is not specified by a client in the request, it is still specified as include=references . Note, if a client explicitly specifies include and leaves out references , references resource objects MUST NOT be included under the top-level field included , as per the definition of included , see section JSON Response Schema: Common Fields. Note : A query with the parameter include set to the empty string means no related resource objects are to be returned under the top-level field included . api_hint str If the client provides the parameter, the value SHOULD have the format vMAJOR or vMAJOR.MINOR , where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends api_hint=v1.0 to the query string, the hint provided is for major version 1 and minor version 0. Source code in optimade/server/query_params.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 class EntryListingQueryParams ( BaseQueryParams ): \"\"\" Common query params for all Entry listing endpoints. Attributes: filter (str): A filter string, in the format described in section API Filtering Format Specification of the specification. response_format (str): The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. **Example**: `http://example.com/v1/structures?response_format=xml` email_address (EmailStr): An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. **Example**: `http://example.com/v1/structures?email_address=user@example.com` response_fields (str): A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. **Example**: `http://example.com/v1/structures?response_fields=last_modified,nsites` sort (str): If supporting sortable queries, an implementation MUST use the `sort` query parameter with format as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-sorting). An implementation MAY support multiple sort fields for a single query. If it does, it again MUST conform to the JSON API 1.0 specification. If an implementation supports sorting for an entry listing endpoint, then the `/info/<entries>` endpoint MUST include, for each field name `<fieldname>` in its `data.properties.<fieldname>` response value that can be used for sorting, the key `sortable` with value `true`. If a field name under an entry listing endpoint supporting sorting cannot be used for sorting, the server MUST either leave out the `sortable` key or set it equal to `false` for the specific field name. The set of field names, with `sortable` equal to `true` are allowed to be used in the \"sort fields\" list according to its definition in the JSON API 1.0 specification. The field `sortable` is in addition to each property description and other OPTIONAL fields. An example is shown in the section Entry Listing Info Endpoints. page_limit (int): Sets a numerical limit on the number of entries returned. See [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-pagination). The API implementation MUST return no more than the number specified. It MAY return fewer. The database MAY have a maximum limit and not accept larger numbers (in which case an error code -- `403 Forbidden` -- MUST be returned). The default limit value is up to the API implementation to decide. **Example**: `http://example.com/optimade/v1/structures?page_limit=100` page_offset (int): RECOMMENDED for use with _offset-based_ pagination: using `page_offset` and `page_limit` is RECOMMENDED. **Example**: Skip 50 structures and fetch up to 100: `/structures?page_offset=50&page_limit=100`. page_number (int): RECOMMENDED for use with _page-based_ pagination: using `page_number` and `page_limit` is RECOMMENDED. It is RECOMMENDED that the first page has number 1, i.e., that `page_number` is 1-based. **Example**: Fetch page 2 of up to 50 structures per page: `/structures?page_number=2&page_limit=50`. page_cursor (int): RECOMMENDED for use with _cursor-based_ pagination: using `page_cursor` and `page_limit` is RECOMMENDED. page_above (int): RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED. **Example**: Fetch up to 100 structures above sort-field value 4000 (in this example, server chooses to fetch results sorted by increasing `id`, so `page_above` value refers to an `id` value): `/structures?page_above=4000&page_limit=100`. page_below (int): RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED. include (str): A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. The **default value** for `include` is `references`. This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`. api_hint (str): If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0. \"\"\" # The reference server implementation only supports offset-based pagination unsupported_params : List [ str ] = [ \"page_cursor\" , \"page_below\" , \"page_above\" , ] def __init__ ( self , * , filter : str = Query ( # pylint: disable=redefined-builtin \"\" , description = \"A filter string, in the format described in section API Filtering Format Specification of the specification.\" , ), response_format : str = Query ( \"json\" , description = \"The output format requested (see section Response Format). \\n Defaults to the format string 'json', which specifies the standard output format described in this specification. \\n Example: `http://example.com/v1/structures?response_format=xml`\" , ), email_address : EmailStr = Query ( \"\" , description = \"An email address of the user making the request. \\n The email SHOULD be that of a person and not an automatic system. \\n Example: `http://example.com/v1/structures?email_address=user@example.com`\" , ), response_fields : str = Query ( \"\" , description = \"A comma-delimited set of fields to be provided in the output. \\n If provided, these fields MUST be returned along with the REQUIRED fields. \\n Other OPTIONAL fields MUST NOT be returned when this parameter is present. \\n Example: `http://example.com/v1/structures?response_fields=last_modified,nsites`\" , regex = r \"([a-z_][a-z_0-9]*(,[a-z_][a-z_0-9]*)*)?\" , ), sort : str = Query ( \"\" , description = 'If supporting sortable queries, an implementation MUST use the `sort` query parameter with format as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-sorting). \\n\\n An implementation MAY support multiple sort fields for a single query. \\n If it does, it again MUST conform to the JSON API 1.0 specification. \\n\\n If an implementation supports sorting for an entry listing endpoint, then the `/info/<entries>` endpoint MUST include, for each field name `<fieldname>` in its `data.properties.<fieldname>` response value that can be used for sorting, the key `sortable` with value `true`. \\n If a field name under an entry listing endpoint supporting sorting cannot be used for sorting, the server MUST either leave out the `sortable` key or set it equal to `false` for the specific field name. \\n The set of field names, with `sortable` equal to `true` are allowed to be used in the \"sort fields\" list according to its definition in the JSON API 1.0 specification. \\n The field `sortable` is in addition to each property description and other OPTIONAL fields. \\n An example is shown in the section Entry Listing Info Endpoints.' , regex = r \"([a-z_][a-z_0-9]*(,[a-z_][a-z_0-9]*)*)?\" , ), page_limit : int = Query ( CONFIG . page_limit , description = \"Sets a numerical limit on the number of entries returned. \\n See [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-pagination). \\n The API implementation MUST return no more than the number specified. \\n It MAY return fewer. \\n The database MAY have a maximum limit and not accept larger numbers (in which case an error code -- 403 Forbidden -- MUST be returned). \\n The default limit value is up to the API implementation to decide. \\n Example: `http://example.com/optimade/v1/structures?page_limit=100`\" , ge = 0 , ), page_offset : int = Query ( 0 , description = \"RECOMMENDED for use with _offset-based_ pagination: using `page_offset` and `page_limit` is RECOMMENDED. \\n Example: Skip 50 structures and fetch up to 100: `/structures?page_offset=50&page_limit=100`.\" , ge = 0 , ), page_number : int = Query ( 0 , description = \"RECOMMENDED for use with _page-based_ pagination: using `page_number` and `page_limit` is RECOMMENDED. \\n It is RECOMMENDED that the first page has number 1, i.e., that `page_number` is 1-based. \\n Example: Fetch page 2 of up to 50 structures per page: `/structures?page_number=2&page_limit=50`.\" , ge = 1 , ), page_cursor : int = Query ( 0 , description = \"RECOMMENDED for use with _cursor-based_ pagination: using `page_cursor` and `page_limit` is RECOMMENDED.\" , ge = 0 , ), page_above : int = Query ( 0 , description = \"RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED. \\n Example: Fetch up to 100 structures above sort-field value 4000 (in this example, server chooses to fetch results sorted by increasing `id`, so `page_above` value refers to an `id` value): `/structures?page_above=4000&page_limit=100`.\" , ge = 0 , ), page_below : int = Query ( 0 , description = \"RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED.\" , ge = 0 , ), include : str = Query ( \"references\" , description = 'A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). \\n\\n All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. \\n\\n The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). \\n If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. \\n\\n The **default value** for `include` is `references`. \\n This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. \\n Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. \\n\\n > **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`.' , ), api_hint : str = Query ( \"\" , description = \"If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0.\" , regex = r \"(v[0-9]+(\\.[0-9]+)?)?\" , ), ): self . filter = filter self . response_format = response_format self . email_address = email_address self . response_fields = response_fields self . sort = sort self . page_limit = page_limit self . page_offset = page_offset self . page_number = page_number self . page_cursor = page_cursor self . page_above = page_above self . page_below = page_below self . include = include self . api_hint = api_hint SingleEntryQueryParams \u00b6 Common query params for single entry endpoints. Attributes: Name Type Description response_format str The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. Example : http://example.com/v1/structures?response_format=xml email_address EmailStr An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. Example : http://example.com/v1/structures?email_address=user@example.com response_fields str A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. Example : http://example.com/v1/structures?response_fields=last_modified,nsites include str A server MAY implement the JSON API concept of returning compound documents by utilizing the include query parameter as specified by JSON API 1.0 . All related resource objects MUST be returned as part of an array value for the top-level included field, see the section JSON Response Schema: Common Fields. The value of include MUST be a comma-separated list of \"relationship paths\", as defined in the JSON API . If relationship paths are not supported, or a server is unable to identify a relationship path a 400 Bad Request response MUST be made. The default value for include is references . This means references entries MUST always be included under the top-level field included as default, since a server assumes if include is not specified by a client in the request, it is still specified as include=references . Note, if a client explicitly specifies include and leaves out references , references resource objects MUST NOT be included under the top-level field included , as per the definition of included , see section JSON Response Schema: Common Fields. Note : A query with the parameter include set to the empty string means no related resource objects are to be returned under the top-level field included . api_hint str If the client provides the parameter, the value SHOULD have the format vMAJOR or vMAJOR.MINOR , where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends api_hint=v1.0 to the query string, the hint provided is for major version 1 and minor version 0. Source code in optimade/server/query_params.py 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 class SingleEntryQueryParams ( BaseQueryParams ): \"\"\" Common query params for single entry endpoints. Attributes: response_format (str): The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. **Example**: `http://example.com/v1/structures?response_format=xml` email_address (EmailStr): An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. **Example**: `http://example.com/v1/structures?email_address=user@example.com` response_fields (str): A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. **Example**: `http://example.com/v1/structures?response_fields=last_modified,nsites` include (str): A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. The **default value** for `include` is `references`. This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`. api_hint (str): If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0. \"\"\" def __init__ ( self , * , response_format : str = Query ( \"json\" , description = \"The output format requested (see section Response Format). \\n Defaults to the format string 'json', which specifies the standard output format described in this specification. \\n Example: `http://example.com/v1/structures?response_format=xml`\" , ), email_address : EmailStr = Query ( \"\" , description = \"An email address of the user making the request. \\n The email SHOULD be that of a person and not an automatic system. \\n Example: `http://example.com/v1/structures?email_address=user@example.com`\" , ), response_fields : str = Query ( \"\" , description = \"A comma-delimited set of fields to be provided in the output. \\n If provided, these fields MUST be returned along with the REQUIRED fields. \\n Other OPTIONAL fields MUST NOT be returned when this parameter is present. \\n Example: `http://example.com/v1/structures?response_fields=last_modified,nsites`\" , regex = r \"([a-z_][a-z_0-9]*(,[a-z_][a-z_0-9]*)*)?\" , ), include : str = Query ( \"references\" , description = 'A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). \\n\\n All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. \\n\\n The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). \\n If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. \\n\\n The **default value** for `include` is `references`. \\n This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. \\n Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. \\n\\n > **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`.' , ), api_hint : str = Query ( \"\" , description = \"If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0.\" , regex = r \"(v[0-9]+(\\.[0-9]+)?)?\" , ), ): self . response_format = response_format self . email_address = email_address self . response_fields = response_fields self . include = include self . api_hint = api_hint","title":"query_params"},{"location":"api_reference/server/query_params/#query_params","text":"","title":"query_params"},{"location":"api_reference/server/query_params/#optimade.server.query_params.BaseQueryParams","text":"A base class for query parameters that provides validation via the check_params method. Attributes: Name Type Description unsupported_params List [ str ] Any string parameter listed here will raise a warning when passed to the check_params methods. Useful for disabling optional OPTIMADE query parameters that are not implemented by the server, e.g., cursor-based pagination. Source code in optimade/server/query_params.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class BaseQueryParams ( ABC ): \"\"\"A base class for query parameters that provides validation via the `check_params` method. Attributes: unsupported_params: Any string parameter listed here will raise a warning when passed to the check_params methods. Useful for disabling optional OPTIMADE query parameters that are not implemented by the server, e.g., cursor-based pagination. \"\"\" unsupported_params : List [ str ] = [] def check_params ( self , query_params : Iterable [ str ]) -> None : \"\"\"This method checks whether all the query parameters that are specified in the URL string are implemented in the relevant `*QueryParams` class. This method handles four cases: * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, and it is not prefixed with a known provider prefix, then a `BadRequest` is raised. * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with a known provider prefix, then the parameter is silently ignored * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with an unknown provider prefix, then a `UnknownProviderQueryParameter` warning is emitted. * If a query parameter is passed that is on the `unsupported_params` list for the inherited class, then a `QueryParamNotUsed` warning is emitted. Arguments: query_params: An iterable of the request's string query parameters. Raises: `BadRequest`: if the query parameter was not found in the relevant class, or if it does not have a valid prefix. \"\"\" if not getattr ( CONFIG , \"validate_query_parameters\" , False ): return errors = [] warnings = [] unsupported_warnings = [] for param in query_params : if param in self . unsupported_params : unsupported_warnings . append ( param ) if not hasattr ( self , param ): split_param = param . split ( \"_\" ) if param . startswith ( \"_\" ) and len ( split_param ) > 2 : prefix = split_param [ 1 ] if prefix in BaseResourceMapper . SUPPORTED_PREFIXES : errors . append ( param ) elif prefix not in BaseResourceMapper . KNOWN_PROVIDER_PREFIXES : warnings . append ( param ) else : errors . append ( param ) if warnings : warn ( f \"The query parameter(s) ' { warnings } ' are unrecognised and have been ignored.\" , UnknownProviderQueryParameter , ) if unsupported_warnings : warn ( f \"The query parameter(s) ' { unsupported_warnings } ' are not supported by this server and have been ignored.\" , QueryParamNotUsed , ) if errors : raise BadRequest ( f \"The query parameter(s) ' { errors } ' are not recognised by this endpoint.\" )","title":"BaseQueryParams"},{"location":"api_reference/server/query_params/#optimade.server.query_params.BaseQueryParams.check_params","text":"This method checks whether all the query parameters that are specified in the URL string are implemented in the relevant *QueryParams class. This method handles four cases: If a query parameter is passed that is not defined in the relevant *QueryParams class, and it is not prefixed with a known provider prefix, then a BadRequest is raised. If a query parameter is passed that is not defined in the relevant *QueryParams class, that is prefixed with a known provider prefix, then the parameter is silently ignored If a query parameter is passed that is not defined in the relevant *QueryParams class, that is prefixed with an unknown provider prefix, then a UnknownProviderQueryParameter warning is emitted. If a query parameter is passed that is on the unsupported_params list for the inherited class, then a QueryParamNotUsed warning is emitted. Parameters: Name Type Description Default query_params Iterable [ str ] An iterable of the request's string query parameters. required Raises: Type Description `BadRequest` if the query parameter was not found in the relevant class, or if it does not have a valid prefix. Source code in optimade/server/query_params.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def check_params ( self , query_params : Iterable [ str ]) -> None : \"\"\"This method checks whether all the query parameters that are specified in the URL string are implemented in the relevant `*QueryParams` class. This method handles four cases: * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, and it is not prefixed with a known provider prefix, then a `BadRequest` is raised. * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with a known provider prefix, then the parameter is silently ignored * If a query parameter is passed that is not defined in the relevant `*QueryParams` class, that is prefixed with an unknown provider prefix, then a `UnknownProviderQueryParameter` warning is emitted. * If a query parameter is passed that is on the `unsupported_params` list for the inherited class, then a `QueryParamNotUsed` warning is emitted. Arguments: query_params: An iterable of the request's string query parameters. Raises: `BadRequest`: if the query parameter was not found in the relevant class, or if it does not have a valid prefix. \"\"\" if not getattr ( CONFIG , \"validate_query_parameters\" , False ): return errors = [] warnings = [] unsupported_warnings = [] for param in query_params : if param in self . unsupported_params : unsupported_warnings . append ( param ) if not hasattr ( self , param ): split_param = param . split ( \"_\" ) if param . startswith ( \"_\" ) and len ( split_param ) > 2 : prefix = split_param [ 1 ] if prefix in BaseResourceMapper . SUPPORTED_PREFIXES : errors . append ( param ) elif prefix not in BaseResourceMapper . KNOWN_PROVIDER_PREFIXES : warnings . append ( param ) else : errors . append ( param ) if warnings : warn ( f \"The query parameter(s) ' { warnings } ' are unrecognised and have been ignored.\" , UnknownProviderQueryParameter , ) if unsupported_warnings : warn ( f \"The query parameter(s) ' { unsupported_warnings } ' are not supported by this server and have been ignored.\" , QueryParamNotUsed , ) if errors : raise BadRequest ( f \"The query parameter(s) ' { errors } ' are not recognised by this endpoint.\" )","title":"check_params()"},{"location":"api_reference/server/query_params/#optimade.server.query_params.EntryListingQueryParams","text":"Common query params for all Entry listing endpoints. Attributes: Name Type Description filter str A filter string, in the format described in section API Filtering Format Specification of the specification. response_format str The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. Example : http://example.com/v1/structures?response_format=xml email_address EmailStr An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. Example : http://example.com/v1/structures?email_address=user@example.com response_fields str A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. Example : http://example.com/v1/structures?response_fields=last_modified,nsites sort str If supporting sortable queries, an implementation MUST use the sort query parameter with format as specified by JSON API 1.0 . An implementation MAY support multiple sort fields for a single query. If it does, it again MUST conform to the JSON API 1.0 specification. If an implementation supports sorting for an entry listing endpoint, then the /info/<entries> endpoint MUST include, for each field name <fieldname> in its data.properties.<fieldname> response value that can be used for sorting, the key sortable with value true . If a field name under an entry listing endpoint supporting sorting cannot be used for sorting, the server MUST either leave out the sortable key or set it equal to false for the specific field name. The set of field names, with sortable equal to true are allowed to be used in the \"sort fields\" list according to its definition in the JSON API 1.0 specification. The field sortable is in addition to each property description and other OPTIONAL fields. An example is shown in the section Entry Listing Info Endpoints. page_limit int Sets a numerical limit on the number of entries returned. See JSON API 1.0 . The API implementation MUST return no more than the number specified. It MAY return fewer. The database MAY have a maximum limit and not accept larger numbers (in which case an error code -- 403 Forbidden -- MUST be returned). The default limit value is up to the API implementation to decide. Example : http://example.com/optimade/v1/structures?page_limit=100 page_offset int RECOMMENDED for use with offset-based pagination: using page_offset and page_limit is RECOMMENDED. Example : Skip 50 structures and fetch up to 100: /structures?page_offset=50&page_limit=100 . page_number int RECOMMENDED for use with page-based pagination: using page_number and page_limit is RECOMMENDED. It is RECOMMENDED that the first page has number 1, i.e., that page_number is 1-based. Example : Fetch page 2 of up to 50 structures per page: /structures?page_number=2&page_limit=50 . page_cursor int RECOMMENDED for use with cursor-based pagination: using page_cursor and page_limit is RECOMMENDED. page_above int RECOMMENDED for use with value-based pagination: using page_above / page_below and page_limit is RECOMMENDED. Example : Fetch up to 100 structures above sort-field value 4000 (in this example, server chooses to fetch results sorted by increasing id , so page_above value refers to an id value): /structures?page_above=4000&page_limit=100 . page_below int RECOMMENDED for use with value-based pagination: using page_above / page_below and page_limit is RECOMMENDED. include str A server MAY implement the JSON API concept of returning compound documents by utilizing the include query parameter as specified by JSON API 1.0 . All related resource objects MUST be returned as part of an array value for the top-level included field, see the section JSON Response Schema: Common Fields. The value of include MUST be a comma-separated list of \"relationship paths\", as defined in the JSON API . If relationship paths are not supported, or a server is unable to identify a relationship path a 400 Bad Request response MUST be made. The default value for include is references . This means references entries MUST always be included under the top-level field included as default, since a server assumes if include is not specified by a client in the request, it is still specified as include=references . Note, if a client explicitly specifies include and leaves out references , references resource objects MUST NOT be included under the top-level field included , as per the definition of included , see section JSON Response Schema: Common Fields. Note : A query with the parameter include set to the empty string means no related resource objects are to be returned under the top-level field included . api_hint str If the client provides the parameter, the value SHOULD have the format vMAJOR or vMAJOR.MINOR , where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends api_hint=v1.0 to the query string, the hint provided is for major version 1 and minor version 0. Source code in optimade/server/query_params.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 class EntryListingQueryParams ( BaseQueryParams ): \"\"\" Common query params for all Entry listing endpoints. Attributes: filter (str): A filter string, in the format described in section API Filtering Format Specification of the specification. response_format (str): The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. **Example**: `http://example.com/v1/structures?response_format=xml` email_address (EmailStr): An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. **Example**: `http://example.com/v1/structures?email_address=user@example.com` response_fields (str): A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. **Example**: `http://example.com/v1/structures?response_fields=last_modified,nsites` sort (str): If supporting sortable queries, an implementation MUST use the `sort` query parameter with format as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-sorting). An implementation MAY support multiple sort fields for a single query. If it does, it again MUST conform to the JSON API 1.0 specification. If an implementation supports sorting for an entry listing endpoint, then the `/info/<entries>` endpoint MUST include, for each field name `<fieldname>` in its `data.properties.<fieldname>` response value that can be used for sorting, the key `sortable` with value `true`. If a field name under an entry listing endpoint supporting sorting cannot be used for sorting, the server MUST either leave out the `sortable` key or set it equal to `false` for the specific field name. The set of field names, with `sortable` equal to `true` are allowed to be used in the \"sort fields\" list according to its definition in the JSON API 1.0 specification. The field `sortable` is in addition to each property description and other OPTIONAL fields. An example is shown in the section Entry Listing Info Endpoints. page_limit (int): Sets a numerical limit on the number of entries returned. See [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-pagination). The API implementation MUST return no more than the number specified. It MAY return fewer. The database MAY have a maximum limit and not accept larger numbers (in which case an error code -- `403 Forbidden` -- MUST be returned). The default limit value is up to the API implementation to decide. **Example**: `http://example.com/optimade/v1/structures?page_limit=100` page_offset (int): RECOMMENDED for use with _offset-based_ pagination: using `page_offset` and `page_limit` is RECOMMENDED. **Example**: Skip 50 structures and fetch up to 100: `/structures?page_offset=50&page_limit=100`. page_number (int): RECOMMENDED for use with _page-based_ pagination: using `page_number` and `page_limit` is RECOMMENDED. It is RECOMMENDED that the first page has number 1, i.e., that `page_number` is 1-based. **Example**: Fetch page 2 of up to 50 structures per page: `/structures?page_number=2&page_limit=50`. page_cursor (int): RECOMMENDED for use with _cursor-based_ pagination: using `page_cursor` and `page_limit` is RECOMMENDED. page_above (int): RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED. **Example**: Fetch up to 100 structures above sort-field value 4000 (in this example, server chooses to fetch results sorted by increasing `id`, so `page_above` value refers to an `id` value): `/structures?page_above=4000&page_limit=100`. page_below (int): RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED. include (str): A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. The **default value** for `include` is `references`. This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`. api_hint (str): If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0. \"\"\" # The reference server implementation only supports offset-based pagination unsupported_params : List [ str ] = [ \"page_cursor\" , \"page_below\" , \"page_above\" , ] def __init__ ( self , * , filter : str = Query ( # pylint: disable=redefined-builtin \"\" , description = \"A filter string, in the format described in section API Filtering Format Specification of the specification.\" , ), response_format : str = Query ( \"json\" , description = \"The output format requested (see section Response Format). \\n Defaults to the format string 'json', which specifies the standard output format described in this specification. \\n Example: `http://example.com/v1/structures?response_format=xml`\" , ), email_address : EmailStr = Query ( \"\" , description = \"An email address of the user making the request. \\n The email SHOULD be that of a person and not an automatic system. \\n Example: `http://example.com/v1/structures?email_address=user@example.com`\" , ), response_fields : str = Query ( \"\" , description = \"A comma-delimited set of fields to be provided in the output. \\n If provided, these fields MUST be returned along with the REQUIRED fields. \\n Other OPTIONAL fields MUST NOT be returned when this parameter is present. \\n Example: `http://example.com/v1/structures?response_fields=last_modified,nsites`\" , regex = r \"([a-z_][a-z_0-9]*(,[a-z_][a-z_0-9]*)*)?\" , ), sort : str = Query ( \"\" , description = 'If supporting sortable queries, an implementation MUST use the `sort` query parameter with format as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-sorting). \\n\\n An implementation MAY support multiple sort fields for a single query. \\n If it does, it again MUST conform to the JSON API 1.0 specification. \\n\\n If an implementation supports sorting for an entry listing endpoint, then the `/info/<entries>` endpoint MUST include, for each field name `<fieldname>` in its `data.properties.<fieldname>` response value that can be used for sorting, the key `sortable` with value `true`. \\n If a field name under an entry listing endpoint supporting sorting cannot be used for sorting, the server MUST either leave out the `sortable` key or set it equal to `false` for the specific field name. \\n The set of field names, with `sortable` equal to `true` are allowed to be used in the \"sort fields\" list according to its definition in the JSON API 1.0 specification. \\n The field `sortable` is in addition to each property description and other OPTIONAL fields. \\n An example is shown in the section Entry Listing Info Endpoints.' , regex = r \"([a-z_][a-z_0-9]*(,[a-z_][a-z_0-9]*)*)?\" , ), page_limit : int = Query ( CONFIG . page_limit , description = \"Sets a numerical limit on the number of entries returned. \\n See [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-pagination). \\n The API implementation MUST return no more than the number specified. \\n It MAY return fewer. \\n The database MAY have a maximum limit and not accept larger numbers (in which case an error code -- 403 Forbidden -- MUST be returned). \\n The default limit value is up to the API implementation to decide. \\n Example: `http://example.com/optimade/v1/structures?page_limit=100`\" , ge = 0 , ), page_offset : int = Query ( 0 , description = \"RECOMMENDED for use with _offset-based_ pagination: using `page_offset` and `page_limit` is RECOMMENDED. \\n Example: Skip 50 structures and fetch up to 100: `/structures?page_offset=50&page_limit=100`.\" , ge = 0 , ), page_number : int = Query ( 0 , description = \"RECOMMENDED for use with _page-based_ pagination: using `page_number` and `page_limit` is RECOMMENDED. \\n It is RECOMMENDED that the first page has number 1, i.e., that `page_number` is 1-based. \\n Example: Fetch page 2 of up to 50 structures per page: `/structures?page_number=2&page_limit=50`.\" , ge = 1 , ), page_cursor : int = Query ( 0 , description = \"RECOMMENDED for use with _cursor-based_ pagination: using `page_cursor` and `page_limit` is RECOMMENDED.\" , ge = 0 , ), page_above : int = Query ( 0 , description = \"RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED. \\n Example: Fetch up to 100 structures above sort-field value 4000 (in this example, server chooses to fetch results sorted by increasing `id`, so `page_above` value refers to an `id` value): `/structures?page_above=4000&page_limit=100`.\" , ge = 0 , ), page_below : int = Query ( 0 , description = \"RECOMMENDED for use with _value-based_ pagination: using `page_above`/`page_below` and `page_limit` is RECOMMENDED.\" , ge = 0 , ), include : str = Query ( \"references\" , description = 'A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). \\n\\n All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. \\n\\n The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). \\n If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. \\n\\n The **default value** for `include` is `references`. \\n This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. \\n Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. \\n\\n > **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`.' , ), api_hint : str = Query ( \"\" , description = \"If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0.\" , regex = r \"(v[0-9]+(\\.[0-9]+)?)?\" , ), ): self . filter = filter self . response_format = response_format self . email_address = email_address self . response_fields = response_fields self . sort = sort self . page_limit = page_limit self . page_offset = page_offset self . page_number = page_number self . page_cursor = page_cursor self . page_above = page_above self . page_below = page_below self . include = include self . api_hint = api_hint","title":"EntryListingQueryParams"},{"location":"api_reference/server/query_params/#optimade.server.query_params.SingleEntryQueryParams","text":"Common query params for single entry endpoints. Attributes: Name Type Description response_format str The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. Example : http://example.com/v1/structures?response_format=xml email_address EmailStr An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. Example : http://example.com/v1/structures?email_address=user@example.com response_fields str A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. Example : http://example.com/v1/structures?response_fields=last_modified,nsites include str A server MAY implement the JSON API concept of returning compound documents by utilizing the include query parameter as specified by JSON API 1.0 . All related resource objects MUST be returned as part of an array value for the top-level included field, see the section JSON Response Schema: Common Fields. The value of include MUST be a comma-separated list of \"relationship paths\", as defined in the JSON API . If relationship paths are not supported, or a server is unable to identify a relationship path a 400 Bad Request response MUST be made. The default value for include is references . This means references entries MUST always be included under the top-level field included as default, since a server assumes if include is not specified by a client in the request, it is still specified as include=references . Note, if a client explicitly specifies include and leaves out references , references resource objects MUST NOT be included under the top-level field included , as per the definition of included , see section JSON Response Schema: Common Fields. Note : A query with the parameter include set to the empty string means no related resource objects are to be returned under the top-level field included . api_hint str If the client provides the parameter, the value SHOULD have the format vMAJOR or vMAJOR.MINOR , where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends api_hint=v1.0 to the query string, the hint provided is for major version 1 and minor version 0. Source code in optimade/server/query_params.py 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 class SingleEntryQueryParams ( BaseQueryParams ): \"\"\" Common query params for single entry endpoints. Attributes: response_format (str): The output format requested (see section Response Format). Defaults to the format string 'json', which specifies the standard output format described in this specification. **Example**: `http://example.com/v1/structures?response_format=xml` email_address (EmailStr): An email address of the user making the request. The email SHOULD be that of a person and not an automatic system. **Example**: `http://example.com/v1/structures?email_address=user@example.com` response_fields (str): A comma-delimited set of fields to be provided in the output. If provided, these fields MUST be returned along with the REQUIRED fields. Other OPTIONAL fields MUST NOT be returned when this parameter is present. **Example**: `http://example.com/v1/structures?response_fields=last_modified,nsites` include (str): A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. The **default value** for `include` is `references`. This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`. api_hint (str): If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0. \"\"\" def __init__ ( self , * , response_format : str = Query ( \"json\" , description = \"The output format requested (see section Response Format). \\n Defaults to the format string 'json', which specifies the standard output format described in this specification. \\n Example: `http://example.com/v1/structures?response_format=xml`\" , ), email_address : EmailStr = Query ( \"\" , description = \"An email address of the user making the request. \\n The email SHOULD be that of a person and not an automatic system. \\n Example: `http://example.com/v1/structures?email_address=user@example.com`\" , ), response_fields : str = Query ( \"\" , description = \"A comma-delimited set of fields to be provided in the output. \\n If provided, these fields MUST be returned along with the REQUIRED fields. \\n Other OPTIONAL fields MUST NOT be returned when this parameter is present. \\n Example: `http://example.com/v1/structures?response_fields=last_modified,nsites`\" , regex = r \"([a-z_][a-z_0-9]*(,[a-z_][a-z_0-9]*)*)?\" , ), include : str = Query ( \"references\" , description = 'A server MAY implement the JSON API concept of returning [compound documents](https://jsonapi.org/format/1.0/#document-compound-documents) by utilizing the `include` query parameter as specified by [JSON API 1.0](https://jsonapi.org/format/1.0/#fetching-includes). \\n\\n All related resource objects MUST be returned as part of an array value for the top-level `included` field, see the section JSON Response Schema: Common Fields. \\n\\n The value of `include` MUST be a comma-separated list of \"relationship paths\", as defined in the [JSON API](https://jsonapi.org/format/1.0/#fetching-includes). \\n If relationship paths are not supported, or a server is unable to identify a relationship path a `400 Bad Request` response MUST be made. \\n\\n The **default value** for `include` is `references`. \\n This means `references` entries MUST always be included under the top-level field `included` as default, since a server assumes if `include` is not specified by a client in the request, it is still specified as `include=references`. \\n Note, if a client explicitly specifies `include` and leaves out `references`, `references` resource objects MUST NOT be included under the top-level field `included`, as per the definition of `included`, see section JSON Response Schema: Common Fields. \\n\\n > **Note**: A query with the parameter `include` set to the empty string means no related resource objects are to be returned under the top-level field `included`.' , ), api_hint : str = Query ( \"\" , description = \"If the client provides the parameter, the value SHOULD have the format `vMAJOR` or `vMAJOR.MINOR`, where MAJOR is a major version and MINOR is a minor version of the API. For example, if a client appends `api_hint=v1.0` to the query string, the hint provided is for major version 1 and minor version 0.\" , regex = r \"(v[0-9]+(\\.[0-9]+)?)?\" , ), ): self . response_format = response_format self . email_address = email_address self . response_fields = response_fields self . include = include self . api_hint = api_hint","title":"SingleEntryQueryParams"},{"location":"api_reference/server/schemas/","text":"schemas \u00b6 ENTRY_INFO_SCHEMAS : Dict [ str , Callable [[ None ], Dict ]] = { 'structures' : StructureResource . schema , 'references' : ReferenceResource . schema } module-attribute \u00b6 This dictionary is used to define the /info/<entry_type> endpoints. retrieve_queryable_properties ( schema , queryable_properties = None , entry_type = None ) \u00b6 Recursively loops through the schema of a pydantic model and resolves all references, returning a dictionary of all the OPTIMADE-queryable properties of that model. Parameters: Name Type Description Default schema dict The schema of the pydantic model. required queryable_properties list The list of properties to find in the schema. None entry_type str An optional entry type for the model. Will be used to lookup schemas for any config-defined fields. None Returns: Type Description dict A flat dictionary with properties as keys, containing the field dict description, unit, sortability, support level, queryability dict and type, where provided. Source code in optimade/server/schemas.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def retrieve_queryable_properties ( schema : dict , queryable_properties : list = None , entry_type : str = None , ) -> dict : \"\"\"Recursively loops through the schema of a pydantic model and resolves all references, returning a dictionary of all the OPTIMADE-queryable properties of that model. Parameters: schema: The schema of the pydantic model. queryable_properties: The list of properties to find in the schema. entry_type: An optional entry type for the model. Will be used to lookup schemas for any config-defined fields. Returns: A flat dictionary with properties as keys, containing the field description, unit, sortability, support level, queryability and type, where provided. \"\"\" properties = {} for name , value in schema [ \"properties\" ] . items (): if not queryable_properties or name in queryable_properties : if \"$ref\" in value : path = value [ \"$ref\" ] . split ( \"/\" )[ 1 :] sub_schema = schema . copy () while path : next_key = path . pop ( 0 ) sub_schema = sub_schema [ next_key ] sub_queryable_properties = sub_schema [ \"properties\" ] . keys () properties . update ( retrieve_queryable_properties ( sub_schema , sub_queryable_properties ) ) else : properties [ name ] = { \"description\" : value . get ( \"description\" , \"\" )} # Update schema with extension keys provided they are not None for key in ( \"x-optimade-unit\" , \"x-optimade-queryable\" , \"x-optimade-support\" , ): if value . get ( key ) is not None : properties [ name ][ key . replace ( \"x-optimade-\" , \"\" )] = value [ key ] # All properties are sortable with the MongoDB backend. # While the result for sorting lists may not be as expected, they are still sorted. properties [ name ][ \"sortable\" ] = value . get ( \"x-optimade-sortable\" , True ) # Try to get OpenAPI-specific \"format\" if possible, else get \"type\"; a mandatory OpenAPI key. properties [ name ][ \"type\" ] = DataType . from_json_type ( value . get ( \"format\" , value . get ( \"type\" )) ) # If specified, check the config for any additional well-described provider fields if entry_type : from optimade.server.config import CONFIG described_provider_fields = [ field for field in CONFIG . provider_fields . get ( entry_type , {}) if isinstance ( field , dict ) ] for field in described_provider_fields : name = f \"_ { CONFIG . provider . prefix } _ { field [ 'name' ] } \" properties [ name ] = { k : field [ k ] for k in field if k != \"name\" } properties [ name ][ \"sortable\" ] = field . get ( \"sortable\" , True ) return properties","title":"schemas"},{"location":"api_reference/server/schemas/#schemas","text":"","title":"schemas"},{"location":"api_reference/server/schemas/#optimade.server.schemas.ENTRY_INFO_SCHEMAS","text":"This dictionary is used to define the /info/<entry_type> endpoints.","title":"ENTRY_INFO_SCHEMAS"},{"location":"api_reference/server/schemas/#optimade.server.schemas.retrieve_queryable_properties","text":"Recursively loops through the schema of a pydantic model and resolves all references, returning a dictionary of all the OPTIMADE-queryable properties of that model. Parameters: Name Type Description Default schema dict The schema of the pydantic model. required queryable_properties list The list of properties to find in the schema. None entry_type str An optional entry type for the model. Will be used to lookup schemas for any config-defined fields. None Returns: Type Description dict A flat dictionary with properties as keys, containing the field dict description, unit, sortability, support level, queryability dict and type, where provided. Source code in optimade/server/schemas.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def retrieve_queryable_properties ( schema : dict , queryable_properties : list = None , entry_type : str = None , ) -> dict : \"\"\"Recursively loops through the schema of a pydantic model and resolves all references, returning a dictionary of all the OPTIMADE-queryable properties of that model. Parameters: schema: The schema of the pydantic model. queryable_properties: The list of properties to find in the schema. entry_type: An optional entry type for the model. Will be used to lookup schemas for any config-defined fields. Returns: A flat dictionary with properties as keys, containing the field description, unit, sortability, support level, queryability and type, where provided. \"\"\" properties = {} for name , value in schema [ \"properties\" ] . items (): if not queryable_properties or name in queryable_properties : if \"$ref\" in value : path = value [ \"$ref\" ] . split ( \"/\" )[ 1 :] sub_schema = schema . copy () while path : next_key = path . pop ( 0 ) sub_schema = sub_schema [ next_key ] sub_queryable_properties = sub_schema [ \"properties\" ] . keys () properties . update ( retrieve_queryable_properties ( sub_schema , sub_queryable_properties ) ) else : properties [ name ] = { \"description\" : value . get ( \"description\" , \"\" )} # Update schema with extension keys provided they are not None for key in ( \"x-optimade-unit\" , \"x-optimade-queryable\" , \"x-optimade-support\" , ): if value . get ( key ) is not None : properties [ name ][ key . replace ( \"x-optimade-\" , \"\" )] = value [ key ] # All properties are sortable with the MongoDB backend. # While the result for sorting lists may not be as expected, they are still sorted. properties [ name ][ \"sortable\" ] = value . get ( \"x-optimade-sortable\" , True ) # Try to get OpenAPI-specific \"format\" if possible, else get \"type\"; a mandatory OpenAPI key. properties [ name ][ \"type\" ] = DataType . from_json_type ( value . get ( \"format\" , value . get ( \"type\" )) ) # If specified, check the config for any additional well-described provider fields if entry_type : from optimade.server.config import CONFIG described_provider_fields = [ field for field in CONFIG . provider_fields . get ( entry_type , {}) if isinstance ( field , dict ) ] for field in described_provider_fields : name = f \"_ { CONFIG . provider . prefix } _ { field [ 'name' ] } \" properties [ name ] = { k : field [ k ] for k in field if k != \"name\" } properties [ name ][ \"sortable\" ] = field . get ( \"sortable\" , True ) return properties","title":"retrieve_queryable_properties()"},{"location":"api_reference/server/warnings/","text":"warnings \u00b6 FieldValueNotRecognized \u00b6 A field or value used in the request is not recognised by this implementation. Source code in optimade/server/warnings.py 27 28 class FieldValueNotRecognized ( OptimadeWarning ): \"\"\"A field or value used in the request is not recognised by this implementation.\"\"\" MissingExpectedField \u00b6 A field was provided with a null value when a related field was provided with a value. Source code in optimade/server/warnings.py 39 40 41 class MissingExpectedField ( OptimadeWarning ): \"\"\"A field was provided with a null value when a related field was provided with a value.\"\"\" OptimadeWarning \u00b6 Base Warning for the optimade package Source code in optimade/server/warnings.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class OptimadeWarning ( Warning ): \"\"\"Base Warning for the `optimade` package\"\"\" def __init__ ( self , detail : str = None , title : str = None , * args ) -> None : detail = detail if detail else self . __doc__ super () . __init__ ( detail , * args ) self . detail = detail self . title = title if title else self . __class__ . __name__ def __repr__ ( self ) -> str : attrs = { \"detail\" : self . detail , \"title\" : self . title } return \"< {:s} ( {:s} )>\" . format ( self . __class__ . __name__ , \" \" . join ( [ f \" { attr } = { value !r} \" for attr , value in attrs . items () if value is not None ] ), ) def __str__ ( self ) -> str : return self . detail if self . detail is not None else \"\" QueryParamNotUsed \u00b6 A query parameter is not used in this request. Source code in optimade/server/warnings.py 35 36 class QueryParamNotUsed ( OptimadeWarning ): \"\"\"A query parameter is not used in this request.\"\"\" TimestampNotRFCCompliant \u00b6 A timestamp has been used in a filter that contains microseconds and is thus not RFC 3339 compliant. This may cause undefined behaviour in the query results. Source code in optimade/server/warnings.py 44 45 46 47 48 class TimestampNotRFCCompliant ( OptimadeWarning ): \"\"\"A timestamp has been used in a filter that contains microseconds and is thus not RFC 3339 compliant. This may cause undefined behaviour in the query results. \"\"\" TooManyValues \u00b6 A field or query parameter has too many values to be handled by this implementation. Source code in optimade/server/warnings.py 31 32 class TooManyValues ( OptimadeWarning ): \"\"\"A field or query parameter has too many values to be handled by this implementation.\"\"\" UnknownProviderProperty \u00b6 A provider-specific property has been requested via response_fields or as in a filter that is not recognised by this implementation. Source code in optimade/server/warnings.py 51 52 53 54 55 class UnknownProviderProperty ( OptimadeWarning ): \"\"\"A provider-specific property has been requested via `response_fields` or as in a `filter` that is not recognised by this implementation. \"\"\" UnknownProviderQueryParameter \u00b6 A provider-specific query parameter has been requested in the query with a prefix not recognised by this implementation. Source code in optimade/server/warnings.py 58 59 60 61 62 class UnknownProviderQueryParameter ( OptimadeWarning ): \"\"\"A provider-specific query parameter has been requested in the query with a prefix not recognised by this implementation. \"\"\"","title":"warnings"},{"location":"api_reference/server/warnings/#warnings","text":"","title":"warnings"},{"location":"api_reference/server/warnings/#optimade.server.warnings.FieldValueNotRecognized","text":"A field or value used in the request is not recognised by this implementation. Source code in optimade/server/warnings.py 27 28 class FieldValueNotRecognized ( OptimadeWarning ): \"\"\"A field or value used in the request is not recognised by this implementation.\"\"\"","title":"FieldValueNotRecognized"},{"location":"api_reference/server/warnings/#optimade.server.warnings.MissingExpectedField","text":"A field was provided with a null value when a related field was provided with a value. Source code in optimade/server/warnings.py 39 40 41 class MissingExpectedField ( OptimadeWarning ): \"\"\"A field was provided with a null value when a related field was provided with a value.\"\"\"","title":"MissingExpectedField"},{"location":"api_reference/server/warnings/#optimade.server.warnings.OptimadeWarning","text":"Base Warning for the optimade package Source code in optimade/server/warnings.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class OptimadeWarning ( Warning ): \"\"\"Base Warning for the `optimade` package\"\"\" def __init__ ( self , detail : str = None , title : str = None , * args ) -> None : detail = detail if detail else self . __doc__ super () . __init__ ( detail , * args ) self . detail = detail self . title = title if title else self . __class__ . __name__ def __repr__ ( self ) -> str : attrs = { \"detail\" : self . detail , \"title\" : self . title } return \"< {:s} ( {:s} )>\" . format ( self . __class__ . __name__ , \" \" . join ( [ f \" { attr } = { value !r} \" for attr , value in attrs . items () if value is not None ] ), ) def __str__ ( self ) -> str : return self . detail if self . detail is not None else \"\"","title":"OptimadeWarning"},{"location":"api_reference/server/warnings/#optimade.server.warnings.QueryParamNotUsed","text":"A query parameter is not used in this request. Source code in optimade/server/warnings.py 35 36 class QueryParamNotUsed ( OptimadeWarning ): \"\"\"A query parameter is not used in this request.\"\"\"","title":"QueryParamNotUsed"},{"location":"api_reference/server/warnings/#optimade.server.warnings.TimestampNotRFCCompliant","text":"A timestamp has been used in a filter that contains microseconds and is thus not RFC 3339 compliant. This may cause undefined behaviour in the query results. Source code in optimade/server/warnings.py 44 45 46 47 48 class TimestampNotRFCCompliant ( OptimadeWarning ): \"\"\"A timestamp has been used in a filter that contains microseconds and is thus not RFC 3339 compliant. This may cause undefined behaviour in the query results. \"\"\"","title":"TimestampNotRFCCompliant"},{"location":"api_reference/server/warnings/#optimade.server.warnings.TooManyValues","text":"A field or query parameter has too many values to be handled by this implementation. Source code in optimade/server/warnings.py 31 32 class TooManyValues ( OptimadeWarning ): \"\"\"A field or query parameter has too many values to be handled by this implementation.\"\"\"","title":"TooManyValues"},{"location":"api_reference/server/warnings/#optimade.server.warnings.UnknownProviderProperty","text":"A provider-specific property has been requested via response_fields or as in a filter that is not recognised by this implementation. Source code in optimade/server/warnings.py 51 52 53 54 55 class UnknownProviderProperty ( OptimadeWarning ): \"\"\"A provider-specific property has been requested via `response_fields` or as in a `filter` that is not recognised by this implementation. \"\"\"","title":"UnknownProviderProperty"},{"location":"api_reference/server/warnings/#optimade.server.warnings.UnknownProviderQueryParameter","text":"A provider-specific query parameter has been requested in the query with a prefix not recognised by this implementation. Source code in optimade/server/warnings.py 58 59 60 61 62 class UnknownProviderQueryParameter ( OptimadeWarning ): \"\"\"A provider-specific query parameter has been requested in the query with a prefix not recognised by this implementation. \"\"\"","title":"UnknownProviderQueryParameter"},{"location":"api_reference/server/entry_collections/elasticsearch/","text":"elasticsearch \u00b6 ElasticCollection \u00b6 Source code in optimade/server/entry_collections/elasticsearch.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 class ElasticCollection ( EntryCollection ): def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , client : Optional [ \"Elasticsearch\" ] = None , ): \"\"\"Initialize the ElasticCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. client: A preconfigured Elasticsearch client. \"\"\" super () . __init__ ( resource_cls = resource_cls , resource_mapper = resource_mapper , transformer = ElasticTransformer ( mapper = resource_mapper ), ) self . client = client if client else CLIENT self . name = name # If we are creating a new collection from scratch, also create the index, # otherwise assume it has already been created externally if CONFIG . insert_test_data : self . create_optimade_index () def count ( self , * args , ** kwargs ) -> int : raise NotImplementedError def create_optimade_index ( self ) -> None : \"\"\"Load or create an index that can handle aliased OPTIMADE fields and attach it to the current client. \"\"\" body = self . predefined_index . get ( self . name ) if body is None : body = self . create_elastic_index_from_mapper ( self . resource_mapper , self . all_fields ) properties = {} for field in list ( body [ \"mappings\" ][ \"properties\" ] . keys ()): properties [ self . resource_mapper . get_backend_field ( field )] = body [ \"mappings\" ][ \"properties\" ] . pop ( field ) properties [ \"id\" ] = { \"type\" : \"keyword\" } body [ \"mappings\" ][ \"properties\" ] = properties self . client . indices . create ( index = self . name , body = body , ignore = 400 ) LOGGER . debug ( f \"Created Elastic index for { self . name !r} with body { body } \" ) @property def predefined_index ( self ) -> Dict [ str , Any ]: \"\"\"Loads and returns the default pre-defined index.\"\"\" with open ( Path ( __file__ ) . parent . joinpath ( \"elastic_indexes.json\" )) as f : index = json . load ( f ) return index @staticmethod def create_elastic_index_from_mapper ( resource_mapper : BaseResourceMapper , fields : Iterable [ str ] ) -> Dict [ str , Any ]: \"\"\"Create a fallback elastic index based on a resource mapper. Arguments: resource_mapper: The resource mapper to create the index for. fields: The list of fields to use in the index. Returns: The `body` parameter to pass to `client.indices.create(..., body=...)`. \"\"\" properties = { resource_mapper . get_optimade_field ( field ): { \"type\" : \"keyword\" } for field in fields } properties [ \"id\" ] = { \"type\" : \"keyword\" } return { \"mappings\" : { \"properties\" : properties }} def __len__ ( self ): \"\"\"Returns the total number of entries in the collection.\"\"\" return Search ( using = self . client , index = self . name ) . execute () . hits . total . value def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" def get_id ( item ): if self . name == \"links\" : id_ = \" %s - %s \" % ( item [ \"id\" ], item [ \"type\" ]) elif \"id\" in item : id_ = item [ \"id\" ] elif \"_id\" in item : # use the existing MongoDB ids in the test data id_ = str ( item [ \"_id\" ]) else : # ES will generate ids id_ = None item . pop ( \"_id\" , None ) return id_ bulk ( self . client , [ { \"_index\" : self . name , \"_id\" : get_id ( item ), \"_type\" : \"_doc\" , \"_source\" : item , } for item in data ], ) def _run_db_query ( self , criteria : Dict [ str , Any ], single_entry = False ) -> Tuple [ Union [ List [ Dict [ str , Any ]], Dict [ str , Any ]], int , bool ]: \"\"\"Run the query on the backend and collect the results. Arguments: criteria: A dictionary representation of the query parameters. single_entry: Whether or not the caller is expecting a single entry response. Returns: The list of entries from the database (without any re-mapping), the total number of entries matching the query and a boolean for whether or not there is more data available. \"\"\" search = Search ( using = self . client , index = self . name ) if criteria . get ( \"filter\" , False ): search = search . query ( criteria [ \"filter\" ]) page_offset = criteria . get ( \"skip\" , 0 ) limit = criteria . get ( \"limit\" , CONFIG . page_limit ) all_aliased_fields = [ self . resource_mapper . get_backend_field ( field ) for field in self . all_fields ] search = search . source ( includes = all_aliased_fields ) elastic_sort = [ { field : { \"order\" : \"desc\" if sort_dir == - 1 else \"asc\" }} for field , sort_dir in criteria . get ( \"sort\" , {}) ] if not elastic_sort : elastic_sort = { self . resource_mapper . get_backend_field ( \"id\" ): { \"order\" : \"asc\" } } search = search . sort ( * elastic_sort ) search = search [ page_offset : page_offset + limit ] search = search . extra ( track_total_hits = True ) response = search . execute () results = [ hit . to_dict () for hit in response . hits ] if not single_entry : data_returned = response . hits . total . value more_data_available = page_offset + limit < data_returned else : # SingleEntryQueryParams, e.g., /structures/{entry_id} data_returned = len ( results ) more_data_available = False return results , data_returned , more_data_available __init__ ( name , resource_cls , resource_mapper , client = None ) \u00b6 Initialize the ElasticCollection for the given parameters. Parameters: Name Type Description Default name str The name of the collection. required resource_cls EntryResource The type of entry resource that is stored by the collection. required resource_mapper BaseResourceMapper A resource mapper object that handles aliases and format changes between deserialization and response. required client Optional [ Elasticsearch ] A preconfigured Elasticsearch client. None Source code in optimade/server/entry_collections/elasticsearch.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , client : Optional [ \"Elasticsearch\" ] = None , ): \"\"\"Initialize the ElasticCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. client: A preconfigured Elasticsearch client. \"\"\" super () . __init__ ( resource_cls = resource_cls , resource_mapper = resource_mapper , transformer = ElasticTransformer ( mapper = resource_mapper ), ) self . client = client if client else CLIENT self . name = name # If we are creating a new collection from scratch, also create the index, # otherwise assume it has already been created externally if CONFIG . insert_test_data : self . create_optimade_index () __len__ () \u00b6 Returns the total number of entries in the collection. Source code in optimade/server/entry_collections/elasticsearch.py 107 108 109 def __len__ ( self ): \"\"\"Returns the total number of entries in the collection.\"\"\" return Search ( using = self . client , index = self . name ) . execute () . hits . total . value create_elastic_index_from_mapper ( resource_mapper , fields ) staticmethod \u00b6 Create a fallback elastic index based on a resource mapper. Parameters: Name Type Description Default resource_mapper BaseResourceMapper The resource mapper to create the index for. required fields Iterable [ str ] The list of fields to use in the index. required Returns: Type Description Dict [ str , Any ] The body parameter to pass to client.indices.create(..., body=...) . Source code in optimade/server/entry_collections/elasticsearch.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 @staticmethod def create_elastic_index_from_mapper ( resource_mapper : BaseResourceMapper , fields : Iterable [ str ] ) -> Dict [ str , Any ]: \"\"\"Create a fallback elastic index based on a resource mapper. Arguments: resource_mapper: The resource mapper to create the index for. fields: The list of fields to use in the index. Returns: The `body` parameter to pass to `client.indices.create(..., body=...)`. \"\"\" properties = { resource_mapper . get_optimade_field ( field ): { \"type\" : \"keyword\" } for field in fields } properties [ \"id\" ] = { \"type\" : \"keyword\" } return { \"mappings\" : { \"properties\" : properties }} create_optimade_index () \u00b6 Load or create an index that can handle aliased OPTIMADE fields and attach it to the current client. Source code in optimade/server/entry_collections/elasticsearch.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def create_optimade_index ( self ) -> None : \"\"\"Load or create an index that can handle aliased OPTIMADE fields and attach it to the current client. \"\"\" body = self . predefined_index . get ( self . name ) if body is None : body = self . create_elastic_index_from_mapper ( self . resource_mapper , self . all_fields ) properties = {} for field in list ( body [ \"mappings\" ][ \"properties\" ] . keys ()): properties [ self . resource_mapper . get_backend_field ( field )] = body [ \"mappings\" ][ \"properties\" ] . pop ( field ) properties [ \"id\" ] = { \"type\" : \"keyword\" } body [ \"mappings\" ][ \"properties\" ] = properties self . client . indices . create ( index = self . name , body = body , ignore = 400 ) LOGGER . debug ( f \"Created Elastic index for { self . name !r} with body { body } \" ) insert ( data ) \u00b6 Add the given entries to the underlying database. Warning No validation is performed on the incoming data. Parameters: Name Type Description Default data List [ EntryResource ] The entry resource objects to add to the database. required Source code in optimade/server/entry_collections/elasticsearch.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" def get_id ( item ): if self . name == \"links\" : id_ = \" %s - %s \" % ( item [ \"id\" ], item [ \"type\" ]) elif \"id\" in item : id_ = item [ \"id\" ] elif \"_id\" in item : # use the existing MongoDB ids in the test data id_ = str ( item [ \"_id\" ]) else : # ES will generate ids id_ = None item . pop ( \"_id\" , None ) return id_ bulk ( self . client , [ { \"_index\" : self . name , \"_id\" : get_id ( item ), \"_type\" : \"_doc\" , \"_source\" : item , } for item in data ], ) predefined_index () property \u00b6 Loads and returns the default pre-defined index. Source code in optimade/server/entry_collections/elasticsearch.py 79 80 81 82 83 84 @property def predefined_index ( self ) -> Dict [ str , Any ]: \"\"\"Loads and returns the default pre-defined index.\"\"\" with open ( Path ( __file__ ) . parent . joinpath ( \"elastic_indexes.json\" )) as f : index = json . load ( f ) return index","title":"elasticsearch"},{"location":"api_reference/server/entry_collections/elasticsearch/#elasticsearch","text":"","title":"elasticsearch"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection","text":"Source code in optimade/server/entry_collections/elasticsearch.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 class ElasticCollection ( EntryCollection ): def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , client : Optional [ \"Elasticsearch\" ] = None , ): \"\"\"Initialize the ElasticCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. client: A preconfigured Elasticsearch client. \"\"\" super () . __init__ ( resource_cls = resource_cls , resource_mapper = resource_mapper , transformer = ElasticTransformer ( mapper = resource_mapper ), ) self . client = client if client else CLIENT self . name = name # If we are creating a new collection from scratch, also create the index, # otherwise assume it has already been created externally if CONFIG . insert_test_data : self . create_optimade_index () def count ( self , * args , ** kwargs ) -> int : raise NotImplementedError def create_optimade_index ( self ) -> None : \"\"\"Load or create an index that can handle aliased OPTIMADE fields and attach it to the current client. \"\"\" body = self . predefined_index . get ( self . name ) if body is None : body = self . create_elastic_index_from_mapper ( self . resource_mapper , self . all_fields ) properties = {} for field in list ( body [ \"mappings\" ][ \"properties\" ] . keys ()): properties [ self . resource_mapper . get_backend_field ( field )] = body [ \"mappings\" ][ \"properties\" ] . pop ( field ) properties [ \"id\" ] = { \"type\" : \"keyword\" } body [ \"mappings\" ][ \"properties\" ] = properties self . client . indices . create ( index = self . name , body = body , ignore = 400 ) LOGGER . debug ( f \"Created Elastic index for { self . name !r} with body { body } \" ) @property def predefined_index ( self ) -> Dict [ str , Any ]: \"\"\"Loads and returns the default pre-defined index.\"\"\" with open ( Path ( __file__ ) . parent . joinpath ( \"elastic_indexes.json\" )) as f : index = json . load ( f ) return index @staticmethod def create_elastic_index_from_mapper ( resource_mapper : BaseResourceMapper , fields : Iterable [ str ] ) -> Dict [ str , Any ]: \"\"\"Create a fallback elastic index based on a resource mapper. Arguments: resource_mapper: The resource mapper to create the index for. fields: The list of fields to use in the index. Returns: The `body` parameter to pass to `client.indices.create(..., body=...)`. \"\"\" properties = { resource_mapper . get_optimade_field ( field ): { \"type\" : \"keyword\" } for field in fields } properties [ \"id\" ] = { \"type\" : \"keyword\" } return { \"mappings\" : { \"properties\" : properties }} def __len__ ( self ): \"\"\"Returns the total number of entries in the collection.\"\"\" return Search ( using = self . client , index = self . name ) . execute () . hits . total . value def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" def get_id ( item ): if self . name == \"links\" : id_ = \" %s - %s \" % ( item [ \"id\" ], item [ \"type\" ]) elif \"id\" in item : id_ = item [ \"id\" ] elif \"_id\" in item : # use the existing MongoDB ids in the test data id_ = str ( item [ \"_id\" ]) else : # ES will generate ids id_ = None item . pop ( \"_id\" , None ) return id_ bulk ( self . client , [ { \"_index\" : self . name , \"_id\" : get_id ( item ), \"_type\" : \"_doc\" , \"_source\" : item , } for item in data ], ) def _run_db_query ( self , criteria : Dict [ str , Any ], single_entry = False ) -> Tuple [ Union [ List [ Dict [ str , Any ]], Dict [ str , Any ]], int , bool ]: \"\"\"Run the query on the backend and collect the results. Arguments: criteria: A dictionary representation of the query parameters. single_entry: Whether or not the caller is expecting a single entry response. Returns: The list of entries from the database (without any re-mapping), the total number of entries matching the query and a boolean for whether or not there is more data available. \"\"\" search = Search ( using = self . client , index = self . name ) if criteria . get ( \"filter\" , False ): search = search . query ( criteria [ \"filter\" ]) page_offset = criteria . get ( \"skip\" , 0 ) limit = criteria . get ( \"limit\" , CONFIG . page_limit ) all_aliased_fields = [ self . resource_mapper . get_backend_field ( field ) for field in self . all_fields ] search = search . source ( includes = all_aliased_fields ) elastic_sort = [ { field : { \"order\" : \"desc\" if sort_dir == - 1 else \"asc\" }} for field , sort_dir in criteria . get ( \"sort\" , {}) ] if not elastic_sort : elastic_sort = { self . resource_mapper . get_backend_field ( \"id\" ): { \"order\" : \"asc\" } } search = search . sort ( * elastic_sort ) search = search [ page_offset : page_offset + limit ] search = search . extra ( track_total_hits = True ) response = search . execute () results = [ hit . to_dict () for hit in response . hits ] if not single_entry : data_returned = response . hits . total . value more_data_available = page_offset + limit < data_returned else : # SingleEntryQueryParams, e.g., /structures/{entry_id} data_returned = len ( results ) more_data_available = False return results , data_returned , more_data_available","title":"ElasticCollection"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection.__init__","text":"Initialize the ElasticCollection for the given parameters. Parameters: Name Type Description Default name str The name of the collection. required resource_cls EntryResource The type of entry resource that is stored by the collection. required resource_mapper BaseResourceMapper A resource mapper object that handles aliases and format changes between deserialization and response. required client Optional [ Elasticsearch ] A preconfigured Elasticsearch client. None Source code in optimade/server/entry_collections/elasticsearch.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , client : Optional [ \"Elasticsearch\" ] = None , ): \"\"\"Initialize the ElasticCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. client: A preconfigured Elasticsearch client. \"\"\" super () . __init__ ( resource_cls = resource_cls , resource_mapper = resource_mapper , transformer = ElasticTransformer ( mapper = resource_mapper ), ) self . client = client if client else CLIENT self . name = name # If we are creating a new collection from scratch, also create the index, # otherwise assume it has already been created externally if CONFIG . insert_test_data : self . create_optimade_index ()","title":"__init__()"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection.__len__","text":"Returns the total number of entries in the collection. Source code in optimade/server/entry_collections/elasticsearch.py 107 108 109 def __len__ ( self ): \"\"\"Returns the total number of entries in the collection.\"\"\" return Search ( using = self . client , index = self . name ) . execute () . hits . total . value","title":"__len__()"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection.create_elastic_index_from_mapper","text":"Create a fallback elastic index based on a resource mapper. Parameters: Name Type Description Default resource_mapper BaseResourceMapper The resource mapper to create the index for. required fields Iterable [ str ] The list of fields to use in the index. required Returns: Type Description Dict [ str , Any ] The body parameter to pass to client.indices.create(..., body=...) . Source code in optimade/server/entry_collections/elasticsearch.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 @staticmethod def create_elastic_index_from_mapper ( resource_mapper : BaseResourceMapper , fields : Iterable [ str ] ) -> Dict [ str , Any ]: \"\"\"Create a fallback elastic index based on a resource mapper. Arguments: resource_mapper: The resource mapper to create the index for. fields: The list of fields to use in the index. Returns: The `body` parameter to pass to `client.indices.create(..., body=...)`. \"\"\" properties = { resource_mapper . get_optimade_field ( field ): { \"type\" : \"keyword\" } for field in fields } properties [ \"id\" ] = { \"type\" : \"keyword\" } return { \"mappings\" : { \"properties\" : properties }}","title":"create_elastic_index_from_mapper()"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection.create_optimade_index","text":"Load or create an index that can handle aliased OPTIMADE fields and attach it to the current client. Source code in optimade/server/entry_collections/elasticsearch.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def create_optimade_index ( self ) -> None : \"\"\"Load or create an index that can handle aliased OPTIMADE fields and attach it to the current client. \"\"\" body = self . predefined_index . get ( self . name ) if body is None : body = self . create_elastic_index_from_mapper ( self . resource_mapper , self . all_fields ) properties = {} for field in list ( body [ \"mappings\" ][ \"properties\" ] . keys ()): properties [ self . resource_mapper . get_backend_field ( field )] = body [ \"mappings\" ][ \"properties\" ] . pop ( field ) properties [ \"id\" ] = { \"type\" : \"keyword\" } body [ \"mappings\" ][ \"properties\" ] = properties self . client . indices . create ( index = self . name , body = body , ignore = 400 ) LOGGER . debug ( f \"Created Elastic index for { self . name !r} with body { body } \" )","title":"create_optimade_index()"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection.insert","text":"Add the given entries to the underlying database. Warning No validation is performed on the incoming data. Parameters: Name Type Description Default data List [ EntryResource ] The entry resource objects to add to the database. required Source code in optimade/server/entry_collections/elasticsearch.py 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" def get_id ( item ): if self . name == \"links\" : id_ = \" %s - %s \" % ( item [ \"id\" ], item [ \"type\" ]) elif \"id\" in item : id_ = item [ \"id\" ] elif \"_id\" in item : # use the existing MongoDB ids in the test data id_ = str ( item [ \"_id\" ]) else : # ES will generate ids id_ = None item . pop ( \"_id\" , None ) return id_ bulk ( self . client , [ { \"_index\" : self . name , \"_id\" : get_id ( item ), \"_type\" : \"_doc\" , \"_source\" : item , } for item in data ], )","title":"insert()"},{"location":"api_reference/server/entry_collections/elasticsearch/#optimade.server.entry_collections.elasticsearch.ElasticCollection.predefined_index","text":"Loads and returns the default pre-defined index. Source code in optimade/server/entry_collections/elasticsearch.py 79 80 81 82 83 84 @property def predefined_index ( self ) -> Dict [ str , Any ]: \"\"\"Loads and returns the default pre-defined index.\"\"\" with open ( Path ( __file__ ) . parent . joinpath ( \"elastic_indexes.json\" )) as f : index = json . load ( f ) return index","title":"predefined_index()"},{"location":"api_reference/server/entry_collections/entry_collections/","text":"entry_collections \u00b6 EntryCollection \u00b6 Backend-agnostic base class for querying collections of EntryResource s. Source code in optimade/server/entry_collections/entry_collections.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 class EntryCollection ( ABC ): \"\"\"Backend-agnostic base class for querying collections of [`EntryResource`][optimade.models.entries.EntryResource]s.\"\"\" def __init__ ( self , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , transformer : Transformer , ): \"\"\"Initialize the collection for the given parameters. Parameters: resource_cls (EntryResource): The `EntryResource` model that is stored by the collection. resource_mapper (BaseResourceMapper): A resource mapper object that handles aliases and format changes between deserialization and response. transformer (Transformer): The Lark `Transformer` used to interpret the filter. \"\"\" self . parser = LarkParser () self . resource_cls = resource_cls self . resource_mapper = resource_mapper self . transformer = transformer self . provider_prefix = CONFIG . provider . prefix self . provider_fields = [ field if isinstance ( field , str ) else field [ \"name\" ] for field in CONFIG . provider_fields . get ( resource_mapper . ENDPOINT , []) ] self . _all_fields : Set [ str ] = None @abstractmethod def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" @abstractmethod def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Arguments: data: The entry resource objects to add to the database. \"\"\" @abstractmethod def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. \"\"\" def find ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Tuple [ Union [ List [ EntryResource ], EntryResource , None ], int , bool , Set [ str ], Set [ str ] ]: \"\"\" Fetches results and indicates if more data is available. Also gives the total number of data available in the absence of `page_limit`. See [`EntryListingQueryParams`][optimade.server.query_params.EntryListingQueryParams] for more information. Parameters: params: Entry listing URL query params. Returns: A tuple of various relevant values: (`results`, `data_returned`, `more_data_available`, `exclude_fields`, `include_fields`). \"\"\" criteria = self . handle_query_params ( params ) single_entry = isinstance ( params , SingleEntryQueryParams ) response_fields = criteria . pop ( \"fields\" ) results , data_returned , more_data_available = self . _run_db_query ( criteria , single_entry ) if single_entry : results = results [ 0 ] if results else None if data_returned > 1 : raise NotFound ( detail = f \"Instead of a single entry, { data_returned } entries were found\" , ) exclude_fields = self . all_fields - response_fields include_fields = ( response_fields - self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS ) bad_optimade_fields = set () bad_provider_fields = set () supported_prefixes = self . resource_mapper . SUPPORTED_PREFIXES all_attributes = self . resource_mapper . ALL_ATTRIBUTES for field in include_fields : if field not in all_attributes : if field . startswith ( \"_\" ): if any ( field . startswith ( f \"_ { prefix } _\" ) for prefix in supported_prefixes ): bad_provider_fields . add ( field ) else : bad_optimade_fields . add ( field ) if bad_provider_fields : warnings . warn ( message = f \"Unrecognised field(s) for this provider requested in `response_fields`: { bad_provider_fields } .\" , category = UnknownProviderProperty , ) if bad_optimade_fields : raise BadRequest ( detail = f \"Unrecognised OPTIMADE field(s) in requested `response_fields`: { bad_optimade_fields } .\" ) if results : results = self . resource_mapper . deserialize ( results ) return ( results , data_returned , more_data_available , exclude_fields , include_fields , ) @abstractmethod def _run_db_query ( self , criteria : Dict [ str , Any ], single_entry : bool = False ) -> Tuple [ List [ Dict [ str , Any ]], int , bool ]: \"\"\"Run the query on the backend and collect the results. Arguments: criteria: A dictionary representation of the query parameters. single_entry: Whether or not the caller is expecting a single entry response. Returns: The list of entries from the database (without any re-mapping), the total number of entries matching the query and a boolean for whether or not there is more data available. \"\"\" @property def all_fields ( self ) -> Set [ str ]: \"\"\"Get the set of all fields handled in this collection, from attribute fields in the schema, provider fields and top-level OPTIMADE fields. The set of all fields are lazily created and then cached. This means the set is created the first time the property is requested and then cached. Returns: All fields handled in this collection. \"\"\" if not self . _all_fields : # All OPTIMADE fields self . _all_fields = ( self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS . copy () ) self . _all_fields |= self . get_attribute_fields () # All provider-specific fields self . _all_fields |= { f \"_ { self . provider_prefix } _ { field_name } \" for field_name in self . provider_fields } return self . _all_fields def get_attribute_fields ( self ) -> Set [ str ]: \"\"\"Get the set of attribute fields Return only the _first-level_ attribute fields from the schema of the resource class, resolving references along the way if needed. Note: It is not needed to take care of other special OpenAPI schema keys than `allOf`, since only `allOf` will be found in this context. Other special keys can be found in [the Swagger documentation](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/). Returns: Property names. \"\"\" schema = self . resource_cls . schema () attributes = schema [ \"properties\" ][ \"attributes\" ] if \"allOf\" in attributes : allOf = attributes . pop ( \"allOf\" ) for dict_ in allOf : attributes . update ( dict_ ) if \"$ref\" in attributes : path = attributes [ \"$ref\" ] . split ( \"/\" )[ 1 :] attributes = schema . copy () while path : next_key = path . pop ( 0 ) attributes = attributes [ next_key ] return set ( attributes [ \"properties\" ] . keys ()) def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by the specific backend. Note: Currently this method returns the pymongo interpretation of the parameters, which will need modification for modified for other backends. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" cursor_kwargs = {} # filter if getattr ( params , \"filter\" , False ): cursor_kwargs [ \"filter\" ] = self . transformer . transform ( self . parser . parse ( params . filter ) ) else : cursor_kwargs [ \"filter\" ] = {} # response_format if ( getattr ( params , \"response_format\" , False ) and params . response_format != \"json\" ): raise BadRequest ( detail = f \"Response format { params . response_format } is not supported, please use response_format='json'\" ) # page_limit if getattr ( params , \"page_limit\" , False ): limit = params . page_limit if limit > CONFIG . page_limit_max : raise Forbidden ( detail = f \"Max allowed page_limit is { CONFIG . page_limit_max } , you requested { limit } \" , ) cursor_kwargs [ \"limit\" ] = limit else : cursor_kwargs [ \"limit\" ] = CONFIG . page_limit # response_fields cursor_kwargs [ \"projection\" ] = { f \" { self . resource_mapper . get_backend_field ( f ) } \" : True for f in self . all_fields } if getattr ( params , \"response_fields\" , False ): response_fields = set ( params . response_fields . split ( \",\" )) response_fields |= self . resource_mapper . get_required_fields () else : response_fields = self . all_fields . copy () cursor_kwargs [ \"fields\" ] = response_fields # sort if getattr ( params , \"sort\" , False ): cursor_kwargs [ \"sort\" ] = self . parse_sort_params ( params . sort ) # page_offset and page_number if getattr ( params , \"page_offset\" , False ): if getattr ( params , \"page_number\" , False ): warnings . warn ( message = \"Only one of the query parameters 'page_number' and 'page_offset' should be set - 'page_number' will be ignored.\" , category = QueryParamNotUsed , ) cursor_kwargs [ \"skip\" ] = params . page_offset elif getattr ( params , \"page_number\" , False ): if isinstance ( params . page_number , int ): cursor_kwargs [ \"skip\" ] = ( params . page_number - 1 ) * cursor_kwargs [ \"limit\" ] return cursor_kwargs def parse_sort_params ( self , sort_params : str ) -> Tuple [ Tuple [ str , int ]]: \"\"\"Handles any sort parameters passed to the collection, resolving aliases and dealing with any invalid fields. Raises: BadRequest: if an invalid sort is requested. Returns: A tuple of tuples containing the aliased field name and sort direction encoded as 1 (ascending) or -1 (descending). \"\"\" sort_spec = [] for field in sort_params . split ( \",\" ): sort_dir = 1 if field . startswith ( \"-\" ): field = field [ 1 :] sort_dir = - 1 aliased_field = self . resource_mapper . get_backend_field ( field ) sort_spec . append (( aliased_field , sort_dir )) unknown_fields = [ field for field , _ in sort_spec if self . resource_mapper . get_optimade_field ( field ) not in self . all_fields ] if unknown_fields : error_detail = \"Unable to sort on unknown field {} ' {} '\" . format ( \"s\" if len ( unknown_fields ) > 1 else \"\" , \"', '\" . join ( unknown_fields ), ) # If all unknown fields are \"other\" provider-specific, then only provide a warning if all ( ( re . match ( r \"_[a-z_0-9]+_[a-z_0-9]*\" , field ) and not field . startswith ( f \"_ { self . provider_prefix } _\" ) ) for field in unknown_fields ): warnings . warn ( error_detail , FieldValueNotRecognized ) # Otherwise, if all fields are unknown, or some fields are unknown and do not # have other provider prefixes, then return 400: Bad Request else : raise BadRequest ( detail = error_detail ) # If at least one valid field has been provided for sorting, then use that sort_spec = tuple ( ( field , sort_dir ) for field , sort_dir in sort_spec if field not in unknown_fields ) return sort_spec __init__ ( resource_cls , resource_mapper , transformer ) \u00b6 Initialize the collection for the given parameters. Parameters: Name Type Description Default resource_cls EntryResource The EntryResource model that is stored by the collection. required resource_mapper BaseResourceMapper A resource mapper object that handles aliases and format changes between deserialization and response. required transformer Transformer The Lark Transformer used to interpret the filter. required Source code in optimade/server/entry_collections/entry_collections.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , transformer : Transformer , ): \"\"\"Initialize the collection for the given parameters. Parameters: resource_cls (EntryResource): The `EntryResource` model that is stored by the collection. resource_mapper (BaseResourceMapper): A resource mapper object that handles aliases and format changes between deserialization and response. transformer (Transformer): The Lark `Transformer` used to interpret the filter. \"\"\" self . parser = LarkParser () self . resource_cls = resource_cls self . resource_mapper = resource_mapper self . transformer = transformer self . provider_prefix = CONFIG . provider . prefix self . provider_fields = [ field if isinstance ( field , str ) else field [ \"name\" ] for field in CONFIG . provider_fields . get ( resource_mapper . ENDPOINT , []) ] self . _all_fields : Set [ str ] = None __len__ () abstractmethod \u00b6 Returns the total number of entries in the collection. Source code in optimade/server/entry_collections/entry_collections.py 97 98 99 @abstractmethod def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" all_fields () property \u00b6 Get the set of all fields handled in this collection, from attribute fields in the schema, provider fields and top-level OPTIMADE fields. The set of all fields are lazily created and then cached. This means the set is created the first time the property is requested and then cached. Returns: Type Description Set [ str ] All fields handled in this collection. Source code in optimade/server/entry_collections/entry_collections.py 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 @property def all_fields ( self ) -> Set [ str ]: \"\"\"Get the set of all fields handled in this collection, from attribute fields in the schema, provider fields and top-level OPTIMADE fields. The set of all fields are lazily created and then cached. This means the set is created the first time the property is requested and then cached. Returns: All fields handled in this collection. \"\"\" if not self . _all_fields : # All OPTIMADE fields self . _all_fields = ( self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS . copy () ) self . _all_fields |= self . get_attribute_fields () # All provider-specific fields self . _all_fields |= { f \"_ { self . provider_prefix } _ { field_name } \" for field_name in self . provider_fields } return self . _all_fields count ( ** kwargs ) abstractmethod \u00b6 Returns the number of entries matching the query specified by the keyword arguments. Parameters: Name Type Description Default **kwargs Any Query parameters as keyword arguments. {} Source code in optimade/server/entry_collections/entry_collections.py 110 111 112 113 114 115 116 117 118 @abstractmethod def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. \"\"\" find ( params ) \u00b6 Fetches results and indicates if more data is available. Also gives the total number of data available in the absence of page_limit . See EntryListingQueryParams for more information. Parameters: Name Type Description Default params Union [ EntryListingQueryParams , SingleEntryQueryParams ] Entry listing URL query params. required Returns: Type Description Union [ List [ EntryResource ], EntryResource , None] A tuple of various relevant values: int ( results , data_returned , more_data_available , exclude_fields , include_fields ). Source code in optimade/server/entry_collections/entry_collections.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def find ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Tuple [ Union [ List [ EntryResource ], EntryResource , None ], int , bool , Set [ str ], Set [ str ] ]: \"\"\" Fetches results and indicates if more data is available. Also gives the total number of data available in the absence of `page_limit`. See [`EntryListingQueryParams`][optimade.server.query_params.EntryListingQueryParams] for more information. Parameters: params: Entry listing URL query params. Returns: A tuple of various relevant values: (`results`, `data_returned`, `more_data_available`, `exclude_fields`, `include_fields`). \"\"\" criteria = self . handle_query_params ( params ) single_entry = isinstance ( params , SingleEntryQueryParams ) response_fields = criteria . pop ( \"fields\" ) results , data_returned , more_data_available = self . _run_db_query ( criteria , single_entry ) if single_entry : results = results [ 0 ] if results else None if data_returned > 1 : raise NotFound ( detail = f \"Instead of a single entry, { data_returned } entries were found\" , ) exclude_fields = self . all_fields - response_fields include_fields = ( response_fields - self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS ) bad_optimade_fields = set () bad_provider_fields = set () supported_prefixes = self . resource_mapper . SUPPORTED_PREFIXES all_attributes = self . resource_mapper . ALL_ATTRIBUTES for field in include_fields : if field not in all_attributes : if field . startswith ( \"_\" ): if any ( field . startswith ( f \"_ { prefix } _\" ) for prefix in supported_prefixes ): bad_provider_fields . add ( field ) else : bad_optimade_fields . add ( field ) if bad_provider_fields : warnings . warn ( message = f \"Unrecognised field(s) for this provider requested in `response_fields`: { bad_provider_fields } .\" , category = UnknownProviderProperty , ) if bad_optimade_fields : raise BadRequest ( detail = f \"Unrecognised OPTIMADE field(s) in requested `response_fields`: { bad_optimade_fields } .\" ) if results : results = self . resource_mapper . deserialize ( results ) return ( results , data_returned , more_data_available , exclude_fields , include_fields , ) get_attribute_fields () \u00b6 Get the set of attribute fields Return only the first-level attribute fields from the schema of the resource class, resolving references along the way if needed. Note It is not needed to take care of other special OpenAPI schema keys than allOf , since only allOf will be found in this context. Other special keys can be found in the Swagger documentation . Returns: Type Description Set [ str ] Property names. Source code in optimade/server/entry_collections/entry_collections.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def get_attribute_fields ( self ) -> Set [ str ]: \"\"\"Get the set of attribute fields Return only the _first-level_ attribute fields from the schema of the resource class, resolving references along the way if needed. Note: It is not needed to take care of other special OpenAPI schema keys than `allOf`, since only `allOf` will be found in this context. Other special keys can be found in [the Swagger documentation](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/). Returns: Property names. \"\"\" schema = self . resource_cls . schema () attributes = schema [ \"properties\" ][ \"attributes\" ] if \"allOf\" in attributes : allOf = attributes . pop ( \"allOf\" ) for dict_ in allOf : attributes . update ( dict_ ) if \"$ref\" in attributes : path = attributes [ \"$ref\" ] . split ( \"/\" )[ 1 :] attributes = schema . copy () while path : next_key = path . pop ( 0 ) attributes = attributes [ next_key ] return set ( attributes [ \"properties\" ] . keys ()) handle_query_params ( params ) \u00b6 Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by the specific backend. Note Currently this method returns the pymongo interpretation of the parameters, which will need modification for modified for other backends. Parameters: Name Type Description Default params Union [ EntryListingQueryParams , SingleEntryQueryParams ] The initialized query parameter model from the server. required Raises: Type Description Forbidden If too large of a page limit is provided. BadRequest If an invalid request is made, e.g., with incorrect fields or response format. Returns: Type Description Dict [ str , Any ] A dictionary representation of the query parameters. Source code in optimade/server/entry_collections/entry_collections.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by the specific backend. Note: Currently this method returns the pymongo interpretation of the parameters, which will need modification for modified for other backends. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" cursor_kwargs = {} # filter if getattr ( params , \"filter\" , False ): cursor_kwargs [ \"filter\" ] = self . transformer . transform ( self . parser . parse ( params . filter ) ) else : cursor_kwargs [ \"filter\" ] = {} # response_format if ( getattr ( params , \"response_format\" , False ) and params . response_format != \"json\" ): raise BadRequest ( detail = f \"Response format { params . response_format } is not supported, please use response_format='json'\" ) # page_limit if getattr ( params , \"page_limit\" , False ): limit = params . page_limit if limit > CONFIG . page_limit_max : raise Forbidden ( detail = f \"Max allowed page_limit is { CONFIG . page_limit_max } , you requested { limit } \" , ) cursor_kwargs [ \"limit\" ] = limit else : cursor_kwargs [ \"limit\" ] = CONFIG . page_limit # response_fields cursor_kwargs [ \"projection\" ] = { f \" { self . resource_mapper . get_backend_field ( f ) } \" : True for f in self . all_fields } if getattr ( params , \"response_fields\" , False ): response_fields = set ( params . response_fields . split ( \",\" )) response_fields |= self . resource_mapper . get_required_fields () else : response_fields = self . all_fields . copy () cursor_kwargs [ \"fields\" ] = response_fields # sort if getattr ( params , \"sort\" , False ): cursor_kwargs [ \"sort\" ] = self . parse_sort_params ( params . sort ) # page_offset and page_number if getattr ( params , \"page_offset\" , False ): if getattr ( params , \"page_number\" , False ): warnings . warn ( message = \"Only one of the query parameters 'page_number' and 'page_offset' should be set - 'page_number' will be ignored.\" , category = QueryParamNotUsed , ) cursor_kwargs [ \"skip\" ] = params . page_offset elif getattr ( params , \"page_number\" , False ): if isinstance ( params . page_number , int ): cursor_kwargs [ \"skip\" ] = ( params . page_number - 1 ) * cursor_kwargs [ \"limit\" ] return cursor_kwargs insert ( data ) abstractmethod \u00b6 Add the given entries to the underlying database. Parameters: Name Type Description Default data List [ EntryResource ] The entry resource objects to add to the database. required Source code in optimade/server/entry_collections/entry_collections.py 101 102 103 104 105 106 107 108 @abstractmethod def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Arguments: data: The entry resource objects to add to the database. \"\"\" parse_sort_params ( sort_params ) \u00b6 Handles any sort parameters passed to the collection, resolving aliases and dealing with any invalid fields. Raises: Type Description BadRequest if an invalid sort is requested. Returns: Type Description Tuple A tuple of tuples containing the aliased field name and str , int sort direction encoded as 1 (ascending) or -1 (descending). Source code in optimade/server/entry_collections/entry_collections.py 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 def parse_sort_params ( self , sort_params : str ) -> Tuple [ Tuple [ str , int ]]: \"\"\"Handles any sort parameters passed to the collection, resolving aliases and dealing with any invalid fields. Raises: BadRequest: if an invalid sort is requested. Returns: A tuple of tuples containing the aliased field name and sort direction encoded as 1 (ascending) or -1 (descending). \"\"\" sort_spec = [] for field in sort_params . split ( \",\" ): sort_dir = 1 if field . startswith ( \"-\" ): field = field [ 1 :] sort_dir = - 1 aliased_field = self . resource_mapper . get_backend_field ( field ) sort_spec . append (( aliased_field , sort_dir )) unknown_fields = [ field for field , _ in sort_spec if self . resource_mapper . get_optimade_field ( field ) not in self . all_fields ] if unknown_fields : error_detail = \"Unable to sort on unknown field {} ' {} '\" . format ( \"s\" if len ( unknown_fields ) > 1 else \"\" , \"', '\" . join ( unknown_fields ), ) # If all unknown fields are \"other\" provider-specific, then only provide a warning if all ( ( re . match ( r \"_[a-z_0-9]+_[a-z_0-9]*\" , field ) and not field . startswith ( f \"_ { self . provider_prefix } _\" ) ) for field in unknown_fields ): warnings . warn ( error_detail , FieldValueNotRecognized ) # Otherwise, if all fields are unknown, or some fields are unknown and do not # have other provider prefixes, then return 400: Bad Request else : raise BadRequest ( detail = error_detail ) # If at least one valid field has been provided for sorting, then use that sort_spec = tuple ( ( field , sort_dir ) for field , sort_dir in sort_spec if field not in unknown_fields ) return sort_spec create_collection ( name , resource_cls , resource_mapper ) \u00b6 Create an EntryCollection of the configured type, depending on the value of CONFIG.database_backend . Parameters: Name Type Description Default name str The collection name. required resource_cls EntryResource The type of entry resource to be stored within the collection. required resource_mapper BaseResourceMapper The associated resource mapper for that entry resource type. required Returns: Type Description EntryCollection The created EntryCollection . Source code in optimade/server/entry_collections/entry_collections.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def create_collection ( name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper ) -> \"EntryCollection\" : \"\"\"Create an `EntryCollection` of the configured type, depending on the value of `CONFIG.database_backend`. Arguments: name: The collection name. resource_cls: The type of entry resource to be stored within the collection. resource_mapper: The associated resource mapper for that entry resource type. Returns: The created `EntryCollection`. \"\"\" if CONFIG . database_backend in ( SupportedBackend . MONGODB , SupportedBackend . MONGOMOCK , ): from optimade.server.entry_collections.mongo import MongoCollection return MongoCollection ( name = name , resource_cls = resource_cls , resource_mapper = resource_mapper , ) if CONFIG . database_backend is SupportedBackend . ELASTIC : from optimade.server.entry_collections.elasticsearch import ElasticCollection return ElasticCollection ( name = name , resource_cls = resource_cls , resource_mapper = resource_mapper , ) raise NotImplementedError ( f \"The database backend { CONFIG . database_backend !r} is not implemented\" )","title":"entry_collections"},{"location":"api_reference/server/entry_collections/entry_collections/#entry_collections","text":"","title":"entry_collections"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection","text":"Backend-agnostic base class for querying collections of EntryResource s. Source code in optimade/server/entry_collections/entry_collections.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 class EntryCollection ( ABC ): \"\"\"Backend-agnostic base class for querying collections of [`EntryResource`][optimade.models.entries.EntryResource]s.\"\"\" def __init__ ( self , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , transformer : Transformer , ): \"\"\"Initialize the collection for the given parameters. Parameters: resource_cls (EntryResource): The `EntryResource` model that is stored by the collection. resource_mapper (BaseResourceMapper): A resource mapper object that handles aliases and format changes between deserialization and response. transformer (Transformer): The Lark `Transformer` used to interpret the filter. \"\"\" self . parser = LarkParser () self . resource_cls = resource_cls self . resource_mapper = resource_mapper self . transformer = transformer self . provider_prefix = CONFIG . provider . prefix self . provider_fields = [ field if isinstance ( field , str ) else field [ \"name\" ] for field in CONFIG . provider_fields . get ( resource_mapper . ENDPOINT , []) ] self . _all_fields : Set [ str ] = None @abstractmethod def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" @abstractmethod def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Arguments: data: The entry resource objects to add to the database. \"\"\" @abstractmethod def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. \"\"\" def find ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Tuple [ Union [ List [ EntryResource ], EntryResource , None ], int , bool , Set [ str ], Set [ str ] ]: \"\"\" Fetches results and indicates if more data is available. Also gives the total number of data available in the absence of `page_limit`. See [`EntryListingQueryParams`][optimade.server.query_params.EntryListingQueryParams] for more information. Parameters: params: Entry listing URL query params. Returns: A tuple of various relevant values: (`results`, `data_returned`, `more_data_available`, `exclude_fields`, `include_fields`). \"\"\" criteria = self . handle_query_params ( params ) single_entry = isinstance ( params , SingleEntryQueryParams ) response_fields = criteria . pop ( \"fields\" ) results , data_returned , more_data_available = self . _run_db_query ( criteria , single_entry ) if single_entry : results = results [ 0 ] if results else None if data_returned > 1 : raise NotFound ( detail = f \"Instead of a single entry, { data_returned } entries were found\" , ) exclude_fields = self . all_fields - response_fields include_fields = ( response_fields - self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS ) bad_optimade_fields = set () bad_provider_fields = set () supported_prefixes = self . resource_mapper . SUPPORTED_PREFIXES all_attributes = self . resource_mapper . ALL_ATTRIBUTES for field in include_fields : if field not in all_attributes : if field . startswith ( \"_\" ): if any ( field . startswith ( f \"_ { prefix } _\" ) for prefix in supported_prefixes ): bad_provider_fields . add ( field ) else : bad_optimade_fields . add ( field ) if bad_provider_fields : warnings . warn ( message = f \"Unrecognised field(s) for this provider requested in `response_fields`: { bad_provider_fields } .\" , category = UnknownProviderProperty , ) if bad_optimade_fields : raise BadRequest ( detail = f \"Unrecognised OPTIMADE field(s) in requested `response_fields`: { bad_optimade_fields } .\" ) if results : results = self . resource_mapper . deserialize ( results ) return ( results , data_returned , more_data_available , exclude_fields , include_fields , ) @abstractmethod def _run_db_query ( self , criteria : Dict [ str , Any ], single_entry : bool = False ) -> Tuple [ List [ Dict [ str , Any ]], int , bool ]: \"\"\"Run the query on the backend and collect the results. Arguments: criteria: A dictionary representation of the query parameters. single_entry: Whether or not the caller is expecting a single entry response. Returns: The list of entries from the database (without any re-mapping), the total number of entries matching the query and a boolean for whether or not there is more data available. \"\"\" @property def all_fields ( self ) -> Set [ str ]: \"\"\"Get the set of all fields handled in this collection, from attribute fields in the schema, provider fields and top-level OPTIMADE fields. The set of all fields are lazily created and then cached. This means the set is created the first time the property is requested and then cached. Returns: All fields handled in this collection. \"\"\" if not self . _all_fields : # All OPTIMADE fields self . _all_fields = ( self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS . copy () ) self . _all_fields |= self . get_attribute_fields () # All provider-specific fields self . _all_fields |= { f \"_ { self . provider_prefix } _ { field_name } \" for field_name in self . provider_fields } return self . _all_fields def get_attribute_fields ( self ) -> Set [ str ]: \"\"\"Get the set of attribute fields Return only the _first-level_ attribute fields from the schema of the resource class, resolving references along the way if needed. Note: It is not needed to take care of other special OpenAPI schema keys than `allOf`, since only `allOf` will be found in this context. Other special keys can be found in [the Swagger documentation](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/). Returns: Property names. \"\"\" schema = self . resource_cls . schema () attributes = schema [ \"properties\" ][ \"attributes\" ] if \"allOf\" in attributes : allOf = attributes . pop ( \"allOf\" ) for dict_ in allOf : attributes . update ( dict_ ) if \"$ref\" in attributes : path = attributes [ \"$ref\" ] . split ( \"/\" )[ 1 :] attributes = schema . copy () while path : next_key = path . pop ( 0 ) attributes = attributes [ next_key ] return set ( attributes [ \"properties\" ] . keys ()) def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by the specific backend. Note: Currently this method returns the pymongo interpretation of the parameters, which will need modification for modified for other backends. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" cursor_kwargs = {} # filter if getattr ( params , \"filter\" , False ): cursor_kwargs [ \"filter\" ] = self . transformer . transform ( self . parser . parse ( params . filter ) ) else : cursor_kwargs [ \"filter\" ] = {} # response_format if ( getattr ( params , \"response_format\" , False ) and params . response_format != \"json\" ): raise BadRequest ( detail = f \"Response format { params . response_format } is not supported, please use response_format='json'\" ) # page_limit if getattr ( params , \"page_limit\" , False ): limit = params . page_limit if limit > CONFIG . page_limit_max : raise Forbidden ( detail = f \"Max allowed page_limit is { CONFIG . page_limit_max } , you requested { limit } \" , ) cursor_kwargs [ \"limit\" ] = limit else : cursor_kwargs [ \"limit\" ] = CONFIG . page_limit # response_fields cursor_kwargs [ \"projection\" ] = { f \" { self . resource_mapper . get_backend_field ( f ) } \" : True for f in self . all_fields } if getattr ( params , \"response_fields\" , False ): response_fields = set ( params . response_fields . split ( \",\" )) response_fields |= self . resource_mapper . get_required_fields () else : response_fields = self . all_fields . copy () cursor_kwargs [ \"fields\" ] = response_fields # sort if getattr ( params , \"sort\" , False ): cursor_kwargs [ \"sort\" ] = self . parse_sort_params ( params . sort ) # page_offset and page_number if getattr ( params , \"page_offset\" , False ): if getattr ( params , \"page_number\" , False ): warnings . warn ( message = \"Only one of the query parameters 'page_number' and 'page_offset' should be set - 'page_number' will be ignored.\" , category = QueryParamNotUsed , ) cursor_kwargs [ \"skip\" ] = params . page_offset elif getattr ( params , \"page_number\" , False ): if isinstance ( params . page_number , int ): cursor_kwargs [ \"skip\" ] = ( params . page_number - 1 ) * cursor_kwargs [ \"limit\" ] return cursor_kwargs def parse_sort_params ( self , sort_params : str ) -> Tuple [ Tuple [ str , int ]]: \"\"\"Handles any sort parameters passed to the collection, resolving aliases and dealing with any invalid fields. Raises: BadRequest: if an invalid sort is requested. Returns: A tuple of tuples containing the aliased field name and sort direction encoded as 1 (ascending) or -1 (descending). \"\"\" sort_spec = [] for field in sort_params . split ( \",\" ): sort_dir = 1 if field . startswith ( \"-\" ): field = field [ 1 :] sort_dir = - 1 aliased_field = self . resource_mapper . get_backend_field ( field ) sort_spec . append (( aliased_field , sort_dir )) unknown_fields = [ field for field , _ in sort_spec if self . resource_mapper . get_optimade_field ( field ) not in self . all_fields ] if unknown_fields : error_detail = \"Unable to sort on unknown field {} ' {} '\" . format ( \"s\" if len ( unknown_fields ) > 1 else \"\" , \"', '\" . join ( unknown_fields ), ) # If all unknown fields are \"other\" provider-specific, then only provide a warning if all ( ( re . match ( r \"_[a-z_0-9]+_[a-z_0-9]*\" , field ) and not field . startswith ( f \"_ { self . provider_prefix } _\" ) ) for field in unknown_fields ): warnings . warn ( error_detail , FieldValueNotRecognized ) # Otherwise, if all fields are unknown, or some fields are unknown and do not # have other provider prefixes, then return 400: Bad Request else : raise BadRequest ( detail = error_detail ) # If at least one valid field has been provided for sorting, then use that sort_spec = tuple ( ( field , sort_dir ) for field , sort_dir in sort_spec if field not in unknown_fields ) return sort_spec","title":"EntryCollection"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.__init__","text":"Initialize the collection for the given parameters. Parameters: Name Type Description Default resource_cls EntryResource The EntryResource model that is stored by the collection. required resource_mapper BaseResourceMapper A resource mapper object that handles aliases and format changes between deserialization and response. required transformer Transformer The Lark Transformer used to interpret the filter. required Source code in optimade/server/entry_collections/entry_collections.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , transformer : Transformer , ): \"\"\"Initialize the collection for the given parameters. Parameters: resource_cls (EntryResource): The `EntryResource` model that is stored by the collection. resource_mapper (BaseResourceMapper): A resource mapper object that handles aliases and format changes between deserialization and response. transformer (Transformer): The Lark `Transformer` used to interpret the filter. \"\"\" self . parser = LarkParser () self . resource_cls = resource_cls self . resource_mapper = resource_mapper self . transformer = transformer self . provider_prefix = CONFIG . provider . prefix self . provider_fields = [ field if isinstance ( field , str ) else field [ \"name\" ] for field in CONFIG . provider_fields . get ( resource_mapper . ENDPOINT , []) ] self . _all_fields : Set [ str ] = None","title":"__init__()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.__len__","text":"Returns the total number of entries in the collection. Source code in optimade/server/entry_collections/entry_collections.py 97 98 99 @abstractmethod def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\"","title":"__len__()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.all_fields","text":"Get the set of all fields handled in this collection, from attribute fields in the schema, provider fields and top-level OPTIMADE fields. The set of all fields are lazily created and then cached. This means the set is created the first time the property is requested and then cached. Returns: Type Description Set [ str ] All fields handled in this collection. Source code in optimade/server/entry_collections/entry_collections.py 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 @property def all_fields ( self ) -> Set [ str ]: \"\"\"Get the set of all fields handled in this collection, from attribute fields in the schema, provider fields and top-level OPTIMADE fields. The set of all fields are lazily created and then cached. This means the set is created the first time the property is requested and then cached. Returns: All fields handled in this collection. \"\"\" if not self . _all_fields : # All OPTIMADE fields self . _all_fields = ( self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS . copy () ) self . _all_fields |= self . get_attribute_fields () # All provider-specific fields self . _all_fields |= { f \"_ { self . provider_prefix } _ { field_name } \" for field_name in self . provider_fields } return self . _all_fields","title":"all_fields()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.count","text":"Returns the number of entries matching the query specified by the keyword arguments. Parameters: Name Type Description Default **kwargs Any Query parameters as keyword arguments. {} Source code in optimade/server/entry_collections/entry_collections.py 110 111 112 113 114 115 116 117 118 @abstractmethod def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. \"\"\"","title":"count()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.find","text":"Fetches results and indicates if more data is available. Also gives the total number of data available in the absence of page_limit . See EntryListingQueryParams for more information. Parameters: Name Type Description Default params Union [ EntryListingQueryParams , SingleEntryQueryParams ] Entry listing URL query params. required Returns: Type Description Union [ List [ EntryResource ], EntryResource , None] A tuple of various relevant values: int ( results , data_returned , more_data_available , exclude_fields , include_fields ). Source code in optimade/server/entry_collections/entry_collections.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def find ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Tuple [ Union [ List [ EntryResource ], EntryResource , None ], int , bool , Set [ str ], Set [ str ] ]: \"\"\" Fetches results and indicates if more data is available. Also gives the total number of data available in the absence of `page_limit`. See [`EntryListingQueryParams`][optimade.server.query_params.EntryListingQueryParams] for more information. Parameters: params: Entry listing URL query params. Returns: A tuple of various relevant values: (`results`, `data_returned`, `more_data_available`, `exclude_fields`, `include_fields`). \"\"\" criteria = self . handle_query_params ( params ) single_entry = isinstance ( params , SingleEntryQueryParams ) response_fields = criteria . pop ( \"fields\" ) results , data_returned , more_data_available = self . _run_db_query ( criteria , single_entry ) if single_entry : results = results [ 0 ] if results else None if data_returned > 1 : raise NotFound ( detail = f \"Instead of a single entry, { data_returned } entries were found\" , ) exclude_fields = self . all_fields - response_fields include_fields = ( response_fields - self . resource_mapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS ) bad_optimade_fields = set () bad_provider_fields = set () supported_prefixes = self . resource_mapper . SUPPORTED_PREFIXES all_attributes = self . resource_mapper . ALL_ATTRIBUTES for field in include_fields : if field not in all_attributes : if field . startswith ( \"_\" ): if any ( field . startswith ( f \"_ { prefix } _\" ) for prefix in supported_prefixes ): bad_provider_fields . add ( field ) else : bad_optimade_fields . add ( field ) if bad_provider_fields : warnings . warn ( message = f \"Unrecognised field(s) for this provider requested in `response_fields`: { bad_provider_fields } .\" , category = UnknownProviderProperty , ) if bad_optimade_fields : raise BadRequest ( detail = f \"Unrecognised OPTIMADE field(s) in requested `response_fields`: { bad_optimade_fields } .\" ) if results : results = self . resource_mapper . deserialize ( results ) return ( results , data_returned , more_data_available , exclude_fields , include_fields , )","title":"find()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.get_attribute_fields","text":"Get the set of attribute fields Return only the first-level attribute fields from the schema of the resource class, resolving references along the way if needed. Note It is not needed to take care of other special OpenAPI schema keys than allOf , since only allOf will be found in this context. Other special keys can be found in the Swagger documentation . Returns: Type Description Set [ str ] Property names. Source code in optimade/server/entry_collections/entry_collections.py 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 def get_attribute_fields ( self ) -> Set [ str ]: \"\"\"Get the set of attribute fields Return only the _first-level_ attribute fields from the schema of the resource class, resolving references along the way if needed. Note: It is not needed to take care of other special OpenAPI schema keys than `allOf`, since only `allOf` will be found in this context. Other special keys can be found in [the Swagger documentation](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/). Returns: Property names. \"\"\" schema = self . resource_cls . schema () attributes = schema [ \"properties\" ][ \"attributes\" ] if \"allOf\" in attributes : allOf = attributes . pop ( \"allOf\" ) for dict_ in allOf : attributes . update ( dict_ ) if \"$ref\" in attributes : path = attributes [ \"$ref\" ] . split ( \"/\" )[ 1 :] attributes = schema . copy () while path : next_key = path . pop ( 0 ) attributes = attributes [ next_key ] return set ( attributes [ \"properties\" ] . keys ())","title":"get_attribute_fields()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.handle_query_params","text":"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by the specific backend. Note Currently this method returns the pymongo interpretation of the parameters, which will need modification for modified for other backends. Parameters: Name Type Description Default params Union [ EntryListingQueryParams , SingleEntryQueryParams ] The initialized query parameter model from the server. required Raises: Type Description Forbidden If too large of a page limit is provided. BadRequest If an invalid request is made, e.g., with incorrect fields or response format. Returns: Type Description Dict [ str , Any ] A dictionary representation of the query parameters. Source code in optimade/server/entry_collections/entry_collections.py 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by the specific backend. Note: Currently this method returns the pymongo interpretation of the parameters, which will need modification for modified for other backends. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" cursor_kwargs = {} # filter if getattr ( params , \"filter\" , False ): cursor_kwargs [ \"filter\" ] = self . transformer . transform ( self . parser . parse ( params . filter ) ) else : cursor_kwargs [ \"filter\" ] = {} # response_format if ( getattr ( params , \"response_format\" , False ) and params . response_format != \"json\" ): raise BadRequest ( detail = f \"Response format { params . response_format } is not supported, please use response_format='json'\" ) # page_limit if getattr ( params , \"page_limit\" , False ): limit = params . page_limit if limit > CONFIG . page_limit_max : raise Forbidden ( detail = f \"Max allowed page_limit is { CONFIG . page_limit_max } , you requested { limit } \" , ) cursor_kwargs [ \"limit\" ] = limit else : cursor_kwargs [ \"limit\" ] = CONFIG . page_limit # response_fields cursor_kwargs [ \"projection\" ] = { f \" { self . resource_mapper . get_backend_field ( f ) } \" : True for f in self . all_fields } if getattr ( params , \"response_fields\" , False ): response_fields = set ( params . response_fields . split ( \",\" )) response_fields |= self . resource_mapper . get_required_fields () else : response_fields = self . all_fields . copy () cursor_kwargs [ \"fields\" ] = response_fields # sort if getattr ( params , \"sort\" , False ): cursor_kwargs [ \"sort\" ] = self . parse_sort_params ( params . sort ) # page_offset and page_number if getattr ( params , \"page_offset\" , False ): if getattr ( params , \"page_number\" , False ): warnings . warn ( message = \"Only one of the query parameters 'page_number' and 'page_offset' should be set - 'page_number' will be ignored.\" , category = QueryParamNotUsed , ) cursor_kwargs [ \"skip\" ] = params . page_offset elif getattr ( params , \"page_number\" , False ): if isinstance ( params . page_number , int ): cursor_kwargs [ \"skip\" ] = ( params . page_number - 1 ) * cursor_kwargs [ \"limit\" ] return cursor_kwargs","title":"handle_query_params()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.insert","text":"Add the given entries to the underlying database. Parameters: Name Type Description Default data List [ EntryResource ] The entry resource objects to add to the database. required Source code in optimade/server/entry_collections/entry_collections.py 101 102 103 104 105 106 107 108 @abstractmethod def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Arguments: data: The entry resource objects to add to the database. \"\"\"","title":"insert()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.EntryCollection.parse_sort_params","text":"Handles any sort parameters passed to the collection, resolving aliases and dealing with any invalid fields. Raises: Type Description BadRequest if an invalid sort is requested. Returns: Type Description Tuple A tuple of tuples containing the aliased field name and str , int sort direction encoded as 1 (ascending) or -1 (descending). Source code in optimade/server/entry_collections/entry_collections.py 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 def parse_sort_params ( self , sort_params : str ) -> Tuple [ Tuple [ str , int ]]: \"\"\"Handles any sort parameters passed to the collection, resolving aliases and dealing with any invalid fields. Raises: BadRequest: if an invalid sort is requested. Returns: A tuple of tuples containing the aliased field name and sort direction encoded as 1 (ascending) or -1 (descending). \"\"\" sort_spec = [] for field in sort_params . split ( \",\" ): sort_dir = 1 if field . startswith ( \"-\" ): field = field [ 1 :] sort_dir = - 1 aliased_field = self . resource_mapper . get_backend_field ( field ) sort_spec . append (( aliased_field , sort_dir )) unknown_fields = [ field for field , _ in sort_spec if self . resource_mapper . get_optimade_field ( field ) not in self . all_fields ] if unknown_fields : error_detail = \"Unable to sort on unknown field {} ' {} '\" . format ( \"s\" if len ( unknown_fields ) > 1 else \"\" , \"', '\" . join ( unknown_fields ), ) # If all unknown fields are \"other\" provider-specific, then only provide a warning if all ( ( re . match ( r \"_[a-z_0-9]+_[a-z_0-9]*\" , field ) and not field . startswith ( f \"_ { self . provider_prefix } _\" ) ) for field in unknown_fields ): warnings . warn ( error_detail , FieldValueNotRecognized ) # Otherwise, if all fields are unknown, or some fields are unknown and do not # have other provider prefixes, then return 400: Bad Request else : raise BadRequest ( detail = error_detail ) # If at least one valid field has been provided for sorting, then use that sort_spec = tuple ( ( field , sort_dir ) for field , sort_dir in sort_spec if field not in unknown_fields ) return sort_spec","title":"parse_sort_params()"},{"location":"api_reference/server/entry_collections/entry_collections/#optimade.server.entry_collections.entry_collections.create_collection","text":"Create an EntryCollection of the configured type, depending on the value of CONFIG.database_backend . Parameters: Name Type Description Default name str The collection name. required resource_cls EntryResource The type of entry resource to be stored within the collection. required resource_mapper BaseResourceMapper The associated resource mapper for that entry resource type. required Returns: Type Description EntryCollection The created EntryCollection . Source code in optimade/server/entry_collections/entry_collections.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 def create_collection ( name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper ) -> \"EntryCollection\" : \"\"\"Create an `EntryCollection` of the configured type, depending on the value of `CONFIG.database_backend`. Arguments: name: The collection name. resource_cls: The type of entry resource to be stored within the collection. resource_mapper: The associated resource mapper for that entry resource type. Returns: The created `EntryCollection`. \"\"\" if CONFIG . database_backend in ( SupportedBackend . MONGODB , SupportedBackend . MONGOMOCK , ): from optimade.server.entry_collections.mongo import MongoCollection return MongoCollection ( name = name , resource_cls = resource_cls , resource_mapper = resource_mapper , ) if CONFIG . database_backend is SupportedBackend . ELASTIC : from optimade.server.entry_collections.elasticsearch import ElasticCollection return ElasticCollection ( name = name , resource_cls = resource_cls , resource_mapper = resource_mapper , ) raise NotImplementedError ( f \"The database backend { CONFIG . database_backend !r} is not implemented\" )","title":"create_collection()"},{"location":"api_reference/server/entry_collections/mongo/","text":"mongo \u00b6 MongoCollection \u00b6 Class for querying MongoDB collections (implemented by either pymongo or mongomock) containing serialized EntryResource s objects. Source code in optimade/server/entry_collections/mongo.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class MongoCollection ( EntryCollection ): \"\"\"Class for querying MongoDB collections (implemented by either pymongo or mongomock) containing serialized [`EntryResource`][optimade.models.entries.EntryResource]s objects. \"\"\" def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , database : str = CONFIG . mongo_database , ): \"\"\"Initialize the MongoCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. database: The name of the underlying MongoDB database to connect to. \"\"\" super () . __init__ ( resource_cls , resource_mapper , MongoTransformer ( mapper = resource_mapper ), ) self . parser = LarkParser ( version = ( 1 , 0 , 0 ), variant = \"default\" ) self . collection = CLIENT [ database ][ name ] # check aliases do not clash with mongo operators self . _check_aliases ( self . resource_mapper . all_aliases ()) self . _check_aliases ( self . resource_mapper . all_length_aliases ()) def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" return self . collection . estimated_document_count () def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. The keys 'filter', 'skip', 'limit', 'hint' and 'maxTimeMS' will be passed to the `pymongo.collection.Collection.count_documents` method. \"\"\" for k in list ( kwargs . keys ()): if k not in ( \"filter\" , \"skip\" , \"limit\" , \"hint\" , \"maxTimeMS\" ): del kwargs [ k ] if \"filter\" not in kwargs : # \"filter\" is needed for count_documents() kwargs [ \"filter\" ] = {} return self . collection . count_documents ( ** kwargs ) def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" self . collection . insert_many ( data ) def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by MongoDB. This Mongo-specific method calls the base `EntryCollection.handle_query_params` method and adds additional handling of the MongoDB ObjectID type. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" criteria = super () . handle_query_params ( params ) # Handle MongoDB ObjectIDs: # - If they were not requested, then explicitly remove them # - If they were requested, then cast them to strings in the response if \"_id\" not in criteria . get ( \"projection\" , {}): criteria [ \"projection\" ][ \"_id\" ] = False if criteria . get ( \"projection\" , {}) . get ( \"_id\" ): criteria [ \"projection\" ][ \"_id\" ] = { \"$toString\" : \"$_id\" } return criteria def _run_db_query ( self , criteria : Dict [ str , Any ], single_entry : bool = False ) -> Tuple [ List [ Dict [ str , Any ]], int , bool ]: \"\"\"Run the query on the backend and collect the results. Arguments: criteria: A dictionary representation of the query parameters. single_entry: Whether or not the caller is expecting a single entry response. Returns: The list of entries from the database (without any re-mapping), the total number of entries matching the query and a boolean for whether or not there is more data available. \"\"\" results = list ( self . collection . find ( ** criteria )) if CONFIG . database_backend == SupportedBackend . MONGOMOCK and criteria . get ( \"projection\" , {} ) . get ( \"_id\" ): # mongomock does not support `$toString`` in projection, so we have to do it manually for ind , doc in enumerate ( results ): results [ ind ][ \"_id\" ] = str ( doc [ \"_id\" ]) nresults_now = len ( results ) if not single_entry : criteria_nolimit = criteria . copy () criteria_nolimit . pop ( \"limit\" , None ) skip = criteria_nolimit . pop ( \"skip\" , 0 ) data_returned = self . count ( ** criteria_nolimit ) more_data_available = nresults_now + skip < data_returned else : # SingleEntryQueryParams, e.g., /structures/{entry_id} data_returned = nresults_now more_data_available = False return results , data_returned , more_data_available def _check_aliases ( self , aliases ): \"\"\"Check that aliases do not clash with mongo keywords.\"\"\" if any ( alias [ 0 ] . startswith ( \"$\" ) or alias [ 1 ] . startswith ( \"$\" ) for alias in aliases ): raise RuntimeError ( f \"Cannot define an alias starting with a '$': { aliases } \" ) __init__ ( name , resource_cls , resource_mapper , database = CONFIG . mongo_database ) \u00b6 Initialize the MongoCollection for the given parameters. Parameters: Name Type Description Default name str The name of the collection. required resource_cls EntryResource The type of entry resource that is stored by the collection. required resource_mapper BaseResourceMapper A resource mapper object that handles aliases and format changes between deserialization and response. required database str The name of the underlying MongoDB database to connect to. CONFIG.mongo_database Source code in optimade/server/entry_collections/mongo.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , database : str = CONFIG . mongo_database , ): \"\"\"Initialize the MongoCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. database: The name of the underlying MongoDB database to connect to. \"\"\" super () . __init__ ( resource_cls , resource_mapper , MongoTransformer ( mapper = resource_mapper ), ) self . parser = LarkParser ( version = ( 1 , 0 , 0 ), variant = \"default\" ) self . collection = CLIENT [ database ][ name ] # check aliases do not clash with mongo operators self . _check_aliases ( self . resource_mapper . all_aliases ()) self . _check_aliases ( self . resource_mapper . all_length_aliases ()) __len__ () \u00b6 Returns the total number of entries in the collection. Source code in optimade/server/entry_collections/mongo.py 69 70 71 def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" return self . collection . estimated_document_count () count ( ** kwargs ) \u00b6 Returns the number of entries matching the query specified by the keyword arguments. Parameters: Name Type Description Default **kwargs Any Query parameters as keyword arguments. The keys 'filter', 'skip', 'limit', 'hint' and 'maxTimeMS' will be passed to the pymongo.collection.Collection.count_documents method. {} Source code in optimade/server/entry_collections/mongo.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. The keys 'filter', 'skip', 'limit', 'hint' and 'maxTimeMS' will be passed to the `pymongo.collection.Collection.count_documents` method. \"\"\" for k in list ( kwargs . keys ()): if k not in ( \"filter\" , \"skip\" , \"limit\" , \"hint\" , \"maxTimeMS\" ): del kwargs [ k ] if \"filter\" not in kwargs : # \"filter\" is needed for count_documents() kwargs [ \"filter\" ] = {} return self . collection . count_documents ( ** kwargs ) handle_query_params ( params ) \u00b6 Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by MongoDB. This Mongo-specific method calls the base EntryCollection.handle_query_params method and adds additional handling of the MongoDB ObjectID type. Parameters: Name Type Description Default params Union [ EntryListingQueryParams , SingleEntryQueryParams ] The initialized query parameter model from the server. required Raises: Type Description Forbidden If too large of a page limit is provided. BadRequest If an invalid request is made, e.g., with incorrect fields or response format. Returns: Type Description Dict [ str , Any ] A dictionary representation of the query parameters. Source code in optimade/server/entry_collections/mongo.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by MongoDB. This Mongo-specific method calls the base `EntryCollection.handle_query_params` method and adds additional handling of the MongoDB ObjectID type. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" criteria = super () . handle_query_params ( params ) # Handle MongoDB ObjectIDs: # - If they were not requested, then explicitly remove them # - If they were requested, then cast them to strings in the response if \"_id\" not in criteria . get ( \"projection\" , {}): criteria [ \"projection\" ][ \"_id\" ] = False if criteria . get ( \"projection\" , {}) . get ( \"_id\" ): criteria [ \"projection\" ][ \"_id\" ] = { \"$toString\" : \"$_id\" } return criteria insert ( data ) \u00b6 Add the given entries to the underlying database. Warning No validation is performed on the incoming data. Parameters: Name Type Description Default data List [ EntryResource ] The entry resource objects to add to the database. required Source code in optimade/server/entry_collections/mongo.py 90 91 92 93 94 95 96 97 98 99 100 def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" self . collection . insert_many ( data )","title":"mongo"},{"location":"api_reference/server/entry_collections/mongo/#mongo","text":"","title":"mongo"},{"location":"api_reference/server/entry_collections/mongo/#optimade.server.entry_collections.mongo.MongoCollection","text":"Class for querying MongoDB collections (implemented by either pymongo or mongomock) containing serialized EntryResource s objects. Source code in optimade/server/entry_collections/mongo.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 class MongoCollection ( EntryCollection ): \"\"\"Class for querying MongoDB collections (implemented by either pymongo or mongomock) containing serialized [`EntryResource`][optimade.models.entries.EntryResource]s objects. \"\"\" def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , database : str = CONFIG . mongo_database , ): \"\"\"Initialize the MongoCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. database: The name of the underlying MongoDB database to connect to. \"\"\" super () . __init__ ( resource_cls , resource_mapper , MongoTransformer ( mapper = resource_mapper ), ) self . parser = LarkParser ( version = ( 1 , 0 , 0 ), variant = \"default\" ) self . collection = CLIENT [ database ][ name ] # check aliases do not clash with mongo operators self . _check_aliases ( self . resource_mapper . all_aliases ()) self . _check_aliases ( self . resource_mapper . all_length_aliases ()) def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" return self . collection . estimated_document_count () def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. The keys 'filter', 'skip', 'limit', 'hint' and 'maxTimeMS' will be passed to the `pymongo.collection.Collection.count_documents` method. \"\"\" for k in list ( kwargs . keys ()): if k not in ( \"filter\" , \"skip\" , \"limit\" , \"hint\" , \"maxTimeMS\" ): del kwargs [ k ] if \"filter\" not in kwargs : # \"filter\" is needed for count_documents() kwargs [ \"filter\" ] = {} return self . collection . count_documents ( ** kwargs ) def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" self . collection . insert_many ( data ) def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by MongoDB. This Mongo-specific method calls the base `EntryCollection.handle_query_params` method and adds additional handling of the MongoDB ObjectID type. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" criteria = super () . handle_query_params ( params ) # Handle MongoDB ObjectIDs: # - If they were not requested, then explicitly remove them # - If they were requested, then cast them to strings in the response if \"_id\" not in criteria . get ( \"projection\" , {}): criteria [ \"projection\" ][ \"_id\" ] = False if criteria . get ( \"projection\" , {}) . get ( \"_id\" ): criteria [ \"projection\" ][ \"_id\" ] = { \"$toString\" : \"$_id\" } return criteria def _run_db_query ( self , criteria : Dict [ str , Any ], single_entry : bool = False ) -> Tuple [ List [ Dict [ str , Any ]], int , bool ]: \"\"\"Run the query on the backend and collect the results. Arguments: criteria: A dictionary representation of the query parameters. single_entry: Whether or not the caller is expecting a single entry response. Returns: The list of entries from the database (without any re-mapping), the total number of entries matching the query and a boolean for whether or not there is more data available. \"\"\" results = list ( self . collection . find ( ** criteria )) if CONFIG . database_backend == SupportedBackend . MONGOMOCK and criteria . get ( \"projection\" , {} ) . get ( \"_id\" ): # mongomock does not support `$toString`` in projection, so we have to do it manually for ind , doc in enumerate ( results ): results [ ind ][ \"_id\" ] = str ( doc [ \"_id\" ]) nresults_now = len ( results ) if not single_entry : criteria_nolimit = criteria . copy () criteria_nolimit . pop ( \"limit\" , None ) skip = criteria_nolimit . pop ( \"skip\" , 0 ) data_returned = self . count ( ** criteria_nolimit ) more_data_available = nresults_now + skip < data_returned else : # SingleEntryQueryParams, e.g., /structures/{entry_id} data_returned = nresults_now more_data_available = False return results , data_returned , more_data_available def _check_aliases ( self , aliases ): \"\"\"Check that aliases do not clash with mongo keywords.\"\"\" if any ( alias [ 0 ] . startswith ( \"$\" ) or alias [ 1 ] . startswith ( \"$\" ) for alias in aliases ): raise RuntimeError ( f \"Cannot define an alias starting with a '$': { aliases } \" )","title":"MongoCollection"},{"location":"api_reference/server/entry_collections/mongo/#optimade.server.entry_collections.mongo.MongoCollection.__init__","text":"Initialize the MongoCollection for the given parameters. Parameters: Name Type Description Default name str The name of the collection. required resource_cls EntryResource The type of entry resource that is stored by the collection. required resource_mapper BaseResourceMapper A resource mapper object that handles aliases and format changes between deserialization and response. required database str The name of the underlying MongoDB database to connect to. CONFIG.mongo_database Source code in optimade/server/entry_collections/mongo.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 def __init__ ( self , name : str , resource_cls : EntryResource , resource_mapper : BaseResourceMapper , database : str = CONFIG . mongo_database , ): \"\"\"Initialize the MongoCollection for the given parameters. Parameters: name: The name of the collection. resource_cls: The type of entry resource that is stored by the collection. resource_mapper: A resource mapper object that handles aliases and format changes between deserialization and response. database: The name of the underlying MongoDB database to connect to. \"\"\" super () . __init__ ( resource_cls , resource_mapper , MongoTransformer ( mapper = resource_mapper ), ) self . parser = LarkParser ( version = ( 1 , 0 , 0 ), variant = \"default\" ) self . collection = CLIENT [ database ][ name ] # check aliases do not clash with mongo operators self . _check_aliases ( self . resource_mapper . all_aliases ()) self . _check_aliases ( self . resource_mapper . all_length_aliases ())","title":"__init__()"},{"location":"api_reference/server/entry_collections/mongo/#optimade.server.entry_collections.mongo.MongoCollection.__len__","text":"Returns the total number of entries in the collection. Source code in optimade/server/entry_collections/mongo.py 69 70 71 def __len__ ( self ) -> int : \"\"\"Returns the total number of entries in the collection.\"\"\" return self . collection . estimated_document_count ()","title":"__len__()"},{"location":"api_reference/server/entry_collections/mongo/#optimade.server.entry_collections.mongo.MongoCollection.count","text":"Returns the number of entries matching the query specified by the keyword arguments. Parameters: Name Type Description Default **kwargs Any Query parameters as keyword arguments. The keys 'filter', 'skip', 'limit', 'hint' and 'maxTimeMS' will be passed to the pymongo.collection.Collection.count_documents method. {} Source code in optimade/server/entry_collections/mongo.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def count ( self , ** kwargs : Any ) -> int : \"\"\"Returns the number of entries matching the query specified by the keyword arguments. Parameters: **kwargs: Query parameters as keyword arguments. The keys 'filter', 'skip', 'limit', 'hint' and 'maxTimeMS' will be passed to the `pymongo.collection.Collection.count_documents` method. \"\"\" for k in list ( kwargs . keys ()): if k not in ( \"filter\" , \"skip\" , \"limit\" , \"hint\" , \"maxTimeMS\" ): del kwargs [ k ] if \"filter\" not in kwargs : # \"filter\" is needed for count_documents() kwargs [ \"filter\" ] = {} return self . collection . count_documents ( ** kwargs )","title":"count()"},{"location":"api_reference/server/entry_collections/mongo/#optimade.server.entry_collections.mongo.MongoCollection.handle_query_params","text":"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by MongoDB. This Mongo-specific method calls the base EntryCollection.handle_query_params method and adds additional handling of the MongoDB ObjectID type. Parameters: Name Type Description Default params Union [ EntryListingQueryParams , SingleEntryQueryParams ] The initialized query parameter model from the server. required Raises: Type Description Forbidden If too large of a page limit is provided. BadRequest If an invalid request is made, e.g., with incorrect fields or response format. Returns: Type Description Dict [ str , Any ] A dictionary representation of the query parameters. Source code in optimade/server/entry_collections/mongo.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def handle_query_params ( self , params : Union [ EntryListingQueryParams , SingleEntryQueryParams ] ) -> Dict [ str , Any ]: \"\"\"Parse and interpret the backend-agnostic query parameter models into a dictionary that can be used by MongoDB. This Mongo-specific method calls the base `EntryCollection.handle_query_params` method and adds additional handling of the MongoDB ObjectID type. Parameters: params: The initialized query parameter model from the server. Raises: Forbidden: If too large of a page limit is provided. BadRequest: If an invalid request is made, e.g., with incorrect fields or response format. Returns: A dictionary representation of the query parameters. \"\"\" criteria = super () . handle_query_params ( params ) # Handle MongoDB ObjectIDs: # - If they were not requested, then explicitly remove them # - If they were requested, then cast them to strings in the response if \"_id\" not in criteria . get ( \"projection\" , {}): criteria [ \"projection\" ][ \"_id\" ] = False if criteria . get ( \"projection\" , {}) . get ( \"_id\" ): criteria [ \"projection\" ][ \"_id\" ] = { \"$toString\" : \"$_id\" } return criteria","title":"handle_query_params()"},{"location":"api_reference/server/entry_collections/mongo/#optimade.server.entry_collections.mongo.MongoCollection.insert","text":"Add the given entries to the underlying database. Warning No validation is performed on the incoming data. Parameters: Name Type Description Default data List [ EntryResource ] The entry resource objects to add to the database. required Source code in optimade/server/entry_collections/mongo.py 90 91 92 93 94 95 96 97 98 99 100 def insert ( self , data : List [ EntryResource ]) -> None : \"\"\"Add the given entries to the underlying database. Warning: No validation is performed on the incoming data. Arguments: data: The entry resource objects to add to the database. \"\"\" self . collection . insert_many ( data )","title":"insert()"},{"location":"api_reference/server/mappers/entries/","text":"entries \u00b6 BaseResourceMapper \u00b6 Generic Resource Mapper that defines and performs the mapping between objects in the database and the resource objects defined by the specification. Attributes: Name Type Description ALIASES Tuple [ Tuple [ str , str ]] a tuple of aliases between OPTIMADE field names and the field names in the database , e.g. ((\"elements\", \"custom_elements_field\")) . LENGTH_ALIASES Tuple [ Tuple [ str , str ]] a tuple of aliases between a field name and another field that defines its length, to be used when querying, e.g. ((\"elements\", \"nelements\")) . e.g. ((\"elements\", \"custom_elements_field\")) . ENTRY_RESOURCE_CLASS Type [ EntryResource ] The entry type that this mapper corresponds to. PROVIDER_FIELDS Tuple [ str ] a tuple of extra field names that this mapper should support when querying with the database prefix. TOP_LEVEL_NON_ATTRIBUTES_FIELDS Set [ str ] the set of top-level field names common to all endpoints. SUPPORTED_PREFIXES Set [ str ] The set of prefixes registered by this mapper. ALL_ATTRIBUTES Set [ str ] The set of attributes defined across the entry resource class and the server configuration. ENTRY_RESOURCE_ATTRIBUTES Dict [ str , Any ] A dictionary of attributes and their definitions defined by the schema of the entry resource class. ENDPOINT str The expected endpoint name for this resource, as defined by the type in the schema of the entry resource class. Source code in optimade/server/mappers/entries.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 class BaseResourceMapper : \"\"\" Generic Resource Mapper that defines and performs the mapping between objects in the database and the resource objects defined by the specification. Attributes: ALIASES: a tuple of aliases between OPTIMADE field names and the field names in the database , e.g. `((\"elements\", \"custom_elements_field\"))`. LENGTH_ALIASES: a tuple of aliases between a field name and another field that defines its length, to be used when querying, e.g. `((\"elements\", \"nelements\"))`. e.g. `((\"elements\", \"custom_elements_field\"))`. ENTRY_RESOURCE_CLASS: The entry type that this mapper corresponds to. PROVIDER_FIELDS: a tuple of extra field names that this mapper should support when querying with the database prefix. TOP_LEVEL_NON_ATTRIBUTES_FIELDS: the set of top-level field names common to all endpoints. SUPPORTED_PREFIXES: The set of prefixes registered by this mapper. ALL_ATTRIBUTES: The set of attributes defined across the entry resource class and the server configuration. ENTRY_RESOURCE_ATTRIBUTES: A dictionary of attributes and their definitions defined by the schema of the entry resource class. ENDPOINT: The expected endpoint name for this resource, as defined by the `type` in the schema of the entry resource class. \"\"\" try : from optimade.server.data import ( providers as PROVIDERS , ) # pylint: disable=no-name-in-module except ( ImportError , ModuleNotFoundError ): PROVIDERS = {} KNOWN_PROVIDER_PREFIXES : Set [ str ] = set ( prov [ \"id\" ] for prov in PROVIDERS . get ( \"data\" , []) ) ALIASES : Tuple [ Tuple [ str , str ]] = () LENGTH_ALIASES : Tuple [ Tuple [ str , str ]] = () PROVIDER_FIELDS : Tuple [ str ] = () ENTRY_RESOURCE_CLASS : Type [ EntryResource ] = EntryResource RELATIONSHIP_ENTRY_TYPES : Set [ str ] = { \"references\" , \"structures\" } TOP_LEVEL_NON_ATTRIBUTES_FIELDS : Set [ str ] = { \"id\" , \"type\" , \"relationships\" , \"links\" } SUPPORTED_PREFIXES : Set [ str ] ALL_ATTRIBUTES : Set [ str ] ENTRY_RESOURCE_ATTRIBUTES : Dict [ str , Any ] ENDPOINT : str @classmethod def all_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated aliases for this entry type, including those defined by the server config. The first member of each tuple is the OPTIMADE-compliant field name, the second is the backend-specific field name. Returns: A tuple of alias tuples. \"\"\" from optimade.server.config import CONFIG return ( tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , str ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field [ 'name' ] } \" , field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , dict ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in cls . PROVIDER_FIELDS ) + tuple ( CONFIG . aliases . get ( cls . ENDPOINT , {}) . items ()) + cls . ALIASES ) @classproperty def SUPPORTED_PREFIXES ( cls ) -> Set [ str ]: \"\"\"A set of prefixes handled by this entry type. !!! note This implementation only includes the provider prefix, but in the future this property may be extended to include other namespaces (for serving fields from, e.g., other providers or domain-specific terms). \"\"\" from optimade.server.config import CONFIG return { CONFIG . provider . prefix } @classproperty def ALL_ATTRIBUTES ( cls ) -> Set [ str ]: \"\"\"Returns all attributes served by this entry.\"\"\" from optimade.server.config import CONFIG return ( set ( cls . ENTRY_RESOURCE_ATTRIBUTES ) . union ( cls . get_optimade_field ( field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , str ) ) . union ( cls . get_optimade_field ( field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , dict ) ) . union ( set ( cls . get_optimade_field ( field ) for field in cls . PROVIDER_FIELDS )) ) @classproperty def ENTRY_RESOURCE_ATTRIBUTES ( cls ) -> Dict [ str , Any ]: \"\"\"Returns the dictionary of attributes defined by the underlying entry resource class.\"\"\" from optimade.server.schemas import retrieve_queryable_properties return retrieve_queryable_properties ( cls . ENTRY_RESOURCE_CLASS . schema ()) @classproperty def ENDPOINT ( cls ) -> str : \"\"\"Returns the expected endpoint for this mapper, corresponding to the `type` property of the resource class. \"\"\" return ( cls . ENTRY_RESOURCE_CLASS . schema () . get ( \"properties\" , {}) . get ( \"type\" , {}) . get ( \"default\" , \"\" ) ) @classmethod def all_length_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated length aliases for this class, including those defined by the server config. Returns: A tuple of length alias tuples. \"\"\" from optimade.server.config import CONFIG return cls . LENGTH_ALIASES + tuple ( CONFIG . length_aliases . get ( cls . ENDPOINT , {}) . items () ) @classmethod def length_alias_for ( cls , field : str ) -> Optional [ str ]: \"\"\"Returns the length alias for the particular field, or `None` if no such alias is found. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_length_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_length_aliases]. \"\"\" return dict ( cls . all_length_aliases ()) . get ( field , None ) @classmethod def get_backend_field ( cls , optimade_field : str ) -> str : \"\"\"Return the field name configured for the particular underlying database for the passed OPTIMADE field name, that would be used in an API filter. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. If a dot-separated OPTIMADE field is provided, e.g., `species.mass`, only the first part will be mapped. This means for an (OPTIMADE, DB) alias of (`species`, `kinds`), `get_backend_fields(\"species.mass\")` will return `kinds.mass`. Arguments: optimade_field: The OPTIMADE field to attempt to map to the backend-specific field. Examples: >>> get_backend_field(\"chemical_formula_anonymous\") 'formula_anon' >>> get_backend_field(\"formula_anon\") 'formula_anon' >>> get_backend_field(\"_exmpl_custom_provider_field\") 'custom_provider_field' Returns: The mapped field name to be used in the query to the backend. \"\"\" split = optimade_field . split ( \".\" ) alias = dict ( cls . all_aliases ()) . get ( split [ 0 ], None ) if alias is not None : return alias + ( \".\" + \".\" . join ( split [ 1 :]) if len ( split ) > 1 else \"\" ) return optimade_field @classmethod def alias_for ( cls , field : str ) -> str : \"\"\"Return aliased field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_backend_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_backend_field]. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. \"\"\" warnings . warn ( \"The `.alias_for(...)` method is deprecated, please use `.get_backend_field(...)`.\" , DeprecationWarning , ) return cls . get_backend_field ( field ) @classmethod def get_optimade_field ( cls , backend_field : str ) -> str : \"\"\"Return the corresponding OPTIMADE field name for the underlying database field, ready to be used to construct the OPTIMADE-compliant JSON response. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. Arguments: backend_field: The backend field to attempt to map to an OPTIMADE field. Examples: >>> get_optimade_field(\"chemical_formula_anonymous\") 'chemical_formula_anonymous' >>> get_optimade_field(\"formula_anon\") 'chemical_formula_anonymous' >>> get_optimade_field(\"custom_provider_field\") '_exmpl_custom_provider_field' Returns: The mapped field name to be used in an OPTIMADE-compliant response. \"\"\" return { alias : real for real , alias in cls . all_aliases ()} . get ( backend_field , backend_field ) @classmethod def alias_of ( cls , field : str ) -> str : \"\"\"Return de-aliased field name, if it exists, otherwise return the input field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_optimade_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_optimade_field]. Parameters: field: Field name to be de-aliased. Returns: De-aliased field name, falling back to returning `field`. \"\"\" warnings . warn ( \"The `.alias_of(...)` method is deprecated, please use `.get_optimade_field(...)`.\" , DeprecationWarning , ) return cls . get_optimade_field ( field ) @classmethod def get_required_fields ( cls ) -> set : \"\"\"Get REQUIRED response fields. Returns: REQUIRED response fields. \"\"\" return cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE. Starting from a MongoDB document `doc`, map the DB fields to the corresponding OPTIMADE fields. Then, the fields are all added to the top-level field \"attributes\", with the exception of other top-level fields, defined in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS`. All fields not in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS` + \"attributes\" will be removed. Finally, the `type` is given the value of the specified `cls.ENDPOINT`. Parameters: doc: A resource object in MongoDB format. Returns: A resource object in OPTIMADE format. \"\"\" mapping = (( real , alias ) for alias , real in cls . all_aliases ()) newdoc = {} reals = { real for alias , real in cls . all_aliases ()} for key in doc : if key not in reals : newdoc [ key ] = doc [ key ] for real , alias in mapping : if real in doc : newdoc [ alias ] = doc [ real ] if \"attributes\" in newdoc : raise Exception ( \"Will overwrite doc field!\" ) attributes = newdoc . copy () for field in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : value = attributes . pop ( field , None ) if value is not None : newdoc [ field ] = value for field in list ( newdoc . keys ()): if field not in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : del newdoc [ field ] newdoc [ \"type\" ] = cls . ENDPOINT newdoc [ \"attributes\" ] = attributes return newdoc @classmethod def deserialize ( cls , results : Union [ dict , Iterable [ dict ]] ) -> Union [ List [ EntryResource ], EntryResource ]: if isinstance ( results , dict ): return cls . ENTRY_RESOURCE_CLASS ( ** cls . map_back ( results )) return [ cls . ENTRY_RESOURCE_CLASS ( ** cls . map_back ( doc )) for doc in results ] ALL_ATTRIBUTES () \u00b6 Returns all attributes served by this entry. Source code in optimade/server/mappers/entries.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @classproperty def ALL_ATTRIBUTES ( cls ) -> Set [ str ]: \"\"\"Returns all attributes served by this entry.\"\"\" from optimade.server.config import CONFIG return ( set ( cls . ENTRY_RESOURCE_ATTRIBUTES ) . union ( cls . get_optimade_field ( field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , str ) ) . union ( cls . get_optimade_field ( field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , dict ) ) . union ( set ( cls . get_optimade_field ( field ) for field in cls . PROVIDER_FIELDS )) ) ENDPOINT () \u00b6 Returns the expected endpoint for this mapper, corresponding to the type property of the resource class. Source code in optimade/server/mappers/entries.py 152 153 154 155 156 157 158 159 160 161 162 163 @classproperty def ENDPOINT ( cls ) -> str : \"\"\"Returns the expected endpoint for this mapper, corresponding to the `type` property of the resource class. \"\"\" return ( cls . ENTRY_RESOURCE_CLASS . schema () . get ( \"properties\" , {}) . get ( \"type\" , {}) . get ( \"default\" , \"\" ) ) ENTRY_RESOURCE_ATTRIBUTES () \u00b6 Returns the dictionary of attributes defined by the underlying entry resource class. Source code in optimade/server/mappers/entries.py 145 146 147 148 149 150 @classproperty def ENTRY_RESOURCE_ATTRIBUTES ( cls ) -> Dict [ str , Any ]: \"\"\"Returns the dictionary of attributes defined by the underlying entry resource class.\"\"\" from optimade.server.schemas import retrieve_queryable_properties return retrieve_queryable_properties ( cls . ENTRY_RESOURCE_CLASS . schema ()) SUPPORTED_PREFIXES () \u00b6 A set of prefixes handled by this entry type. Note This implementation only includes the provider prefix, but in the future this property may be extended to include other namespaces (for serving fields from, e.g., other providers or domain-specific terms). Source code in optimade/server/mappers/entries.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 @classproperty def SUPPORTED_PREFIXES ( cls ) -> Set [ str ]: \"\"\"A set of prefixes handled by this entry type. !!! note This implementation only includes the provider prefix, but in the future this property may be extended to include other namespaces (for serving fields from, e.g., other providers or domain-specific terms). \"\"\" from optimade.server.config import CONFIG return { CONFIG . provider . prefix } alias_for ( field ) classmethod \u00b6 Return aliased field name. Deprecated This method is deprecated could be removed without further warning. Please use get_backend_field() . Parameters: Name Type Description Default field str OPTIMADE field name. required Returns: Type Description str Aliased field as found in all_aliases() . Source code in optimade/server/mappers/entries.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 @classmethod def alias_for ( cls , field : str ) -> str : \"\"\"Return aliased field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_backend_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_backend_field]. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. \"\"\" warnings . warn ( \"The `.alias_for(...)` method is deprecated, please use `.get_backend_field(...)`.\" , DeprecationWarning , ) return cls . get_backend_field ( field ) alias_of ( field ) classmethod \u00b6 Return de-aliased field name, if it exists, otherwise return the input field name. Deprecated This method is deprecated could be removed without further warning. Please use get_optimade_field() . Parameters: Name Type Description Default field str Field name to be de-aliased. required Returns: Type Description str De-aliased field name, falling back to returning field . Source code in optimade/server/mappers/entries.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 @classmethod def alias_of ( cls , field : str ) -> str : \"\"\"Return de-aliased field name, if it exists, otherwise return the input field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_optimade_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_optimade_field]. Parameters: field: Field name to be de-aliased. Returns: De-aliased field name, falling back to returning `field`. \"\"\" warnings . warn ( \"The `.alias_of(...)` method is deprecated, please use `.get_optimade_field(...)`.\" , DeprecationWarning , ) return cls . get_optimade_field ( field ) all_aliases () classmethod \u00b6 Returns all of the associated aliases for this entry type, including those defined by the server config. The first member of each tuple is the OPTIMADE-compliant field name, the second is the backend-specific field name. Returns: Type Description Tuple [ Tuple [ str , str ]] A tuple of alias tuples. Source code in optimade/server/mappers/entries.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 @classmethod def all_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated aliases for this entry type, including those defined by the server config. The first member of each tuple is the OPTIMADE-compliant field name, the second is the backend-specific field name. Returns: A tuple of alias tuples. \"\"\" from optimade.server.config import CONFIG return ( tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , str ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field [ 'name' ] } \" , field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , dict ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in cls . PROVIDER_FIELDS ) + tuple ( CONFIG . aliases . get ( cls . ENDPOINT , {}) . items ()) + cls . ALIASES ) all_length_aliases () classmethod \u00b6 Returns all of the associated length aliases for this class, including those defined by the server config. Returns: Type Description Tuple [ Tuple [ str , str ]] A tuple of length alias tuples. Source code in optimade/server/mappers/entries.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 @classmethod def all_length_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated length aliases for this class, including those defined by the server config. Returns: A tuple of length alias tuples. \"\"\" from optimade.server.config import CONFIG return cls . LENGTH_ALIASES + tuple ( CONFIG . length_aliases . get ( cls . ENDPOINT , {}) . items () ) get_backend_field ( optimade_field ) classmethod \u00b6 Return the field name configured for the particular underlying database for the passed OPTIMADE field name, that would be used in an API filter. Aliases are read from all_aliases() . If a dot-separated OPTIMADE field is provided, e.g., species.mass , only the first part will be mapped. This means for an (OPTIMADE, DB) alias of ( species , kinds ), get_backend_fields(\"species.mass\") will return kinds.mass . Parameters: Name Type Description Default optimade_field str The OPTIMADE field to attempt to map to the backend-specific field. required Examples: >>> get_backend_field ( \"chemical_formula_anonymous\" ) 'formula_anon' >>> get_backend_field ( \"formula_anon\" ) 'formula_anon' >>> get_backend_field ( \"_exmpl_custom_provider_field\" ) 'custom_provider_field' Returns: Type Description str The mapped field name to be used in the query to the backend. Source code in optimade/server/mappers/entries.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 @classmethod def get_backend_field ( cls , optimade_field : str ) -> str : \"\"\"Return the field name configured for the particular underlying database for the passed OPTIMADE field name, that would be used in an API filter. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. If a dot-separated OPTIMADE field is provided, e.g., `species.mass`, only the first part will be mapped. This means for an (OPTIMADE, DB) alias of (`species`, `kinds`), `get_backend_fields(\"species.mass\")` will return `kinds.mass`. Arguments: optimade_field: The OPTIMADE field to attempt to map to the backend-specific field. Examples: >>> get_backend_field(\"chemical_formula_anonymous\") 'formula_anon' >>> get_backend_field(\"formula_anon\") 'formula_anon' >>> get_backend_field(\"_exmpl_custom_provider_field\") 'custom_provider_field' Returns: The mapped field name to be used in the query to the backend. \"\"\" split = optimade_field . split ( \".\" ) alias = dict ( cls . all_aliases ()) . get ( split [ 0 ], None ) if alias is not None : return alias + ( \".\" + \".\" . join ( split [ 1 :]) if len ( split ) > 1 else \"\" ) return optimade_field get_optimade_field ( backend_field ) classmethod \u00b6 Return the corresponding OPTIMADE field name for the underlying database field, ready to be used to construct the OPTIMADE-compliant JSON response. Aliases are read from all_aliases() . Parameters: Name Type Description Default backend_field str The backend field to attempt to map to an OPTIMADE field. required Examples: >>> get_optimade_field ( \"chemical_formula_anonymous\" ) 'chemical_formula_anonymous' >>> get_optimade_field ( \"formula_anon\" ) 'chemical_formula_anonymous' >>> get_optimade_field ( \"custom_provider_field\" ) '_exmpl_custom_provider_field' Returns: Type Description str The mapped field name to be used in an OPTIMADE-compliant response. Source code in optimade/server/mappers/entries.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 @classmethod def get_optimade_field ( cls , backend_field : str ) -> str : \"\"\"Return the corresponding OPTIMADE field name for the underlying database field, ready to be used to construct the OPTIMADE-compliant JSON response. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. Arguments: backend_field: The backend field to attempt to map to an OPTIMADE field. Examples: >>> get_optimade_field(\"chemical_formula_anonymous\") 'chemical_formula_anonymous' >>> get_optimade_field(\"formula_anon\") 'chemical_formula_anonymous' >>> get_optimade_field(\"custom_provider_field\") '_exmpl_custom_provider_field' Returns: The mapped field name to be used in an OPTIMADE-compliant response. \"\"\" return { alias : real for real , alias in cls . all_aliases ()} . get ( backend_field , backend_field ) get_required_fields () classmethod \u00b6 Get REQUIRED response fields. Returns: Type Description set REQUIRED response fields. Source code in optimade/server/mappers/entries.py 298 299 300 301 302 303 304 305 306 @classmethod def get_required_fields ( cls ) -> set : \"\"\"Get REQUIRED response fields. Returns: REQUIRED response fields. \"\"\" return cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS length_alias_for ( field ) classmethod \u00b6 Returns the length alias for the particular field, or None if no such alias is found. Parameters: Name Type Description Default field str OPTIMADE field name. required Returns: Type Description Optional [ str ] Aliased field as found in all_length_aliases() . Source code in optimade/server/mappers/entries.py 180 181 182 183 184 185 186 187 188 189 190 191 192 @classmethod def length_alias_for ( cls , field : str ) -> Optional [ str ]: \"\"\"Returns the length alias for the particular field, or `None` if no such alias is found. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_length_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_length_aliases]. \"\"\" return dict ( cls . all_length_aliases ()) . get ( field , None ) map_back ( doc ) classmethod \u00b6 Map properties from MongoDB to OPTIMADE. Starting from a MongoDB document doc , map the DB fields to the corresponding OPTIMADE fields. Then, the fields are all added to the top-level field \"attributes\", with the exception of other top-level fields, defined in cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS . All fields not in cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS + \"attributes\" will be removed. Finally, the type is given the value of the specified cls.ENDPOINT . Parameters: Name Type Description Default doc dict A resource object in MongoDB format. required Returns: Type Description dict A resource object in OPTIMADE format. Source code in optimade/server/mappers/entries.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE. Starting from a MongoDB document `doc`, map the DB fields to the corresponding OPTIMADE fields. Then, the fields are all added to the top-level field \"attributes\", with the exception of other top-level fields, defined in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS`. All fields not in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS` + \"attributes\" will be removed. Finally, the `type` is given the value of the specified `cls.ENDPOINT`. Parameters: doc: A resource object in MongoDB format. Returns: A resource object in OPTIMADE format. \"\"\" mapping = (( real , alias ) for alias , real in cls . all_aliases ()) newdoc = {} reals = { real for alias , real in cls . all_aliases ()} for key in doc : if key not in reals : newdoc [ key ] = doc [ key ] for real , alias in mapping : if real in doc : newdoc [ alias ] = doc [ real ] if \"attributes\" in newdoc : raise Exception ( \"Will overwrite doc field!\" ) attributes = newdoc . copy () for field in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : value = attributes . pop ( field , None ) if value is not None : newdoc [ field ] = value for field in list ( newdoc . keys ()): if field not in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : del newdoc [ field ] newdoc [ \"type\" ] = cls . ENDPOINT newdoc [ \"attributes\" ] = attributes return newdoc classproperty \u00b6 A simple extension of the property decorator that binds to types rather than instances. Modelled on this StackOverflow answer with some tweaks to allow mkdocstrings to do its thing. Source code in optimade/server/mappers/entries.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class classproperty ( property ): \"\"\"A simple extension of the property decorator that binds to types rather than instances. Modelled on this [StackOverflow answer](https://stackoverflow.com/a/5192374) with some tweaks to allow mkdocstrings to do its thing. \"\"\" def __init__ ( self , func ): self . __name__ = func . __name__ self . __module__ = func . __module__ self . __doc__ = func . __doc__ self . __wrapped__ = func def __get__ ( self , _ , owner ): return self . __wrapped__ ( owner )","title":"entries"},{"location":"api_reference/server/mappers/entries/#entries","text":"","title":"entries"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper","text":"Generic Resource Mapper that defines and performs the mapping between objects in the database and the resource objects defined by the specification. Attributes: Name Type Description ALIASES Tuple [ Tuple [ str , str ]] a tuple of aliases between OPTIMADE field names and the field names in the database , e.g. ((\"elements\", \"custom_elements_field\")) . LENGTH_ALIASES Tuple [ Tuple [ str , str ]] a tuple of aliases between a field name and another field that defines its length, to be used when querying, e.g. ((\"elements\", \"nelements\")) . e.g. ((\"elements\", \"custom_elements_field\")) . ENTRY_RESOURCE_CLASS Type [ EntryResource ] The entry type that this mapper corresponds to. PROVIDER_FIELDS Tuple [ str ] a tuple of extra field names that this mapper should support when querying with the database prefix. TOP_LEVEL_NON_ATTRIBUTES_FIELDS Set [ str ] the set of top-level field names common to all endpoints. SUPPORTED_PREFIXES Set [ str ] The set of prefixes registered by this mapper. ALL_ATTRIBUTES Set [ str ] The set of attributes defined across the entry resource class and the server configuration. ENTRY_RESOURCE_ATTRIBUTES Dict [ str , Any ] A dictionary of attributes and their definitions defined by the schema of the entry resource class. ENDPOINT str The expected endpoint name for this resource, as defined by the type in the schema of the entry resource class. Source code in optimade/server/mappers/entries.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 class BaseResourceMapper : \"\"\" Generic Resource Mapper that defines and performs the mapping between objects in the database and the resource objects defined by the specification. Attributes: ALIASES: a tuple of aliases between OPTIMADE field names and the field names in the database , e.g. `((\"elements\", \"custom_elements_field\"))`. LENGTH_ALIASES: a tuple of aliases between a field name and another field that defines its length, to be used when querying, e.g. `((\"elements\", \"nelements\"))`. e.g. `((\"elements\", \"custom_elements_field\"))`. ENTRY_RESOURCE_CLASS: The entry type that this mapper corresponds to. PROVIDER_FIELDS: a tuple of extra field names that this mapper should support when querying with the database prefix. TOP_LEVEL_NON_ATTRIBUTES_FIELDS: the set of top-level field names common to all endpoints. SUPPORTED_PREFIXES: The set of prefixes registered by this mapper. ALL_ATTRIBUTES: The set of attributes defined across the entry resource class and the server configuration. ENTRY_RESOURCE_ATTRIBUTES: A dictionary of attributes and their definitions defined by the schema of the entry resource class. ENDPOINT: The expected endpoint name for this resource, as defined by the `type` in the schema of the entry resource class. \"\"\" try : from optimade.server.data import ( providers as PROVIDERS , ) # pylint: disable=no-name-in-module except ( ImportError , ModuleNotFoundError ): PROVIDERS = {} KNOWN_PROVIDER_PREFIXES : Set [ str ] = set ( prov [ \"id\" ] for prov in PROVIDERS . get ( \"data\" , []) ) ALIASES : Tuple [ Tuple [ str , str ]] = () LENGTH_ALIASES : Tuple [ Tuple [ str , str ]] = () PROVIDER_FIELDS : Tuple [ str ] = () ENTRY_RESOURCE_CLASS : Type [ EntryResource ] = EntryResource RELATIONSHIP_ENTRY_TYPES : Set [ str ] = { \"references\" , \"structures\" } TOP_LEVEL_NON_ATTRIBUTES_FIELDS : Set [ str ] = { \"id\" , \"type\" , \"relationships\" , \"links\" } SUPPORTED_PREFIXES : Set [ str ] ALL_ATTRIBUTES : Set [ str ] ENTRY_RESOURCE_ATTRIBUTES : Dict [ str , Any ] ENDPOINT : str @classmethod def all_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated aliases for this entry type, including those defined by the server config. The first member of each tuple is the OPTIMADE-compliant field name, the second is the backend-specific field name. Returns: A tuple of alias tuples. \"\"\" from optimade.server.config import CONFIG return ( tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , str ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field [ 'name' ] } \" , field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , dict ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in cls . PROVIDER_FIELDS ) + tuple ( CONFIG . aliases . get ( cls . ENDPOINT , {}) . items ()) + cls . ALIASES ) @classproperty def SUPPORTED_PREFIXES ( cls ) -> Set [ str ]: \"\"\"A set of prefixes handled by this entry type. !!! note This implementation only includes the provider prefix, but in the future this property may be extended to include other namespaces (for serving fields from, e.g., other providers or domain-specific terms). \"\"\" from optimade.server.config import CONFIG return { CONFIG . provider . prefix } @classproperty def ALL_ATTRIBUTES ( cls ) -> Set [ str ]: \"\"\"Returns all attributes served by this entry.\"\"\" from optimade.server.config import CONFIG return ( set ( cls . ENTRY_RESOURCE_ATTRIBUTES ) . union ( cls . get_optimade_field ( field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , str ) ) . union ( cls . get_optimade_field ( field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , dict ) ) . union ( set ( cls . get_optimade_field ( field ) for field in cls . PROVIDER_FIELDS )) ) @classproperty def ENTRY_RESOURCE_ATTRIBUTES ( cls ) -> Dict [ str , Any ]: \"\"\"Returns the dictionary of attributes defined by the underlying entry resource class.\"\"\" from optimade.server.schemas import retrieve_queryable_properties return retrieve_queryable_properties ( cls . ENTRY_RESOURCE_CLASS . schema ()) @classproperty def ENDPOINT ( cls ) -> str : \"\"\"Returns the expected endpoint for this mapper, corresponding to the `type` property of the resource class. \"\"\" return ( cls . ENTRY_RESOURCE_CLASS . schema () . get ( \"properties\" , {}) . get ( \"type\" , {}) . get ( \"default\" , \"\" ) ) @classmethod def all_length_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated length aliases for this class, including those defined by the server config. Returns: A tuple of length alias tuples. \"\"\" from optimade.server.config import CONFIG return cls . LENGTH_ALIASES + tuple ( CONFIG . length_aliases . get ( cls . ENDPOINT , {}) . items () ) @classmethod def length_alias_for ( cls , field : str ) -> Optional [ str ]: \"\"\"Returns the length alias for the particular field, or `None` if no such alias is found. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_length_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_length_aliases]. \"\"\" return dict ( cls . all_length_aliases ()) . get ( field , None ) @classmethod def get_backend_field ( cls , optimade_field : str ) -> str : \"\"\"Return the field name configured for the particular underlying database for the passed OPTIMADE field name, that would be used in an API filter. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. If a dot-separated OPTIMADE field is provided, e.g., `species.mass`, only the first part will be mapped. This means for an (OPTIMADE, DB) alias of (`species`, `kinds`), `get_backend_fields(\"species.mass\")` will return `kinds.mass`. Arguments: optimade_field: The OPTIMADE field to attempt to map to the backend-specific field. Examples: >>> get_backend_field(\"chemical_formula_anonymous\") 'formula_anon' >>> get_backend_field(\"formula_anon\") 'formula_anon' >>> get_backend_field(\"_exmpl_custom_provider_field\") 'custom_provider_field' Returns: The mapped field name to be used in the query to the backend. \"\"\" split = optimade_field . split ( \".\" ) alias = dict ( cls . all_aliases ()) . get ( split [ 0 ], None ) if alias is not None : return alias + ( \".\" + \".\" . join ( split [ 1 :]) if len ( split ) > 1 else \"\" ) return optimade_field @classmethod def alias_for ( cls , field : str ) -> str : \"\"\"Return aliased field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_backend_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_backend_field]. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. \"\"\" warnings . warn ( \"The `.alias_for(...)` method is deprecated, please use `.get_backend_field(...)`.\" , DeprecationWarning , ) return cls . get_backend_field ( field ) @classmethod def get_optimade_field ( cls , backend_field : str ) -> str : \"\"\"Return the corresponding OPTIMADE field name for the underlying database field, ready to be used to construct the OPTIMADE-compliant JSON response. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. Arguments: backend_field: The backend field to attempt to map to an OPTIMADE field. Examples: >>> get_optimade_field(\"chemical_formula_anonymous\") 'chemical_formula_anonymous' >>> get_optimade_field(\"formula_anon\") 'chemical_formula_anonymous' >>> get_optimade_field(\"custom_provider_field\") '_exmpl_custom_provider_field' Returns: The mapped field name to be used in an OPTIMADE-compliant response. \"\"\" return { alias : real for real , alias in cls . all_aliases ()} . get ( backend_field , backend_field ) @classmethod def alias_of ( cls , field : str ) -> str : \"\"\"Return de-aliased field name, if it exists, otherwise return the input field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_optimade_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_optimade_field]. Parameters: field: Field name to be de-aliased. Returns: De-aliased field name, falling back to returning `field`. \"\"\" warnings . warn ( \"The `.alias_of(...)` method is deprecated, please use `.get_optimade_field(...)`.\" , DeprecationWarning , ) return cls . get_optimade_field ( field ) @classmethod def get_required_fields ( cls ) -> set : \"\"\"Get REQUIRED response fields. Returns: REQUIRED response fields. \"\"\" return cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE. Starting from a MongoDB document `doc`, map the DB fields to the corresponding OPTIMADE fields. Then, the fields are all added to the top-level field \"attributes\", with the exception of other top-level fields, defined in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS`. All fields not in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS` + \"attributes\" will be removed. Finally, the `type` is given the value of the specified `cls.ENDPOINT`. Parameters: doc: A resource object in MongoDB format. Returns: A resource object in OPTIMADE format. \"\"\" mapping = (( real , alias ) for alias , real in cls . all_aliases ()) newdoc = {} reals = { real for alias , real in cls . all_aliases ()} for key in doc : if key not in reals : newdoc [ key ] = doc [ key ] for real , alias in mapping : if real in doc : newdoc [ alias ] = doc [ real ] if \"attributes\" in newdoc : raise Exception ( \"Will overwrite doc field!\" ) attributes = newdoc . copy () for field in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : value = attributes . pop ( field , None ) if value is not None : newdoc [ field ] = value for field in list ( newdoc . keys ()): if field not in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : del newdoc [ field ] newdoc [ \"type\" ] = cls . ENDPOINT newdoc [ \"attributes\" ] = attributes return newdoc @classmethod def deserialize ( cls , results : Union [ dict , Iterable [ dict ]] ) -> Union [ List [ EntryResource ], EntryResource ]: if isinstance ( results , dict ): return cls . ENTRY_RESOURCE_CLASS ( ** cls . map_back ( results )) return [ cls . ENTRY_RESOURCE_CLASS ( ** cls . map_back ( doc )) for doc in results ]","title":"BaseResourceMapper"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.ALL_ATTRIBUTES","text":"Returns all attributes served by this entry. Source code in optimade/server/mappers/entries.py 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 @classproperty def ALL_ATTRIBUTES ( cls ) -> Set [ str ]: \"\"\"Returns all attributes served by this entry.\"\"\" from optimade.server.config import CONFIG return ( set ( cls . ENTRY_RESOURCE_ATTRIBUTES ) . union ( cls . get_optimade_field ( field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , str ) ) . union ( cls . get_optimade_field ( field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , ()) if isinstance ( field , dict ) ) . union ( set ( cls . get_optimade_field ( field ) for field in cls . PROVIDER_FIELDS )) )","title":"ALL_ATTRIBUTES()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.ENDPOINT","text":"Returns the expected endpoint for this mapper, corresponding to the type property of the resource class. Source code in optimade/server/mappers/entries.py 152 153 154 155 156 157 158 159 160 161 162 163 @classproperty def ENDPOINT ( cls ) -> str : \"\"\"Returns the expected endpoint for this mapper, corresponding to the `type` property of the resource class. \"\"\" return ( cls . ENTRY_RESOURCE_CLASS . schema () . get ( \"properties\" , {}) . get ( \"type\" , {}) . get ( \"default\" , \"\" ) )","title":"ENDPOINT()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.ENTRY_RESOURCE_ATTRIBUTES","text":"Returns the dictionary of attributes defined by the underlying entry resource class. Source code in optimade/server/mappers/entries.py 145 146 147 148 149 150 @classproperty def ENTRY_RESOURCE_ATTRIBUTES ( cls ) -> Dict [ str , Any ]: \"\"\"Returns the dictionary of attributes defined by the underlying entry resource class.\"\"\" from optimade.server.schemas import retrieve_queryable_properties return retrieve_queryable_properties ( cls . ENTRY_RESOURCE_CLASS . schema ())","title":"ENTRY_RESOURCE_ATTRIBUTES()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.SUPPORTED_PREFIXES","text":"A set of prefixes handled by this entry type. Note This implementation only includes the provider prefix, but in the future this property may be extended to include other namespaces (for serving fields from, e.g., other providers or domain-specific terms). Source code in optimade/server/mappers/entries.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 @classproperty def SUPPORTED_PREFIXES ( cls ) -> Set [ str ]: \"\"\"A set of prefixes handled by this entry type. !!! note This implementation only includes the provider prefix, but in the future this property may be extended to include other namespaces (for serving fields from, e.g., other providers or domain-specific terms). \"\"\" from optimade.server.config import CONFIG return { CONFIG . provider . prefix }","title":"SUPPORTED_PREFIXES()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.alias_for","text":"Return aliased field name. Deprecated This method is deprecated could be removed without further warning. Please use get_backend_field() . Parameters: Name Type Description Default field str OPTIMADE field name. required Returns: Type Description str Aliased field as found in all_aliases() . Source code in optimade/server/mappers/entries.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 @classmethod def alias_for ( cls , field : str ) -> str : \"\"\"Return aliased field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_backend_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_backend_field]. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. \"\"\" warnings . warn ( \"The `.alias_for(...)` method is deprecated, please use `.get_backend_field(...)`.\" , DeprecationWarning , ) return cls . get_backend_field ( field )","title":"alias_for()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.alias_of","text":"Return de-aliased field name, if it exists, otherwise return the input field name. Deprecated This method is deprecated could be removed without further warning. Please use get_optimade_field() . Parameters: Name Type Description Default field str Field name to be de-aliased. required Returns: Type Description str De-aliased field name, falling back to returning field . Source code in optimade/server/mappers/entries.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 @classmethod def alias_of ( cls , field : str ) -> str : \"\"\"Return de-aliased field name, if it exists, otherwise return the input field name. !!! warning \"Deprecated\" This method is deprecated could be removed without further warning. Please use [`get_optimade_field()`][optimade.server.mappers.entries.BaseResourceMapper.get_optimade_field]. Parameters: field: Field name to be de-aliased. Returns: De-aliased field name, falling back to returning `field`. \"\"\" warnings . warn ( \"The `.alias_of(...)` method is deprecated, please use `.get_optimade_field(...)`.\" , DeprecationWarning , ) return cls . get_optimade_field ( field )","title":"alias_of()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.all_aliases","text":"Returns all of the associated aliases for this entry type, including those defined by the server config. The first member of each tuple is the OPTIMADE-compliant field name, the second is the backend-specific field name. Returns: Type Description Tuple [ Tuple [ str , str ]] A tuple of alias tuples. Source code in optimade/server/mappers/entries.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 @classmethod def all_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated aliases for this entry type, including those defined by the server config. The first member of each tuple is the OPTIMADE-compliant field name, the second is the backend-specific field name. Returns: A tuple of alias tuples. \"\"\" from optimade.server.config import CONFIG return ( tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , str ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field [ 'name' ] } \" , field [ \"name\" ]) for field in CONFIG . provider_fields . get ( cls . ENDPOINT , []) if isinstance ( field , dict ) ) + tuple ( ( f \"_ { CONFIG . provider . prefix } _ { field } \" , field ) for field in cls . PROVIDER_FIELDS ) + tuple ( CONFIG . aliases . get ( cls . ENDPOINT , {}) . items ()) + cls . ALIASES )","title":"all_aliases()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.all_length_aliases","text":"Returns all of the associated length aliases for this class, including those defined by the server config. Returns: Type Description Tuple [ Tuple [ str , str ]] A tuple of length alias tuples. Source code in optimade/server/mappers/entries.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 @classmethod def all_length_aliases ( cls ) -> Tuple [ Tuple [ str , str ]]: \"\"\"Returns all of the associated length aliases for this class, including those defined by the server config. Returns: A tuple of length alias tuples. \"\"\" from optimade.server.config import CONFIG return cls . LENGTH_ALIASES + tuple ( CONFIG . length_aliases . get ( cls . ENDPOINT , {}) . items () )","title":"all_length_aliases()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.get_backend_field","text":"Return the field name configured for the particular underlying database for the passed OPTIMADE field name, that would be used in an API filter. Aliases are read from all_aliases() . If a dot-separated OPTIMADE field is provided, e.g., species.mass , only the first part will be mapped. This means for an (OPTIMADE, DB) alias of ( species , kinds ), get_backend_fields(\"species.mass\") will return kinds.mass . Parameters: Name Type Description Default optimade_field str The OPTIMADE field to attempt to map to the backend-specific field. required Examples: >>> get_backend_field ( \"chemical_formula_anonymous\" ) 'formula_anon' >>> get_backend_field ( \"formula_anon\" ) 'formula_anon' >>> get_backend_field ( \"_exmpl_custom_provider_field\" ) 'custom_provider_field' Returns: Type Description str The mapped field name to be used in the query to the backend. Source code in optimade/server/mappers/entries.py 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 @classmethod def get_backend_field ( cls , optimade_field : str ) -> str : \"\"\"Return the field name configured for the particular underlying database for the passed OPTIMADE field name, that would be used in an API filter. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. If a dot-separated OPTIMADE field is provided, e.g., `species.mass`, only the first part will be mapped. This means for an (OPTIMADE, DB) alias of (`species`, `kinds`), `get_backend_fields(\"species.mass\")` will return `kinds.mass`. Arguments: optimade_field: The OPTIMADE field to attempt to map to the backend-specific field. Examples: >>> get_backend_field(\"chemical_formula_anonymous\") 'formula_anon' >>> get_backend_field(\"formula_anon\") 'formula_anon' >>> get_backend_field(\"_exmpl_custom_provider_field\") 'custom_provider_field' Returns: The mapped field name to be used in the query to the backend. \"\"\" split = optimade_field . split ( \".\" ) alias = dict ( cls . all_aliases ()) . get ( split [ 0 ], None ) if alias is not None : return alias + ( \".\" + \".\" . join ( split [ 1 :]) if len ( split ) > 1 else \"\" ) return optimade_field","title":"get_backend_field()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.get_optimade_field","text":"Return the corresponding OPTIMADE field name for the underlying database field, ready to be used to construct the OPTIMADE-compliant JSON response. Aliases are read from all_aliases() . Parameters: Name Type Description Default backend_field str The backend field to attempt to map to an OPTIMADE field. required Examples: >>> get_optimade_field ( \"chemical_formula_anonymous\" ) 'chemical_formula_anonymous' >>> get_optimade_field ( \"formula_anon\" ) 'chemical_formula_anonymous' >>> get_optimade_field ( \"custom_provider_field\" ) '_exmpl_custom_provider_field' Returns: Type Description str The mapped field name to be used in an OPTIMADE-compliant response. Source code in optimade/server/mappers/entries.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 @classmethod def get_optimade_field ( cls , backend_field : str ) -> str : \"\"\"Return the corresponding OPTIMADE field name for the underlying database field, ready to be used to construct the OPTIMADE-compliant JSON response. Aliases are read from [`all_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_aliases]. Arguments: backend_field: The backend field to attempt to map to an OPTIMADE field. Examples: >>> get_optimade_field(\"chemical_formula_anonymous\") 'chemical_formula_anonymous' >>> get_optimade_field(\"formula_anon\") 'chemical_formula_anonymous' >>> get_optimade_field(\"custom_provider_field\") '_exmpl_custom_provider_field' Returns: The mapped field name to be used in an OPTIMADE-compliant response. \"\"\" return { alias : real for real , alias in cls . all_aliases ()} . get ( backend_field , backend_field )","title":"get_optimade_field()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.get_required_fields","text":"Get REQUIRED response fields. Returns: Type Description set REQUIRED response fields. Source code in optimade/server/mappers/entries.py 298 299 300 301 302 303 304 305 306 @classmethod def get_required_fields ( cls ) -> set : \"\"\"Get REQUIRED response fields. Returns: REQUIRED response fields. \"\"\" return cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS","title":"get_required_fields()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.length_alias_for","text":"Returns the length alias for the particular field, or None if no such alias is found. Parameters: Name Type Description Default field str OPTIMADE field name. required Returns: Type Description Optional [ str ] Aliased field as found in all_length_aliases() . Source code in optimade/server/mappers/entries.py 180 181 182 183 184 185 186 187 188 189 190 191 192 @classmethod def length_alias_for ( cls , field : str ) -> Optional [ str ]: \"\"\"Returns the length alias for the particular field, or `None` if no such alias is found. Parameters: field: OPTIMADE field name. Returns: Aliased field as found in [`all_length_aliases()`][optimade.server.mappers.entries.BaseResourceMapper.all_length_aliases]. \"\"\" return dict ( cls . all_length_aliases ()) . get ( field , None )","title":"length_alias_for()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.BaseResourceMapper.map_back","text":"Map properties from MongoDB to OPTIMADE. Starting from a MongoDB document doc , map the DB fields to the corresponding OPTIMADE fields. Then, the fields are all added to the top-level field \"attributes\", with the exception of other top-level fields, defined in cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS . All fields not in cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS + \"attributes\" will be removed. Finally, the type is given the value of the specified cls.ENDPOINT . Parameters: Name Type Description Default doc dict A resource object in MongoDB format. required Returns: Type Description dict A resource object in OPTIMADE format. Source code in optimade/server/mappers/entries.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE. Starting from a MongoDB document `doc`, map the DB fields to the corresponding OPTIMADE fields. Then, the fields are all added to the top-level field \"attributes\", with the exception of other top-level fields, defined in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS`. All fields not in `cls.TOP_LEVEL_NON_ATTRIBUTES_FIELDS` + \"attributes\" will be removed. Finally, the `type` is given the value of the specified `cls.ENDPOINT`. Parameters: doc: A resource object in MongoDB format. Returns: A resource object in OPTIMADE format. \"\"\" mapping = (( real , alias ) for alias , real in cls . all_aliases ()) newdoc = {} reals = { real for alias , real in cls . all_aliases ()} for key in doc : if key not in reals : newdoc [ key ] = doc [ key ] for real , alias in mapping : if real in doc : newdoc [ alias ] = doc [ real ] if \"attributes\" in newdoc : raise Exception ( \"Will overwrite doc field!\" ) attributes = newdoc . copy () for field in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : value = attributes . pop ( field , None ) if value is not None : newdoc [ field ] = value for field in list ( newdoc . keys ()): if field not in cls . TOP_LEVEL_NON_ATTRIBUTES_FIELDS : del newdoc [ field ] newdoc [ \"type\" ] = cls . ENDPOINT newdoc [ \"attributes\" ] = attributes return newdoc","title":"map_back()"},{"location":"api_reference/server/mappers/entries/#optimade.server.mappers.entries.classproperty","text":"A simple extension of the property decorator that binds to types rather than instances. Modelled on this StackOverflow answer with some tweaks to allow mkdocstrings to do its thing. Source code in optimade/server/mappers/entries.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class classproperty ( property ): \"\"\"A simple extension of the property decorator that binds to types rather than instances. Modelled on this [StackOverflow answer](https://stackoverflow.com/a/5192374) with some tweaks to allow mkdocstrings to do its thing. \"\"\" def __init__ ( self , func ): self . __name__ = func . __name__ self . __module__ = func . __module__ self . __doc__ = func . __doc__ self . __wrapped__ = func def __get__ ( self , _ , owner ): return self . __wrapped__ ( owner )","title":"classproperty"},{"location":"api_reference/server/mappers/links/","text":"links \u00b6 LinksMapper \u00b6 Source code in optimade/server/mappers/links.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class LinksMapper ( BaseResourceMapper ): ENDPOINT = \"links\" ENTRY_RESOURCE_CLASS = LinksResource @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE :param doc: A resource object in MongoDB format :type doc: dict :return: A resource object in OPTIMADE format :rtype: dict \"\"\" type_ = doc [ \"type\" ] newdoc = super () . map_back ( doc ) newdoc [ \"type\" ] = type_ return newdoc map_back ( doc ) classmethod \u00b6 Map properties from MongoDB to OPTIMADE :param doc: A resource object in MongoDB format :type doc: dict :return: A resource object in OPTIMADE format :rtype: dict Source code in optimade/server/mappers/links.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE :param doc: A resource object in MongoDB format :type doc: dict :return: A resource object in OPTIMADE format :rtype: dict \"\"\" type_ = doc [ \"type\" ] newdoc = super () . map_back ( doc ) newdoc [ \"type\" ] = type_ return newdoc","title":"links"},{"location":"api_reference/server/mappers/links/#links","text":"","title":"links"},{"location":"api_reference/server/mappers/links/#optimade.server.mappers.links.LinksMapper","text":"Source code in optimade/server/mappers/links.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class LinksMapper ( BaseResourceMapper ): ENDPOINT = \"links\" ENTRY_RESOURCE_CLASS = LinksResource @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE :param doc: A resource object in MongoDB format :type doc: dict :return: A resource object in OPTIMADE format :rtype: dict \"\"\" type_ = doc [ \"type\" ] newdoc = super () . map_back ( doc ) newdoc [ \"type\" ] = type_ return newdoc","title":"LinksMapper"},{"location":"api_reference/server/mappers/links/#optimade.server.mappers.links.LinksMapper.map_back","text":"Map properties from MongoDB to OPTIMADE :param doc: A resource object in MongoDB format :type doc: dict :return: A resource object in OPTIMADE format :rtype: dict Source code in optimade/server/mappers/links.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @classmethod def map_back ( cls , doc : dict ) -> dict : \"\"\"Map properties from MongoDB to OPTIMADE :param doc: A resource object in MongoDB format :type doc: dict :return: A resource object in OPTIMADE format :rtype: dict \"\"\" type_ = doc [ \"type\" ] newdoc = super () . map_back ( doc ) newdoc [ \"type\" ] = type_ return newdoc","title":"map_back()"},{"location":"api_reference/server/mappers/references/","text":"references \u00b6","title":"references"},{"location":"api_reference/server/mappers/references/#references","text":"","title":"references"},{"location":"api_reference/server/mappers/structures/","text":"structures \u00b6","title":"structures"},{"location":"api_reference/server/mappers/structures/#structures","text":"","title":"structures"},{"location":"api_reference/server/routers/index_info/","text":"index_info \u00b6","title":"index_info"},{"location":"api_reference/server/routers/index_info/#index_info","text":"","title":"index_info"},{"location":"api_reference/server/routers/info/","text":"info \u00b6","title":"info"},{"location":"api_reference/server/routers/info/#info","text":"","title":"info"},{"location":"api_reference/server/routers/landing/","text":"landing \u00b6 OPTIMADE landing page router. landing ( request ) async \u00b6 Show a human-readable landing page when the base URL is accessed. Source code in optimade/server/routers/landing.py 82 83 84 async def landing ( request : Request ): \"\"\"Show a human-readable landing page when the base URL is accessed.\"\"\" return render_landing_page ( str ( request . url )) render_landing_page ( url ) cached \u00b6 Render and cache the landing page. This function uses the template file ./static/landing_page.html , adapted from the original Jinja template. Instead of Jinja, some basic string replacement is used to fill out the fields from the server configuration. Careful The removal of Jinja means that the fields are no longer validated as web safe before inclusion in the template. Source code in optimade/server/routers/landing.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @lru_cache () def render_landing_page ( url : str ) -> HTMLResponse : \"\"\"Render and cache the landing page. This function uses the template file `./static/landing_page.html`, adapted from the original Jinja template. Instead of Jinja, some basic string replacement is used to fill out the fields from the server configuration. !!! warning \"Careful\" The removal of Jinja means that the fields are no longer validated as web safe before inclusion in the template. \"\"\" meta = meta_values ( url , 1 , 1 , more_data_available = False , schema = CONFIG . schema_url ) major_version = __api_version__ . split ( \".\" )[ 0 ] versioned_url = f \" { get_base_url ( url ) } /v { major_version } /\" template_dir = Path ( __file__ ) . parent . joinpath ( \"static\" ) . resolve () html = ( template_dir / \"landing_page.html\" ) . read_text () # Build a dictionary that maps the old Jinja keys to the new simplified replacements replacements = { \"api_version\" : __api_version__ , } if meta . provider : replacements . update ( { \"provider.name\" : meta . provider . name , \"provider.prefix\" : meta . provider . prefix , \"provider.description\" : meta . provider . description , \"provider.homepage\" : str ( meta . provider . homepage ) or \"\" , } ) if meta . implementation : replacements . update ( { \"implementation.name\" : meta . implementation . name or \"\" , \"implementation.version\" : meta . implementation . version or \"\" , \"implementation.source_url\" : str ( meta . implementation . source_url or \"\" ), } ) for replacement in replacements : html = html . replace ( f \" {{{{ { replacement } }}}} \" , replacements [ replacement ]) # Build the list of endpoints. The template already opens and closes the `<ul>` tag. endpoints_list = [ f '<li><a href=\" { versioned_url }{ endp } \"> { versioned_url }{ endp } </a></li>' for endp in list ( ENTRY_COLLECTIONS . keys ()) + [ \"info\" ] ] html = html . replace ( \"{ % E NDPOINTS %}\" , \" \\n \" . join ( endpoints_list )) # If the index base URL has been configured, also list it index_base_url_html = \"\" if CONFIG . index_base_url : index_base_url_html = f \"\"\"<h3>Index base URL:</h3> <p><a href= { CONFIG . index_base_url } > { CONFIG . index_base_url } </a></p> \"\"\" html = html . replace ( \"{% INDEX_BASE_URL %}\" , index_base_url_html ) return HTMLResponse ( html )","title":"landing"},{"location":"api_reference/server/routers/landing/#landing","text":"OPTIMADE landing page router.","title":"landing"},{"location":"api_reference/server/routers/landing/#optimade.server.routers.landing.landing","text":"Show a human-readable landing page when the base URL is accessed. Source code in optimade/server/routers/landing.py 82 83 84 async def landing ( request : Request ): \"\"\"Show a human-readable landing page when the base URL is accessed.\"\"\" return render_landing_page ( str ( request . url ))","title":"landing()"},{"location":"api_reference/server/routers/landing/#optimade.server.routers.landing.render_landing_page","text":"Render and cache the landing page. This function uses the template file ./static/landing_page.html , adapted from the original Jinja template. Instead of Jinja, some basic string replacement is used to fill out the fields from the server configuration. Careful The removal of Jinja means that the fields are no longer validated as web safe before inclusion in the template. Source code in optimade/server/routers/landing.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @lru_cache () def render_landing_page ( url : str ) -> HTMLResponse : \"\"\"Render and cache the landing page. This function uses the template file `./static/landing_page.html`, adapted from the original Jinja template. Instead of Jinja, some basic string replacement is used to fill out the fields from the server configuration. !!! warning \"Careful\" The removal of Jinja means that the fields are no longer validated as web safe before inclusion in the template. \"\"\" meta = meta_values ( url , 1 , 1 , more_data_available = False , schema = CONFIG . schema_url ) major_version = __api_version__ . split ( \".\" )[ 0 ] versioned_url = f \" { get_base_url ( url ) } /v { major_version } /\" template_dir = Path ( __file__ ) . parent . joinpath ( \"static\" ) . resolve () html = ( template_dir / \"landing_page.html\" ) . read_text () # Build a dictionary that maps the old Jinja keys to the new simplified replacements replacements = { \"api_version\" : __api_version__ , } if meta . provider : replacements . update ( { \"provider.name\" : meta . provider . name , \"provider.prefix\" : meta . provider . prefix , \"provider.description\" : meta . provider . description , \"provider.homepage\" : str ( meta . provider . homepage ) or \"\" , } ) if meta . implementation : replacements . update ( { \"implementation.name\" : meta . implementation . name or \"\" , \"implementation.version\" : meta . implementation . version or \"\" , \"implementation.source_url\" : str ( meta . implementation . source_url or \"\" ), } ) for replacement in replacements : html = html . replace ( f \" {{{{ { replacement } }}}} \" , replacements [ replacement ]) # Build the list of endpoints. The template already opens and closes the `<ul>` tag. endpoints_list = [ f '<li><a href=\" { versioned_url }{ endp } \"> { versioned_url }{ endp } </a></li>' for endp in list ( ENTRY_COLLECTIONS . keys ()) + [ \"info\" ] ] html = html . replace ( \"{ % E NDPOINTS %}\" , \" \\n \" . join ( endpoints_list )) # If the index base URL has been configured, also list it index_base_url_html = \"\" if CONFIG . index_base_url : index_base_url_html = f \"\"\"<h3>Index base URL:</h3> <p><a href= { CONFIG . index_base_url } > { CONFIG . index_base_url } </a></p> \"\"\" html = html . replace ( \"{% INDEX_BASE_URL %}\" , index_base_url_html ) return HTMLResponse ( html )","title":"render_landing_page()"},{"location":"api_reference/server/routers/links/","text":"links \u00b6","title":"links"},{"location":"api_reference/server/routers/links/#links","text":"","title":"links"},{"location":"api_reference/server/routers/references/","text":"references \u00b6","title":"references"},{"location":"api_reference/server/routers/references/#references","text":"","title":"references"},{"location":"api_reference/server/routers/structures/","text":"structures \u00b6","title":"structures"},{"location":"api_reference/server/routers/structures/#structures","text":"","title":"structures"},{"location":"api_reference/server/routers/utils/","text":"utils \u00b6 JSONAPIResponse \u00b6 This class simply patches fastapi.responses.JSONResponse to use the JSON:API 'application/vnd.api+json' MIME type. Source code in optimade/server/routers/utils.py 48 49 50 51 52 53 54 class JSONAPIResponse ( JSONResponse ): \"\"\"This class simply patches `fastapi.responses.JSONResponse` to use the JSON:API 'application/vnd.api+json' MIME type. \"\"\" media_type = \"application/vnd.api+json\" get_base_url ( parsed_url_request ) \u00b6 Get base URL for current server Take the base URL from the config file, if it exists, otherwise use the request. Source code in optimade/server/routers/utils.py 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def get_base_url ( parsed_url_request : Union [ urllib . parse . ParseResult , urllib . parse . SplitResult , StarletteURL , str ] ) -> str : \"\"\"Get base URL for current server Take the base URL from the config file, if it exists, otherwise use the request. \"\"\" parsed_url_request = ( urllib . parse . urlparse ( parsed_url_request ) if isinstance ( parsed_url_request , str ) else parsed_url_request ) return ( CONFIG . base_url . rstrip ( \"/\" ) if CONFIG . base_url else f \" { parsed_url_request . scheme } :// { parsed_url_request . netloc } \" ) get_entries ( collection , response , request , params ) \u00b6 Generalized /{entry} endpoint getter Source code in optimade/server/routers/utils.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def get_entries ( collection : EntryCollection , response : EntryResponseMany , request : Request , params : EntryListingQueryParams , ) -> EntryResponseMany : \"\"\"Generalized /{entry} endpoint getter\"\"\" from optimade.server.routers import ENTRY_COLLECTIONS params . check_params ( request . query_params ) ( results , data_returned , more_data_available , fields , include_fields , ) = collection . find ( params ) include = [] if getattr ( params , \"include\" , False ): include . extend ( params . include . split ( \",\" )) included = get_included_relationships ( results , ENTRY_COLLECTIONS , include ) if more_data_available : # Deduce the `next` link from the current request query = urllib . parse . parse_qs ( request . url . query ) query [ \"page_offset\" ] = int ( query . get ( \"page_offset\" , [ 0 ])[ 0 ]) + len ( results ) urlencoded = urllib . parse . urlencode ( query , doseq = True ) base_url = get_base_url ( request . url ) links = ToplevelLinks ( next = f \" { base_url }{ request . url . path } ? { urlencoded } \" ) else : links = ToplevelLinks ( next = None ) if fields or include_fields : results = handle_response_fields ( results , fields , include_fields ) return response ( links = links , data = results , meta = meta_values ( url = request . url , data_returned = data_returned , data_available = len ( collection ), more_data_available = more_data_available , schema = CONFIG . schema_url , ), included = included , ) get_included_relationships ( results , ENTRY_COLLECTIONS , include_param ) \u00b6 Filters the included relationships and makes the appropriate compound request to include them in the response. Parameters: Name Type Description Default results Union [ EntryResource , List [ EntryResource ]] list of returned documents. required ENTRY_COLLECTIONS Dict [ str , EntryCollection ] dictionary containing collections to query, with key based on endpoint type. required include_param List [ str ] list of queried related resources that should be included in included . required Returns: Type Description Dict [ str , List [ EntryResource ]] Dictionary with the same keys as ENTRY_COLLECTIONS, each containing the list of resource objects for that entry type. Source code in optimade/server/routers/utils.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 def get_included_relationships ( results : Union [ EntryResource , List [ EntryResource ]], ENTRY_COLLECTIONS : Dict [ str , EntryCollection ], include_param : List [ str ], ) -> Dict [ str , List [ EntryResource ]]: \"\"\"Filters the included relationships and makes the appropriate compound request to include them in the response. Parameters: results: list of returned documents. ENTRY_COLLECTIONS: dictionary containing collections to query, with key based on endpoint type. include_param: list of queried related resources that should be included in `included`. Returns: Dictionary with the same keys as ENTRY_COLLECTIONS, each containing the list of resource objects for that entry type. \"\"\" from collections import defaultdict if not isinstance ( results , list ): results = [ results ] for entry_type in include_param : if entry_type not in ENTRY_COLLECTIONS and entry_type != \"\" : raise BadRequest ( detail = f \"' { entry_type } ' cannot be identified as a valid relationship type. \" f \"Known relationship types: { sorted ( ENTRY_COLLECTIONS . keys ()) } \" ) endpoint_includes = defaultdict ( dict ) for doc in results : # convert list of references into dict by ID to only included unique IDs if doc is None : continue relationships = doc . relationships if relationships is None : continue relationships = relationships . dict () for entry_type in ENTRY_COLLECTIONS : # Skip entry type if it is not in `include_param` if entry_type not in include_param : continue entry_relationship = relationships . get ( entry_type , {}) if entry_relationship is not None : refs = entry_relationship . get ( \"data\" , []) for ref in refs : if ref [ \"id\" ] not in endpoint_includes [ entry_type ]: endpoint_includes [ entry_type ][ ref [ \"id\" ]] = ref included = {} for entry_type in endpoint_includes : compound_filter = \" OR \" . join ( [ 'id=\" {} \"' . format ( ref_id ) for ref_id in endpoint_includes [ entry_type ]] ) params = EntryListingQueryParams ( filter = compound_filter , response_format = \"json\" , response_fields = None , sort = None , page_limit = 0 , page_offset = 0 , ) # still need to handle pagination ref_results , _ , _ , _ , _ = ENTRY_COLLECTIONS [ entry_type ] . find ( params ) included [ entry_type ] = ref_results # flatten dict by endpoint to list return [ obj for endp in included . values () for obj in endp ] get_providers ( add_mongo_id = False ) \u00b6 Retrieve Materials-Consortia providers (from https://providers.optimade.org/v1/links). Fallback order if providers.optimade.org is not available: Try Materials-Consortia/providers on GitHub. Try submodule providers ' list of providers. Log warning that providers list from Materials-Consortia is not included in the /links -endpoint. Parameters: Name Type Description Default add_mongo_id bool Whether to populate the _id field of the provider with MongoDB ObjectID. False Returns: Type Description list List of raw JSON-decoded providers including MongoDB object IDs. Source code in optimade/utils.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def get_providers ( add_mongo_id : bool = False ) -> list : \"\"\"Retrieve Materials-Consortia providers (from https://providers.optimade.org/v1/links). Fallback order if providers.optimade.org is not available: 1. Try Materials-Consortia/providers on GitHub. 2. Try submodule `providers`' list of providers. 3. Log warning that providers list from Materials-Consortia is not included in the `/links`-endpoint. Arguments: add_mongo_id: Whether to populate the `_id` field of the provider with MongoDB ObjectID. Returns: List of raw JSON-decoded providers including MongoDB object IDs. \"\"\" import requests try : import simplejson as json except ImportError : import json for provider_list_url in PROVIDER_LIST_URLS : try : providers = requests . get ( provider_list_url ) . json () except ( requests . exceptions . ConnectionError , requests . exceptions . ConnectTimeout , json . JSONDecodeError , ): pass else : break else : try : from optimade.server.data import providers except ImportError : from optimade.server.logger import LOGGER LOGGER . warning ( \"\"\"Could not retrieve a list of providers! Tried the following resources: {} The list of providers will not be included in the `/links`-endpoint. \"\"\" . format ( \"\" . join ([ f \" * { _ } \\n \" for _ in PROVIDER_LIST_URLS ]) ) ) return [] providers_list = [] for provider in providers . get ( \"data\" , []): # Remove/skip \"exmpl\" if provider [ \"id\" ] == \"exmpl\" : continue provider . update ( provider . pop ( \"attributes\" , {})) # Add MongoDB ObjectId if add_mongo_id : provider [ \"_id\" ] = { \"$oid\" : mongo_id_for_database ( provider [ \"id\" ], provider [ \"type\" ]) } providers_list . append ( provider ) return providers_list handle_response_fields ( results , exclude_fields , include_fields ) \u00b6 Handle query parameter response_fields . It is assumed that all fields are under attributes . This is due to all other top-level fields are REQUIRED in the response. Parameters: Name Type Description Default exclude_fields Set [ str ] Fields under attributes to be excluded from the response. required include_fields Set [ str ] Fields under attributes that were requested that should be set to null if missing in the entry. required Returns: Type Description List [ Dict [ str , Any ]] List of resulting resources as dictionaries after pruning according to List [ Dict [ str , Any ]] the response_fields OPTIMADE URL query parameter. Source code in optimade/server/routers/utils.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def handle_response_fields ( results : Union [ List [ EntryResource ], EntryResource ], exclude_fields : Set [ str ], include_fields : Set [ str ], ) -> List [ Dict [ str , Any ]]: \"\"\"Handle query parameter `response_fields`. It is assumed that all fields are under `attributes`. This is due to all other top-level fields are REQUIRED in the response. Parameters: exclude_fields: Fields under `attributes` to be excluded from the response. include_fields: Fields under `attributes` that were requested that should be set to null if missing in the entry. Returns: List of resulting resources as dictionaries after pruning according to the `response_fields` OPTIMADE URL query parameter. \"\"\" if not isinstance ( results , list ): results = [ results ] new_results = [] while results : new_entry = results . pop ( 0 ) . dict ( exclude_unset = True , by_alias = True ) # Remove fields excluded by their omission in `response_fields` for field in exclude_fields : if field in new_entry [ \"attributes\" ]: del new_entry [ \"attributes\" ][ field ] # Include missing fields that were requested in `response_fields` for field in include_fields : if field not in new_entry [ \"attributes\" ]: new_entry [ \"attributes\" ][ field ] = None new_results . append ( new_entry ) return new_results meta_values ( url , data_returned , data_available , more_data_available , schema , ** kwargs ) \u00b6 Helper to initialize the meta values Source code in optimade/server/routers/utils.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def meta_values ( url : Union [ urllib . parse . ParseResult , urllib . parse . SplitResult , StarletteURL , str ], data_returned : int , data_available : int , more_data_available : bool , schema : str , ** kwargs , ) -> ResponseMeta : \"\"\"Helper to initialize the meta values\"\"\" from optimade.models import ResponseMetaQuery if isinstance ( url , str ): url = urllib . parse . urlparse ( url ) # To catch all (valid) variations of the version part of the URL, a regex is used if re . match ( r \"/v[0-9]+(\\.[0-9]+){,2}/.*\" , url . path ) is not None : url_path = re . sub ( r \"/v[0-9]+(\\.[0-9]+){,2}/\" , \"/\" , url . path ) else : url_path = url . path return ResponseMeta ( query = ResponseMetaQuery ( representation = f \" { url_path } ? { url . query } \" ), api_version = __api_version__ , time_stamp = datetime . now (), data_returned = data_returned , more_data_available = more_data_available , provider = CONFIG . provider , data_available = data_available , implementation = CONFIG . implementation , schema = schema , ** kwargs , ) mongo_id_for_database ( database_id , database_type ) \u00b6 Produce a MongoDB ObjectId for a database Source code in optimade/utils.py 18 19 20 21 22 23 24 25 26 27 28 def mongo_id_for_database ( database_id : str , database_type : str ) -> str : \"\"\"Produce a MongoDB ObjectId for a database\"\"\" from bson.objectid import ObjectId oid = f \" { database_id }{ database_type } \" if len ( oid ) > 12 : oid = oid [: 12 ] elif len ( oid ) < 12 : oid = f \" { oid }{ '0' * ( 12 - len ( oid )) } \" return str ( ObjectId ( oid . encode ( \"UTF-8\" )))","title":"utils"},{"location":"api_reference/server/routers/utils/#utils","text":"","title":"utils"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.JSONAPIResponse","text":"This class simply patches fastapi.responses.JSONResponse to use the JSON:API 'application/vnd.api+json' MIME type. Source code in optimade/server/routers/utils.py 48 49 50 51 52 53 54 class JSONAPIResponse ( JSONResponse ): \"\"\"This class simply patches `fastapi.responses.JSONResponse` to use the JSON:API 'application/vnd.api+json' MIME type. \"\"\" media_type = \"application/vnd.api+json\"","title":"JSONAPIResponse"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.get_base_url","text":"Get base URL for current server Take the base URL from the config file, if it exists, otherwise use the request. Source code in optimade/server/routers/utils.py 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def get_base_url ( parsed_url_request : Union [ urllib . parse . ParseResult , urllib . parse . SplitResult , StarletteURL , str ] ) -> str : \"\"\"Get base URL for current server Take the base URL from the config file, if it exists, otherwise use the request. \"\"\" parsed_url_request = ( urllib . parse . urlparse ( parsed_url_request ) if isinstance ( parsed_url_request , str ) else parsed_url_request ) return ( CONFIG . base_url . rstrip ( \"/\" ) if CONFIG . base_url else f \" { parsed_url_request . scheme } :// { parsed_url_request . netloc } \" )","title":"get_base_url()"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.get_entries","text":"Generalized /{entry} endpoint getter Source code in optimade/server/routers/utils.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 def get_entries ( collection : EntryCollection , response : EntryResponseMany , request : Request , params : EntryListingQueryParams , ) -> EntryResponseMany : \"\"\"Generalized /{entry} endpoint getter\"\"\" from optimade.server.routers import ENTRY_COLLECTIONS params . check_params ( request . query_params ) ( results , data_returned , more_data_available , fields , include_fields , ) = collection . find ( params ) include = [] if getattr ( params , \"include\" , False ): include . extend ( params . include . split ( \",\" )) included = get_included_relationships ( results , ENTRY_COLLECTIONS , include ) if more_data_available : # Deduce the `next` link from the current request query = urllib . parse . parse_qs ( request . url . query ) query [ \"page_offset\" ] = int ( query . get ( \"page_offset\" , [ 0 ])[ 0 ]) + len ( results ) urlencoded = urllib . parse . urlencode ( query , doseq = True ) base_url = get_base_url ( request . url ) links = ToplevelLinks ( next = f \" { base_url }{ request . url . path } ? { urlencoded } \" ) else : links = ToplevelLinks ( next = None ) if fields or include_fields : results = handle_response_fields ( results , fields , include_fields ) return response ( links = links , data = results , meta = meta_values ( url = request . url , data_returned = data_returned , data_available = len ( collection ), more_data_available = more_data_available , schema = CONFIG . schema_url , ), included = included , )","title":"get_entries()"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.get_included_relationships","text":"Filters the included relationships and makes the appropriate compound request to include them in the response. Parameters: Name Type Description Default results Union [ EntryResource , List [ EntryResource ]] list of returned documents. required ENTRY_COLLECTIONS Dict [ str , EntryCollection ] dictionary containing collections to query, with key based on endpoint type. required include_param List [ str ] list of queried related resources that should be included in included . required Returns: Type Description Dict [ str , List [ EntryResource ]] Dictionary with the same keys as ENTRY_COLLECTIONS, each containing the list of resource objects for that entry type. Source code in optimade/server/routers/utils.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 def get_included_relationships ( results : Union [ EntryResource , List [ EntryResource ]], ENTRY_COLLECTIONS : Dict [ str , EntryCollection ], include_param : List [ str ], ) -> Dict [ str , List [ EntryResource ]]: \"\"\"Filters the included relationships and makes the appropriate compound request to include them in the response. Parameters: results: list of returned documents. ENTRY_COLLECTIONS: dictionary containing collections to query, with key based on endpoint type. include_param: list of queried related resources that should be included in `included`. Returns: Dictionary with the same keys as ENTRY_COLLECTIONS, each containing the list of resource objects for that entry type. \"\"\" from collections import defaultdict if not isinstance ( results , list ): results = [ results ] for entry_type in include_param : if entry_type not in ENTRY_COLLECTIONS and entry_type != \"\" : raise BadRequest ( detail = f \"' { entry_type } ' cannot be identified as a valid relationship type. \" f \"Known relationship types: { sorted ( ENTRY_COLLECTIONS . keys ()) } \" ) endpoint_includes = defaultdict ( dict ) for doc in results : # convert list of references into dict by ID to only included unique IDs if doc is None : continue relationships = doc . relationships if relationships is None : continue relationships = relationships . dict () for entry_type in ENTRY_COLLECTIONS : # Skip entry type if it is not in `include_param` if entry_type not in include_param : continue entry_relationship = relationships . get ( entry_type , {}) if entry_relationship is not None : refs = entry_relationship . get ( \"data\" , []) for ref in refs : if ref [ \"id\" ] not in endpoint_includes [ entry_type ]: endpoint_includes [ entry_type ][ ref [ \"id\" ]] = ref included = {} for entry_type in endpoint_includes : compound_filter = \" OR \" . join ( [ 'id=\" {} \"' . format ( ref_id ) for ref_id in endpoint_includes [ entry_type ]] ) params = EntryListingQueryParams ( filter = compound_filter , response_format = \"json\" , response_fields = None , sort = None , page_limit = 0 , page_offset = 0 , ) # still need to handle pagination ref_results , _ , _ , _ , _ = ENTRY_COLLECTIONS [ entry_type ] . find ( params ) included [ entry_type ] = ref_results # flatten dict by endpoint to list return [ obj for endp in included . values () for obj in endp ]","title":"get_included_relationships()"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.get_providers","text":"Retrieve Materials-Consortia providers (from https://providers.optimade.org/v1/links). Fallback order if providers.optimade.org is not available: Try Materials-Consortia/providers on GitHub. Try submodule providers ' list of providers. Log warning that providers list from Materials-Consortia is not included in the /links -endpoint. Parameters: Name Type Description Default add_mongo_id bool Whether to populate the _id field of the provider with MongoDB ObjectID. False Returns: Type Description list List of raw JSON-decoded providers including MongoDB object IDs. Source code in optimade/utils.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def get_providers ( add_mongo_id : bool = False ) -> list : \"\"\"Retrieve Materials-Consortia providers (from https://providers.optimade.org/v1/links). Fallback order if providers.optimade.org is not available: 1. Try Materials-Consortia/providers on GitHub. 2. Try submodule `providers`' list of providers. 3. Log warning that providers list from Materials-Consortia is not included in the `/links`-endpoint. Arguments: add_mongo_id: Whether to populate the `_id` field of the provider with MongoDB ObjectID. Returns: List of raw JSON-decoded providers including MongoDB object IDs. \"\"\" import requests try : import simplejson as json except ImportError : import json for provider_list_url in PROVIDER_LIST_URLS : try : providers = requests . get ( provider_list_url ) . json () except ( requests . exceptions . ConnectionError , requests . exceptions . ConnectTimeout , json . JSONDecodeError , ): pass else : break else : try : from optimade.server.data import providers except ImportError : from optimade.server.logger import LOGGER LOGGER . warning ( \"\"\"Could not retrieve a list of providers! Tried the following resources: {} The list of providers will not be included in the `/links`-endpoint. \"\"\" . format ( \"\" . join ([ f \" * { _ } \\n \" for _ in PROVIDER_LIST_URLS ]) ) ) return [] providers_list = [] for provider in providers . get ( \"data\" , []): # Remove/skip \"exmpl\" if provider [ \"id\" ] == \"exmpl\" : continue provider . update ( provider . pop ( \"attributes\" , {})) # Add MongoDB ObjectId if add_mongo_id : provider [ \"_id\" ] = { \"$oid\" : mongo_id_for_database ( provider [ \"id\" ], provider [ \"type\" ]) } providers_list . append ( provider ) return providers_list","title":"get_providers()"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.handle_response_fields","text":"Handle query parameter response_fields . It is assumed that all fields are under attributes . This is due to all other top-level fields are REQUIRED in the response. Parameters: Name Type Description Default exclude_fields Set [ str ] Fields under attributes to be excluded from the response. required include_fields Set [ str ] Fields under attributes that were requested that should be set to null if missing in the entry. required Returns: Type Description List [ Dict [ str , Any ]] List of resulting resources as dictionaries after pruning according to List [ Dict [ str , Any ]] the response_fields OPTIMADE URL query parameter. Source code in optimade/server/routers/utils.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def handle_response_fields ( results : Union [ List [ EntryResource ], EntryResource ], exclude_fields : Set [ str ], include_fields : Set [ str ], ) -> List [ Dict [ str , Any ]]: \"\"\"Handle query parameter `response_fields`. It is assumed that all fields are under `attributes`. This is due to all other top-level fields are REQUIRED in the response. Parameters: exclude_fields: Fields under `attributes` to be excluded from the response. include_fields: Fields under `attributes` that were requested that should be set to null if missing in the entry. Returns: List of resulting resources as dictionaries after pruning according to the `response_fields` OPTIMADE URL query parameter. \"\"\" if not isinstance ( results , list ): results = [ results ] new_results = [] while results : new_entry = results . pop ( 0 ) . dict ( exclude_unset = True , by_alias = True ) # Remove fields excluded by their omission in `response_fields` for field in exclude_fields : if field in new_entry [ \"attributes\" ]: del new_entry [ \"attributes\" ][ field ] # Include missing fields that were requested in `response_fields` for field in include_fields : if field not in new_entry [ \"attributes\" ]: new_entry [ \"attributes\" ][ field ] = None new_results . append ( new_entry ) return new_results","title":"handle_response_fields()"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.meta_values","text":"Helper to initialize the meta values Source code in optimade/server/routers/utils.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def meta_values ( url : Union [ urllib . parse . ParseResult , urllib . parse . SplitResult , StarletteURL , str ], data_returned : int , data_available : int , more_data_available : bool , schema : str , ** kwargs , ) -> ResponseMeta : \"\"\"Helper to initialize the meta values\"\"\" from optimade.models import ResponseMetaQuery if isinstance ( url , str ): url = urllib . parse . urlparse ( url ) # To catch all (valid) variations of the version part of the URL, a regex is used if re . match ( r \"/v[0-9]+(\\.[0-9]+){,2}/.*\" , url . path ) is not None : url_path = re . sub ( r \"/v[0-9]+(\\.[0-9]+){,2}/\" , \"/\" , url . path ) else : url_path = url . path return ResponseMeta ( query = ResponseMetaQuery ( representation = f \" { url_path } ? { url . query } \" ), api_version = __api_version__ , time_stamp = datetime . now (), data_returned = data_returned , more_data_available = more_data_available , provider = CONFIG . provider , data_available = data_available , implementation = CONFIG . implementation , schema = schema , ** kwargs , )","title":"meta_values()"},{"location":"api_reference/server/routers/utils/#optimade.server.routers.utils.mongo_id_for_database","text":"Produce a MongoDB ObjectId for a database Source code in optimade/utils.py 18 19 20 21 22 23 24 25 26 27 28 def mongo_id_for_database ( database_id : str , database_type : str ) -> str : \"\"\"Produce a MongoDB ObjectId for a database\"\"\" from bson.objectid import ObjectId oid = f \" { database_id }{ database_type } \" if len ( oid ) > 12 : oid = oid [: 12 ] elif len ( oid ) < 12 : oid = f \" { oid }{ '0' * ( 12 - len ( oid )) } \" return str ( ObjectId ( oid . encode ( \"UTF-8\" )))","title":"mongo_id_for_database()"},{"location":"api_reference/server/routers/versions/","text":"versions \u00b6 get_versions ( request ) \u00b6 Respond with the text/csv representation for the served versions. Source code in optimade/server/routers/versions.py 13 14 15 16 17 18 19 20 21 22 @router . get ( \"/versions\" , tags = [ \"Versions\" ], response_class = CsvResponse , ) def get_versions ( request : Request ) -> CsvResponse : \"\"\"Respond with the text/csv representation for the served versions.\"\"\" version = BASE_URL_PREFIXES [ \"major\" ] . replace ( \"/v\" , \"\" ) response = f \"version \\n { version } \" return CsvResponse ( content = response )","title":"versions"},{"location":"api_reference/server/routers/versions/#versions","text":"","title":"versions"},{"location":"api_reference/server/routers/versions/#optimade.server.routers.versions.get_versions","text":"Respond with the text/csv representation for the served versions. Source code in optimade/server/routers/versions.py 13 14 15 16 17 18 19 20 21 22 @router . get ( \"/versions\" , tags = [ \"Versions\" ], response_class = CsvResponse , ) def get_versions ( request : Request ) -> CsvResponse : \"\"\"Respond with the text/csv representation for the served versions.\"\"\" version = BASE_URL_PREFIXES [ \"major\" ] . replace ( \"/v\" , \"\" ) response = f \"version \\n { version } \" return CsvResponse ( content = response )","title":"get_versions()"},{"location":"api_reference/validator/config/","text":"config \u00b6 This submodule defines constant values and definitions from the OPTIMADE specification for use by the validator. The VALIDATOR_CONFIG object can be imported and modified before calling the validator inside a Python script to customise the hardcoded values. ValidatorConfig \u00b6 This class stores validator config parameters in a way that can be easily modified for testing niche implementations. Many of these fields are determined by the specification directly, but it may be desirable to modify them in certain cases. Source code in optimade/validator/config.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 class ValidatorConfig ( BaseSettings ): \"\"\"This class stores validator config parameters in a way that can be easily modified for testing niche implementations. Many of these fields are determined by the specification directly, but it may be desirable to modify them in certain cases. \"\"\" response_classes : Dict [ str , Any ] = Field ( _RESPONSE_CLASSES , description = \"Dictionary containing the mapping between endpoints and response classes for the main database\" , ) response_classes_index : Dict [ str , Any ] = Field ( _RESPONSE_CLASSES_INDEX , description = \"Dictionary containing the mapping between endpoints and response classes for the index meta-database\" , ) entry_schemas : Dict [ str , Any ] = Field ( _ENTRY_SCHEMAS , description = \"The entry listing endpoint schemas\" ) entry_endpoints : Set [ str ] = Field ( _ENTRY_ENDPOINTS , description = \"The entry endpoints to validate, if present in the API's `/info` response `entry_types_by_format['json']`\" , ) unique_properties : Set [ str ] = Field ( _UNIQUE_PROPERTIES , description = ( \"Fields that should be treated as unique indexes for all endpoints, \" \"i.e. fields on which filters should return at most one entry.\" ), ) inclusive_operators : Dict [ DataType , Set [ str ]] = Field ( _INCLUSIVE_OPERATORS , description = ( \"Dictionary mapping OPTIMADE `DataType`s to a list of operators that are 'inclusive', \" \"i.e. those that should return entries with the matching value from the filter.\" ), ) exclusive_operators : Dict [ DataType , Set [ str ]] = Field ( _EXCLUSIVE_OPERATORS , description = ( \"Dictionary mapping OPTIMADE `DataType`s to a list of operators that are 'exclusive', \" \"i.e. those that should not return entries with the matching value from the filter.\" ), ) field_specific_overrides : Dict [ str , Dict [ SupportLevel , Container [ str ]]] = Field ( _FIELD_SPECIFIC_OVERRIDES , description = ( \"Some fields do not require all type comparison operators to be supported. \" \"This dictionary allows overriding the list of supported operators for a field, using \" \"the field name as a key, and the support level of different operators with a subkey. \" \"Queries on fields listed in this way will pass the validator provided the server returns a 501 status.\" ), ) links_endpoint : str = Field ( \"links\" , description = \"The name of the links endpoint\" ) versions_endpoint : str = Field ( \"versions\" , description = \"The name of the versions endpoint\" ) info_endpoint : str = Field ( \"info\" , description = \"The name of the info endpoint\" ) non_entry_endpoints : Set [ str ] = Field ( _NON_ENTRY_ENDPOINTS , description = \"The list specification-mandated endpoint names that do not contain entries\" , ) top_level_non_attribute_fields : Set [ str ] = Field ( BaseResourceMapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS , description = \"Field names to treat as top-level\" , ) enum_fallback_values : Dict [ str , Dict [ str , List [ str ]]] = Field ( _ENUM_DUMMY_VALUES , description = \"Provide fallback values for enum fields to use when validating filters.\" , )","title":"config"},{"location":"api_reference/validator/config/#config","text":"This submodule defines constant values and definitions from the OPTIMADE specification for use by the validator. The VALIDATOR_CONFIG object can be imported and modified before calling the validator inside a Python script to customise the hardcoded values.","title":"config"},{"location":"api_reference/validator/config/#optimade.validator.config.ValidatorConfig","text":"This class stores validator config parameters in a way that can be easily modified for testing niche implementations. Many of these fields are determined by the specification directly, but it may be desirable to modify them in certain cases. Source code in optimade/validator/config.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 class ValidatorConfig ( BaseSettings ): \"\"\"This class stores validator config parameters in a way that can be easily modified for testing niche implementations. Many of these fields are determined by the specification directly, but it may be desirable to modify them in certain cases. \"\"\" response_classes : Dict [ str , Any ] = Field ( _RESPONSE_CLASSES , description = \"Dictionary containing the mapping between endpoints and response classes for the main database\" , ) response_classes_index : Dict [ str , Any ] = Field ( _RESPONSE_CLASSES_INDEX , description = \"Dictionary containing the mapping between endpoints and response classes for the index meta-database\" , ) entry_schemas : Dict [ str , Any ] = Field ( _ENTRY_SCHEMAS , description = \"The entry listing endpoint schemas\" ) entry_endpoints : Set [ str ] = Field ( _ENTRY_ENDPOINTS , description = \"The entry endpoints to validate, if present in the API's `/info` response `entry_types_by_format['json']`\" , ) unique_properties : Set [ str ] = Field ( _UNIQUE_PROPERTIES , description = ( \"Fields that should be treated as unique indexes for all endpoints, \" \"i.e. fields on which filters should return at most one entry.\" ), ) inclusive_operators : Dict [ DataType , Set [ str ]] = Field ( _INCLUSIVE_OPERATORS , description = ( \"Dictionary mapping OPTIMADE `DataType`s to a list of operators that are 'inclusive', \" \"i.e. those that should return entries with the matching value from the filter.\" ), ) exclusive_operators : Dict [ DataType , Set [ str ]] = Field ( _EXCLUSIVE_OPERATORS , description = ( \"Dictionary mapping OPTIMADE `DataType`s to a list of operators that are 'exclusive', \" \"i.e. those that should not return entries with the matching value from the filter.\" ), ) field_specific_overrides : Dict [ str , Dict [ SupportLevel , Container [ str ]]] = Field ( _FIELD_SPECIFIC_OVERRIDES , description = ( \"Some fields do not require all type comparison operators to be supported. \" \"This dictionary allows overriding the list of supported operators for a field, using \" \"the field name as a key, and the support level of different operators with a subkey. \" \"Queries on fields listed in this way will pass the validator provided the server returns a 501 status.\" ), ) links_endpoint : str = Field ( \"links\" , description = \"The name of the links endpoint\" ) versions_endpoint : str = Field ( \"versions\" , description = \"The name of the versions endpoint\" ) info_endpoint : str = Field ( \"info\" , description = \"The name of the info endpoint\" ) non_entry_endpoints : Set [ str ] = Field ( _NON_ENTRY_ENDPOINTS , description = \"The list specification-mandated endpoint names that do not contain entries\" , ) top_level_non_attribute_fields : Set [ str ] = Field ( BaseResourceMapper . TOP_LEVEL_NON_ATTRIBUTES_FIELDS , description = \"Field names to treat as top-level\" , ) enum_fallback_values : Dict [ str , Dict [ str , List [ str ]]] = Field ( _ENUM_DUMMY_VALUES , description = \"Provide fallback values for enum fields to use when validating filters.\" , )","title":"ValidatorConfig"},{"location":"api_reference/validator/utils/","text":"utils \u00b6 This submodule contains utility methods and models used by the validator. The two main features being: The @test_case decorator can be used to decorate validation methods and performs error handling, output and logging of test successes and failures. The patched Validator versions allow for stricter validation of server responses. The standard response classes allow entries to be provided as bare dictionaries, whilst these patched classes force them to be validated with the corresponding entry models themselves. Client \u00b6 Source code in optimade/validator/utils.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class Client : # pragma: no cover def __init__ ( self , base_url : str , max_retries : int = 5 , headers : Dict [ str , str ] = None , timeout : Optional [ float ] = DEFAULT_CONN_TIMEOUT , read_timeout : Optional [ float ] = DEFAULT_READ_TIMEOUT , ) -> None : \"\"\"Initialises the Client with the given `base_url` without testing if it is valid. Parameters: base_url: the base URL of the optimade implementation, including request protocol (e.g. `'http://'`) and API version number if necessary. Examples: - `'http://example.org/optimade/v1'`, - `'www.crystallography.net/cod-test/optimade/v0.10.0/'` Note: A maximum of one slash (\"/\") is allowed as the last character. max_retries: The maximum number of attempts to make for each query. headers: Dictionary of additional headers to add to every request. timeout: Connection timeout in seconds. read_timeout: Read timeout in seconds. \"\"\" self . base_url = base_url self . last_request = None self . response = None self . max_retries = max_retries self . headers = headers or {} if \"User-Agent\" not in self . headers : self . headers [ \"User-Agent\" ] = DEFAULT_USER_AGENT_STRING self . timeout = timeout or DEFAULT_CONN_TIMEOUT self . read_timeout = read_timeout or DEFAULT_READ_TIMEOUT def get ( self , request : str ): \"\"\"Makes the given request, with a number of retries if being rate limited. The request will be prepended with the `base_url` unless the request appears to be an absolute URL (i.e. starts with `http://` or `https://`). Parameters: request (str): the request to make against the base URL of this client. Returns: response (requests.models.Response): the response from the server. Raises: SystemExit: if there is no response from the server, or if the URL is invalid. ResponseError: if the server does not respond with a non-429 status code within the `MAX_RETRIES` attempts. \"\"\" if urllib . parse . urlparse ( request , allow_fragments = True ) . scheme : self . last_request = request else : if request and not request . startswith ( \"/\" ): request = f \"/ { request } \" self . last_request = f \" { self . base_url }{ request } \" status_code = None retries = 0 errors = [] while retries < self . max_retries : retries += 1 try : self . response = requests . get ( self . last_request , headers = self . headers , timeout = ( self . timeout , self . read_timeout ), ) status_code = self . response . status_code # If we hit a 429 Too Many Requests status, then try again in 1 second if status_code != 429 : return self . response # If the connection times out, retry but cache the error except requests . exceptions . ConnectionError as exc : errors . append ( str ( exc )) # Read timeouts should prevent further retries except requests . exceptions . ReadTimeout as exc : raise ResponseError ( str ( exc )) from exc except requests . exceptions . MissingSchema : sys . exit ( f \"Unable to make request on { self . last_request } , did you mean http:// { self . last_request } ?\" ) # If the connection failed, or returned a 429, then wait 1 second before retrying time . sleep ( 1 ) else : message = f \"Hit max retries ( { self . max_retries } ) on request { self . last_request !r} .\" if errors : error_str = \" \\n\\t \" . join ( errors ) message += f \" \\n Errors: \\n\\t { error_str } \" raise ResponseError ( message ) __init__ ( base_url , max_retries = 5 , headers = None , timeout = DEFAULT_CONN_TIMEOUT , read_timeout = DEFAULT_READ_TIMEOUT ) \u00b6 Initialises the Client with the given base_url without testing if it is valid. Parameters: Name Type Description Default base_url str the base URL of the optimade implementation, including request protocol (e.g. 'http://' ) and API version number if necessary. Examples: 'http://example.org/optimade/v1' , 'www.crystallography.net/cod-test/optimade/v0.10.0/' Note: A maximum of one slash (\"/\") is allowed as the last character. required max_retries int The maximum number of attempts to make for each query. 5 headers Dict [ str , str ] Dictionary of additional headers to add to every request. None timeout Optional [ float ] Connection timeout in seconds. DEFAULT_CONN_TIMEOUT read_timeout Optional [ float ] Read timeout in seconds. DEFAULT_READ_TIMEOUT Source code in optimade/validator/utils.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 def __init__ ( self , base_url : str , max_retries : int = 5 , headers : Dict [ str , str ] = None , timeout : Optional [ float ] = DEFAULT_CONN_TIMEOUT , read_timeout : Optional [ float ] = DEFAULT_READ_TIMEOUT , ) -> None : \"\"\"Initialises the Client with the given `base_url` without testing if it is valid. Parameters: base_url: the base URL of the optimade implementation, including request protocol (e.g. `'http://'`) and API version number if necessary. Examples: - `'http://example.org/optimade/v1'`, - `'www.crystallography.net/cod-test/optimade/v0.10.0/'` Note: A maximum of one slash (\"/\") is allowed as the last character. max_retries: The maximum number of attempts to make for each query. headers: Dictionary of additional headers to add to every request. timeout: Connection timeout in seconds. read_timeout: Read timeout in seconds. \"\"\" self . base_url = base_url self . last_request = None self . response = None self . max_retries = max_retries self . headers = headers or {} if \"User-Agent\" not in self . headers : self . headers [ \"User-Agent\" ] = DEFAULT_USER_AGENT_STRING self . timeout = timeout or DEFAULT_CONN_TIMEOUT self . read_timeout = read_timeout or DEFAULT_READ_TIMEOUT get ( request ) \u00b6 Makes the given request, with a number of retries if being rate limited. The request will be prepended with the base_url unless the request appears to be an absolute URL (i.e. starts with http:// or https:// ). Parameters: Name Type Description Default request str the request to make against the base URL of this client. required Returns: Name Type Description response requests . models . Response the response from the server. Raises: Type Description SystemExit if there is no response from the server, or if the URL is invalid. ResponseError if the server does not respond with a non-429 status code within the MAX_RETRIES attempts. Source code in optimade/validator/utils.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def get ( self , request : str ): \"\"\"Makes the given request, with a number of retries if being rate limited. The request will be prepended with the `base_url` unless the request appears to be an absolute URL (i.e. starts with `http://` or `https://`). Parameters: request (str): the request to make against the base URL of this client. Returns: response (requests.models.Response): the response from the server. Raises: SystemExit: if there is no response from the server, or if the URL is invalid. ResponseError: if the server does not respond with a non-429 status code within the `MAX_RETRIES` attempts. \"\"\" if urllib . parse . urlparse ( request , allow_fragments = True ) . scheme : self . last_request = request else : if request and not request . startswith ( \"/\" ): request = f \"/ { request } \" self . last_request = f \" { self . base_url }{ request } \" status_code = None retries = 0 errors = [] while retries < self . max_retries : retries += 1 try : self . response = requests . get ( self . last_request , headers = self . headers , timeout = ( self . timeout , self . read_timeout ), ) status_code = self . response . status_code # If we hit a 429 Too Many Requests status, then try again in 1 second if status_code != 429 : return self . response # If the connection times out, retry but cache the error except requests . exceptions . ConnectionError as exc : errors . append ( str ( exc )) # Read timeouts should prevent further retries except requests . exceptions . ReadTimeout as exc : raise ResponseError ( str ( exc )) from exc except requests . exceptions . MissingSchema : sys . exit ( f \"Unable to make request on { self . last_request } , did you mean http:// { self . last_request } ?\" ) # If the connection failed, or returned a 429, then wait 1 second before retrying time . sleep ( 1 ) else : message = f \"Hit max retries ( { self . max_retries } ) on request { self . last_request !r} .\" if errors : error_str = \" \\n\\t \" . join ( errors ) message += f \" \\n Errors: \\n\\t { error_str } \" raise ResponseError ( message ) InternalError \u00b6 This exception should be raised when validation throws an unexpected error. These should be counted separately from ResponseError 's and ValidationError 's. Source code in optimade/validator/utils.py 51 52 53 54 55 class InternalError ( Exception ): \"\"\"This exception should be raised when validation throws an unexpected error. These should be counted separately from `ResponseError`'s and `ValidationError`'s. \"\"\" ResponseError \u00b6 This exception should be raised for a manual hardcoded test failure. Source code in optimade/validator/utils.py 47 48 class ResponseError ( Exception ): \"\"\"This exception should be raised for a manual hardcoded test failure.\"\"\" print_failure ( string , ** kwargs ) \u00b6 Print but sad. Source code in optimade/validator/utils.py 68 69 70 def print_failure ( string , ** kwargs ): \"\"\"Print but sad.\"\"\" print ( f \" \\033 [91m \\033 [1m { string } \\033 [0m\" , ** kwargs ) print_notify ( string , ** kwargs ) \u00b6 Print but louder. Source code in optimade/validator/utils.py 63 64 65 def print_notify ( string , ** kwargs ): \"\"\"Print but louder.\"\"\" print ( f \" \\033 [94m \\033 [1m { string } \\033 [0m\" , ** kwargs ) print_success ( string , ** kwargs ) \u00b6 Print but happy. Source code in optimade/validator/utils.py 73 74 75 def print_success ( string , ** kwargs ): \"\"\"Print but happy.\"\"\" print ( f \" \\033 [92m \\033 [1m { string } \\033 [0m\" , ** kwargs ) print_warning ( string , ** kwargs ) \u00b6 Print but angry. Source code in optimade/validator/utils.py 58 59 60 def print_warning ( string , ** kwargs ): \"\"\"Print but angry.\"\"\" print ( f \" \\033 [93m { string } \\033 [0m\" , ** kwargs ) test_case ( test_fn ) \u00b6 Wrapper for test case functions, which pretty-prints any errors depending on verbosity level, collates the number and severity of test failures, returns the response and summary string to the caller. Any additional positional or keyword arguments are passed directly to test_fn . The wrapper will intercept the named arguments optional , multistage and request and interpret them according to the docstring for wrapper(...) below. Parameters: Name Type Description Default test_fn Callable [[ Any ], Tuple [ Any , str ]] Any function that returns an object and a message to print upon success. The function should raise a ResponseError , ValidationError or a ManualValidationError if the test case has failed. The function can return None to indicate that the test was not appropriate and should be ignored. required Source code in optimade/validator/utils.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 def test_case ( test_fn : Callable [[ Any ], Tuple [ Any , str ]]): \"\"\"Wrapper for test case functions, which pretty-prints any errors depending on verbosity level, collates the number and severity of test failures, returns the response and summary string to the caller. Any additional positional or keyword arguments are passed directly to `test_fn`. The wrapper will intercept the named arguments `optional`, `multistage` and `request` and interpret them according to the docstring for `wrapper(...)` below. Parameters: test_fn: Any function that returns an object and a message to print upon success. The function should raise a `ResponseError`, `ValidationError` or a `ManualValidationError` if the test case has failed. The function can return `None` to indicate that the test was not appropriate and should be ignored. \"\"\" from functools import wraps @wraps ( test_fn ) def wrapper ( validator , * args , request : str = None , optional : bool = False , multistage : bool = False , ** kwargs , ): \"\"\"Wraps a function or validator method and handles success, failure and output depending on the keyword arguments passed. Arguments: validator: The validator object to accumulate errors/counters. *args: Positional arguments passed to the test function. request: Description of the request made by the wrapped function (e.g. a URL or a summary). optional: Whether or not to treat the test as optional. multistage: If `True`, no output will be printed for this test, and it will not increment the success counter. Errors will be handled in the normal way. This can be used to avoid flooding the output for mutli-stage tests. **kwargs: Extra named arguments passed to the test function. \"\"\" try : try : if optional and not validator . run_optional_tests : result = None msg = \"skipping optional\" else : result , msg = test_fn ( validator , * args , ** kwargs ) except ( json . JSONDecodeError , ResponseError , ValidationError ) as exc : msg = f \" { exc . __class__ . __name__ } : { exc } \" raise exc except Exception as exc : msg = f \" { exc . __class__ . __name__ } : { exc } \" raise InternalError ( msg ) # Catch SystemExit and KeyboardInterrupt explicitly so that we can pass # them to the finally block, where they are immediately raised except ( Exception , SystemExit , KeyboardInterrupt ) as exc : result = exc traceback = tb . format_exc () finally : # This catches the case of the Client throwing a SystemExit if the server # did not respond, the case of the validator \"fail-fast\"'ing and throwing # a SystemExit below, and the case of the user interrupting the process manually if isinstance ( result , ( SystemExit , KeyboardInterrupt )): raise result display_request = None try : display_request = validator . client . last_request except AttributeError : pass if display_request is None : display_request = validator . base_url if request is not None : display_request += \"/\" + request request = display_request # If the result was None, return it here and ignore statuses if result is None : return result , msg if not isinstance ( result , Exception ): if not multistage : success_type = \"optional\" if optional else None validator . results . add_success ( f \" { request } - { msg } \" , success_type ) else : request = request . replace ( \" \\n \" , \"\" ) message = msg . split ( \" \\n \" ) if validator . verbosity > 1 : # ValidationErrors from pydantic already include very detailed errors # that get duplicated in the traceback if not isinstance ( result , ValidationError ): message += traceback . split ( \" \\n \" ) message = \" \\n \" . join ( message ) if isinstance ( result , InternalError ): summary = ( f \" { request } - { test_fn . __name__ } - failed with internal error\" ) failure_type = \"internal\" else : summary = f \" { request } - { test_fn . __name__ } - failed with error\" failure_type = \"optional\" if optional else None validator . results . add_failure ( summary , message , failure_type = failure_type ) # set failure result to None as this is expected by other functions result = None if validator . fail_fast and not optional : validator . print_summary () raise SystemExit # Reset the client request so that it can be properly # displayed if the next request fails if not multistage : validator . client . last_request = None return result , msg return wrapper","title":"utils"},{"location":"api_reference/validator/utils/#utils","text":"This submodule contains utility methods and models used by the validator. The two main features being: The @test_case decorator can be used to decorate validation methods and performs error handling, output and logging of test successes and failures. The patched Validator versions allow for stricter validation of server responses. The standard response classes allow entries to be provided as bare dictionaries, whilst these patched classes force them to be validated with the corresponding entry models themselves.","title":"utils"},{"location":"api_reference/validator/utils/#optimade.validator.utils.Client","text":"Source code in optimade/validator/utils.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 class Client : # pragma: no cover def __init__ ( self , base_url : str , max_retries : int = 5 , headers : Dict [ str , str ] = None , timeout : Optional [ float ] = DEFAULT_CONN_TIMEOUT , read_timeout : Optional [ float ] = DEFAULT_READ_TIMEOUT , ) -> None : \"\"\"Initialises the Client with the given `base_url` without testing if it is valid. Parameters: base_url: the base URL of the optimade implementation, including request protocol (e.g. `'http://'`) and API version number if necessary. Examples: - `'http://example.org/optimade/v1'`, - `'www.crystallography.net/cod-test/optimade/v0.10.0/'` Note: A maximum of one slash (\"/\") is allowed as the last character. max_retries: The maximum number of attempts to make for each query. headers: Dictionary of additional headers to add to every request. timeout: Connection timeout in seconds. read_timeout: Read timeout in seconds. \"\"\" self . base_url = base_url self . last_request = None self . response = None self . max_retries = max_retries self . headers = headers or {} if \"User-Agent\" not in self . headers : self . headers [ \"User-Agent\" ] = DEFAULT_USER_AGENT_STRING self . timeout = timeout or DEFAULT_CONN_TIMEOUT self . read_timeout = read_timeout or DEFAULT_READ_TIMEOUT def get ( self , request : str ): \"\"\"Makes the given request, with a number of retries if being rate limited. The request will be prepended with the `base_url` unless the request appears to be an absolute URL (i.e. starts with `http://` or `https://`). Parameters: request (str): the request to make against the base URL of this client. Returns: response (requests.models.Response): the response from the server. Raises: SystemExit: if there is no response from the server, or if the URL is invalid. ResponseError: if the server does not respond with a non-429 status code within the `MAX_RETRIES` attempts. \"\"\" if urllib . parse . urlparse ( request , allow_fragments = True ) . scheme : self . last_request = request else : if request and not request . startswith ( \"/\" ): request = f \"/ { request } \" self . last_request = f \" { self . base_url }{ request } \" status_code = None retries = 0 errors = [] while retries < self . max_retries : retries += 1 try : self . response = requests . get ( self . last_request , headers = self . headers , timeout = ( self . timeout , self . read_timeout ), ) status_code = self . response . status_code # If we hit a 429 Too Many Requests status, then try again in 1 second if status_code != 429 : return self . response # If the connection times out, retry but cache the error except requests . exceptions . ConnectionError as exc : errors . append ( str ( exc )) # Read timeouts should prevent further retries except requests . exceptions . ReadTimeout as exc : raise ResponseError ( str ( exc )) from exc except requests . exceptions . MissingSchema : sys . exit ( f \"Unable to make request on { self . last_request } , did you mean http:// { self . last_request } ?\" ) # If the connection failed, or returned a 429, then wait 1 second before retrying time . sleep ( 1 ) else : message = f \"Hit max retries ( { self . max_retries } ) on request { self . last_request !r} .\" if errors : error_str = \" \\n\\t \" . join ( errors ) message += f \" \\n Errors: \\n\\t { error_str } \" raise ResponseError ( message )","title":"Client"},{"location":"api_reference/validator/utils/#optimade.validator.utils.Client.__init__","text":"Initialises the Client with the given base_url without testing if it is valid. Parameters: Name Type Description Default base_url str the base URL of the optimade implementation, including request protocol (e.g. 'http://' ) and API version number if necessary. Examples: 'http://example.org/optimade/v1' , 'www.crystallography.net/cod-test/optimade/v0.10.0/' Note: A maximum of one slash (\"/\") is allowed as the last character. required max_retries int The maximum number of attempts to make for each query. 5 headers Dict [ str , str ] Dictionary of additional headers to add to every request. None timeout Optional [ float ] Connection timeout in seconds. DEFAULT_CONN_TIMEOUT read_timeout Optional [ float ] Read timeout in seconds. DEFAULT_READ_TIMEOUT Source code in optimade/validator/utils.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 def __init__ ( self , base_url : str , max_retries : int = 5 , headers : Dict [ str , str ] = None , timeout : Optional [ float ] = DEFAULT_CONN_TIMEOUT , read_timeout : Optional [ float ] = DEFAULT_READ_TIMEOUT , ) -> None : \"\"\"Initialises the Client with the given `base_url` without testing if it is valid. Parameters: base_url: the base URL of the optimade implementation, including request protocol (e.g. `'http://'`) and API version number if necessary. Examples: - `'http://example.org/optimade/v1'`, - `'www.crystallography.net/cod-test/optimade/v0.10.0/'` Note: A maximum of one slash (\"/\") is allowed as the last character. max_retries: The maximum number of attempts to make for each query. headers: Dictionary of additional headers to add to every request. timeout: Connection timeout in seconds. read_timeout: Read timeout in seconds. \"\"\" self . base_url = base_url self . last_request = None self . response = None self . max_retries = max_retries self . headers = headers or {} if \"User-Agent\" not in self . headers : self . headers [ \"User-Agent\" ] = DEFAULT_USER_AGENT_STRING self . timeout = timeout or DEFAULT_CONN_TIMEOUT self . read_timeout = read_timeout or DEFAULT_READ_TIMEOUT","title":"__init__()"},{"location":"api_reference/validator/utils/#optimade.validator.utils.Client.get","text":"Makes the given request, with a number of retries if being rate limited. The request will be prepended with the base_url unless the request appears to be an absolute URL (i.e. starts with http:// or https:// ). Parameters: Name Type Description Default request str the request to make against the base URL of this client. required Returns: Name Type Description response requests . models . Response the response from the server. Raises: Type Description SystemExit if there is no response from the server, or if the URL is invalid. ResponseError if the server does not respond with a non-429 status code within the MAX_RETRIES attempts. Source code in optimade/validator/utils.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def get ( self , request : str ): \"\"\"Makes the given request, with a number of retries if being rate limited. The request will be prepended with the `base_url` unless the request appears to be an absolute URL (i.e. starts with `http://` or `https://`). Parameters: request (str): the request to make against the base URL of this client. Returns: response (requests.models.Response): the response from the server. Raises: SystemExit: if there is no response from the server, or if the URL is invalid. ResponseError: if the server does not respond with a non-429 status code within the `MAX_RETRIES` attempts. \"\"\" if urllib . parse . urlparse ( request , allow_fragments = True ) . scheme : self . last_request = request else : if request and not request . startswith ( \"/\" ): request = f \"/ { request } \" self . last_request = f \" { self . base_url }{ request } \" status_code = None retries = 0 errors = [] while retries < self . max_retries : retries += 1 try : self . response = requests . get ( self . last_request , headers = self . headers , timeout = ( self . timeout , self . read_timeout ), ) status_code = self . response . status_code # If we hit a 429 Too Many Requests status, then try again in 1 second if status_code != 429 : return self . response # If the connection times out, retry but cache the error except requests . exceptions . ConnectionError as exc : errors . append ( str ( exc )) # Read timeouts should prevent further retries except requests . exceptions . ReadTimeout as exc : raise ResponseError ( str ( exc )) from exc except requests . exceptions . MissingSchema : sys . exit ( f \"Unable to make request on { self . last_request } , did you mean http:// { self . last_request } ?\" ) # If the connection failed, or returned a 429, then wait 1 second before retrying time . sleep ( 1 ) else : message = f \"Hit max retries ( { self . max_retries } ) on request { self . last_request !r} .\" if errors : error_str = \" \\n\\t \" . join ( errors ) message += f \" \\n Errors: \\n\\t { error_str } \" raise ResponseError ( message )","title":"get()"},{"location":"api_reference/validator/utils/#optimade.validator.utils.InternalError","text":"This exception should be raised when validation throws an unexpected error. These should be counted separately from ResponseError 's and ValidationError 's. Source code in optimade/validator/utils.py 51 52 53 54 55 class InternalError ( Exception ): \"\"\"This exception should be raised when validation throws an unexpected error. These should be counted separately from `ResponseError`'s and `ValidationError`'s. \"\"\"","title":"InternalError"},{"location":"api_reference/validator/utils/#optimade.validator.utils.ResponseError","text":"This exception should be raised for a manual hardcoded test failure. Source code in optimade/validator/utils.py 47 48 class ResponseError ( Exception ): \"\"\"This exception should be raised for a manual hardcoded test failure.\"\"\"","title":"ResponseError"},{"location":"api_reference/validator/utils/#optimade.validator.utils.print_failure","text":"Print but sad. Source code in optimade/validator/utils.py 68 69 70 def print_failure ( string , ** kwargs ): \"\"\"Print but sad.\"\"\" print ( f \" \\033 [91m \\033 [1m { string } \\033 [0m\" , ** kwargs )","title":"print_failure()"},{"location":"api_reference/validator/utils/#optimade.validator.utils.print_notify","text":"Print but louder. Source code in optimade/validator/utils.py 63 64 65 def print_notify ( string , ** kwargs ): \"\"\"Print but louder.\"\"\" print ( f \" \\033 [94m \\033 [1m { string } \\033 [0m\" , ** kwargs )","title":"print_notify()"},{"location":"api_reference/validator/utils/#optimade.validator.utils.print_success","text":"Print but happy. Source code in optimade/validator/utils.py 73 74 75 def print_success ( string , ** kwargs ): \"\"\"Print but happy.\"\"\" print ( f \" \\033 [92m \\033 [1m { string } \\033 [0m\" , ** kwargs )","title":"print_success()"},{"location":"api_reference/validator/utils/#optimade.validator.utils.print_warning","text":"Print but angry. Source code in optimade/validator/utils.py 58 59 60 def print_warning ( string , ** kwargs ): \"\"\"Print but angry.\"\"\" print ( f \" \\033 [93m { string } \\033 [0m\" , ** kwargs )","title":"print_warning()"},{"location":"api_reference/validator/utils/#optimade.validator.utils.test_case","text":"Wrapper for test case functions, which pretty-prints any errors depending on verbosity level, collates the number and severity of test failures, returns the response and summary string to the caller. Any additional positional or keyword arguments are passed directly to test_fn . The wrapper will intercept the named arguments optional , multistage and request and interpret them according to the docstring for wrapper(...) below. Parameters: Name Type Description Default test_fn Callable [[ Any ], Tuple [ Any , str ]] Any function that returns an object and a message to print upon success. The function should raise a ResponseError , ValidationError or a ManualValidationError if the test case has failed. The function can return None to indicate that the test was not appropriate and should be ignored. required Source code in optimade/validator/utils.py 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 def test_case ( test_fn : Callable [[ Any ], Tuple [ Any , str ]]): \"\"\"Wrapper for test case functions, which pretty-prints any errors depending on verbosity level, collates the number and severity of test failures, returns the response and summary string to the caller. Any additional positional or keyword arguments are passed directly to `test_fn`. The wrapper will intercept the named arguments `optional`, `multistage` and `request` and interpret them according to the docstring for `wrapper(...)` below. Parameters: test_fn: Any function that returns an object and a message to print upon success. The function should raise a `ResponseError`, `ValidationError` or a `ManualValidationError` if the test case has failed. The function can return `None` to indicate that the test was not appropriate and should be ignored. \"\"\" from functools import wraps @wraps ( test_fn ) def wrapper ( validator , * args , request : str = None , optional : bool = False , multistage : bool = False , ** kwargs , ): \"\"\"Wraps a function or validator method and handles success, failure and output depending on the keyword arguments passed. Arguments: validator: The validator object to accumulate errors/counters. *args: Positional arguments passed to the test function. request: Description of the request made by the wrapped function (e.g. a URL or a summary). optional: Whether or not to treat the test as optional. multistage: If `True`, no output will be printed for this test, and it will not increment the success counter. Errors will be handled in the normal way. This can be used to avoid flooding the output for mutli-stage tests. **kwargs: Extra named arguments passed to the test function. \"\"\" try : try : if optional and not validator . run_optional_tests : result = None msg = \"skipping optional\" else : result , msg = test_fn ( validator , * args , ** kwargs ) except ( json . JSONDecodeError , ResponseError , ValidationError ) as exc : msg = f \" { exc . __class__ . __name__ } : { exc } \" raise exc except Exception as exc : msg = f \" { exc . __class__ . __name__ } : { exc } \" raise InternalError ( msg ) # Catch SystemExit and KeyboardInterrupt explicitly so that we can pass # them to the finally block, where they are immediately raised except ( Exception , SystemExit , KeyboardInterrupt ) as exc : result = exc traceback = tb . format_exc () finally : # This catches the case of the Client throwing a SystemExit if the server # did not respond, the case of the validator \"fail-fast\"'ing and throwing # a SystemExit below, and the case of the user interrupting the process manually if isinstance ( result , ( SystemExit , KeyboardInterrupt )): raise result display_request = None try : display_request = validator . client . last_request except AttributeError : pass if display_request is None : display_request = validator . base_url if request is not None : display_request += \"/\" + request request = display_request # If the result was None, return it here and ignore statuses if result is None : return result , msg if not isinstance ( result , Exception ): if not multistage : success_type = \"optional\" if optional else None validator . results . add_success ( f \" { request } - { msg } \" , success_type ) else : request = request . replace ( \" \\n \" , \"\" ) message = msg . split ( \" \\n \" ) if validator . verbosity > 1 : # ValidationErrors from pydantic already include very detailed errors # that get duplicated in the traceback if not isinstance ( result , ValidationError ): message += traceback . split ( \" \\n \" ) message = \" \\n \" . join ( message ) if isinstance ( result , InternalError ): summary = ( f \" { request } - { test_fn . __name__ } - failed with internal error\" ) failure_type = \"internal\" else : summary = f \" { request } - { test_fn . __name__ } - failed with error\" failure_type = \"optional\" if optional else None validator . results . add_failure ( summary , message , failure_type = failure_type ) # set failure result to None as this is expected by other functions result = None if validator . fail_fast and not optional : validator . print_summary () raise SystemExit # Reset the client request so that it can be properly # displayed if the next request fails if not multistage : validator . client . last_request = None return result , msg return wrapper","title":"test_case()"},{"location":"api_reference/validator/validator/","text":"validator \u00b6 This module contains the ImplementationValidator class that can be pointed at an OPTIMADE implementation and validated against the specification via the pydantic models implemented in this package. ImplementationValidator \u00b6 Class used to make a series of checks against a particular OPTIMADE implementation over HTTP. Uses the pydantic models in optimade.models to validate the response from the server and crawl through the available endpoints. Attributes: Name Type Description valid whether or not the implementation was deemed valid, with None signifying that tests did not run. Caution Only works for current version of the specification as defined by optimade.models . Source code in optimade/validator/validator.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 class ImplementationValidator : \"\"\"Class used to make a series of checks against a particular OPTIMADE implementation over HTTP. Uses the pydantic models in [`optimade.models`][optimade.models] to validate the response from the server and crawl through the available endpoints. Attributes: valid: whether or not the implementation was deemed valid, with `None` signifying that tests did not run. Caution: Only works for current version of the specification as defined by [`optimade.models`][optimade.models]. \"\"\" valid : Optional [ bool ] def __init__ ( # pylint: disable=too-many-arguments self , client : Any = None , base_url : str = None , verbosity : int = 0 , respond_json : bool = False , page_limit : int = 4 , max_retries : int = 5 , run_optional_tests : bool = True , fail_fast : bool = False , as_type : str = None , index : bool = False , minimal : bool = False , http_headers : Dict [ str , str ] = None , timeout : float = DEFAULT_CONN_TIMEOUT , read_timeout : float = DEFAULT_READ_TIMEOUT , ): \"\"\"Set up the tests to run, based on constants in this module for required endpoints. Arguments: client: A client that has a `.get()` method to obtain the response from the implementation. If `None`, then [`Client`][optimade.validator.utils.Client] will be used. base_url: The URL of the implementation to validate. Unless performing \"as_type\" validation, this should point to the base of the OPTIMADE implementation. verbosity: The verbosity of the output and logging as an integer (`0`: critical, `1`: warning, `2`: info, `3`: debug). respond_json: If `True`, print only a JSON representation of the results of validation to stdout. page_limit: The default page limit to apply to filters. max_retries: Argument is passed to the client for how many attempts to make for a request before failing. run_optional_tests: Whether to run the tests on optional OPTIMADE features. fail_fast: Whether to exit validation after the first failure of a mandatory test. as_type: An OPTIMADE entry or endpoint type to coerce the response from implementation into, e.g. \"structures\". Requires `base_url` to be pointed to the corresponding endpoint. index: Whether to validate the implementation as an index meta-database. minimal: Whether or not to run only a minimal test set. http_headers: Dictionary of additional headers to add to every request. timeout: The connection timeout to use for all requests (in seconds). read_timeout: The read timeout to use for all requests (in seconds). \"\"\" self . verbosity = verbosity self . max_retries = max_retries self . page_limit = page_limit self . index = index self . run_optional_tests = run_optional_tests self . fail_fast = fail_fast self . respond_json = respond_json self . minimal = minimal if as_type is None : self . as_type_cls = None elif self . index : if as_type not in CONF . response_classes_index : raise RuntimeError ( f \"Provided as_type=' { as_type } ' not allowed for an Index meta-database.\" ) self . as_type_cls = CONF . response_classes_index [ as_type ] elif as_type in ( \"structure\" , \"reference\" ): self . as_type_cls = CONF . response_classes [ f \" { as_type } s/\" ] else : self . as_type_cls = CONF . response_classes [ as_type ] if client is None and base_url is None : raise RuntimeError ( \"Need at least a URL or a client to initialize validator.\" ) if base_url and client : raise RuntimeError ( \"Please specify at most one of base_url or client.\" ) if client : self . client = client self . base_url = self . client . base_url # If a custom client has been provided, try to set custom headers if they have been specified, # but do not overwrite any existing attributes if http_headers : if not hasattr ( self . client , \"headers\" ): self . client . headers = http_headers else : print_warning ( f \"Not using specified request headers { http_headers } with custom client { self . client } .\" ) else : while base_url . endswith ( \"/\" ): base_url = base_url [: - 1 ] self . base_url = base_url self . client = Client ( base_url , max_retries = self . max_retries , headers = http_headers , timeout = timeout , read_timeout = read_timeout , ) self . _setup_log () self . _response_classes = ( CONF . response_classes_index if self . index else CONF . response_classes ) # some simple checks on base_url self . base_url_parsed = urllib . parse . urlparse ( self . base_url ) # only allow filters/endpoints if we are working in \"as_type\" mode if self . as_type_cls is None and self . base_url_parsed . query : raise SystemExit ( \"Base URL not appropriate: should not contain a filter.\" ) self . valid = None self . _test_id_by_type = {} self . _entry_info_by_type = {} self . results = ValidatorResults ( verbosity = self . verbosity ) def _setup_log ( self ): \"\"\"Define stdout log based on given verbosity.\"\"\" self . _log = logging . getLogger ( \"optimade\" ) . getChild ( \"validator\" ) self . _log . handlers = [] stdout_handler = logging . StreamHandler ( sys . stdout ) stdout_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(name)s | %(levelname)8s : %(message)s \" ) ) if not self . respond_json : self . _log . addHandler ( stdout_handler ) else : self . verbosity = - 1 if self . verbosity == 0 : self . _log . setLevel ( logging . CRITICAL ) elif self . verbosity == 1 : self . _log . setLevel ( logging . WARNING ) elif self . verbosity == 2 : self . _log . setLevel ( logging . INFO ) elif self . verbosity > 0 : self . _log . setLevel ( logging . DEBUG ) def print_summary ( self ): \"\"\"Print a summary of the results of validation.\"\"\" if self . respond_json : print ( json . dumps ( dataclasses . asdict ( self . results ), indent = 2 )) return if self . results . failure_messages : print ( \" \\n\\n FAILURES\" ) print ( \"======== \\n \" ) for message in self . results . failure_messages : print_failure ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . optional_failure_messages : print ( \" \\n\\n OPTIONAL TEST FAILURES\" ) print ( \"====================== \\n \" ) for message in self . results . optional_failure_messages : print_notify ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . internal_failure_messages : print ( \" \\n\\n INTERNAL FAILURES\" ) print ( \"================= \\n \" ) print ( \"There were internal validator failures associated with this run. \\n \" \"If this problem persists, please report it at: \\n \" \"https://github.com/Materials-Consortia/optimade-python-tools/issues/new \\n \" ) for message in self . results . internal_failure_messages : print_warning ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . valid or ( not self . valid and not self . fail_fast ): final_message = f \" \\n\\n Passed { self . results . success_count } out of { self . results . success_count + self . results . failure_count + self . results . internal_failure_count } tests.\" if not self . valid : print_failure ( final_message ) else : print_success ( final_message ) if self . run_optional_tests and not self . fail_fast : print ( f \"Additionally passed { self . results . optional_success_count } out of \" f \" { self . results . optional_success_count + self . results . optional_failure_count } optional tests.\" ) def validate_implementation ( self ): \"\"\"Run all the test cases on the implementation, or the single type test, depending on what options were provided on initialiation. Sets the `self.valid` attribute to `True` or `False` depending on the outcome of the tests. Raises: RuntimeError: If it was not possible to start the validation process. \"\"\" # If a single \"as type\" has been set, only run that test if self . as_type_cls is not None : self . _log . debug ( \"Validating response of %s with model %s \" , self . base_url , self . as_type_cls , ) self . _test_as_type () self . valid = not bool ( self . results . failure_count ) self . print_summary () return # Test entire implementation if self . verbosity >= 0 : print ( f \"Testing entire implementation at { self . base_url } \" ) info_endp = CONF . info_endpoint self . _log . debug ( \"Testing base info endpoint of %s \" , info_endp ) # Get and validate base info to find endpoints # If this is not possible, then exit at this stage base_info = self . _test_info_or_links_endpoint ( info_endp ) if not base_info : self . _log . critical ( f \"Unable to deserialize response from introspective { info_endp !r} endpoint. \" \"This is required for all further validation, so the validator will now exit.\" ) # Set valid to False to ensure error code 1 is raised at CLI self . valid = False self . print_summary () return # Grab the provider prefix from base info and use it when looking for provider fields self . provider_prefix = None meta = base_info . get ( \"meta\" , {}) if meta . get ( \"provider\" ) is not None : self . provider_prefix = meta [ \"provider\" ] . get ( \"prefix\" ) # Set the response class for all `/info/entry` endpoints based on `/info` response self . available_json_endpoints , _ = self . _get_available_endpoints ( base_info , request = info_endp ) for endp in self . available_json_endpoints : self . _response_classes [ f \" { info_endp } / { endp } \" ] = EntryInfoResponse # Run some tests on the versions endpoint self . _log . debug ( \"Testing versions endpoint %s \" , CONF . versions_endpoint ) self . _test_versions_endpoint () self . _test_bad_version_returns_553 () # Test that entry info endpoints deserialize correctly # If they do not, the corresponding entry in _entry_info_by_type # is set to False, which must be checked for further validation for endp in self . available_json_endpoints : entry_info_endpoint = f \" { info_endp } / { endp } \" self . _log . debug ( \"Testing expected info endpoint %s \" , entry_info_endpoint ) self . _entry_info_by_type [ endp ] = self . _test_info_or_links_endpoint ( entry_info_endpoint ) # Test that the results from multi-entry-endpoints obey, e.g. page limits, # and that all entries can be deserialized with the patched models. # These methods also set the test_ids for each type of entry, which are validated # in the next loop. for endp in self . available_json_endpoints : self . _log . debug ( \"Testing multiple entry endpoint of %s \" , endp ) self . _test_multi_entry_endpoint ( endp ) # Test that the single IDs scraped earlier work with the single entry endpoint for endp in self . available_json_endpoints : self . _log . debug ( \"Testing single entry request of type %s \" , endp ) self . _test_single_entry_endpoint ( endp ) # Use the _entry_info_by_type to construct filters on the relevant endpoints if not self . minimal : for endp in self . available_json_endpoints : self . _log . debug ( \"Testing queries on JSON entry endpoint of %s \" , endp ) self . _recurse_through_endpoint ( endp ) # Test that the links endpoint can be serialized correctly self . _log . debug ( \"Testing %s endpoint\" , CONF . links_endpoint ) self . _test_info_or_links_endpoint ( CONF . links_endpoint ) self . valid = not ( self . results . failure_count or self . results . internal_failure_count ) self . print_summary () @test_case def _recurse_through_endpoint ( self , endp : str ) -> Tuple [ bool , str ]: \"\"\"For a given endpoint (`endp`), get the entry type and supported fields, testing that all mandatory fields are supported, then test queries on every property according to the reported type, with optionality decided by the specification-level support level for that field. Parameters: endp: Endpoint to be tested. Returns: `True` if endpoint passed the tests, and a string summary. \"\"\" entry_info = self . _entry_info_by_type . get ( endp ) if not entry_info : raise ResponseError ( f \"Unable to generate filters for endpoint { endp } : 'info/ { endp } ' response was malformed.\" ) _impl_properties = self . _check_entry_info ( entry_info , endp ) prop_list = list ( _impl_properties . keys ()) self . _check_response_fields ( endp , prop_list ) chosen_entry , _ = self . _get_archetypal_entry ( endp , prop_list ) if not chosen_entry : return ( None , f \"Unable to generate filters for endpoint { endp } : no valid entries found.\" , ) for prop in _impl_properties : # check support level of property prop_type = _impl_properties [ prop ][ \"type\" ] sortable = _impl_properties [ prop ][ \"sortable\" ] optional = ( CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"queryable\" ) == SupportLevel . OPTIONAL ) if optional and not self . run_optional_tests : continue self . _construct_queries_for_property ( prop , prop_type , sortable , endp , chosen_entry , request = f \"; testing queries for { endp } -> { prop } \" , optional = optional , ) self . _test_unknown_provider_property ( endp ) self . _test_completely_unknown_property ( endp ) return True , f \"successfully recursed through endpoint { endp } .\" @test_case def _test_completely_unknown_property ( self , endp ): request = f \" { endp } ?filter=crazyfield = 2\" response , _ = self . _get_endpoint ( request , expected_status_code = 400 , ) return True , \"unknown field returned 400 Bad Request, as expected\" @test_case def _test_unknown_provider_property ( self , endp ): dummy_provider_field = \"_crazyprovider_field\" request = f \" { endp } ?filter= { dummy_provider_field } =2\" response , _ = self . _get_endpoint ( request , multistage = True , request = request , ) if response is not None : deserialized , _ = self . _deserialize_response ( response , CONF . response_classes [ endp ], request = request , multistage = True ) return ( True , \"Unknown provider field was ignored when filtering, as expected\" , ) raise ResponseError ( \"Failed to handle field from unknown provider; should return without affecting filter results\" ) def _check_entry_info ( self , entry_info : Dict [ str , Any ], endp : str ) -> List [ str ]: \"\"\"Checks that `entry_info` contains all the required properties, and returns the property list for the endpoint. Parameters: entry_info: JSON representation of the response from the entry info endpoint. endp: The name of the entry endpoint. Returns: The list of property names supported by this implementation. \"\"\" properties = entry_info . get ( \"data\" , {}) . get ( \"properties\" , []) self . _test_must_properties ( properties , endp , request = f \" { CONF . info_endpoint } / { endp } \" ) return properties @test_case def _test_must_properties ( self , properties : List [ str ], endp : str ) -> Tuple [ bool , str ]: \"\"\"Check that the entry info lists all properties with the \"MUST\" support level for this endpoint. Parameters: properties: The list of property names supported by the endpoint. endp: The endpoint. Returns: `True` if the properties were found, and a string summary. \"\"\" must_props = set ( prop for prop in CONF . entry_schemas . get ( endp , {}) if CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"support\" ) == SupportLevel . MUST ) must_props_supported = set ( prop for prop in properties if prop in must_props ) missing = must_props - must_props_supported if len ( missing ) != 0 : raise ResponseError ( f \"Some 'MUST' properties were missing from info/ { endp } : { missing } \" ) return True , f \"Found all required properties in entry info for endpoint { endp } \" @test_case def _get_archetypal_entry ( self , endp : str , properties : List [ str ] ) -> Tuple [ Dict [ str , Any ], str ]: \"\"\"Get a random entry from the first page of results for this endpoint. Parameters: endp: The endpoint to query. Returns: The JSON representation of the chosen entry and the summary message. \"\"\" response , message = self . _get_endpoint ( endp , multistage = True ) if response : data = response . json () . get ( \"data\" , []) data_returned = len ( data ) if data_returned < 1 : return ( None , \"Endpoint {endp!r} returned no entries, cannot get archetypal entry or test filtering.\" , ) archetypal_entry = response . json ()[ \"data\" ][ random . randint ( 0 , data_returned - 1 ) ] return ( archetypal_entry , f \"set archetypal entry for { endp } with ID { archetypal_entry [ 'id' ] } .\" , ) raise ResponseError ( f \"Failed to get archetypal entry. Details: { message } \" ) @test_case def _check_response_fields ( self , endp : str , fields : List [ str ]) -> Tuple [ bool , str ]: \"\"\"Check that the response field query parameter is obeyed. Parameters: endp: The endpoint to query. fields: The known fields for this endpoint to test. Returns: Bool indicating success and a summary message. \"\"\" subset_fields = random . sample ( fields , min ( len ( fields ) - 1 , 3 )) test_query = f \" { endp } ?response_fields= { ',' . join ( subset_fields ) } &page_limit=1\" response , _ = self . _get_endpoint ( test_query , multistage = True ) if response and len ( response . json ()[ \"data\" ]) >= 0 : doc = response . json ()[ \"data\" ][ 0 ] expected_fields = set ( subset_fields ) expected_fields -= CONF . top_level_non_attribute_fields if \"attributes\" not in doc : raise ResponseError ( f \"Entries are missing `attributes` key. \\n Received: { doc } \" ) returned_fields = set ( sorted ( list ( doc . get ( \"attributes\" , {}) . keys ()))) returned_fields -= CONF . top_level_non_attribute_fields if expected_fields != returned_fields : raise ResponseError ( f \"Response fields not obeyed by { endp !r} : \\n Expected: { expected_fields } \\n Returned: { returned_fields } \" ) return True , \"Successfully limited response fields\" return ( None , f \"Unable to test adherence to response fields as no entries were returned for endpoint { endp !r} .\" , ) @test_case def _construct_queries_for_property ( self , prop : str , prop_type : DataType , sortable : bool , endp : str , chosen_entry : Dict [ str , Any ], ) -> Tuple [ Optional [ bool ], str ]: \"\"\"For the given property, property type and chose entry, this method runs a series of queries for each field in the entry, testing that the initial document is returned where expected. Parameters: prop: The property name. prop_type: The property type. sortable: Whether the implementation has indicated that the field is sortable. endp: The corresponding entry endpoint. chosen_entry: A JSON respresentation of the chosen entry that will be used to construct the filters. Returns: Boolean indicating success (`True`) or failure/irrelevance (`None`) and the string summary of the test case. \"\"\" # Explicitly handle top level keys that do not have types in info if not chosen_entry : raise ResponseError ( f \"Chosen entry of endpoint '/ { endp } ' failed validation.\" ) if prop == \"type\" : if chosen_entry [ \"type\" ] == endp : return True , f \"Successfully validated { prop } \" raise ResponseError ( f \"Chosen entry of endpoint ' { endp } ' had unexpected type { chosen_entry [ 'type' ] !r} .\" ) prop_type = ( CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"type\" ) if prop_type is None else prop_type ) if prop_type is None : raise ResponseError ( f \"Cannot validate queries on { prop !r} as field type was not reported in `/info/ { endp } `\" ) # this is the case of a provider field if prop not in CONF . entry_schemas [ endp ]: if self . provider_prefix is None : raise ResponseError ( f \"Found unknown field { prop !r} in `/info/ { endp } ` and no provider prefix was provided in `/info`\" ) elif not prop . startswith ( f \"_ { self . provider_prefix } _\" ): raise ResponseError ( f \"Found unknown field { prop !r} that did not start with provider prefix '_ { self . provider_prefix } _'\" ) return ( None , f \"Found provider field { prop !r} , will not test queries as they are strictly optional.\" , ) query_optional = ( CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"queryable\" ) == SupportLevel . OPTIONAL ) return self . _construct_single_property_filters ( prop , prop_type , sortable , endp , chosen_entry , query_optional ) @staticmethod def _format_test_value ( test_value : Any , prop_type : DataType , operator : str ) -> str : \"\"\"Formats the test value as a string according to the type of the property. Parameters: test_value: The value to format. prop_type: The OPTIMADE data type of the field. operator: The operator that will be applied to it. Returns: The value formatted as a string to use in an OPTIMADE filter. \"\"\" if prop_type == DataType . LIST : if operator in ( \"HAS ALL\" , \"HAS ANY\" ): _vals = sorted ( set ( test_value )) if isinstance ( test_value [ 0 ], str ): _vals = [ f '\" { val } \"' for val in _vals ] else : _vals = [ f \" { val } \" for val in _vals ] _test_value = \",\" . join ( _vals ) else : if isinstance ( test_value [ 0 ], str ): _test_value = f '\" { test_value [ 0 ] } \"' else : _test_value = test_value [ 0 ] elif prop_type in ( DataType . STRING , DataType . TIMESTAMP ): _test_value = f '\" { test_value } \"' else : _test_value = test_value return _test_value def _construct_single_property_filters ( self , prop : str , prop_type : DataType , sortable : bool , endp : str , chosen_entry : Dict [ str , Any ], query_optional : bool , ) -> Tuple [ Optional [ bool ], str ]: \"\"\"This method constructs appropriate queries using all operators for a certain field and applies some tests: - inclusive operators return compatible entries, e.g. `>=` always returns at least the results of `=`. - exclusive operators never return contradictory entries, e.g. `nsites=1` never returns the same entries as `nsites!=1`, modulo pagination. Parameters: prop: The property name. prop_type: The property type. sortable: Whether the implementation has indicated that the field is sortable. endp: The corresponding entry endpoint. chosen_entry: A JSON respresentation of the chosen entry that will be used to construct the filters. query_optional: Whether to treat query success as optional. Returns: Boolean indicating success (`True`) or failure/irrelevance (`None`) and the string summary of the test case. \"\"\" if prop == \"id\" : test_value = chosen_entry . get ( \"id\" ) else : test_value = chosen_entry . get ( \"attributes\" , {}) . get ( prop , \"_missing\" ) if test_value in ( \"_missing\" , None ): support = CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"support\" ) queryable = CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"queryable\" ) submsg = \"had no value\" if test_value == \"_missing\" else \"had `None` value\" msg = ( f \"Chosen entry { submsg } for { prop !r} with support level { support } and queryability { queryable } , \" f \"so cannot construct test queries. This field should potentially be removed from the `/info/ { endp } ` endpoint response.\" ) # None values are allowed for OPTIONAL and SHOULD, so we can just skip if support in ( SupportLevel . OPTIONAL , SupportLevel . SHOULD , ): self . _log . info ( msg ) return None , msg # Otherwise, None values are not allowed for MUST's, and entire missing fields are not allowed raise ResponseError ( msg ) using_fallback = False if prop_type == DataType . LIST : if not test_value : test_value = CONF . enum_fallback_values . get ( endp , {}) . get ( prop ) using_fallback = True if not test_value : msg = f \"Not testing filters on field { prop } of type { prop_type } as no test value was found to use in filter.\" self . _log . warning ( msg ) return None , msg if isinstance ( test_value [ 0 ], dict ) or isinstance ( test_value [ 0 ], list ): msg = f \"Not testing filters on field { prop } of type { prop_type } with nested dictionary/list test value.\" self . _log . warning ( msg ) return None , msg # Try to infer if the test value is a float from its string representation # and decide whether to do inclusive/exclusive query tests try : float ( test_value [ 0 ]) msg = f \"Not testing filters on field { prop } of type { prop_type } containing float values.\" self . _log . warning ( msg ) return None , msg except ValueError : pass if prop_type in ( DataType . DICTIONARY ,): msg = f \"Not testing queries on field { prop } of type { prop_type } .\" self . _log . warning ( msg ) return None , msg num_data_returned = {} inclusive_operators = CONF . inclusive_operators [ prop_type ] exclusive_operators = CONF . exclusive_operators [ prop_type ] field_specific_support_overrides = CONF . field_specific_overrides . get ( prop , {}) for operator in inclusive_operators | exclusive_operators : # Need to pre-format list and string test values for the query _test_value = self . _format_test_value ( test_value , prop_type , operator ) query_optional = ( query_optional or operator in field_specific_support_overrides . get ( SupportLevel . OPTIONAL , []) ) query = f \" { prop } { operator } { _test_value } \" request = f \" { endp } ?filter= { query } \" response , message = self . _get_endpoint ( request , multistage = True , optional = query_optional , expected_status_code = ( 200 , 501 ), ) if not response : if query_optional : return ( None , \"Optional query {query!r} raised the error: {message} .\" , ) raise ResponseError ( f \"Unable to perform mandatory query { query !r} , which raised the error: { message } \" ) response = response . json () if \"meta\" not in response or \"more_data_available\" not in response [ \"meta\" ]: raise ResponseError ( f \"Required field `meta->more_data_available` missing from response for { request } .\" ) if not response [ \"meta\" ][ \"more_data_available\" ]: num_data_returned [ operator ] = len ( response [ \"data\" ]) else : num_data_returned [ operator ] = response [ \"meta\" ] . get ( \"data_returned\" ) if prop in CONF . unique_properties and operator == \"=\" : if num_data_returned [ \"=\" ] is not None and num_data_returned [ \"=\" ] == 0 : raise ResponseError ( f \"Unable to filter field 'id' for equality, no data was returned for { query } .\" ) if num_data_returned [ \"=\" ] is not None and num_data_returned [ \"=\" ] > 1 : raise ResponseError ( f \"Filter for an individual 'id' returned { num_data_returned [ '=' ] } results, when only 1 was expected.\" ) num_response = num_data_returned [ operator ] excluded = operator in exclusive_operators # if we have all results on this page, check that the blessed ID is in the response # if not response[\"meta\"][\"more_data_available\"]: if excluded and ( chosen_entry [ \"id\" ] in set ( entry [ \"id\" ] for entry in response [ \"data\" ]) ): raise ResponseError ( f \"Entry { chosen_entry [ 'id' ] } with value { prop !r} : { test_value } was not excluded by { query !r} \" ) # check that at least the archetypal structure was returned, unless we are using a fallback value if not excluded and not using_fallback : if ( num_data_returned [ operator ] is not None and num_data_returned [ operator ] < 1 ): raise ResponseError ( f \"Supposedly inclusive query { query !r} did not include original entry ID { chosen_entry [ 'id' ] !r} \" f \"(with field { prop !r} = { test_value } ) potentially indicating a problem with filtering on this field.\" ) # check that the filter returned no entries that had a null or missing value for the filtered property if any ( entry [ \"attributes\" ] . get ( prop , entry . get ( prop , None )) is None for entry in response . get ( \"data\" , []) ): raise ResponseError ( f \"Filter { query !r} on field { prop !r} returned entries that had null or missing values for the field.\" ) # Numeric and string comparisons must work both ways... if prop_type in ( DataType . STRING , DataType . INTEGER , DataType . FLOAT , DataType . TIMESTAMP , ) and operator not in ( \"CONTAINS\" , \"STARTS\" , \"STARTS WITH\" , \"ENDS\" , \"ENDS WITH\" , ): reversed_operator = operator . replace ( \"<\" , \">\" ) if \"<\" in operator : reversed_operator = operator . replace ( \"<\" , \">\" ) elif \">\" in operator : reversed_operator = operator . replace ( \">\" , \"<\" ) # Don't try to reverse string comparison as it is ill-defined if prop_type == DataType . STRING and any ( comp in operator for comp in ( \"<\" , \">\" ) ): continue reversed_query = f \" { _test_value } { reversed_operator } { prop } \" reversed_request = f \" { endp } ?filter= { reversed_query } \" reversed_response , message = self . _get_endpoint ( reversed_request , multistage = True , optional = query_optional , expected_status_code = ( 200 , 501 ), ) if not reversed_response : if query_optional : return ( None , \"Optional query {reversed_query!r} raised the error: {message} .\" , ) raise ResponseError ( f \"Unable to perform mandatory query { reversed_query !r} , which raised the error: { message } \" ) reversed_response = reversed_response . json () if ( \"meta\" not in reversed_response or \"more_data_available\" not in reversed_response [ \"meta\" ] ): raise ResponseError ( f \"Required field `meta->more_data_available` missing from response for { request } .\" ) if not reversed_response [ \"meta\" ][ \"more_data_available\" ]: num_reversed_response = len ( reversed_response [ \"data\" ]) else : num_reversed_response = reversed_response [ \"meta\" ] . get ( \"data_returned\" ) if num_response is not None and num_reversed_response is not None : if reversed_response [ \"meta\" ] . get ( \"data_returned\" ) != response [ \"meta\" ] . get ( \"data_returned\" ): raise ResponseError ( f \"Query { query } did not work both ways around: { reversed_query } , \" \"returning different results each time.\" ) # check that the filter returned no entries that had a null or missing value for the filtered property if any ( entry [ \"attributes\" ] . get ( prop , entry . get ( prop , None )) is None for entry in reversed_response . get ( \"data\" , []) ): raise ResponseError ( f \"Filter { reversed_query !r} on field { prop !r} returned entries that had null or missing values for the field.\" ) return True , f \" { prop } passed filter tests\" def _test_info_or_links_endpoint ( self , request_str : str ) -> Union [ bool , dict ]: \"\"\"Requests an info or links endpoint and attempts to deserialize the response. Parameters: request_str: The request to make, e.g. \"links\". Returns: `False` if the info response failed deserialization, otherwise returns the deserialized object. \"\"\" response , _ = self . _get_endpoint ( request_str ) if response : deserialized , _ = self . _deserialize_response ( response , self . _response_classes [ request_str ], request = request_str , ) if deserialized : return deserialized . dict () return False def _test_single_entry_endpoint ( self , endp : str ) -> None : \"\"\"Requests and deserializes a single entry endpoint with the appropriate model. Parameters: request_str: The single entry request to make, e.g. \"structures/id_1\". \"\"\" response_cls_name = endp + \"/\" if response_cls_name in self . _response_classes : response_cls = self . _response_classes [ response_cls_name ] else : self . _log . warning ( \"Deserializing single entry response %s with generic response rather than defined endpoint.\" , endp , ) response_cls = ValidatorEntryResponseOne response_fields = set () if endp in CONF . entry_schemas : response_fields = ( set ( CONF . entry_schemas [ endp ] . keys ()) - CONF . top_level_non_attribute_fields ) if endp in self . _test_id_by_type : test_id = self . _test_id_by_type [ endp ] request_str = f \" { endp } / { test_id } \" if response_fields : request_str += f \"?response_fields= { ',' . join ( response_fields ) } \" response , _ = self . _get_endpoint ( request_str ) if response : self . _deserialize_response ( response , response_cls , request = request_str ) def _test_multi_entry_endpoint ( self , endp : str ) -> None : \"\"\"Requests and deserializes a multi-entry endpoint with the appropriate model. Parameters: request_str: The multi-entry request to make, e.g., \"structures?filter=nsites<10\" \"\"\" if endp in self . _response_classes : response_cls = self . _response_classes [ endp ] else : self . _log . warning ( \"Deserializing multi entry response from %s with generic response rather than defined endpoint.\" , endp , ) response_cls = ValidatorEntryResponseMany response_fields = set () if endp in CONF . entry_schemas : response_fields = ( set ( CONF . entry_schemas [ endp ] . keys ()) - CONF . top_level_non_attribute_fields ) request_str = f \" { endp } ?page_limit= { self . page_limit } \" if response_fields : request_str += f '&response_fields= { \",\" . join ( response_fields ) } ' response , _ = self . _get_endpoint ( request_str ) self . _test_page_limit ( response ) deserialized , _ = self . _deserialize_response ( response , response_cls , request = request_str ) self . _get_single_id_from_multi_entry_endpoint ( deserialized , request = request_str ) if deserialized : self . _test_data_available_matches_data_returned ( deserialized , request = request_str ) @test_case def _test_data_available_matches_data_returned ( self , deserialized : Any ) -> Tuple [ bool , str ]: \"\"\"In the case where no query is requested, `data_available` must equal `data_returned` in the meta response, which is tested here. Parameters: deserialized: The deserialized response to a multi-entry endpoint. Returns: `True` if successful, with a string summary. \"\"\" if ( deserialized . meta . data_available is None or deserialized . meta . data_returned is None ): return ( None , \"`meta->data_available` and/or `meta->data_returned` were not provided.\" , ) if deserialized . meta . data_available != deserialized . meta . data_returned : raise ResponseError ( \"No query was performed, but `data_returned` != `data_available`.\" ) return ( True , \"Meta response contained correct values for data_available and data_returned.\" , ) def _test_versions_endpoint ( self ): \"\"\"Requests and validate responses for the versions endpoint, which MUST exist for unversioned base URLs and MUST NOT exist for versioned base URLs. \"\"\" # First, check that there is a versions endpoint in the appropriate place: # If passed a versioned URL, then strip that version from # the URL before looking for `/versions`. _old_base_url = self . base_url if re . match ( VERSIONS_REGEXP , self . base_url_parsed . path ) is not None : self . client . base_url = \"/\" . join ( self . client . base_url . split ( \"/\" )[: - 1 ]) self . base_url = self . client . base_url response , _ = self . _get_endpoint ( CONF . versions_endpoint , expected_status_code = 200 ) if response : self . _test_versions_endpoint_content ( response , request = CONF . versions_endpoint ) # If passed a versioned URL, first reset the URL of the client to the # versioned one, then test that this versioned URL does NOT host a versions endpoint if re . match ( VERSIONS_REGEXP , self . base_url_parsed . path ) is not None : self . client . base_url = _old_base_url self . base_url = _old_base_url self . _get_endpoint ( CONF . versions_endpoint , expected_status_code = 404 ) @test_case def _test_versions_endpoint_content ( self , response : requests . Response ) -> Tuple [ requests . Response , str ]: \"\"\"Checks that the response from the versions endpoint complies with the specification and that its 'Content-Type' header complies with [RFC 4180](https://tools.ietf.org/html/rfc4180.html). Parameters: response: The HTTP response from the versions endpoint. Raises: ResponseError: If any content checks fail. Returns: The successful HTTP response or `None`, and a summary string. \"\"\" text_content = response . text . strip () . split ( \" \\n \" ) if text_content [ 0 ] != \"version\" : raise ResponseError ( f \"First line of `/ { CONF . versions_endpoint } ` response must be 'version', not { text_content [ 0 ] !r} \" ) if len ( text_content ) <= 1 : raise ResponseError ( f \"No version numbers found in `/ { CONF . versions_endpoint } ` response, only { text_content } \" ) for version in text_content [ 1 :]: try : int ( version ) except ValueError : raise ResponseError ( f \"Version numbers reported by `/ { CONF . versions_endpoint } ` must be integers specifying the major version, not { text_content } .\" ) content_type = response . headers . get ( \"content-type\" ) if not content_type : raise ResponseError ( \"Missing 'Content-Type' in response header from `/versions`.\" ) content_type = [ _ . replace ( \" \" , \"\" ) for _ in content_type . split ( \";\" )] self . _test_versions_headers ( content_type , ( \"text/csv\" , \"text/plain\" ), optional = True , request = CONF . versions_endpoint , ) self . _test_versions_headers ( content_type , \"header=present\" , optional = True , request = CONF . versions_endpoint , ) return response , \"`/versions` endpoint responded correctly.\" @test_case def _test_versions_headers ( self , content_type : Dict [ str , Any ], expected_parameter : Union [ str , List [ str ]], ) -> Tuple [ Dict [ str , Any ], str ]: \"\"\"Tests that the `Content-Type` field of the `/versions` header contains the passed parameter. Arguments: content_type: The 'Content-Type' field from the response of the `/versions` endpoint. expected_paramter: A substring or list of substrings that are expected in the Content-Type of the response. If multiple strings are passed, they will be treated as possible alternatives to one another. Raises: ResponseError: If the expected 'Content-Type' parameter is missing. Returns: The HTTP response headers and a summary string. \"\"\" if isinstance ( expected_parameter , str ): expected_parameter = [ expected_parameter ] if not any ( param in content_type for param in expected_parameter ): raise ResponseError ( f \"Incorrect 'Content-Type' header { ';' . join ( content_type ) !r} . \\n \" f \"Missing at least one expected parameter(s): { expected_parameter !r} \" ) return ( content_type , f \"`/versions` response had one of the expected Content-Type parameters { expected_parameter } .\" , ) def _test_as_type ( self ) -> None : \"\"\"Tests that the base URL of the validator (i.e. with no additional path added) validates with the model selected. \"\"\" response , _ = self . _get_endpoint ( \"\" ) if response : self . _log . debug ( \"Deserialzing response as type %s \" , self . as_type_cls ) self . _deserialize_response ( response , self . as_type_cls ) def _test_bad_version_returns_553 ( self ) -> None : \"\"\"Tests that a garbage version number responds with a 553 error code. \"\"\" expected_status_code = 553 if re . match ( VERSIONS_REGEXP , self . base_url_parsed . path ) is not None : expected_status_code = [ 404 , 400 ] self . _get_endpoint ( \"v123123\" , expected_status_code = expected_status_code , optional = True ) @test_case def _test_page_limit ( self , response : requests . models . Response , check_next_link : int = 5 , previous_links : Optional [ Set [ str ]] = None , ) -> Tuple [ Optional [ bool ], str ]: \"\"\"Test that a multi-entry endpoint obeys the page limit by following pagination links up to a depth of `check_next_link`. Parameters: response: The response to test for page limit compliance. check_next_link: Maximum recursion depth for following pagination links. previous_links: A set of previous links that will be used to check that the `next` link is actually new. Returns: `True` if the test was successful and `None` if not, with a string summary. \"\"\" if previous_links is None : previous_links = set () try : response = response . json () except ( AttributeError , json . JSONDecodeError ): raise ResponseError ( \"Unable to test endpoint `page_limit` parameter.\" ) try : num_entries = len ( response [ \"data\" ]) except ( KeyError , TypeError ): raise ResponseError ( \"Response under `data` field was missing or had wrong type.\" ) if num_entries > self . page_limit : raise ResponseError ( f \"Endpoint did not obey page limit: { num_entries } entries vs { self . page_limit } limit\" ) try : more_data_available = response [ \"meta\" ][ \"more_data_available\" ] except KeyError : raise ResponseError ( \"Field `meta->more_data_available` was missing.\" ) if more_data_available and check_next_link : try : next_link = response [ \"links\" ][ \"next\" ] if isinstance ( next_link , dict ): next_link = next_link [ \"href\" ] except KeyError : raise ResponseError ( \"Endpoint suggested more data was available but provided no valid links->next link.\" ) if next_link in previous_links : raise ResponseError ( f \"The next link { next_link } has been provided already for a previous page.\" ) previous_links . add ( next_link ) if not isinstance ( next_link , str ): raise ResponseError ( f \"Unable to parse links->next { next_link !r} as a link.\" ) self . _log . debug ( \"Following pagination link to %r .\" , next_link ) next_response , _ = self . _get_endpoint ( next_link ) if not next_response : raise ResponseError ( f \"Error when testing pagination: the response from `links->next` { next_link !r} failed the previous test.\" ) check_next_link = bool ( check_next_link - 1 ) self . _test_page_limit ( next_response , check_next_link = check_next_link , multistage = check_next_link , previous_links = previous_links , ) return ( True , f \"Endpoint obeyed page limit of { self . page_limit } by returning { num_entries } entries.\" , ) @test_case def _get_single_id_from_multi_entry_endpoint ( self , deserialized ): \"\"\"Scrape an ID from the multi-entry endpoint to use as query for single entry endpoint. \"\"\" if deserialized and deserialized . data : self . _test_id_by_type [ deserialized . data [ 0 ] . type ] = deserialized . data [ 0 ] . id self . _log . debug ( \"Set type %s test ID to %s \" , deserialized . data [ 0 ] . type , deserialized . data [ 0 ] . id , ) else : return ( None , \"No entries found under endpoint to scrape ID from. \" \"This may be caused by previous errors, if e.g. the endpoint failed deserialization.\" , ) return ( self . _test_id_by_type [ deserialized . data [ 0 ] . type ], f \"successfully scraped test ID from { deserialized . data [ 0 ] . type } endpoint\" , ) @test_case def _deserialize_response ( self , response : requests . models . Response , response_cls : Any , request : str = None ) -> Tuple [ Any , str ]: \"\"\"Try to create the appropriate pydantic model from the response. Parameters: response: The response to try to deserialize. response_cls: The class to use for deserialization. request: Optional string that will be displayed as the attempted request in the validator output. Returns: The deserialized object (or `None` if unsuccessful) and a human-readable summary \"\"\" if not response : raise ResponseError ( \"Request failed\" ) try : json_response = response . json () except json . JSONDecodeError : raise ResponseError ( f \"Unable to decode response as JSON. Response: { response } \" ) self . _log . debug ( f \"Deserializing { json . dumps ( json_response , indent = 2 ) } as model { response_cls } \" ) return ( response_cls ( ** json_response ), \"deserialized correctly as object of type {} \" . format ( response_cls ), ) @test_case def _get_available_endpoints ( self , base_info : Union [ Any , Dict [ str , Any ]] ) -> Tuple [ Optional [ List [ str ]], str ]: \"\"\"Tries to get `entry_types_by_format` from base info response even if it could not be deserialized. Parameters: base_info: Either the unvalidated JSON representation of the base info, or the deserialized object. Returns: The list of JSON entry endpoints (or `None` if unavailable) and a string summary. \"\"\" for _ in [ 0 ]: try : available_json_entry_endpoints = base_info [ \"data\" ][ \"attributes\" ][ \"entry_types_by_format\" ][ \"json\" ] break except ( KeyError , TypeError ): raise ResponseError ( \"Unable to get entry_types_by_format from unserializable base info response {} .\" . format ( base_info ) ) else : raise ResponseError ( \"Unable to find any JSON entry types in entry_types_by_format\" ) if self . index and available_json_entry_endpoints != []: raise ResponseError ( \"No entry endpoint are allowed for an Index meta-database\" ) for non_entry_endpoint in CONF . non_entry_endpoints : if non_entry_endpoint in available_json_entry_endpoints : raise ResponseError ( f 'Illegal entry \" { non_entry_endpoint } \" was found in entry_types_by_format\"' ) # Filter out custom extension endpoints that are not covered in the specification available_json_entry_endpoints = [ endp for endp in available_json_entry_endpoints if endp in CONF . entry_endpoints ] return ( available_json_entry_endpoints , \"successfully found available entry types in baseinfo\" , ) @test_case def _get_endpoint ( self , request_str : str , expected_status_code : Union [ List [ int ], int ] = 200 ) -> Tuple [ Optional [ requests . Response ], str ]: \"\"\"Gets the response from the endpoint specified by `request_str`. function is wrapped by the `test_case` decorator Parameters: request_str: The request to make to the client. expected_status_code: If the request responds with a different status code to this one, raise a ResponseError. Returns: The response to the request (if successful) or `None`, plus a string summary. \"\"\" request_str = request_str . replace ( \" \\n \" , \"\" ) response = self . client . get ( request_str ) if isinstance ( expected_status_code , int ): expected_status_code = [ expected_status_code ] message = f \"received expected response: { response } .\" if response . status_code != 200 : message = f \"Request to ' { request_str } ' returned HTTP status code { response . status_code } .\" message += \" \\n Additional details from implementation:\" try : for error in response . json () . get ( \"errors\" , []): message += f ' \\n { error . get ( \"title\" , \"N/A\" ) } : { error . get ( \"detail\" , \"N/A\" ) } ( { error . get ( \"source\" , {}) . get ( \"pointer\" , \"N/A\" ) } )' except json . JSONDecodeError : message += f \" \\n Could not parse response as JSON. Content type was { response . headers . get ( 'content-type' ) !r} .\" if response . status_code not in expected_status_code : raise ResponseError ( message ) return response , message __init__ ( client = None , base_url = None , verbosity = 0 , respond_json = False , page_limit = 4 , max_retries = 5 , run_optional_tests = True , fail_fast = False , as_type = None , index = False , minimal = False , http_headers = None , timeout = DEFAULT_CONN_TIMEOUT , read_timeout = DEFAULT_READ_TIMEOUT ) \u00b6 Set up the tests to run, based on constants in this module for required endpoints. Parameters: Name Type Description Default client Any A client that has a .get() method to obtain the response from the implementation. If None , then Client will be used. None base_url str The URL of the implementation to validate. Unless performing \"as_type\" validation, this should point to the base of the OPTIMADE implementation. None verbosity int The verbosity of the output and logging as an integer ( 0 : critical, 1 : warning, 2 : info, 3 : debug). 0 respond_json bool If True , print only a JSON representation of the results of validation to stdout. False page_limit int The default page limit to apply to filters. 4 max_retries int Argument is passed to the client for how many attempts to make for a request before failing. 5 run_optional_tests bool Whether to run the tests on optional OPTIMADE features. True fail_fast bool Whether to exit validation after the first failure of a mandatory test. False as_type str An OPTIMADE entry or endpoint type to coerce the response from implementation into, e.g. \"structures\". Requires base_url to be pointed to the corresponding endpoint. None index bool Whether to validate the implementation as an index meta-database. False minimal bool Whether or not to run only a minimal test set. False http_headers Dict [ str , str ] Dictionary of additional headers to add to every request. None timeout float The connection timeout to use for all requests (in seconds). DEFAULT_CONN_TIMEOUT read_timeout float The read timeout to use for all requests (in seconds). DEFAULT_READ_TIMEOUT Source code in optimade/validator/validator.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def __init__ ( # pylint: disable=too-many-arguments self , client : Any = None , base_url : str = None , verbosity : int = 0 , respond_json : bool = False , page_limit : int = 4 , max_retries : int = 5 , run_optional_tests : bool = True , fail_fast : bool = False , as_type : str = None , index : bool = False , minimal : bool = False , http_headers : Dict [ str , str ] = None , timeout : float = DEFAULT_CONN_TIMEOUT , read_timeout : float = DEFAULT_READ_TIMEOUT , ): \"\"\"Set up the tests to run, based on constants in this module for required endpoints. Arguments: client: A client that has a `.get()` method to obtain the response from the implementation. If `None`, then [`Client`][optimade.validator.utils.Client] will be used. base_url: The URL of the implementation to validate. Unless performing \"as_type\" validation, this should point to the base of the OPTIMADE implementation. verbosity: The verbosity of the output and logging as an integer (`0`: critical, `1`: warning, `2`: info, `3`: debug). respond_json: If `True`, print only a JSON representation of the results of validation to stdout. page_limit: The default page limit to apply to filters. max_retries: Argument is passed to the client for how many attempts to make for a request before failing. run_optional_tests: Whether to run the tests on optional OPTIMADE features. fail_fast: Whether to exit validation after the first failure of a mandatory test. as_type: An OPTIMADE entry or endpoint type to coerce the response from implementation into, e.g. \"structures\". Requires `base_url` to be pointed to the corresponding endpoint. index: Whether to validate the implementation as an index meta-database. minimal: Whether or not to run only a minimal test set. http_headers: Dictionary of additional headers to add to every request. timeout: The connection timeout to use for all requests (in seconds). read_timeout: The read timeout to use for all requests (in seconds). \"\"\" self . verbosity = verbosity self . max_retries = max_retries self . page_limit = page_limit self . index = index self . run_optional_tests = run_optional_tests self . fail_fast = fail_fast self . respond_json = respond_json self . minimal = minimal if as_type is None : self . as_type_cls = None elif self . index : if as_type not in CONF . response_classes_index : raise RuntimeError ( f \"Provided as_type=' { as_type } ' not allowed for an Index meta-database.\" ) self . as_type_cls = CONF . response_classes_index [ as_type ] elif as_type in ( \"structure\" , \"reference\" ): self . as_type_cls = CONF . response_classes [ f \" { as_type } s/\" ] else : self . as_type_cls = CONF . response_classes [ as_type ] if client is None and base_url is None : raise RuntimeError ( \"Need at least a URL or a client to initialize validator.\" ) if base_url and client : raise RuntimeError ( \"Please specify at most one of base_url or client.\" ) if client : self . client = client self . base_url = self . client . base_url # If a custom client has been provided, try to set custom headers if they have been specified, # but do not overwrite any existing attributes if http_headers : if not hasattr ( self . client , \"headers\" ): self . client . headers = http_headers else : print_warning ( f \"Not using specified request headers { http_headers } with custom client { self . client } .\" ) else : while base_url . endswith ( \"/\" ): base_url = base_url [: - 1 ] self . base_url = base_url self . client = Client ( base_url , max_retries = self . max_retries , headers = http_headers , timeout = timeout , read_timeout = read_timeout , ) self . _setup_log () self . _response_classes = ( CONF . response_classes_index if self . index else CONF . response_classes ) # some simple checks on base_url self . base_url_parsed = urllib . parse . urlparse ( self . base_url ) # only allow filters/endpoints if we are working in \"as_type\" mode if self . as_type_cls is None and self . base_url_parsed . query : raise SystemExit ( \"Base URL not appropriate: should not contain a filter.\" ) self . valid = None self . _test_id_by_type = {} self . _entry_info_by_type = {} self . results = ValidatorResults ( verbosity = self . verbosity ) print_summary () \u00b6 Print a summary of the results of validation. Source code in optimade/validator/validator.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def print_summary ( self ): \"\"\"Print a summary of the results of validation.\"\"\" if self . respond_json : print ( json . dumps ( dataclasses . asdict ( self . results ), indent = 2 )) return if self . results . failure_messages : print ( \" \\n\\n FAILURES\" ) print ( \"======== \\n \" ) for message in self . results . failure_messages : print_failure ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . optional_failure_messages : print ( \" \\n\\n OPTIONAL TEST FAILURES\" ) print ( \"====================== \\n \" ) for message in self . results . optional_failure_messages : print_notify ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . internal_failure_messages : print ( \" \\n\\n INTERNAL FAILURES\" ) print ( \"================= \\n \" ) print ( \"There were internal validator failures associated with this run. \\n \" \"If this problem persists, please report it at: \\n \" \"https://github.com/Materials-Consortia/optimade-python-tools/issues/new \\n \" ) for message in self . results . internal_failure_messages : print_warning ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . valid or ( not self . valid and not self . fail_fast ): final_message = f \" \\n\\n Passed { self . results . success_count } out of { self . results . success_count + self . results . failure_count + self . results . internal_failure_count } tests.\" if not self . valid : print_failure ( final_message ) else : print_success ( final_message ) if self . run_optional_tests and not self . fail_fast : print ( f \"Additionally passed { self . results . optional_success_count } out of \" f \" { self . results . optional_success_count + self . results . optional_failure_count } optional tests.\" ) validate_implementation () \u00b6 Run all the test cases on the implementation, or the single type test, depending on what options were provided on initialiation. Sets the self.valid attribute to True or False depending on the outcome of the tests. Raises: Type Description RuntimeError If it was not possible to start the validation process. Source code in optimade/validator/validator.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 def validate_implementation ( self ): \"\"\"Run all the test cases on the implementation, or the single type test, depending on what options were provided on initialiation. Sets the `self.valid` attribute to `True` or `False` depending on the outcome of the tests. Raises: RuntimeError: If it was not possible to start the validation process. \"\"\" # If a single \"as type\" has been set, only run that test if self . as_type_cls is not None : self . _log . debug ( \"Validating response of %s with model %s \" , self . base_url , self . as_type_cls , ) self . _test_as_type () self . valid = not bool ( self . results . failure_count ) self . print_summary () return # Test entire implementation if self . verbosity >= 0 : print ( f \"Testing entire implementation at { self . base_url } \" ) info_endp = CONF . info_endpoint self . _log . debug ( \"Testing base info endpoint of %s \" , info_endp ) # Get and validate base info to find endpoints # If this is not possible, then exit at this stage base_info = self . _test_info_or_links_endpoint ( info_endp ) if not base_info : self . _log . critical ( f \"Unable to deserialize response from introspective { info_endp !r} endpoint. \" \"This is required for all further validation, so the validator will now exit.\" ) # Set valid to False to ensure error code 1 is raised at CLI self . valid = False self . print_summary () return # Grab the provider prefix from base info and use it when looking for provider fields self . provider_prefix = None meta = base_info . get ( \"meta\" , {}) if meta . get ( \"provider\" ) is not None : self . provider_prefix = meta [ \"provider\" ] . get ( \"prefix\" ) # Set the response class for all `/info/entry` endpoints based on `/info` response self . available_json_endpoints , _ = self . _get_available_endpoints ( base_info , request = info_endp ) for endp in self . available_json_endpoints : self . _response_classes [ f \" { info_endp } / { endp } \" ] = EntryInfoResponse # Run some tests on the versions endpoint self . _log . debug ( \"Testing versions endpoint %s \" , CONF . versions_endpoint ) self . _test_versions_endpoint () self . _test_bad_version_returns_553 () # Test that entry info endpoints deserialize correctly # If they do not, the corresponding entry in _entry_info_by_type # is set to False, which must be checked for further validation for endp in self . available_json_endpoints : entry_info_endpoint = f \" { info_endp } / { endp } \" self . _log . debug ( \"Testing expected info endpoint %s \" , entry_info_endpoint ) self . _entry_info_by_type [ endp ] = self . _test_info_or_links_endpoint ( entry_info_endpoint ) # Test that the results from multi-entry-endpoints obey, e.g. page limits, # and that all entries can be deserialized with the patched models. # These methods also set the test_ids for each type of entry, which are validated # in the next loop. for endp in self . available_json_endpoints : self . _log . debug ( \"Testing multiple entry endpoint of %s \" , endp ) self . _test_multi_entry_endpoint ( endp ) # Test that the single IDs scraped earlier work with the single entry endpoint for endp in self . available_json_endpoints : self . _log . debug ( \"Testing single entry request of type %s \" , endp ) self . _test_single_entry_endpoint ( endp ) # Use the _entry_info_by_type to construct filters on the relevant endpoints if not self . minimal : for endp in self . available_json_endpoints : self . _log . debug ( \"Testing queries on JSON entry endpoint of %s \" , endp ) self . _recurse_through_endpoint ( endp ) # Test that the links endpoint can be serialized correctly self . _log . debug ( \"Testing %s endpoint\" , CONF . links_endpoint ) self . _test_info_or_links_endpoint ( CONF . links_endpoint ) self . valid = not ( self . results . failure_count or self . results . internal_failure_count ) self . print_summary ()","title":"validator"},{"location":"api_reference/validator/validator/#validator","text":"This module contains the ImplementationValidator class that can be pointed at an OPTIMADE implementation and validated against the specification via the pydantic models implemented in this package.","title":"validator"},{"location":"api_reference/validator/validator/#optimade.validator.validator.ImplementationValidator","text":"Class used to make a series of checks against a particular OPTIMADE implementation over HTTP. Uses the pydantic models in optimade.models to validate the response from the server and crawl through the available endpoints. Attributes: Name Type Description valid whether or not the implementation was deemed valid, with None signifying that tests did not run. Caution Only works for current version of the specification as defined by optimade.models . Source code in optimade/validator/validator.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 class ImplementationValidator : \"\"\"Class used to make a series of checks against a particular OPTIMADE implementation over HTTP. Uses the pydantic models in [`optimade.models`][optimade.models] to validate the response from the server and crawl through the available endpoints. Attributes: valid: whether or not the implementation was deemed valid, with `None` signifying that tests did not run. Caution: Only works for current version of the specification as defined by [`optimade.models`][optimade.models]. \"\"\" valid : Optional [ bool ] def __init__ ( # pylint: disable=too-many-arguments self , client : Any = None , base_url : str = None , verbosity : int = 0 , respond_json : bool = False , page_limit : int = 4 , max_retries : int = 5 , run_optional_tests : bool = True , fail_fast : bool = False , as_type : str = None , index : bool = False , minimal : bool = False , http_headers : Dict [ str , str ] = None , timeout : float = DEFAULT_CONN_TIMEOUT , read_timeout : float = DEFAULT_READ_TIMEOUT , ): \"\"\"Set up the tests to run, based on constants in this module for required endpoints. Arguments: client: A client that has a `.get()` method to obtain the response from the implementation. If `None`, then [`Client`][optimade.validator.utils.Client] will be used. base_url: The URL of the implementation to validate. Unless performing \"as_type\" validation, this should point to the base of the OPTIMADE implementation. verbosity: The verbosity of the output and logging as an integer (`0`: critical, `1`: warning, `2`: info, `3`: debug). respond_json: If `True`, print only a JSON representation of the results of validation to stdout. page_limit: The default page limit to apply to filters. max_retries: Argument is passed to the client for how many attempts to make for a request before failing. run_optional_tests: Whether to run the tests on optional OPTIMADE features. fail_fast: Whether to exit validation after the first failure of a mandatory test. as_type: An OPTIMADE entry or endpoint type to coerce the response from implementation into, e.g. \"structures\". Requires `base_url` to be pointed to the corresponding endpoint. index: Whether to validate the implementation as an index meta-database. minimal: Whether or not to run only a minimal test set. http_headers: Dictionary of additional headers to add to every request. timeout: The connection timeout to use for all requests (in seconds). read_timeout: The read timeout to use for all requests (in seconds). \"\"\" self . verbosity = verbosity self . max_retries = max_retries self . page_limit = page_limit self . index = index self . run_optional_tests = run_optional_tests self . fail_fast = fail_fast self . respond_json = respond_json self . minimal = minimal if as_type is None : self . as_type_cls = None elif self . index : if as_type not in CONF . response_classes_index : raise RuntimeError ( f \"Provided as_type=' { as_type } ' not allowed for an Index meta-database.\" ) self . as_type_cls = CONF . response_classes_index [ as_type ] elif as_type in ( \"structure\" , \"reference\" ): self . as_type_cls = CONF . response_classes [ f \" { as_type } s/\" ] else : self . as_type_cls = CONF . response_classes [ as_type ] if client is None and base_url is None : raise RuntimeError ( \"Need at least a URL or a client to initialize validator.\" ) if base_url and client : raise RuntimeError ( \"Please specify at most one of base_url or client.\" ) if client : self . client = client self . base_url = self . client . base_url # If a custom client has been provided, try to set custom headers if they have been specified, # but do not overwrite any existing attributes if http_headers : if not hasattr ( self . client , \"headers\" ): self . client . headers = http_headers else : print_warning ( f \"Not using specified request headers { http_headers } with custom client { self . client } .\" ) else : while base_url . endswith ( \"/\" ): base_url = base_url [: - 1 ] self . base_url = base_url self . client = Client ( base_url , max_retries = self . max_retries , headers = http_headers , timeout = timeout , read_timeout = read_timeout , ) self . _setup_log () self . _response_classes = ( CONF . response_classes_index if self . index else CONF . response_classes ) # some simple checks on base_url self . base_url_parsed = urllib . parse . urlparse ( self . base_url ) # only allow filters/endpoints if we are working in \"as_type\" mode if self . as_type_cls is None and self . base_url_parsed . query : raise SystemExit ( \"Base URL not appropriate: should not contain a filter.\" ) self . valid = None self . _test_id_by_type = {} self . _entry_info_by_type = {} self . results = ValidatorResults ( verbosity = self . verbosity ) def _setup_log ( self ): \"\"\"Define stdout log based on given verbosity.\"\"\" self . _log = logging . getLogger ( \"optimade\" ) . getChild ( \"validator\" ) self . _log . handlers = [] stdout_handler = logging . StreamHandler ( sys . stdout ) stdout_handler . setFormatter ( logging . Formatter ( \" %(asctime)s - %(name)s | %(levelname)8s : %(message)s \" ) ) if not self . respond_json : self . _log . addHandler ( stdout_handler ) else : self . verbosity = - 1 if self . verbosity == 0 : self . _log . setLevel ( logging . CRITICAL ) elif self . verbosity == 1 : self . _log . setLevel ( logging . WARNING ) elif self . verbosity == 2 : self . _log . setLevel ( logging . INFO ) elif self . verbosity > 0 : self . _log . setLevel ( logging . DEBUG ) def print_summary ( self ): \"\"\"Print a summary of the results of validation.\"\"\" if self . respond_json : print ( json . dumps ( dataclasses . asdict ( self . results ), indent = 2 )) return if self . results . failure_messages : print ( \" \\n\\n FAILURES\" ) print ( \"======== \\n \" ) for message in self . results . failure_messages : print_failure ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . optional_failure_messages : print ( \" \\n\\n OPTIONAL TEST FAILURES\" ) print ( \"====================== \\n \" ) for message in self . results . optional_failure_messages : print_notify ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . internal_failure_messages : print ( \" \\n\\n INTERNAL FAILURES\" ) print ( \"================= \\n \" ) print ( \"There were internal validator failures associated with this run. \\n \" \"If this problem persists, please report it at: \\n \" \"https://github.com/Materials-Consortia/optimade-python-tools/issues/new \\n \" ) for message in self . results . internal_failure_messages : print_warning ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . valid or ( not self . valid and not self . fail_fast ): final_message = f \" \\n\\n Passed { self . results . success_count } out of { self . results . success_count + self . results . failure_count + self . results . internal_failure_count } tests.\" if not self . valid : print_failure ( final_message ) else : print_success ( final_message ) if self . run_optional_tests and not self . fail_fast : print ( f \"Additionally passed { self . results . optional_success_count } out of \" f \" { self . results . optional_success_count + self . results . optional_failure_count } optional tests.\" ) def validate_implementation ( self ): \"\"\"Run all the test cases on the implementation, or the single type test, depending on what options were provided on initialiation. Sets the `self.valid` attribute to `True` or `False` depending on the outcome of the tests. Raises: RuntimeError: If it was not possible to start the validation process. \"\"\" # If a single \"as type\" has been set, only run that test if self . as_type_cls is not None : self . _log . debug ( \"Validating response of %s with model %s \" , self . base_url , self . as_type_cls , ) self . _test_as_type () self . valid = not bool ( self . results . failure_count ) self . print_summary () return # Test entire implementation if self . verbosity >= 0 : print ( f \"Testing entire implementation at { self . base_url } \" ) info_endp = CONF . info_endpoint self . _log . debug ( \"Testing base info endpoint of %s \" , info_endp ) # Get and validate base info to find endpoints # If this is not possible, then exit at this stage base_info = self . _test_info_or_links_endpoint ( info_endp ) if not base_info : self . _log . critical ( f \"Unable to deserialize response from introspective { info_endp !r} endpoint. \" \"This is required for all further validation, so the validator will now exit.\" ) # Set valid to False to ensure error code 1 is raised at CLI self . valid = False self . print_summary () return # Grab the provider prefix from base info and use it when looking for provider fields self . provider_prefix = None meta = base_info . get ( \"meta\" , {}) if meta . get ( \"provider\" ) is not None : self . provider_prefix = meta [ \"provider\" ] . get ( \"prefix\" ) # Set the response class for all `/info/entry` endpoints based on `/info` response self . available_json_endpoints , _ = self . _get_available_endpoints ( base_info , request = info_endp ) for endp in self . available_json_endpoints : self . _response_classes [ f \" { info_endp } / { endp } \" ] = EntryInfoResponse # Run some tests on the versions endpoint self . _log . debug ( \"Testing versions endpoint %s \" , CONF . versions_endpoint ) self . _test_versions_endpoint () self . _test_bad_version_returns_553 () # Test that entry info endpoints deserialize correctly # If they do not, the corresponding entry in _entry_info_by_type # is set to False, which must be checked for further validation for endp in self . available_json_endpoints : entry_info_endpoint = f \" { info_endp } / { endp } \" self . _log . debug ( \"Testing expected info endpoint %s \" , entry_info_endpoint ) self . _entry_info_by_type [ endp ] = self . _test_info_or_links_endpoint ( entry_info_endpoint ) # Test that the results from multi-entry-endpoints obey, e.g. page limits, # and that all entries can be deserialized with the patched models. # These methods also set the test_ids for each type of entry, which are validated # in the next loop. for endp in self . available_json_endpoints : self . _log . debug ( \"Testing multiple entry endpoint of %s \" , endp ) self . _test_multi_entry_endpoint ( endp ) # Test that the single IDs scraped earlier work with the single entry endpoint for endp in self . available_json_endpoints : self . _log . debug ( \"Testing single entry request of type %s \" , endp ) self . _test_single_entry_endpoint ( endp ) # Use the _entry_info_by_type to construct filters on the relevant endpoints if not self . minimal : for endp in self . available_json_endpoints : self . _log . debug ( \"Testing queries on JSON entry endpoint of %s \" , endp ) self . _recurse_through_endpoint ( endp ) # Test that the links endpoint can be serialized correctly self . _log . debug ( \"Testing %s endpoint\" , CONF . links_endpoint ) self . _test_info_or_links_endpoint ( CONF . links_endpoint ) self . valid = not ( self . results . failure_count or self . results . internal_failure_count ) self . print_summary () @test_case def _recurse_through_endpoint ( self , endp : str ) -> Tuple [ bool , str ]: \"\"\"For a given endpoint (`endp`), get the entry type and supported fields, testing that all mandatory fields are supported, then test queries on every property according to the reported type, with optionality decided by the specification-level support level for that field. Parameters: endp: Endpoint to be tested. Returns: `True` if endpoint passed the tests, and a string summary. \"\"\" entry_info = self . _entry_info_by_type . get ( endp ) if not entry_info : raise ResponseError ( f \"Unable to generate filters for endpoint { endp } : 'info/ { endp } ' response was malformed.\" ) _impl_properties = self . _check_entry_info ( entry_info , endp ) prop_list = list ( _impl_properties . keys ()) self . _check_response_fields ( endp , prop_list ) chosen_entry , _ = self . _get_archetypal_entry ( endp , prop_list ) if not chosen_entry : return ( None , f \"Unable to generate filters for endpoint { endp } : no valid entries found.\" , ) for prop in _impl_properties : # check support level of property prop_type = _impl_properties [ prop ][ \"type\" ] sortable = _impl_properties [ prop ][ \"sortable\" ] optional = ( CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"queryable\" ) == SupportLevel . OPTIONAL ) if optional and not self . run_optional_tests : continue self . _construct_queries_for_property ( prop , prop_type , sortable , endp , chosen_entry , request = f \"; testing queries for { endp } -> { prop } \" , optional = optional , ) self . _test_unknown_provider_property ( endp ) self . _test_completely_unknown_property ( endp ) return True , f \"successfully recursed through endpoint { endp } .\" @test_case def _test_completely_unknown_property ( self , endp ): request = f \" { endp } ?filter=crazyfield = 2\" response , _ = self . _get_endpoint ( request , expected_status_code = 400 , ) return True , \"unknown field returned 400 Bad Request, as expected\" @test_case def _test_unknown_provider_property ( self , endp ): dummy_provider_field = \"_crazyprovider_field\" request = f \" { endp } ?filter= { dummy_provider_field } =2\" response , _ = self . _get_endpoint ( request , multistage = True , request = request , ) if response is not None : deserialized , _ = self . _deserialize_response ( response , CONF . response_classes [ endp ], request = request , multistage = True ) return ( True , \"Unknown provider field was ignored when filtering, as expected\" , ) raise ResponseError ( \"Failed to handle field from unknown provider; should return without affecting filter results\" ) def _check_entry_info ( self , entry_info : Dict [ str , Any ], endp : str ) -> List [ str ]: \"\"\"Checks that `entry_info` contains all the required properties, and returns the property list for the endpoint. Parameters: entry_info: JSON representation of the response from the entry info endpoint. endp: The name of the entry endpoint. Returns: The list of property names supported by this implementation. \"\"\" properties = entry_info . get ( \"data\" , {}) . get ( \"properties\" , []) self . _test_must_properties ( properties , endp , request = f \" { CONF . info_endpoint } / { endp } \" ) return properties @test_case def _test_must_properties ( self , properties : List [ str ], endp : str ) -> Tuple [ bool , str ]: \"\"\"Check that the entry info lists all properties with the \"MUST\" support level for this endpoint. Parameters: properties: The list of property names supported by the endpoint. endp: The endpoint. Returns: `True` if the properties were found, and a string summary. \"\"\" must_props = set ( prop for prop in CONF . entry_schemas . get ( endp , {}) if CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"support\" ) == SupportLevel . MUST ) must_props_supported = set ( prop for prop in properties if prop in must_props ) missing = must_props - must_props_supported if len ( missing ) != 0 : raise ResponseError ( f \"Some 'MUST' properties were missing from info/ { endp } : { missing } \" ) return True , f \"Found all required properties in entry info for endpoint { endp } \" @test_case def _get_archetypal_entry ( self , endp : str , properties : List [ str ] ) -> Tuple [ Dict [ str , Any ], str ]: \"\"\"Get a random entry from the first page of results for this endpoint. Parameters: endp: The endpoint to query. Returns: The JSON representation of the chosen entry and the summary message. \"\"\" response , message = self . _get_endpoint ( endp , multistage = True ) if response : data = response . json () . get ( \"data\" , []) data_returned = len ( data ) if data_returned < 1 : return ( None , \"Endpoint {endp!r} returned no entries, cannot get archetypal entry or test filtering.\" , ) archetypal_entry = response . json ()[ \"data\" ][ random . randint ( 0 , data_returned - 1 ) ] return ( archetypal_entry , f \"set archetypal entry for { endp } with ID { archetypal_entry [ 'id' ] } .\" , ) raise ResponseError ( f \"Failed to get archetypal entry. Details: { message } \" ) @test_case def _check_response_fields ( self , endp : str , fields : List [ str ]) -> Tuple [ bool , str ]: \"\"\"Check that the response field query parameter is obeyed. Parameters: endp: The endpoint to query. fields: The known fields for this endpoint to test. Returns: Bool indicating success and a summary message. \"\"\" subset_fields = random . sample ( fields , min ( len ( fields ) - 1 , 3 )) test_query = f \" { endp } ?response_fields= { ',' . join ( subset_fields ) } &page_limit=1\" response , _ = self . _get_endpoint ( test_query , multistage = True ) if response and len ( response . json ()[ \"data\" ]) >= 0 : doc = response . json ()[ \"data\" ][ 0 ] expected_fields = set ( subset_fields ) expected_fields -= CONF . top_level_non_attribute_fields if \"attributes\" not in doc : raise ResponseError ( f \"Entries are missing `attributes` key. \\n Received: { doc } \" ) returned_fields = set ( sorted ( list ( doc . get ( \"attributes\" , {}) . keys ()))) returned_fields -= CONF . top_level_non_attribute_fields if expected_fields != returned_fields : raise ResponseError ( f \"Response fields not obeyed by { endp !r} : \\n Expected: { expected_fields } \\n Returned: { returned_fields } \" ) return True , \"Successfully limited response fields\" return ( None , f \"Unable to test adherence to response fields as no entries were returned for endpoint { endp !r} .\" , ) @test_case def _construct_queries_for_property ( self , prop : str , prop_type : DataType , sortable : bool , endp : str , chosen_entry : Dict [ str , Any ], ) -> Tuple [ Optional [ bool ], str ]: \"\"\"For the given property, property type and chose entry, this method runs a series of queries for each field in the entry, testing that the initial document is returned where expected. Parameters: prop: The property name. prop_type: The property type. sortable: Whether the implementation has indicated that the field is sortable. endp: The corresponding entry endpoint. chosen_entry: A JSON respresentation of the chosen entry that will be used to construct the filters. Returns: Boolean indicating success (`True`) or failure/irrelevance (`None`) and the string summary of the test case. \"\"\" # Explicitly handle top level keys that do not have types in info if not chosen_entry : raise ResponseError ( f \"Chosen entry of endpoint '/ { endp } ' failed validation.\" ) if prop == \"type\" : if chosen_entry [ \"type\" ] == endp : return True , f \"Successfully validated { prop } \" raise ResponseError ( f \"Chosen entry of endpoint ' { endp } ' had unexpected type { chosen_entry [ 'type' ] !r} .\" ) prop_type = ( CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"type\" ) if prop_type is None else prop_type ) if prop_type is None : raise ResponseError ( f \"Cannot validate queries on { prop !r} as field type was not reported in `/info/ { endp } `\" ) # this is the case of a provider field if prop not in CONF . entry_schemas [ endp ]: if self . provider_prefix is None : raise ResponseError ( f \"Found unknown field { prop !r} in `/info/ { endp } ` and no provider prefix was provided in `/info`\" ) elif not prop . startswith ( f \"_ { self . provider_prefix } _\" ): raise ResponseError ( f \"Found unknown field { prop !r} that did not start with provider prefix '_ { self . provider_prefix } _'\" ) return ( None , f \"Found provider field { prop !r} , will not test queries as they are strictly optional.\" , ) query_optional = ( CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"queryable\" ) == SupportLevel . OPTIONAL ) return self . _construct_single_property_filters ( prop , prop_type , sortable , endp , chosen_entry , query_optional ) @staticmethod def _format_test_value ( test_value : Any , prop_type : DataType , operator : str ) -> str : \"\"\"Formats the test value as a string according to the type of the property. Parameters: test_value: The value to format. prop_type: The OPTIMADE data type of the field. operator: The operator that will be applied to it. Returns: The value formatted as a string to use in an OPTIMADE filter. \"\"\" if prop_type == DataType . LIST : if operator in ( \"HAS ALL\" , \"HAS ANY\" ): _vals = sorted ( set ( test_value )) if isinstance ( test_value [ 0 ], str ): _vals = [ f '\" { val } \"' for val in _vals ] else : _vals = [ f \" { val } \" for val in _vals ] _test_value = \",\" . join ( _vals ) else : if isinstance ( test_value [ 0 ], str ): _test_value = f '\" { test_value [ 0 ] } \"' else : _test_value = test_value [ 0 ] elif prop_type in ( DataType . STRING , DataType . TIMESTAMP ): _test_value = f '\" { test_value } \"' else : _test_value = test_value return _test_value def _construct_single_property_filters ( self , prop : str , prop_type : DataType , sortable : bool , endp : str , chosen_entry : Dict [ str , Any ], query_optional : bool , ) -> Tuple [ Optional [ bool ], str ]: \"\"\"This method constructs appropriate queries using all operators for a certain field and applies some tests: - inclusive operators return compatible entries, e.g. `>=` always returns at least the results of `=`. - exclusive operators never return contradictory entries, e.g. `nsites=1` never returns the same entries as `nsites!=1`, modulo pagination. Parameters: prop: The property name. prop_type: The property type. sortable: Whether the implementation has indicated that the field is sortable. endp: The corresponding entry endpoint. chosen_entry: A JSON respresentation of the chosen entry that will be used to construct the filters. query_optional: Whether to treat query success as optional. Returns: Boolean indicating success (`True`) or failure/irrelevance (`None`) and the string summary of the test case. \"\"\" if prop == \"id\" : test_value = chosen_entry . get ( \"id\" ) else : test_value = chosen_entry . get ( \"attributes\" , {}) . get ( prop , \"_missing\" ) if test_value in ( \"_missing\" , None ): support = CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"support\" ) queryable = CONF . entry_schemas [ endp ] . get ( prop , {}) . get ( \"queryable\" ) submsg = \"had no value\" if test_value == \"_missing\" else \"had `None` value\" msg = ( f \"Chosen entry { submsg } for { prop !r} with support level { support } and queryability { queryable } , \" f \"so cannot construct test queries. This field should potentially be removed from the `/info/ { endp } ` endpoint response.\" ) # None values are allowed for OPTIONAL and SHOULD, so we can just skip if support in ( SupportLevel . OPTIONAL , SupportLevel . SHOULD , ): self . _log . info ( msg ) return None , msg # Otherwise, None values are not allowed for MUST's, and entire missing fields are not allowed raise ResponseError ( msg ) using_fallback = False if prop_type == DataType . LIST : if not test_value : test_value = CONF . enum_fallback_values . get ( endp , {}) . get ( prop ) using_fallback = True if not test_value : msg = f \"Not testing filters on field { prop } of type { prop_type } as no test value was found to use in filter.\" self . _log . warning ( msg ) return None , msg if isinstance ( test_value [ 0 ], dict ) or isinstance ( test_value [ 0 ], list ): msg = f \"Not testing filters on field { prop } of type { prop_type } with nested dictionary/list test value.\" self . _log . warning ( msg ) return None , msg # Try to infer if the test value is a float from its string representation # and decide whether to do inclusive/exclusive query tests try : float ( test_value [ 0 ]) msg = f \"Not testing filters on field { prop } of type { prop_type } containing float values.\" self . _log . warning ( msg ) return None , msg except ValueError : pass if prop_type in ( DataType . DICTIONARY ,): msg = f \"Not testing queries on field { prop } of type { prop_type } .\" self . _log . warning ( msg ) return None , msg num_data_returned = {} inclusive_operators = CONF . inclusive_operators [ prop_type ] exclusive_operators = CONF . exclusive_operators [ prop_type ] field_specific_support_overrides = CONF . field_specific_overrides . get ( prop , {}) for operator in inclusive_operators | exclusive_operators : # Need to pre-format list and string test values for the query _test_value = self . _format_test_value ( test_value , prop_type , operator ) query_optional = ( query_optional or operator in field_specific_support_overrides . get ( SupportLevel . OPTIONAL , []) ) query = f \" { prop } { operator } { _test_value } \" request = f \" { endp } ?filter= { query } \" response , message = self . _get_endpoint ( request , multistage = True , optional = query_optional , expected_status_code = ( 200 , 501 ), ) if not response : if query_optional : return ( None , \"Optional query {query!r} raised the error: {message} .\" , ) raise ResponseError ( f \"Unable to perform mandatory query { query !r} , which raised the error: { message } \" ) response = response . json () if \"meta\" not in response or \"more_data_available\" not in response [ \"meta\" ]: raise ResponseError ( f \"Required field `meta->more_data_available` missing from response for { request } .\" ) if not response [ \"meta\" ][ \"more_data_available\" ]: num_data_returned [ operator ] = len ( response [ \"data\" ]) else : num_data_returned [ operator ] = response [ \"meta\" ] . get ( \"data_returned\" ) if prop in CONF . unique_properties and operator == \"=\" : if num_data_returned [ \"=\" ] is not None and num_data_returned [ \"=\" ] == 0 : raise ResponseError ( f \"Unable to filter field 'id' for equality, no data was returned for { query } .\" ) if num_data_returned [ \"=\" ] is not None and num_data_returned [ \"=\" ] > 1 : raise ResponseError ( f \"Filter for an individual 'id' returned { num_data_returned [ '=' ] } results, when only 1 was expected.\" ) num_response = num_data_returned [ operator ] excluded = operator in exclusive_operators # if we have all results on this page, check that the blessed ID is in the response # if not response[\"meta\"][\"more_data_available\"]: if excluded and ( chosen_entry [ \"id\" ] in set ( entry [ \"id\" ] for entry in response [ \"data\" ]) ): raise ResponseError ( f \"Entry { chosen_entry [ 'id' ] } with value { prop !r} : { test_value } was not excluded by { query !r} \" ) # check that at least the archetypal structure was returned, unless we are using a fallback value if not excluded and not using_fallback : if ( num_data_returned [ operator ] is not None and num_data_returned [ operator ] < 1 ): raise ResponseError ( f \"Supposedly inclusive query { query !r} did not include original entry ID { chosen_entry [ 'id' ] !r} \" f \"(with field { prop !r} = { test_value } ) potentially indicating a problem with filtering on this field.\" ) # check that the filter returned no entries that had a null or missing value for the filtered property if any ( entry [ \"attributes\" ] . get ( prop , entry . get ( prop , None )) is None for entry in response . get ( \"data\" , []) ): raise ResponseError ( f \"Filter { query !r} on field { prop !r} returned entries that had null or missing values for the field.\" ) # Numeric and string comparisons must work both ways... if prop_type in ( DataType . STRING , DataType . INTEGER , DataType . FLOAT , DataType . TIMESTAMP , ) and operator not in ( \"CONTAINS\" , \"STARTS\" , \"STARTS WITH\" , \"ENDS\" , \"ENDS WITH\" , ): reversed_operator = operator . replace ( \"<\" , \">\" ) if \"<\" in operator : reversed_operator = operator . replace ( \"<\" , \">\" ) elif \">\" in operator : reversed_operator = operator . replace ( \">\" , \"<\" ) # Don't try to reverse string comparison as it is ill-defined if prop_type == DataType . STRING and any ( comp in operator for comp in ( \"<\" , \">\" ) ): continue reversed_query = f \" { _test_value } { reversed_operator } { prop } \" reversed_request = f \" { endp } ?filter= { reversed_query } \" reversed_response , message = self . _get_endpoint ( reversed_request , multistage = True , optional = query_optional , expected_status_code = ( 200 , 501 ), ) if not reversed_response : if query_optional : return ( None , \"Optional query {reversed_query!r} raised the error: {message} .\" , ) raise ResponseError ( f \"Unable to perform mandatory query { reversed_query !r} , which raised the error: { message } \" ) reversed_response = reversed_response . json () if ( \"meta\" not in reversed_response or \"more_data_available\" not in reversed_response [ \"meta\" ] ): raise ResponseError ( f \"Required field `meta->more_data_available` missing from response for { request } .\" ) if not reversed_response [ \"meta\" ][ \"more_data_available\" ]: num_reversed_response = len ( reversed_response [ \"data\" ]) else : num_reversed_response = reversed_response [ \"meta\" ] . get ( \"data_returned\" ) if num_response is not None and num_reversed_response is not None : if reversed_response [ \"meta\" ] . get ( \"data_returned\" ) != response [ \"meta\" ] . get ( \"data_returned\" ): raise ResponseError ( f \"Query { query } did not work both ways around: { reversed_query } , \" \"returning different results each time.\" ) # check that the filter returned no entries that had a null or missing value for the filtered property if any ( entry [ \"attributes\" ] . get ( prop , entry . get ( prop , None )) is None for entry in reversed_response . get ( \"data\" , []) ): raise ResponseError ( f \"Filter { reversed_query !r} on field { prop !r} returned entries that had null or missing values for the field.\" ) return True , f \" { prop } passed filter tests\" def _test_info_or_links_endpoint ( self , request_str : str ) -> Union [ bool , dict ]: \"\"\"Requests an info or links endpoint and attempts to deserialize the response. Parameters: request_str: The request to make, e.g. \"links\". Returns: `False` if the info response failed deserialization, otherwise returns the deserialized object. \"\"\" response , _ = self . _get_endpoint ( request_str ) if response : deserialized , _ = self . _deserialize_response ( response , self . _response_classes [ request_str ], request = request_str , ) if deserialized : return deserialized . dict () return False def _test_single_entry_endpoint ( self , endp : str ) -> None : \"\"\"Requests and deserializes a single entry endpoint with the appropriate model. Parameters: request_str: The single entry request to make, e.g. \"structures/id_1\". \"\"\" response_cls_name = endp + \"/\" if response_cls_name in self . _response_classes : response_cls = self . _response_classes [ response_cls_name ] else : self . _log . warning ( \"Deserializing single entry response %s with generic response rather than defined endpoint.\" , endp , ) response_cls = ValidatorEntryResponseOne response_fields = set () if endp in CONF . entry_schemas : response_fields = ( set ( CONF . entry_schemas [ endp ] . keys ()) - CONF . top_level_non_attribute_fields ) if endp in self . _test_id_by_type : test_id = self . _test_id_by_type [ endp ] request_str = f \" { endp } / { test_id } \" if response_fields : request_str += f \"?response_fields= { ',' . join ( response_fields ) } \" response , _ = self . _get_endpoint ( request_str ) if response : self . _deserialize_response ( response , response_cls , request = request_str ) def _test_multi_entry_endpoint ( self , endp : str ) -> None : \"\"\"Requests and deserializes a multi-entry endpoint with the appropriate model. Parameters: request_str: The multi-entry request to make, e.g., \"structures?filter=nsites<10\" \"\"\" if endp in self . _response_classes : response_cls = self . _response_classes [ endp ] else : self . _log . warning ( \"Deserializing multi entry response from %s with generic response rather than defined endpoint.\" , endp , ) response_cls = ValidatorEntryResponseMany response_fields = set () if endp in CONF . entry_schemas : response_fields = ( set ( CONF . entry_schemas [ endp ] . keys ()) - CONF . top_level_non_attribute_fields ) request_str = f \" { endp } ?page_limit= { self . page_limit } \" if response_fields : request_str += f '&response_fields= { \",\" . join ( response_fields ) } ' response , _ = self . _get_endpoint ( request_str ) self . _test_page_limit ( response ) deserialized , _ = self . _deserialize_response ( response , response_cls , request = request_str ) self . _get_single_id_from_multi_entry_endpoint ( deserialized , request = request_str ) if deserialized : self . _test_data_available_matches_data_returned ( deserialized , request = request_str ) @test_case def _test_data_available_matches_data_returned ( self , deserialized : Any ) -> Tuple [ bool , str ]: \"\"\"In the case where no query is requested, `data_available` must equal `data_returned` in the meta response, which is tested here. Parameters: deserialized: The deserialized response to a multi-entry endpoint. Returns: `True` if successful, with a string summary. \"\"\" if ( deserialized . meta . data_available is None or deserialized . meta . data_returned is None ): return ( None , \"`meta->data_available` and/or `meta->data_returned` were not provided.\" , ) if deserialized . meta . data_available != deserialized . meta . data_returned : raise ResponseError ( \"No query was performed, but `data_returned` != `data_available`.\" ) return ( True , \"Meta response contained correct values for data_available and data_returned.\" , ) def _test_versions_endpoint ( self ): \"\"\"Requests and validate responses for the versions endpoint, which MUST exist for unversioned base URLs and MUST NOT exist for versioned base URLs. \"\"\" # First, check that there is a versions endpoint in the appropriate place: # If passed a versioned URL, then strip that version from # the URL before looking for `/versions`. _old_base_url = self . base_url if re . match ( VERSIONS_REGEXP , self . base_url_parsed . path ) is not None : self . client . base_url = \"/\" . join ( self . client . base_url . split ( \"/\" )[: - 1 ]) self . base_url = self . client . base_url response , _ = self . _get_endpoint ( CONF . versions_endpoint , expected_status_code = 200 ) if response : self . _test_versions_endpoint_content ( response , request = CONF . versions_endpoint ) # If passed a versioned URL, first reset the URL of the client to the # versioned one, then test that this versioned URL does NOT host a versions endpoint if re . match ( VERSIONS_REGEXP , self . base_url_parsed . path ) is not None : self . client . base_url = _old_base_url self . base_url = _old_base_url self . _get_endpoint ( CONF . versions_endpoint , expected_status_code = 404 ) @test_case def _test_versions_endpoint_content ( self , response : requests . Response ) -> Tuple [ requests . Response , str ]: \"\"\"Checks that the response from the versions endpoint complies with the specification and that its 'Content-Type' header complies with [RFC 4180](https://tools.ietf.org/html/rfc4180.html). Parameters: response: The HTTP response from the versions endpoint. Raises: ResponseError: If any content checks fail. Returns: The successful HTTP response or `None`, and a summary string. \"\"\" text_content = response . text . strip () . split ( \" \\n \" ) if text_content [ 0 ] != \"version\" : raise ResponseError ( f \"First line of `/ { CONF . versions_endpoint } ` response must be 'version', not { text_content [ 0 ] !r} \" ) if len ( text_content ) <= 1 : raise ResponseError ( f \"No version numbers found in `/ { CONF . versions_endpoint } ` response, only { text_content } \" ) for version in text_content [ 1 :]: try : int ( version ) except ValueError : raise ResponseError ( f \"Version numbers reported by `/ { CONF . versions_endpoint } ` must be integers specifying the major version, not { text_content } .\" ) content_type = response . headers . get ( \"content-type\" ) if not content_type : raise ResponseError ( \"Missing 'Content-Type' in response header from `/versions`.\" ) content_type = [ _ . replace ( \" \" , \"\" ) for _ in content_type . split ( \";\" )] self . _test_versions_headers ( content_type , ( \"text/csv\" , \"text/plain\" ), optional = True , request = CONF . versions_endpoint , ) self . _test_versions_headers ( content_type , \"header=present\" , optional = True , request = CONF . versions_endpoint , ) return response , \"`/versions` endpoint responded correctly.\" @test_case def _test_versions_headers ( self , content_type : Dict [ str , Any ], expected_parameter : Union [ str , List [ str ]], ) -> Tuple [ Dict [ str , Any ], str ]: \"\"\"Tests that the `Content-Type` field of the `/versions` header contains the passed parameter. Arguments: content_type: The 'Content-Type' field from the response of the `/versions` endpoint. expected_paramter: A substring or list of substrings that are expected in the Content-Type of the response. If multiple strings are passed, they will be treated as possible alternatives to one another. Raises: ResponseError: If the expected 'Content-Type' parameter is missing. Returns: The HTTP response headers and a summary string. \"\"\" if isinstance ( expected_parameter , str ): expected_parameter = [ expected_parameter ] if not any ( param in content_type for param in expected_parameter ): raise ResponseError ( f \"Incorrect 'Content-Type' header { ';' . join ( content_type ) !r} . \\n \" f \"Missing at least one expected parameter(s): { expected_parameter !r} \" ) return ( content_type , f \"`/versions` response had one of the expected Content-Type parameters { expected_parameter } .\" , ) def _test_as_type ( self ) -> None : \"\"\"Tests that the base URL of the validator (i.e. with no additional path added) validates with the model selected. \"\"\" response , _ = self . _get_endpoint ( \"\" ) if response : self . _log . debug ( \"Deserialzing response as type %s \" , self . as_type_cls ) self . _deserialize_response ( response , self . as_type_cls ) def _test_bad_version_returns_553 ( self ) -> None : \"\"\"Tests that a garbage version number responds with a 553 error code. \"\"\" expected_status_code = 553 if re . match ( VERSIONS_REGEXP , self . base_url_parsed . path ) is not None : expected_status_code = [ 404 , 400 ] self . _get_endpoint ( \"v123123\" , expected_status_code = expected_status_code , optional = True ) @test_case def _test_page_limit ( self , response : requests . models . Response , check_next_link : int = 5 , previous_links : Optional [ Set [ str ]] = None , ) -> Tuple [ Optional [ bool ], str ]: \"\"\"Test that a multi-entry endpoint obeys the page limit by following pagination links up to a depth of `check_next_link`. Parameters: response: The response to test for page limit compliance. check_next_link: Maximum recursion depth for following pagination links. previous_links: A set of previous links that will be used to check that the `next` link is actually new. Returns: `True` if the test was successful and `None` if not, with a string summary. \"\"\" if previous_links is None : previous_links = set () try : response = response . json () except ( AttributeError , json . JSONDecodeError ): raise ResponseError ( \"Unable to test endpoint `page_limit` parameter.\" ) try : num_entries = len ( response [ \"data\" ]) except ( KeyError , TypeError ): raise ResponseError ( \"Response under `data` field was missing or had wrong type.\" ) if num_entries > self . page_limit : raise ResponseError ( f \"Endpoint did not obey page limit: { num_entries } entries vs { self . page_limit } limit\" ) try : more_data_available = response [ \"meta\" ][ \"more_data_available\" ] except KeyError : raise ResponseError ( \"Field `meta->more_data_available` was missing.\" ) if more_data_available and check_next_link : try : next_link = response [ \"links\" ][ \"next\" ] if isinstance ( next_link , dict ): next_link = next_link [ \"href\" ] except KeyError : raise ResponseError ( \"Endpoint suggested more data was available but provided no valid links->next link.\" ) if next_link in previous_links : raise ResponseError ( f \"The next link { next_link } has been provided already for a previous page.\" ) previous_links . add ( next_link ) if not isinstance ( next_link , str ): raise ResponseError ( f \"Unable to parse links->next { next_link !r} as a link.\" ) self . _log . debug ( \"Following pagination link to %r .\" , next_link ) next_response , _ = self . _get_endpoint ( next_link ) if not next_response : raise ResponseError ( f \"Error when testing pagination: the response from `links->next` { next_link !r} failed the previous test.\" ) check_next_link = bool ( check_next_link - 1 ) self . _test_page_limit ( next_response , check_next_link = check_next_link , multistage = check_next_link , previous_links = previous_links , ) return ( True , f \"Endpoint obeyed page limit of { self . page_limit } by returning { num_entries } entries.\" , ) @test_case def _get_single_id_from_multi_entry_endpoint ( self , deserialized ): \"\"\"Scrape an ID from the multi-entry endpoint to use as query for single entry endpoint. \"\"\" if deserialized and deserialized . data : self . _test_id_by_type [ deserialized . data [ 0 ] . type ] = deserialized . data [ 0 ] . id self . _log . debug ( \"Set type %s test ID to %s \" , deserialized . data [ 0 ] . type , deserialized . data [ 0 ] . id , ) else : return ( None , \"No entries found under endpoint to scrape ID from. \" \"This may be caused by previous errors, if e.g. the endpoint failed deserialization.\" , ) return ( self . _test_id_by_type [ deserialized . data [ 0 ] . type ], f \"successfully scraped test ID from { deserialized . data [ 0 ] . type } endpoint\" , ) @test_case def _deserialize_response ( self , response : requests . models . Response , response_cls : Any , request : str = None ) -> Tuple [ Any , str ]: \"\"\"Try to create the appropriate pydantic model from the response. Parameters: response: The response to try to deserialize. response_cls: The class to use for deserialization. request: Optional string that will be displayed as the attempted request in the validator output. Returns: The deserialized object (or `None` if unsuccessful) and a human-readable summary \"\"\" if not response : raise ResponseError ( \"Request failed\" ) try : json_response = response . json () except json . JSONDecodeError : raise ResponseError ( f \"Unable to decode response as JSON. Response: { response } \" ) self . _log . debug ( f \"Deserializing { json . dumps ( json_response , indent = 2 ) } as model { response_cls } \" ) return ( response_cls ( ** json_response ), \"deserialized correctly as object of type {} \" . format ( response_cls ), ) @test_case def _get_available_endpoints ( self , base_info : Union [ Any , Dict [ str , Any ]] ) -> Tuple [ Optional [ List [ str ]], str ]: \"\"\"Tries to get `entry_types_by_format` from base info response even if it could not be deserialized. Parameters: base_info: Either the unvalidated JSON representation of the base info, or the deserialized object. Returns: The list of JSON entry endpoints (or `None` if unavailable) and a string summary. \"\"\" for _ in [ 0 ]: try : available_json_entry_endpoints = base_info [ \"data\" ][ \"attributes\" ][ \"entry_types_by_format\" ][ \"json\" ] break except ( KeyError , TypeError ): raise ResponseError ( \"Unable to get entry_types_by_format from unserializable base info response {} .\" . format ( base_info ) ) else : raise ResponseError ( \"Unable to find any JSON entry types in entry_types_by_format\" ) if self . index and available_json_entry_endpoints != []: raise ResponseError ( \"No entry endpoint are allowed for an Index meta-database\" ) for non_entry_endpoint in CONF . non_entry_endpoints : if non_entry_endpoint in available_json_entry_endpoints : raise ResponseError ( f 'Illegal entry \" { non_entry_endpoint } \" was found in entry_types_by_format\"' ) # Filter out custom extension endpoints that are not covered in the specification available_json_entry_endpoints = [ endp for endp in available_json_entry_endpoints if endp in CONF . entry_endpoints ] return ( available_json_entry_endpoints , \"successfully found available entry types in baseinfo\" , ) @test_case def _get_endpoint ( self , request_str : str , expected_status_code : Union [ List [ int ], int ] = 200 ) -> Tuple [ Optional [ requests . Response ], str ]: \"\"\"Gets the response from the endpoint specified by `request_str`. function is wrapped by the `test_case` decorator Parameters: request_str: The request to make to the client. expected_status_code: If the request responds with a different status code to this one, raise a ResponseError. Returns: The response to the request (if successful) or `None`, plus a string summary. \"\"\" request_str = request_str . replace ( \" \\n \" , \"\" ) response = self . client . get ( request_str ) if isinstance ( expected_status_code , int ): expected_status_code = [ expected_status_code ] message = f \"received expected response: { response } .\" if response . status_code != 200 : message = f \"Request to ' { request_str } ' returned HTTP status code { response . status_code } .\" message += \" \\n Additional details from implementation:\" try : for error in response . json () . get ( \"errors\" , []): message += f ' \\n { error . get ( \"title\" , \"N/A\" ) } : { error . get ( \"detail\" , \"N/A\" ) } ( { error . get ( \"source\" , {}) . get ( \"pointer\" , \"N/A\" ) } )' except json . JSONDecodeError : message += f \" \\n Could not parse response as JSON. Content type was { response . headers . get ( 'content-type' ) !r} .\" if response . status_code not in expected_status_code : raise ResponseError ( message ) return response , message","title":"ImplementationValidator"},{"location":"api_reference/validator/validator/#optimade.validator.validator.ImplementationValidator.__init__","text":"Set up the tests to run, based on constants in this module for required endpoints. Parameters: Name Type Description Default client Any A client that has a .get() method to obtain the response from the implementation. If None , then Client will be used. None base_url str The URL of the implementation to validate. Unless performing \"as_type\" validation, this should point to the base of the OPTIMADE implementation. None verbosity int The verbosity of the output and logging as an integer ( 0 : critical, 1 : warning, 2 : info, 3 : debug). 0 respond_json bool If True , print only a JSON representation of the results of validation to stdout. False page_limit int The default page limit to apply to filters. 4 max_retries int Argument is passed to the client for how many attempts to make for a request before failing. 5 run_optional_tests bool Whether to run the tests on optional OPTIMADE features. True fail_fast bool Whether to exit validation after the first failure of a mandatory test. False as_type str An OPTIMADE entry or endpoint type to coerce the response from implementation into, e.g. \"structures\". Requires base_url to be pointed to the corresponding endpoint. None index bool Whether to validate the implementation as an index meta-database. False minimal bool Whether or not to run only a minimal test set. False http_headers Dict [ str , str ] Dictionary of additional headers to add to every request. None timeout float The connection timeout to use for all requests (in seconds). DEFAULT_CONN_TIMEOUT read_timeout float The read timeout to use for all requests (in seconds). DEFAULT_READ_TIMEOUT Source code in optimade/validator/validator.py 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 def __init__ ( # pylint: disable=too-many-arguments self , client : Any = None , base_url : str = None , verbosity : int = 0 , respond_json : bool = False , page_limit : int = 4 , max_retries : int = 5 , run_optional_tests : bool = True , fail_fast : bool = False , as_type : str = None , index : bool = False , minimal : bool = False , http_headers : Dict [ str , str ] = None , timeout : float = DEFAULT_CONN_TIMEOUT , read_timeout : float = DEFAULT_READ_TIMEOUT , ): \"\"\"Set up the tests to run, based on constants in this module for required endpoints. Arguments: client: A client that has a `.get()` method to obtain the response from the implementation. If `None`, then [`Client`][optimade.validator.utils.Client] will be used. base_url: The URL of the implementation to validate. Unless performing \"as_type\" validation, this should point to the base of the OPTIMADE implementation. verbosity: The verbosity of the output and logging as an integer (`0`: critical, `1`: warning, `2`: info, `3`: debug). respond_json: If `True`, print only a JSON representation of the results of validation to stdout. page_limit: The default page limit to apply to filters. max_retries: Argument is passed to the client for how many attempts to make for a request before failing. run_optional_tests: Whether to run the tests on optional OPTIMADE features. fail_fast: Whether to exit validation after the first failure of a mandatory test. as_type: An OPTIMADE entry or endpoint type to coerce the response from implementation into, e.g. \"structures\". Requires `base_url` to be pointed to the corresponding endpoint. index: Whether to validate the implementation as an index meta-database. minimal: Whether or not to run only a minimal test set. http_headers: Dictionary of additional headers to add to every request. timeout: The connection timeout to use for all requests (in seconds). read_timeout: The read timeout to use for all requests (in seconds). \"\"\" self . verbosity = verbosity self . max_retries = max_retries self . page_limit = page_limit self . index = index self . run_optional_tests = run_optional_tests self . fail_fast = fail_fast self . respond_json = respond_json self . minimal = minimal if as_type is None : self . as_type_cls = None elif self . index : if as_type not in CONF . response_classes_index : raise RuntimeError ( f \"Provided as_type=' { as_type } ' not allowed for an Index meta-database.\" ) self . as_type_cls = CONF . response_classes_index [ as_type ] elif as_type in ( \"structure\" , \"reference\" ): self . as_type_cls = CONF . response_classes [ f \" { as_type } s/\" ] else : self . as_type_cls = CONF . response_classes [ as_type ] if client is None and base_url is None : raise RuntimeError ( \"Need at least a URL or a client to initialize validator.\" ) if base_url and client : raise RuntimeError ( \"Please specify at most one of base_url or client.\" ) if client : self . client = client self . base_url = self . client . base_url # If a custom client has been provided, try to set custom headers if they have been specified, # but do not overwrite any existing attributes if http_headers : if not hasattr ( self . client , \"headers\" ): self . client . headers = http_headers else : print_warning ( f \"Not using specified request headers { http_headers } with custom client { self . client } .\" ) else : while base_url . endswith ( \"/\" ): base_url = base_url [: - 1 ] self . base_url = base_url self . client = Client ( base_url , max_retries = self . max_retries , headers = http_headers , timeout = timeout , read_timeout = read_timeout , ) self . _setup_log () self . _response_classes = ( CONF . response_classes_index if self . index else CONF . response_classes ) # some simple checks on base_url self . base_url_parsed = urllib . parse . urlparse ( self . base_url ) # only allow filters/endpoints if we are working in \"as_type\" mode if self . as_type_cls is None and self . base_url_parsed . query : raise SystemExit ( \"Base URL not appropriate: should not contain a filter.\" ) self . valid = None self . _test_id_by_type = {} self . _entry_info_by_type = {} self . results = ValidatorResults ( verbosity = self . verbosity )","title":"__init__()"},{"location":"api_reference/validator/validator/#optimade.validator.validator.ImplementationValidator.print_summary","text":"Print a summary of the results of validation. Source code in optimade/validator/validator.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def print_summary ( self ): \"\"\"Print a summary of the results of validation.\"\"\" if self . respond_json : print ( json . dumps ( dataclasses . asdict ( self . results ), indent = 2 )) return if self . results . failure_messages : print ( \" \\n\\n FAILURES\" ) print ( \"======== \\n \" ) for message in self . results . failure_messages : print_failure ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . optional_failure_messages : print ( \" \\n\\n OPTIONAL TEST FAILURES\" ) print ( \"====================== \\n \" ) for message in self . results . optional_failure_messages : print_notify ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . results . internal_failure_messages : print ( \" \\n\\n INTERNAL FAILURES\" ) print ( \"================= \\n \" ) print ( \"There were internal validator failures associated with this run. \\n \" \"If this problem persists, please report it at: \\n \" \"https://github.com/Materials-Consortia/optimade-python-tools/issues/new \\n \" ) for message in self . results . internal_failure_messages : print_warning ( message [ 0 ]) for line in message [ 1 ] . split ( \" \\n \" ): print_warning ( \" \\t \" + line ) if self . valid or ( not self . valid and not self . fail_fast ): final_message = f \" \\n\\n Passed { self . results . success_count } out of { self . results . success_count + self . results . failure_count + self . results . internal_failure_count } tests.\" if not self . valid : print_failure ( final_message ) else : print_success ( final_message ) if self . run_optional_tests and not self . fail_fast : print ( f \"Additionally passed { self . results . optional_success_count } out of \" f \" { self . results . optional_success_count + self . results . optional_failure_count } optional tests.\" )","title":"print_summary()"},{"location":"api_reference/validator/validator/#optimade.validator.validator.ImplementationValidator.validate_implementation","text":"Run all the test cases on the implementation, or the single type test, depending on what options were provided on initialiation. Sets the self.valid attribute to True or False depending on the outcome of the tests. Raises: Type Description RuntimeError If it was not possible to start the validation process. Source code in optimade/validator/validator.py 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 def validate_implementation ( self ): \"\"\"Run all the test cases on the implementation, or the single type test, depending on what options were provided on initialiation. Sets the `self.valid` attribute to `True` or `False` depending on the outcome of the tests. Raises: RuntimeError: If it was not possible to start the validation process. \"\"\" # If a single \"as type\" has been set, only run that test if self . as_type_cls is not None : self . _log . debug ( \"Validating response of %s with model %s \" , self . base_url , self . as_type_cls , ) self . _test_as_type () self . valid = not bool ( self . results . failure_count ) self . print_summary () return # Test entire implementation if self . verbosity >= 0 : print ( f \"Testing entire implementation at { self . base_url } \" ) info_endp = CONF . info_endpoint self . _log . debug ( \"Testing base info endpoint of %s \" , info_endp ) # Get and validate base info to find endpoints # If this is not possible, then exit at this stage base_info = self . _test_info_or_links_endpoint ( info_endp ) if not base_info : self . _log . critical ( f \"Unable to deserialize response from introspective { info_endp !r} endpoint. \" \"This is required for all further validation, so the validator will now exit.\" ) # Set valid to False to ensure error code 1 is raised at CLI self . valid = False self . print_summary () return # Grab the provider prefix from base info and use it when looking for provider fields self . provider_prefix = None meta = base_info . get ( \"meta\" , {}) if meta . get ( \"provider\" ) is not None : self . provider_prefix = meta [ \"provider\" ] . get ( \"prefix\" ) # Set the response class for all `/info/entry` endpoints based on `/info` response self . available_json_endpoints , _ = self . _get_available_endpoints ( base_info , request = info_endp ) for endp in self . available_json_endpoints : self . _response_classes [ f \" { info_endp } / { endp } \" ] = EntryInfoResponse # Run some tests on the versions endpoint self . _log . debug ( \"Testing versions endpoint %s \" , CONF . versions_endpoint ) self . _test_versions_endpoint () self . _test_bad_version_returns_553 () # Test that entry info endpoints deserialize correctly # If they do not, the corresponding entry in _entry_info_by_type # is set to False, which must be checked for further validation for endp in self . available_json_endpoints : entry_info_endpoint = f \" { info_endp } / { endp } \" self . _log . debug ( \"Testing expected info endpoint %s \" , entry_info_endpoint ) self . _entry_info_by_type [ endp ] = self . _test_info_or_links_endpoint ( entry_info_endpoint ) # Test that the results from multi-entry-endpoints obey, e.g. page limits, # and that all entries can be deserialized with the patched models. # These methods also set the test_ids for each type of entry, which are validated # in the next loop. for endp in self . available_json_endpoints : self . _log . debug ( \"Testing multiple entry endpoint of %s \" , endp ) self . _test_multi_entry_endpoint ( endp ) # Test that the single IDs scraped earlier work with the single entry endpoint for endp in self . available_json_endpoints : self . _log . debug ( \"Testing single entry request of type %s \" , endp ) self . _test_single_entry_endpoint ( endp ) # Use the _entry_info_by_type to construct filters on the relevant endpoints if not self . minimal : for endp in self . available_json_endpoints : self . _log . debug ( \"Testing queries on JSON entry endpoint of %s \" , endp ) self . _recurse_through_endpoint ( endp ) # Test that the links endpoint can be serialized correctly self . _log . debug ( \"Testing %s endpoint\" , CONF . links_endpoint ) self . _test_info_or_links_endpoint ( CONF . links_endpoint ) self . valid = not ( self . results . failure_count or self . results . internal_failure_count ) self . print_summary ()","title":"validate_implementation()"},{"location":"concepts/filtering/","text":"Filter parsing and transforming \u00b6 One of the aims of this package is to integrate with existing databases and APIs, and as such your particular backend may not have a supported filter transformer. This guide will briefly outline how to parse OPTIMADE filter strings into database or API-specific queries. Parsing OPTIMADE filter strings \u00b6 The LarkParser class will take an OPTIMADE filter string, supplied by the user, and parse it into a lark.Tree instance. Example use: from optimade.filterparser import LarkParser p = LarkParser ( version = ( 1 , 0 , 0 )) tree = p . parse ( \"nelements<3\" ) print ( tree ) Tree ( 'filter' , [ Tree ( 'expression' , [ Tree ( 'expression_clause' , [ Tree ( 'expression_phrase' , [ Tree ( 'comparison' , [ Tree ( 'property_first_comparison' , [ Tree ( 'property' , [ Token ( 'IDENTIFIER' , 'nelements' )]) , Tree ( 'value_op_rhs' , [ Token ( 'OPERATOR' , '<' ) , Tree ( 'value' , [ Tree ( 'number' , [ Token ( 'SIGNED_INT' , '3' )])])])])])])])])]) print ( tree . pretty ()) filter expression expression_clause expression_phrase comparison property_first_comparison property nelements value_op_rhs < value number 3 tree = p . parse ( '_mp_bandgap > 5.0 AND _cod_molecular_weight < 350' ) print ( tree . pretty ()) filter expression expression_clause expression_phrase comparison property_first_comparison property _mp_bandgap value_op_rhs > value number 5 .0 expression_phrase comparison property_first_comparison property _cod_molecular_weight value_op_rhs < value number 350 Flow for parsing a user-supplied filter and converting to a backend query \u00b6 After the LarkParser has turned the filter string into a lark.Tree , it is fed to a lark.Transformer instance, which transforms the 'lark.Tree' into a backend-specific representation of the query. For example, MongoTransformer will turn the tree into something useful for a MongoDB backend: # Example: Converting to MongoDB Query Syntax from optimade.filtertransformers.mongo import MongoTransformer transformer = MongoTransformer () tree = p . parse ( '_mp_bandgap > 5.0 AND _cod_molecular_weight < 350' ) query = transformer . transform ( tree ) print ( query ) { \"$and\" : [ { \"_mp_bandgap\" : { \"$gt\" : 5.0 }}, { \"_cod_molecular_weight\" : { \"$lt\" : 350.0 }} ] } Developing new filter transformers \u00b6 In order to support a new backend, you will need to create a new filter transformer that inherits from the BaseTransformer . This transformer will need to override the methods that match the particular grammatical constructs in the Lark grammar in order to construct a query. Two examples can be found within optimade-python-tools , one for MongoDB ( MongoTransformer ) and one for Elasticsearch ( ElasticTransformer ). In some cases, you may also need to extend the base EntryCollection , the class that receives the transformed filter as an argument to its private ._run_db_query() method. This class handles the connections to the underlying database, formatting of the response in an OPTIMADE format, and other API features such as sorting and pagination. Again, the examples for MongoDB ( MongoCollection ) and Elasticsearch ( ElasticCollection ) should be helpful. If you would like to contribute your new filter transformer back to the package, please raise an issue to signal your intent (in case someone else is already working on this). Adding a transformer requires the following: A new submodule ( .py file) in the optimade/filtertransformers folder containing an implementation of the transformer object that extends optimade.filtertransformers.base_transformer.BaseTransformer . Any additional Python requirements must be optional and provided as a separate \" extra_requires \" entry in setup.py and in the requirements.txt file. Tests in optimade/filtertransformers/tests that are skipped if the required packages fail to import.","title":"Filter parsing and transforming"},{"location":"concepts/filtering/#filter-parsing-and-transforming","text":"One of the aims of this package is to integrate with existing databases and APIs, and as such your particular backend may not have a supported filter transformer. This guide will briefly outline how to parse OPTIMADE filter strings into database or API-specific queries.","title":"Filter parsing and transforming"},{"location":"concepts/filtering/#parsing-optimade-filter-strings","text":"The LarkParser class will take an OPTIMADE filter string, supplied by the user, and parse it into a lark.Tree instance. Example use: from optimade.filterparser import LarkParser p = LarkParser ( version = ( 1 , 0 , 0 )) tree = p . parse ( \"nelements<3\" ) print ( tree ) Tree ( 'filter' , [ Tree ( 'expression' , [ Tree ( 'expression_clause' , [ Tree ( 'expression_phrase' , [ Tree ( 'comparison' , [ Tree ( 'property_first_comparison' , [ Tree ( 'property' , [ Token ( 'IDENTIFIER' , 'nelements' )]) , Tree ( 'value_op_rhs' , [ Token ( 'OPERATOR' , '<' ) , Tree ( 'value' , [ Tree ( 'number' , [ Token ( 'SIGNED_INT' , '3' )])])])])])])])])]) print ( tree . pretty ()) filter expression expression_clause expression_phrase comparison property_first_comparison property nelements value_op_rhs < value number 3 tree = p . parse ( '_mp_bandgap > 5.0 AND _cod_molecular_weight < 350' ) print ( tree . pretty ()) filter expression expression_clause expression_phrase comparison property_first_comparison property _mp_bandgap value_op_rhs > value number 5 .0 expression_phrase comparison property_first_comparison property _cod_molecular_weight value_op_rhs < value number 350","title":"Parsing OPTIMADE filter strings"},{"location":"concepts/filtering/#flow-for-parsing-a-user-supplied-filter-and-converting-to-a-backend-query","text":"After the LarkParser has turned the filter string into a lark.Tree , it is fed to a lark.Transformer instance, which transforms the 'lark.Tree' into a backend-specific representation of the query. For example, MongoTransformer will turn the tree into something useful for a MongoDB backend: # Example: Converting to MongoDB Query Syntax from optimade.filtertransformers.mongo import MongoTransformer transformer = MongoTransformer () tree = p . parse ( '_mp_bandgap > 5.0 AND _cod_molecular_weight < 350' ) query = transformer . transform ( tree ) print ( query ) { \"$and\" : [ { \"_mp_bandgap\" : { \"$gt\" : 5.0 }}, { \"_cod_molecular_weight\" : { \"$lt\" : 350.0 }} ] }","title":"Flow for parsing a user-supplied filter and converting to a backend query"},{"location":"concepts/filtering/#developing-new-filter-transformers","text":"In order to support a new backend, you will need to create a new filter transformer that inherits from the BaseTransformer . This transformer will need to override the methods that match the particular grammatical constructs in the Lark grammar in order to construct a query. Two examples can be found within optimade-python-tools , one for MongoDB ( MongoTransformer ) and one for Elasticsearch ( ElasticTransformer ). In some cases, you may also need to extend the base EntryCollection , the class that receives the transformed filter as an argument to its private ._run_db_query() method. This class handles the connections to the underlying database, formatting of the response in an OPTIMADE format, and other API features such as sorting and pagination. Again, the examples for MongoDB ( MongoCollection ) and Elasticsearch ( ElasticCollection ) should be helpful. If you would like to contribute your new filter transformer back to the package, please raise an issue to signal your intent (in case someone else is already working on this). Adding a transformer requires the following: A new submodule ( .py file) in the optimade/filtertransformers folder containing an implementation of the transformer object that extends optimade.filtertransformers.base_transformer.BaseTransformer . Any additional Python requirements must be optional and provided as a separate \" extra_requires \" entry in setup.py and in the requirements.txt file. Tests in optimade/filtertransformers/tests that are skipped if the required packages fail to import.","title":"Developing new filter transformers"},{"location":"concepts/validation/","text":"Validation of OPTIMADE APIs \u00b6 optimade-python-tools contains tools for validating external OPTIMADE implementations that may be helpful for all OPTIMADE providers. The validator is dynamic and fuzzy, in that the tested filters are generated based on random entries served by the API, and the description of the API provided at the /info endpoint. The validator is implemented in the optimade.validator submodule, but the two main entry points are: The optimade-validator script, which is installed alongside the package. The optimade-validator-action which allows the validator to be used as a GitHub Action. To run the script, simply provide an OPTIMADE URL to the script at the command-line. You can use the following to validate the Heroku deployment of our reference server: $ optimade-validator https://optimade.herokuapp.com/ Testing entire implementation at https://optimade.herokuapp.com ... Several additional options can be found under the --help flag, with the most important being -v/-vvvv to set the verbosity, --index to validate OPTIMADE index meta-databases and --json to receive the validation results as JSON document for programmatic use. $ optimade-validator --help usage: optimade-validator [ -h ] [ -v ] [ -j ] [ -t AS_TYPE ] [ --index ] [ --skip-optional ] [ --fail-fast ] [ -m ] [ --page_limit PAGE_LIMIT ] [ --headers HEADERS ] [ base_url ] Tests OPTIMADE implementations for compliance with the optimade-python-tools models. - To test an entire implementation ( at say example.com/optimade/v1 ) for all required/available endpoints: $ optimade-validator http://example.com/optimade/v1 - To test a particular response of an implementation against a particular model: $ optimade-validator http://example.com/optimade/v1/structures/id = 1234 --as-type structure - To test a particular response of an implementation against a particular model: $ optimade-validator http://example.com/optimade/v1/structures --as-type structures positional arguments: base_url The base URL of the OPTIMADE implementation to point at, e.g. 'http://example.com/optimade/v1' or 'http://localhost:5000/v1' optional arguments: -h, --help show this help message and exit -v, --verbosity Increase the verbosity of the output. ( -v: warning, -vv: info, -vvv: debug ) -j, --json Only a JSON summary of the validator results will be printed to stdout. -t AS_TYPE, --as-type AS_TYPE Validate the request URL with the provided type, rather than scanning the entire implementation e.g. optimade- validator ` http://example.com/optimade/v1 /structures/0 --as-type structure ` --index Flag for whether the specified OPTIMADE implementation is an Index meta-database or not. --skip-optional Flag for whether the skip the tests of optional features. --fail-fast Whether to exit on first test failure. -m, --minimal Run only a minimal test set. --page_limit PAGE_LIMIT Alter the requested page limit for some tests. --headers HEADERS Additional HTTP headers to use for each request, specified as a JSON object.","title":"Validation of OPTIMADE APIs"},{"location":"concepts/validation/#validation-of-optimade-apis","text":"optimade-python-tools contains tools for validating external OPTIMADE implementations that may be helpful for all OPTIMADE providers. The validator is dynamic and fuzzy, in that the tested filters are generated based on random entries served by the API, and the description of the API provided at the /info endpoint. The validator is implemented in the optimade.validator submodule, but the two main entry points are: The optimade-validator script, which is installed alongside the package. The optimade-validator-action which allows the validator to be used as a GitHub Action. To run the script, simply provide an OPTIMADE URL to the script at the command-line. You can use the following to validate the Heroku deployment of our reference server: $ optimade-validator https://optimade.herokuapp.com/ Testing entire implementation at https://optimade.herokuapp.com ... Several additional options can be found under the --help flag, with the most important being -v/-vvvv to set the verbosity, --index to validate OPTIMADE index meta-databases and --json to receive the validation results as JSON document for programmatic use. $ optimade-validator --help usage: optimade-validator [ -h ] [ -v ] [ -j ] [ -t AS_TYPE ] [ --index ] [ --skip-optional ] [ --fail-fast ] [ -m ] [ --page_limit PAGE_LIMIT ] [ --headers HEADERS ] [ base_url ] Tests OPTIMADE implementations for compliance with the optimade-python-tools models. - To test an entire implementation ( at say example.com/optimade/v1 ) for all required/available endpoints: $ optimade-validator http://example.com/optimade/v1 - To test a particular response of an implementation against a particular model: $ optimade-validator http://example.com/optimade/v1/structures/id = 1234 --as-type structure - To test a particular response of an implementation against a particular model: $ optimade-validator http://example.com/optimade/v1/structures --as-type structures positional arguments: base_url The base URL of the OPTIMADE implementation to point at, e.g. 'http://example.com/optimade/v1' or 'http://localhost:5000/v1' optional arguments: -h, --help show this help message and exit -v, --verbosity Increase the verbosity of the output. ( -v: warning, -vv: info, -vvv: debug ) -j, --json Only a JSON summary of the validator results will be printed to stdout. -t AS_TYPE, --as-type AS_TYPE Validate the request URL with the provided type, rather than scanning the entire implementation e.g. optimade- validator ` http://example.com/optimade/v1 /structures/0 --as-type structure ` --index Flag for whether the specified OPTIMADE implementation is an Index meta-database or not. --skip-optional Flag for whether the skip the tests of optional features. --fail-fast Whether to exit on first test failure. -m, --minimal Run only a minimal test set. --page_limit PAGE_LIMIT Alter the requested page limit for some tests. --headers HEADERS Additional HTTP headers to use for each request, specified as a JSON object.","title":"Validation of OPTIMADE APIs"},{"location":"deployment/container/","text":"Run in a container (Docker) \u00b6 Retrieve the container image \u00b6 Retrieving the container image is explained in the installation instructions . In short, using Docker you can run: docker pull ghcr.io/materials-consortia/optimade A general overview on running a container is also given in the installations instructions . Prepare the container and configure the server \u00b6 Tip A more complete overview of configuring the OPTIMADE server can be seen in the configuration section . By default, the server will use the test configuration, including test data for structures and references and an in-memory mongomock database backend. This can be changed in several different ways. One is to git clone the repository locally and bind the repository folder to the /app folder in the container: # volume will bind the local version of `optimade-python-tools` to the container. docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main \\ --name my-optimade \\ --volume /path/to/optimade-python-tools:/app \\ ghcr.io/materials-consortia/optimade:latest Help To clone the repository you can run: git clone --recursive https://github.com/Materials-Consortia/optimade-python-tools.git You should change the /path/to/optimade-python-tools to the full local path to the repository - or use $PWD if you are running this command from the root of the cloned repository on a Unix system. Equivalently, %cd% should work on Windows. In this setup you can change the repository root file optimade_config.json with the appropriate information. E.g., if you do not wish to use the test data you can add the insert_test_data key with a value of false . Another option is to not git clone the repository locally, but instead only generate a JSON or YAML file somewhere, where the directory of its location is bound to another location in the container that is not used, e.g., /config or similar. As an example, let us say we generate config.yml locally, with the full path /home/user/optimade/config.yml . Then we can start the server with the following command: # volume will bind the local directory to an unused folder in the container. docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main \\ --name my-optimade \\ --volume /home/user/optimade:/config \\ --env OPTIMADE_CONFIG_FILE = /config/config.yml \\ ghcr.io/materials-consortia/optimade:latest As shown, it is necessary to update the environment variable OPTIMADE_CONFIG_FILE within the container to point to the new internal path to the config file. By default, this environment variable points to /app/optimade_config.json . This also reveals another way of configuring the server: set environment variables when running the container to supply values that would otherwise be supplied from the configuration file. The docker run command even has the opportunity to pass a path to a file containing a list of environment variables ( --env-file /path/to/env_file ), if you wish to configure the server in this way instead of through the standard configuration file. Example : Multiple container services in closed network \u00b6 In this example we want to setup various services through containers that interact with each other on a closed internal network, only the OPTIMADE servers are exposed to the \"outside\". For this example we will use Docker only. One could choose to use the Docker Compose framework to neatly express the services in a single YAML file, however, to keep this compatible with Docker alternatives, we will focus on only using Docker. We will also setup an index meta-database, with an associated OPTIMADE server, serving data from a MongoDB backend. Hence, we need to run three separate services, configure it properly, and make sure only the OPTIMADE APIs are exposed. 1. Setup closed network \u00b6 First, we want to create the internal network: docker network create -d bridge optimade 2. Run MongoDB service \u00b6 Then, we can create a volume for the MongoDB server to use and start it. Note This can be setup in other ways, binding to local paths or otherwise. For more information on the specifics of how to use the MongoDB container image, see the Docker Hub documentation . For more information from the MongoDB team concerning the Enterprise version, see the MongoDB documentation . docker volume create mongodb-persist # `mongo` will be the host name in the docker network, using `--name`. docker run \\ --detach \\ --name mongo \\ --volume mongodb-persist:/data/db \\ --network optimade \\ docker.io/library/mongo:latest At this point you should fill up the database with your data, or instead of doing the command above exactly, you could choose to bind to another \"local\" path that contains an existing MongoDB you have. Most likely, you will have a database dump archive, which you will now be able to import. If you do so, please note the name of the database, the collection, and consider any data model mappings from your data to OPTIMADE data models for structures and/or references . In the example, we assume the database has been filled with fully valid OPTIMADE structures and references in a database called optimade_prod , within the collections structures and references , respectively. 3. Run the OPTIMADE service \u00b6 With this information, we can now start the OPTIMADE server: docker run \\ --rm \\ --detach \\ --publish 8081 :5000 \\ --env MAIN = main \\ --name my-optimade \\ --network optimade \\ --env OPTIMADE_CONFIG_FILE = \\ --env optimade_insert_test_data = false \\ --env optimade_database_backend = mongodb \\ --env optimade_mongo_uri = mongodb://mongo:27017 \\ --env optimade_mongo_database = optimade_prod \\ --env optimade_references_collection = references \\ --env optimade_structures_collection = structures \\ --env optimade_page_limit = 25 \\ --env optimade_page_limit_max = 100 \\ --env optimade_base_url = http://localhost:8081 \\ --env optimade_index_base_url = http://localhost:8080 \\ --env optimade_provider = \"{\\\"prefix\\\":\\\"myorg\\\",\\\"name\\\":\\\"My Organization\\\",\\\"description\\\":\\\"Short description for My Organization\\\",\\\"homepage\\\":\\\"https://example.org\\\"}\" \\ ghcr.io/materials-consortia/optimade:latest Note, the optimade_base_url and optimade_index_base_url values should be different if the server is run through a reverse-proxy service like NGINX, Apache or other. For this example, we are only concerned with exposing the OPTIMADE APIs from the localhost . Furthermore, note that we \"unset\" the OPTIMADE_CONFIG_FILE environment variable to ensure the system defaults are used instead of configuration values that matches the test data. 4. Setup and run the OPTIMADE index meta-database service \u00b6 The next step is to start the OPTIMADE index meta-database. For this, we will first create a JSON file to reference and load as data for the /links endpoint: [ { \"id\" : \"my-optimade-db\" , \"type\" : \"links\" , \"name\" : \"My OPTIMADE API\" , \"description\" : \"An OPTIMADE API for my database of essential material structures.\" , \"base_url\" : \"http://localhost:8081\" , \"homepage\" : \"https://example.org\" , \"link_type\" : \"child\" } ] This file is stored in a newly created directory at /home/user/optimade/index_data/index_links.json . Now, we can start the index meta-database server: # `optimade_insert_test_data` needs to be `true` to insert JSON file data docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main_index \\ --name my-optimade-index \\ --network optimade \\ --env OPTIMADE_CONFIG_FILE = \\ --env optimade_insert_test_data = true \\ --env optimade_database_backend = mongodb \\ --env optimade_mongo_uri = mongodb://mongo:27017 \\ --env optimade_mongo_database = optimade_index_prod \\ --env optimade_links_collection = links \\ --env optimade_page_limit = 25 \\ --env optimade_page_limit_max = 100 \\ --env optimade_base_url = http://localhost:8080 \\ --env optimade_index_base_url = http://localhost:8080 \\ --env optimade_provider = \"{\\\"prefix\\\":\\\"myorg\\\",\\\"name\\\":\\\"My Organization\\\",\\\"description\\\":\\\"Short description for My Organization\\\",\\\"homepage\\\":\\\"https://example.org\\\"}\" \\ --env optimade_default_db = my-optimade-db \\ --env optimade_index_links_path = /external/index_data/index_links.json \\ --volume /home/user/optimade/index_data:/external/index_data \\ ghcr.io/materials-consortia/optimade:latest 5. Test the services \u00b6 Finally, we can test it all works as intended. Go to localhost:8080/links to check you see the list of OPTIMADE databases linked to by the index meta-database. This list should include the entry from the JSON file above with ID my-optimade-db . You could from there go to localhost:8081/info and see the introspective information about the OPTIMADE database. Furthermore, now you could go search through the material structures in your database, e.g., retrieving all structures that include carbon and oxygen in their list of chemical elements: localhost:8081/structures?filter=elements HAS ALL \"C\",\"O\" . It is also good to test the limits we specified are upheld, e.g., the maximum number of requested entries is not allowed to exceed 100 according to the optimade_page_limit_max value we have specified. To test this, we could request a response with 101 entries, which should return an error: localhost:8081/structures?page_limit=101 . And then a request for a response with 101 entries, which should not return an error: localhost:8081/structures?page_limit=100 . If you wish to inspect the logs of any service, you can use the docker logs command, followed by any of the service container names, e.g., docker logs my-optimade will display the logged stdout and stderr from the OPTIMADE database server. Use the test data If you do not have any data with which to fill up the MongoDB backend, you can run through the example using test data with some minor changes. However, it is crucial you first git clone the repository locally, since the test data is included only in the repository - not the container image. Run all docker commands from the root of the cloned repository. When running the OPTIMADE servers, leave out the line concerning \"unsetting\" the OPTIMADE_CONFIG_FILE environment variable. When first running the OPTIMADE server (not the index meta-database) set the optimade_insert_test_data value to true . If you stop the server and want to restart it, you should then set the variable to false , since the startup of the server will otherwise fail, due to the test data already existing in the MongoDB database collections and the subsequent re-insertion will throw an error.","title":"Run in a container (Docker)"},{"location":"deployment/container/#run-in-a-container-docker","text":"","title":"Run in a container (Docker)"},{"location":"deployment/container/#retrieve-the-container-image","text":"Retrieving the container image is explained in the installation instructions . In short, using Docker you can run: docker pull ghcr.io/materials-consortia/optimade A general overview on running a container is also given in the installations instructions .","title":"Retrieve the container image"},{"location":"deployment/container/#prepare-the-container-and-configure-the-server","text":"Tip A more complete overview of configuring the OPTIMADE server can be seen in the configuration section . By default, the server will use the test configuration, including test data for structures and references and an in-memory mongomock database backend. This can be changed in several different ways. One is to git clone the repository locally and bind the repository folder to the /app folder in the container: # volume will bind the local version of `optimade-python-tools` to the container. docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main \\ --name my-optimade \\ --volume /path/to/optimade-python-tools:/app \\ ghcr.io/materials-consortia/optimade:latest Help To clone the repository you can run: git clone --recursive https://github.com/Materials-Consortia/optimade-python-tools.git You should change the /path/to/optimade-python-tools to the full local path to the repository - or use $PWD if you are running this command from the root of the cloned repository on a Unix system. Equivalently, %cd% should work on Windows. In this setup you can change the repository root file optimade_config.json with the appropriate information. E.g., if you do not wish to use the test data you can add the insert_test_data key with a value of false . Another option is to not git clone the repository locally, but instead only generate a JSON or YAML file somewhere, where the directory of its location is bound to another location in the container that is not used, e.g., /config or similar. As an example, let us say we generate config.yml locally, with the full path /home/user/optimade/config.yml . Then we can start the server with the following command: # volume will bind the local directory to an unused folder in the container. docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main \\ --name my-optimade \\ --volume /home/user/optimade:/config \\ --env OPTIMADE_CONFIG_FILE = /config/config.yml \\ ghcr.io/materials-consortia/optimade:latest As shown, it is necessary to update the environment variable OPTIMADE_CONFIG_FILE within the container to point to the new internal path to the config file. By default, this environment variable points to /app/optimade_config.json . This also reveals another way of configuring the server: set environment variables when running the container to supply values that would otherwise be supplied from the configuration file. The docker run command even has the opportunity to pass a path to a file containing a list of environment variables ( --env-file /path/to/env_file ), if you wish to configure the server in this way instead of through the standard configuration file.","title":"Prepare the container and configure the server"},{"location":"deployment/container/#example-multiple-container-services-in-closed-network","text":"In this example we want to setup various services through containers that interact with each other on a closed internal network, only the OPTIMADE servers are exposed to the \"outside\". For this example we will use Docker only. One could choose to use the Docker Compose framework to neatly express the services in a single YAML file, however, to keep this compatible with Docker alternatives, we will focus on only using Docker. We will also setup an index meta-database, with an associated OPTIMADE server, serving data from a MongoDB backend. Hence, we need to run three separate services, configure it properly, and make sure only the OPTIMADE APIs are exposed.","title":"Example: Multiple container services in closed network"},{"location":"deployment/container/#1-setup-closed-network","text":"First, we want to create the internal network: docker network create -d bridge optimade","title":"1. Setup closed network"},{"location":"deployment/container/#2-run-mongodb-service","text":"Then, we can create a volume for the MongoDB server to use and start it. Note This can be setup in other ways, binding to local paths or otherwise. For more information on the specifics of how to use the MongoDB container image, see the Docker Hub documentation . For more information from the MongoDB team concerning the Enterprise version, see the MongoDB documentation . docker volume create mongodb-persist # `mongo` will be the host name in the docker network, using `--name`. docker run \\ --detach \\ --name mongo \\ --volume mongodb-persist:/data/db \\ --network optimade \\ docker.io/library/mongo:latest At this point you should fill up the database with your data, or instead of doing the command above exactly, you could choose to bind to another \"local\" path that contains an existing MongoDB you have. Most likely, you will have a database dump archive, which you will now be able to import. If you do so, please note the name of the database, the collection, and consider any data model mappings from your data to OPTIMADE data models for structures and/or references . In the example, we assume the database has been filled with fully valid OPTIMADE structures and references in a database called optimade_prod , within the collections structures and references , respectively.","title":"2. Run MongoDB service"},{"location":"deployment/container/#3-run-the-optimade-service","text":"With this information, we can now start the OPTIMADE server: docker run \\ --rm \\ --detach \\ --publish 8081 :5000 \\ --env MAIN = main \\ --name my-optimade \\ --network optimade \\ --env OPTIMADE_CONFIG_FILE = \\ --env optimade_insert_test_data = false \\ --env optimade_database_backend = mongodb \\ --env optimade_mongo_uri = mongodb://mongo:27017 \\ --env optimade_mongo_database = optimade_prod \\ --env optimade_references_collection = references \\ --env optimade_structures_collection = structures \\ --env optimade_page_limit = 25 \\ --env optimade_page_limit_max = 100 \\ --env optimade_base_url = http://localhost:8081 \\ --env optimade_index_base_url = http://localhost:8080 \\ --env optimade_provider = \"{\\\"prefix\\\":\\\"myorg\\\",\\\"name\\\":\\\"My Organization\\\",\\\"description\\\":\\\"Short description for My Organization\\\",\\\"homepage\\\":\\\"https://example.org\\\"}\" \\ ghcr.io/materials-consortia/optimade:latest Note, the optimade_base_url and optimade_index_base_url values should be different if the server is run through a reverse-proxy service like NGINX, Apache or other. For this example, we are only concerned with exposing the OPTIMADE APIs from the localhost . Furthermore, note that we \"unset\" the OPTIMADE_CONFIG_FILE environment variable to ensure the system defaults are used instead of configuration values that matches the test data.","title":"3. Run the OPTIMADE service"},{"location":"deployment/container/#4-setup-and-run-the-optimade-index-meta-database-service","text":"The next step is to start the OPTIMADE index meta-database. For this, we will first create a JSON file to reference and load as data for the /links endpoint: [ { \"id\" : \"my-optimade-db\" , \"type\" : \"links\" , \"name\" : \"My OPTIMADE API\" , \"description\" : \"An OPTIMADE API for my database of essential material structures.\" , \"base_url\" : \"http://localhost:8081\" , \"homepage\" : \"https://example.org\" , \"link_type\" : \"child\" } ] This file is stored in a newly created directory at /home/user/optimade/index_data/index_links.json . Now, we can start the index meta-database server: # `optimade_insert_test_data` needs to be `true` to insert JSON file data docker run \\ --rm \\ --detach \\ --publish 8080 :5000 \\ --env MAIN = main_index \\ --name my-optimade-index \\ --network optimade \\ --env OPTIMADE_CONFIG_FILE = \\ --env optimade_insert_test_data = true \\ --env optimade_database_backend = mongodb \\ --env optimade_mongo_uri = mongodb://mongo:27017 \\ --env optimade_mongo_database = optimade_index_prod \\ --env optimade_links_collection = links \\ --env optimade_page_limit = 25 \\ --env optimade_page_limit_max = 100 \\ --env optimade_base_url = http://localhost:8080 \\ --env optimade_index_base_url = http://localhost:8080 \\ --env optimade_provider = \"{\\\"prefix\\\":\\\"myorg\\\",\\\"name\\\":\\\"My Organization\\\",\\\"description\\\":\\\"Short description for My Organization\\\",\\\"homepage\\\":\\\"https://example.org\\\"}\" \\ --env optimade_default_db = my-optimade-db \\ --env optimade_index_links_path = /external/index_data/index_links.json \\ --volume /home/user/optimade/index_data:/external/index_data \\ ghcr.io/materials-consortia/optimade:latest","title":"4. Setup and run the OPTIMADE index meta-database service"},{"location":"deployment/container/#5-test-the-services","text":"Finally, we can test it all works as intended. Go to localhost:8080/links to check you see the list of OPTIMADE databases linked to by the index meta-database. This list should include the entry from the JSON file above with ID my-optimade-db . You could from there go to localhost:8081/info and see the introspective information about the OPTIMADE database. Furthermore, now you could go search through the material structures in your database, e.g., retrieving all structures that include carbon and oxygen in their list of chemical elements: localhost:8081/structures?filter=elements HAS ALL \"C\",\"O\" . It is also good to test the limits we specified are upheld, e.g., the maximum number of requested entries is not allowed to exceed 100 according to the optimade_page_limit_max value we have specified. To test this, we could request a response with 101 entries, which should return an error: localhost:8081/structures?page_limit=101 . And then a request for a response with 101 entries, which should not return an error: localhost:8081/structures?page_limit=100 . If you wish to inspect the logs of any service, you can use the docker logs command, followed by any of the service container names, e.g., docker logs my-optimade will display the logged stdout and stderr from the OPTIMADE database server. Use the test data If you do not have any data with which to fill up the MongoDB backend, you can run through the example using test data with some minor changes. However, it is crucial you first git clone the repository locally, since the test data is included only in the repository - not the container image. Run all docker commands from the root of the cloned repository. When running the OPTIMADE servers, leave out the line concerning \"unsetting\" the OPTIMADE_CONFIG_FILE environment variable. When first running the OPTIMADE server (not the index meta-database) set the optimade_insert_test_data value to true . If you stop the server and want to restart it, you should then set the variable to false , since the startup of the server will otherwise fail, due to the test data already existing in the MongoDB database collections and the subsequent re-insertion will throw an error.","title":"5. Test the services"},{"location":"deployment/integrated/","text":"Integrate OPTIMADE with an existing web application \u00b6 The optimade package can be used to create a standalone web application that serves the OPTIMADE API based on a pre-configured MongoDB backend. In this document, we are going to use optimade differently and use it to add an OPTIMADE API implementation alongside an existing API that employs an Elasticsearch storage layer. Let's assume we already have a FastAPI application that runs an unrelated web service, and that we use an Elasticsearch backend that contains all structure data, but not necessarily in a form that OPTIMADE expects. Providing the optimade configuration \u00b6 optimade can read its configuration from a JSON file. It uses the OPTIMADE_CONFIG_FILE environment variable (or a default path) to find the config file. If you run optimade code inside another application, you might want to provide this config file as part of the source code and not via environment variables. Let's say you have a file optimade_config.json as part of the Python module that you use to create your OPTIMADE API. Tip You can find more detailed information about configuring the optimade server in the Configuration section. Before importing any optimade modules, you can set the OPTIMADE_CONFIG_FILE environment variable to refer to your config file: import os from pathlib import Path os . environ [ 'OPTIMADE_CONFIG_FILE' ] = str ( Path ( __file__ ) . parent / \"optimade_config.json\" ) Customize the EntryCollection implementation \u00b6 Let's assume that your Elasticsearch backend stores structure data in a different enough manner that you need to provide your own custom implementation. The following code customizes the EntryCollection class for structures, whilst keeping the default MongoDB-based implementation (using MongoCollection ) for all other entry types. from optimade.server.routers import structures structures . structures_coll = MyElasticsearchStructureCollection () You can imagine that MyElasticsearchStructureCollection either sub-classes the default optimade Elasticsearch implementation ( ElasticsearchCollection ) or sub-classes EntryCollection , depending on how deeply you need to customize the default optimade behavior. Mounting the OPTIMADE Python tools FastAPI app into an existing FastAPI app \u00b6 Let's assume you have an existing FastAPI app my_app . It already implements a few routers under certain path prefixes, and now you want to add an OPTIMADE implementation under the path prefix /optimade . First, you have to set the root_path in the optimade configuration, so that the app expects all requests to be prefixed with /optimade . Second, you simply mount the optimade app into your existing app my_app : from optimade.server.config import CONFIG CONFIG . root_path = \"/optimade\" from optimade.server import main as optimade optimade . add_major_version_base_url ( optimade . app ) my_app . mount ( \"/optimade\" , optimade . app ) Tip In the example above, we imported CONFIG before main so that our config was loaded before app creation. To avoid the need for this, the root_path can be set in your JSON config file, passed as an environment variable, or declared in a custom Python module (see Configuration ). See also the FastAPI documentation on sub-applications . Now, if you run my_app , it will still serve all its routers as before and in addition it will also serve all OPTIMADE routes under /optimade/ and the versioned URLs /optimade/v1/ .","title":"Integrate OPTIMADE with an existing web application"},{"location":"deployment/integrated/#integrate-optimade-with-an-existing-web-application","text":"The optimade package can be used to create a standalone web application that serves the OPTIMADE API based on a pre-configured MongoDB backend. In this document, we are going to use optimade differently and use it to add an OPTIMADE API implementation alongside an existing API that employs an Elasticsearch storage layer. Let's assume we already have a FastAPI application that runs an unrelated web service, and that we use an Elasticsearch backend that contains all structure data, but not necessarily in a form that OPTIMADE expects.","title":"Integrate OPTIMADE with an existing web application"},{"location":"deployment/integrated/#providing-the-optimade-configuration","text":"optimade can read its configuration from a JSON file. It uses the OPTIMADE_CONFIG_FILE environment variable (or a default path) to find the config file. If you run optimade code inside another application, you might want to provide this config file as part of the source code and not via environment variables. Let's say you have a file optimade_config.json as part of the Python module that you use to create your OPTIMADE API. Tip You can find more detailed information about configuring the optimade server in the Configuration section. Before importing any optimade modules, you can set the OPTIMADE_CONFIG_FILE environment variable to refer to your config file: import os from pathlib import Path os . environ [ 'OPTIMADE_CONFIG_FILE' ] = str ( Path ( __file__ ) . parent / \"optimade_config.json\" )","title":"Providing the optimade configuration"},{"location":"deployment/integrated/#customize-the-entrycollection-implementation","text":"Let's assume that your Elasticsearch backend stores structure data in a different enough manner that you need to provide your own custom implementation. The following code customizes the EntryCollection class for structures, whilst keeping the default MongoDB-based implementation (using MongoCollection ) for all other entry types. from optimade.server.routers import structures structures . structures_coll = MyElasticsearchStructureCollection () You can imagine that MyElasticsearchStructureCollection either sub-classes the default optimade Elasticsearch implementation ( ElasticsearchCollection ) or sub-classes EntryCollection , depending on how deeply you need to customize the default optimade behavior.","title":"Customize the EntryCollection implementation"},{"location":"deployment/integrated/#mounting-the-optimade-python-tools-fastapi-app-into-an-existing-fastapi-app","text":"Let's assume you have an existing FastAPI app my_app . It already implements a few routers under certain path prefixes, and now you want to add an OPTIMADE implementation under the path prefix /optimade . First, you have to set the root_path in the optimade configuration, so that the app expects all requests to be prefixed with /optimade . Second, you simply mount the optimade app into your existing app my_app : from optimade.server.config import CONFIG CONFIG . root_path = \"/optimade\" from optimade.server import main as optimade optimade . add_major_version_base_url ( optimade . app ) my_app . mount ( \"/optimade\" , optimade . app ) Tip In the example above, we imported CONFIG before main so that our config was loaded before app creation. To avoid the need for this, the root_path can be set in your JSON config file, passed as an environment variable, or declared in a custom Python module (see Configuration ). See also the FastAPI documentation on sub-applications . Now, if you run my_app , it will still serve all its routers as before and in addition it will also serve all OPTIMADE routes under /optimade/ and the versioned URLs /optimade/v1/ .","title":"Mounting the OPTIMADE Python tools FastAPI app into an existing FastAPI app"},{"location":"getting_started/client/","text":"Using the OPTIMADE client \u00b6 This package includes a Python client that can be used to query multiple OPTIMADE APIs simultaneously, whilst automatically paginating through the results of each query. The client can be used from the command-line ( optimade-get ), or called in Python code. The client does not currently validate the returned data it comes back from the databases, and as some OPTIMADE APIs do not implement all features, it is worth paying attention to any error messages emitted by each database. Features \u00b6 This list outlines the current and planned features for the client: Query multiple OPTIMADE APIs simultaneously and asynchronously, with support for different endpoints, filters, sorting and response fields. Automatically paginate through the results for each query. Validate filters against the OPTIMADE grammar before they are sent to each database. Count the number of results for a query without downloading them all. Valiate the results against the optimade-python-tools models and export into other supported formats (ASE, pymatgen, CIF, AiiDA). Enable asynchronous use in cases where there is already a running event loop (e.g., inside a Jupyter notebook). Cache the results for queries to disk, and use them in future sessions without making new requests. Support for querying databases indirectly via an OPTIMADE gateway server . Installation \u00b6 The client requires some extra dependencies that can be installed with the PyPI package with pip install optimade [ http_client ] or from a local copy of the repository with pip install -e . [ http_client ] Usage \u00b6 By default, the client will query all OPTIMADE API URLs that it can find via the Providers list : Command line Python optimade-get --filter 'elements HAS \"Ag\"' from optimade.client import OptimadeClient client = OptimadeClient () results = client . get ( 'elements HAS \"Ag\"' ) At the command line, it may be immediately useful to redirect or save these results to a file: # Save the results to a JSON file directly optimade-get --filter 'elements HAS \"Ag\"' --output-file results.json # or redirect the results (in a POSIX shell) optimade-get --filter 'elements HAS \"Ag\"' > results.json We can refine the search by manually specifying some URLs: Command line Python optimade-get --output-file results.json https://optimade.herokuapp.com https://optimade.odbx.science from optimade.client import OptimadeClient client = OptimadeClient ( base_urls = [ \"https://optimade.herokuapp.com\" , \"https://optimade.odbx.science\" ] ) client . get () Filtering \u00b6 By default, an empty filter will be used (which will return all entries in a database). You can specify your desired filter as follows (note the quotation marks): Command line Python optimade-get --filter 'elements HAS \"Ag\" AND nsites < 2' --output-file results.json from optimade.client import OptimadeClient client = OptimadeClient () client . get ( 'elements HAS \"Ag\" AND nsites < 2' ) The filter will be validated against the optimade-python-tools reference grammar before it is sent to the underlying servers. Accessing the results \u00b6 At the command-line, the results of the query will be printed to stdout , ready to be redirected to a file or piped into another program. For example: optimade-get --filter 'nsites = 1' --output-file results.json https://optimade.herokuapp.com cat results.json has the followng (truncated) output: { // The endpoint that was queried \"structures\" : { // The filter applied to that endpointk \"nsites = 1\" : { // The base URL of the OPTIMADE API \"https://optimade.herokuapp.com\" : { // The OPTIMADE API response as if called with an infinite `page_limit` \"data\" : [ { \"id\" : \"mpf_1\" , \"type\" : \"structures\" , \"attributes\" : { ... } \"relationships\" : { ... } }, ... ], \"errors\" : [], \"links\" : { \"next\" : null , \"prev\" : null }, \"included\" : [ ... ], \"meta\" : { ... } } } } } The response is broken down by queried endpoint, filter and then base URL so that the query URL can be easily reconstructed. This is the same format as the cached results of the Python client: from optimade.client import OptimadeClient client = OptimadeClient ( base_urls = \"https://optimade.herokuapp.com\" ) client . get ( 'nsites = 1' ) client . get ( 'nsites = 2' ) print ( client . all_results ) will return a dictionary with top-level keys: { \"structures\" : { \"nsites = 1\" : { \"https://optimade.herokuapp.com\" : { ... } }, \"nsites = 2\" : { \"https://optimade.herokuapp.com\" : { ... } } } } For a given session, this cache can be written and reloaded into an OPTIMADE client object to avoid needing to repeat queries. Info In a future release, this cache will be automatically restored from disk and will obey defined cache lifetimes. Querying other endpoints \u00b6 The client can also query other endpoints, rather than just the default /structures endpoint. This includes any provider-specific extensions/<example> endpoints that may be implemented at a given base URL, which can be found listed at the corresponding /info endpoint for that database. In the CLI, this is done with the --endpoint flag. In the Python interface, the different endpoints can be queried as attributes of the client class or equivalently as a paramter to client.get() or client.count() (see below). Command line Python optimade-get --endpoint \"structures\" optimade-get --endpoint \"references\" optimade-get --endpoint \"info\" optimade-get --endpoint \"info/structures\" optimade-get --endpoint \"extensions/properties\" from optimade.client import OptimadeClient client = OptimadeClient () client . references . count () client . count ( endpoint = \"references\" ) client . info . get () client . get ( endpoint = \"info\" ) client . info . structures . get () client . get ( endpoint = \"info/structures\" ) client . extensions . properties . get () client . get ( endpoint = \"extensions/properties\" ) Limiting the number of responses \u00b6 Querying all OPTIMADE APIs without limiting the number of entries can result in a lot of data. The client will limit the number of results returned per database to the value of max_results_per_provider (defaults: 1000 for Python, 10 for CLI). This limit will be enforced up to a difference of the default page limit for the underlying OPTIMADE API (which is used everywhere). This parameter can be controlled via the --max-results-per-provider 10 at the CLI, or as an argument to OptimadeClient(max_results_per_provider=10) . Setting this to a value of -1 or 0 (or additionally None , if using the Python interface) will remove the limit on the number of results per provider. In the CLI, this setting should be used alongside --output-file or redirection to avoid overflowing your terminal! Counting the number of responses without downloading \u00b6 Downloading all the results for a given query can require hundreds or thousands of requests, depending on the number of results and the database's page limit. It is possible to just count the number of results before downloading the entries themselves, which only requires 1 request per database. This is achieved via the --count flag in the CLI, or the .count() method in the Python interface. We can use this to repeat the queries from the OPTIMADE paper : Command line Python optimade-get \\ --count \\ --filter 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\"' \\ --filter 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\" AND nelements=2' \\ --filter 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\" AND NOT elements HAS \"Pb\" AND elements LENGTH 3' from optimade.client import OptimadeClient client = OptimadeClient () filters = [ 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\"' , 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\" AND nelements=2' 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\" AND NOT elements HAS \"Pb\" AND elements LENGTH 3' ] for f in filters : client . count ( f ) which, at the timing of writing, yields the results: { \"structures\" : { \"elements HAS ANY \\\"C\\\", \\\"Si\\\", \\\"Ge\\\", \\\"Sn\\\", \\\"Pb\\\"\" : { \"http://aflow.org/API/optimade/\" : null , \"https://www.crystallography.net/cod/optimade\" : 436062 , \"https://aiida.materialscloud.org/sssplibrary/optimade\" : 487 , \"https://aiida.materialscloud.org/2dstructures/optimade\" : 1427 , \"https://aiida.materialscloud.org/2dtopo/optimade\" : 0 , \"https://aiida.materialscloud.org/tc-applicability/optimade\" : 3719 , \"https://aiida.materialscloud.org/3dd/optimade\" : null , \"https://aiida.materialscloud.org/mc3d-structures/optimade\" : 9592 , \"https://aiida.materialscloud.org/autowannier/optimade\" : 1093 , \"https://aiida.materialscloud.org/curated-cofs/optimade\" : 4395 , \"https://aiida.materialscloud.org/stoceriaitf/optimade\" : 0 , \"https://aiida.materialscloud.org/pyrene-mofs/optimade\" : 348 , \"https://aiida.materialscloud.org/tin-antimony-sulfoiodide/optimade\" : 503 , \"https://optimade.materialsproject.org\" : 30351 , \"https://api.mpds.io\" : null , \"https://nomad-lab.eu/prod/rae/optimade/\" : 4451056 , \"https://optimade.odbx.science\" : 55 , \"http://optimade.openmaterialsdb.se\" : 58718 , \"http://oqmd.org/optimade/\" : null , \"https://jarvis.nist.gov/optimade/jarvisdft\" : null , \"https://www.crystallography.net/tcod/optimade\" : 2632 , \"http://optimade.2dmatpedia.org\" : 1172 }, \"elements HAS ANY \\\"C\\\", \\\"Si\\\", \\\"Ge\\\", \\\"Sn\\\", \\\"Pb\\\" AND nelements=2\" : { \"http://aflow.org/API/optimade/\" : 63011 , \"https://www.crystallography.net/cod/optimade\" : 3968 , \"https://aiida.materialscloud.org/sssplibrary/optimade\" : 2 , \"https://aiida.materialscloud.org/2dstructures/optimade\" : 779 , \"https://aiida.materialscloud.org/2dtopo/optimade\" : 0 , \"https://aiida.materialscloud.org/tc-applicability/optimade\" : 334 , \"https://aiida.materialscloud.org/3dd/optimade\" : null , \"https://aiida.materialscloud.org/mc3d-structures/optimade\" : 1566 , \"https://aiida.materialscloud.org/autowannier/optimade\" : 276 , \"https://aiida.materialscloud.org/curated-cofs/optimade\" : 24 , \"https://aiida.materialscloud.org/stoceriaitf/optimade\" : 0 , \"https://aiida.materialscloud.org/pyrene-mofs/optimade\" : 0 , \"https://aiida.materialscloud.org/tin-antimony-sulfoiodide/optimade\" : 0 , \"https://optimade.materialsproject.org\" : 3728 , \"https://api.mpds.io\" : null , \"https://nomad-lab.eu/prod/rae/optimade/\" : 587923 , \"https://optimade.odbx.science\" : 54 , \"http://optimade.openmaterialsdb.se\" : 690 , \"http://oqmd.org/optimade/\" : null , \"https://jarvis.nist.gov/optimade/jarvisdft\" : null , \"https://www.crystallography.net/tcod/optimade\" : 296 , \"http://optimade.2dmatpedia.org\" : 739 }, \"elements HAS ANY \\\"C\\\", \\\"Si\\\", \\\"Ge\\\", \\\"Sn\\\" AND NOT elements HAS \\\"Pb\\\" AND elements LENGTH 3\" : { \"http://aflow.org/API/optimade/\" : null , \"https://www.crystallography.net/cod/optimade\" : 33776 , \"https://aiida.materialscloud.org/sssplibrary/optimade\" : 0 , \"https://aiida.materialscloud.org/2dstructures/optimade\" : 378 , \"https://aiida.materialscloud.org/2dtopo/optimade\" : 0 , \"https://aiida.materialscloud.org/tc-applicability/optimade\" : 144 , \"https://aiida.materialscloud.org/3dd/optimade\" : null , \"https://aiida.materialscloud.org/mc3d-structures/optimade\" : 4398 , \"https://aiida.materialscloud.org/autowannier/optimade\" : 74 , \"https://aiida.materialscloud.org/curated-cofs/optimade\" : 1447 , \"https://aiida.materialscloud.org/stoceriaitf/optimade\" : 0 , \"https://aiida.materialscloud.org/pyrene-mofs/optimade\" : 0 , \"https://aiida.materialscloud.org/tin-antimony-sulfoiodide/optimade\" : 0 , \"https://optimade.materialsproject.org\" : 11559 , \"https://api.mpds.io\" : null , \"https://nomad-lab.eu/prod/rae/optimade/\" : 2092989 , \"https://optimade.odbx.science\" : 0 , \"http://optimade.openmaterialsdb.se\" : 7428 , \"http://oqmd.org/optimade/\" : null , \"https://jarvis.nist.gov/optimade/jarvisdft\" : null , \"https://www.crystallography.net/tcod/optimade\" : 661 , \"http://optimade.2dmatpedia.org\" : 255 } } }","title":"Using the OPTIMADE client"},{"location":"getting_started/client/#using-the-optimade-client","text":"This package includes a Python client that can be used to query multiple OPTIMADE APIs simultaneously, whilst automatically paginating through the results of each query. The client can be used from the command-line ( optimade-get ), or called in Python code. The client does not currently validate the returned data it comes back from the databases, and as some OPTIMADE APIs do not implement all features, it is worth paying attention to any error messages emitted by each database.","title":"Using the OPTIMADE client"},{"location":"getting_started/client/#features","text":"This list outlines the current and planned features for the client: Query multiple OPTIMADE APIs simultaneously and asynchronously, with support for different endpoints, filters, sorting and response fields. Automatically paginate through the results for each query. Validate filters against the OPTIMADE grammar before they are sent to each database. Count the number of results for a query without downloading them all. Valiate the results against the optimade-python-tools models and export into other supported formats (ASE, pymatgen, CIF, AiiDA). Enable asynchronous use in cases where there is already a running event loop (e.g., inside a Jupyter notebook). Cache the results for queries to disk, and use them in future sessions without making new requests. Support for querying databases indirectly via an OPTIMADE gateway server .","title":"Features"},{"location":"getting_started/client/#installation","text":"The client requires some extra dependencies that can be installed with the PyPI package with pip install optimade [ http_client ] or from a local copy of the repository with pip install -e . [ http_client ]","title":"Installation"},{"location":"getting_started/client/#usage","text":"By default, the client will query all OPTIMADE API URLs that it can find via the Providers list : Command line Python optimade-get --filter 'elements HAS \"Ag\"' from optimade.client import OptimadeClient client = OptimadeClient () results = client . get ( 'elements HAS \"Ag\"' ) At the command line, it may be immediately useful to redirect or save these results to a file: # Save the results to a JSON file directly optimade-get --filter 'elements HAS \"Ag\"' --output-file results.json # or redirect the results (in a POSIX shell) optimade-get --filter 'elements HAS \"Ag\"' > results.json We can refine the search by manually specifying some URLs: Command line Python optimade-get --output-file results.json https://optimade.herokuapp.com https://optimade.odbx.science from optimade.client import OptimadeClient client = OptimadeClient ( base_urls = [ \"https://optimade.herokuapp.com\" , \"https://optimade.odbx.science\" ] ) client . get ()","title":"Usage"},{"location":"getting_started/client/#filtering","text":"By default, an empty filter will be used (which will return all entries in a database). You can specify your desired filter as follows (note the quotation marks): Command line Python optimade-get --filter 'elements HAS \"Ag\" AND nsites < 2' --output-file results.json from optimade.client import OptimadeClient client = OptimadeClient () client . get ( 'elements HAS \"Ag\" AND nsites < 2' ) The filter will be validated against the optimade-python-tools reference grammar before it is sent to the underlying servers.","title":"Filtering"},{"location":"getting_started/client/#accessing-the-results","text":"At the command-line, the results of the query will be printed to stdout , ready to be redirected to a file or piped into another program. For example: optimade-get --filter 'nsites = 1' --output-file results.json https://optimade.herokuapp.com cat results.json has the followng (truncated) output: { // The endpoint that was queried \"structures\" : { // The filter applied to that endpointk \"nsites = 1\" : { // The base URL of the OPTIMADE API \"https://optimade.herokuapp.com\" : { // The OPTIMADE API response as if called with an infinite `page_limit` \"data\" : [ { \"id\" : \"mpf_1\" , \"type\" : \"structures\" , \"attributes\" : { ... } \"relationships\" : { ... } }, ... ], \"errors\" : [], \"links\" : { \"next\" : null , \"prev\" : null }, \"included\" : [ ... ], \"meta\" : { ... } } } } } The response is broken down by queried endpoint, filter and then base URL so that the query URL can be easily reconstructed. This is the same format as the cached results of the Python client: from optimade.client import OptimadeClient client = OptimadeClient ( base_urls = \"https://optimade.herokuapp.com\" ) client . get ( 'nsites = 1' ) client . get ( 'nsites = 2' ) print ( client . all_results ) will return a dictionary with top-level keys: { \"structures\" : { \"nsites = 1\" : { \"https://optimade.herokuapp.com\" : { ... } }, \"nsites = 2\" : { \"https://optimade.herokuapp.com\" : { ... } } } } For a given session, this cache can be written and reloaded into an OPTIMADE client object to avoid needing to repeat queries. Info In a future release, this cache will be automatically restored from disk and will obey defined cache lifetimes.","title":"Accessing the results"},{"location":"getting_started/client/#querying-other-endpoints","text":"The client can also query other endpoints, rather than just the default /structures endpoint. This includes any provider-specific extensions/<example> endpoints that may be implemented at a given base URL, which can be found listed at the corresponding /info endpoint for that database. In the CLI, this is done with the --endpoint flag. In the Python interface, the different endpoints can be queried as attributes of the client class or equivalently as a paramter to client.get() or client.count() (see below). Command line Python optimade-get --endpoint \"structures\" optimade-get --endpoint \"references\" optimade-get --endpoint \"info\" optimade-get --endpoint \"info/structures\" optimade-get --endpoint \"extensions/properties\" from optimade.client import OptimadeClient client = OptimadeClient () client . references . count () client . count ( endpoint = \"references\" ) client . info . get () client . get ( endpoint = \"info\" ) client . info . structures . get () client . get ( endpoint = \"info/structures\" ) client . extensions . properties . get () client . get ( endpoint = \"extensions/properties\" )","title":"Querying other endpoints"},{"location":"getting_started/client/#limiting-the-number-of-responses","text":"Querying all OPTIMADE APIs without limiting the number of entries can result in a lot of data. The client will limit the number of results returned per database to the value of max_results_per_provider (defaults: 1000 for Python, 10 for CLI). This limit will be enforced up to a difference of the default page limit for the underlying OPTIMADE API (which is used everywhere). This parameter can be controlled via the --max-results-per-provider 10 at the CLI, or as an argument to OptimadeClient(max_results_per_provider=10) . Setting this to a value of -1 or 0 (or additionally None , if using the Python interface) will remove the limit on the number of results per provider. In the CLI, this setting should be used alongside --output-file or redirection to avoid overflowing your terminal!","title":"Limiting the number of responses"},{"location":"getting_started/client/#counting-the-number-of-responses-without-downloading","text":"Downloading all the results for a given query can require hundreds or thousands of requests, depending on the number of results and the database's page limit. It is possible to just count the number of results before downloading the entries themselves, which only requires 1 request per database. This is achieved via the --count flag in the CLI, or the .count() method in the Python interface. We can use this to repeat the queries from the OPTIMADE paper : Command line Python optimade-get \\ --count \\ --filter 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\"' \\ --filter 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\" AND nelements=2' \\ --filter 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\" AND NOT elements HAS \"Pb\" AND elements LENGTH 3' from optimade.client import OptimadeClient client = OptimadeClient () filters = [ 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\"' , 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\", \"Pb\" AND nelements=2' 'elements HAS ANY \"C\", \"Si\", \"Ge\", \"Sn\" AND NOT elements HAS \"Pb\" AND elements LENGTH 3' ] for f in filters : client . count ( f ) which, at the timing of writing, yields the results: { \"structures\" : { \"elements HAS ANY \\\"C\\\", \\\"Si\\\", \\\"Ge\\\", \\\"Sn\\\", \\\"Pb\\\"\" : { \"http://aflow.org/API/optimade/\" : null , \"https://www.crystallography.net/cod/optimade\" : 436062 , \"https://aiida.materialscloud.org/sssplibrary/optimade\" : 487 , \"https://aiida.materialscloud.org/2dstructures/optimade\" : 1427 , \"https://aiida.materialscloud.org/2dtopo/optimade\" : 0 , \"https://aiida.materialscloud.org/tc-applicability/optimade\" : 3719 , \"https://aiida.materialscloud.org/3dd/optimade\" : null , \"https://aiida.materialscloud.org/mc3d-structures/optimade\" : 9592 , \"https://aiida.materialscloud.org/autowannier/optimade\" : 1093 , \"https://aiida.materialscloud.org/curated-cofs/optimade\" : 4395 , \"https://aiida.materialscloud.org/stoceriaitf/optimade\" : 0 , \"https://aiida.materialscloud.org/pyrene-mofs/optimade\" : 348 , \"https://aiida.materialscloud.org/tin-antimony-sulfoiodide/optimade\" : 503 , \"https://optimade.materialsproject.org\" : 30351 , \"https://api.mpds.io\" : null , \"https://nomad-lab.eu/prod/rae/optimade/\" : 4451056 , \"https://optimade.odbx.science\" : 55 , \"http://optimade.openmaterialsdb.se\" : 58718 , \"http://oqmd.org/optimade/\" : null , \"https://jarvis.nist.gov/optimade/jarvisdft\" : null , \"https://www.crystallography.net/tcod/optimade\" : 2632 , \"http://optimade.2dmatpedia.org\" : 1172 }, \"elements HAS ANY \\\"C\\\", \\\"Si\\\", \\\"Ge\\\", \\\"Sn\\\", \\\"Pb\\\" AND nelements=2\" : { \"http://aflow.org/API/optimade/\" : 63011 , \"https://www.crystallography.net/cod/optimade\" : 3968 , \"https://aiida.materialscloud.org/sssplibrary/optimade\" : 2 , \"https://aiida.materialscloud.org/2dstructures/optimade\" : 779 , \"https://aiida.materialscloud.org/2dtopo/optimade\" : 0 , \"https://aiida.materialscloud.org/tc-applicability/optimade\" : 334 , \"https://aiida.materialscloud.org/3dd/optimade\" : null , \"https://aiida.materialscloud.org/mc3d-structures/optimade\" : 1566 , \"https://aiida.materialscloud.org/autowannier/optimade\" : 276 , \"https://aiida.materialscloud.org/curated-cofs/optimade\" : 24 , \"https://aiida.materialscloud.org/stoceriaitf/optimade\" : 0 , \"https://aiida.materialscloud.org/pyrene-mofs/optimade\" : 0 , \"https://aiida.materialscloud.org/tin-antimony-sulfoiodide/optimade\" : 0 , \"https://optimade.materialsproject.org\" : 3728 , \"https://api.mpds.io\" : null , \"https://nomad-lab.eu/prod/rae/optimade/\" : 587923 , \"https://optimade.odbx.science\" : 54 , \"http://optimade.openmaterialsdb.se\" : 690 , \"http://oqmd.org/optimade/\" : null , \"https://jarvis.nist.gov/optimade/jarvisdft\" : null , \"https://www.crystallography.net/tcod/optimade\" : 296 , \"http://optimade.2dmatpedia.org\" : 739 }, \"elements HAS ANY \\\"C\\\", \\\"Si\\\", \\\"Ge\\\", \\\"Sn\\\" AND NOT elements HAS \\\"Pb\\\" AND elements LENGTH 3\" : { \"http://aflow.org/API/optimade/\" : null , \"https://www.crystallography.net/cod/optimade\" : 33776 , \"https://aiida.materialscloud.org/sssplibrary/optimade\" : 0 , \"https://aiida.materialscloud.org/2dstructures/optimade\" : 378 , \"https://aiida.materialscloud.org/2dtopo/optimade\" : 0 , \"https://aiida.materialscloud.org/tc-applicability/optimade\" : 144 , \"https://aiida.materialscloud.org/3dd/optimade\" : null , \"https://aiida.materialscloud.org/mc3d-structures/optimade\" : 4398 , \"https://aiida.materialscloud.org/autowannier/optimade\" : 74 , \"https://aiida.materialscloud.org/curated-cofs/optimade\" : 1447 , \"https://aiida.materialscloud.org/stoceriaitf/optimade\" : 0 , \"https://aiida.materialscloud.org/pyrene-mofs/optimade\" : 0 , \"https://aiida.materialscloud.org/tin-antimony-sulfoiodide/optimade\" : 0 , \"https://optimade.materialsproject.org\" : 11559 , \"https://api.mpds.io\" : null , \"https://nomad-lab.eu/prod/rae/optimade/\" : 2092989 , \"https://optimade.odbx.science\" : 0 , \"http://optimade.openmaterialsdb.se\" : 7428 , \"http://oqmd.org/optimade/\" : null , \"https://jarvis.nist.gov/optimade/jarvisdft\" : null , \"https://www.crystallography.net/tcod/optimade\" : 661 , \"http://optimade.2dmatpedia.org\" : 255 } } }","title":"Counting the number of responses without downloading"},{"location":"getting_started/setting_up_an_api/","text":"Setting up an OPTIMADE API \u00b6 These notes describe how to set up and customize an OPTIMADE API based on the reference server in this package for some existing crystal structure data. To follow this guide, you will need to have a working development installation, as described in the installation instructions . Complete examples of APIs that use this package are described in the Use Cases section. Setting up the database \u00b6 The optimade reference server requires a data source per OPTIMADE entry type ( structures , references , links ). In the simplest case, these can be configured as named MongoDB collections with a defined MongoDB URI and database name (see below), but they can also be set up as custom subclasses of EntryCollection that could simply read from a static file. In the reference server, these data sources, or collections, are created in the submodule for the corresponding routers/endpoints. Here, we shall use the built-in MongoDB collections for each entry type, by simply specifying the appropriate options in the configuration , namely \"database_backend\": \"mongodb\" , \"mongo_uri\": \"mongodb://localhost:27017\" , \"mongo_database\": \"optimade\" and the collection names for each entry type ( \"structures_collection\": \"structures\" etc.). These notes will now assume that you have a MongoDB instance running and you have created a database that matches your \"mongo_database\" config option. If you disable inserting test data (with the \"insert_test_data\": false configuration option), you can test your API/database connection by running the web server with uvicorn optimade.server.main:app --port 5000 and visiting the (hopefully empty) structures endpoint at localhost:5000/v1/structures (or your chosen base URL). Note As of version v0.16, the other supported database backend is Elasticsearch. If you are interested in using another backend, or would like it to be supported in the optimade package, please raise an issue on GitHub and visit the notes on implementing new filter transformers . Mapping non-OPTIMADE data \u00b6 There are two ways to work with data that does not exactly match the OPTIMADE specification, both of which require configuring a subclass of BaseResourceMapper that converts your stored data format into an OPTIMADE-compliant entry. The two options are: Use the mapper to dynamically convert the data stored in the database, and the filters on that data, to an OPTIMADE format when responding to API requests. Apply the mapper to your entries before ingestion and use it to create a secondary database that stores the converted entries (e.g., normalized data), or equivalently, adding all the required OPTIMADE fields inside the existing entries (e.g., denormalized data) The main consideration when choosing these options is not necessarily how closely your data matches the OPTIMADE format, but instead how readily the OPTIMADE filtering of that document can be mapped into the corresponding database query. This could require writing or extending the BaseFilterTransformer class, which takes an OPTIMADE filter string and converts it into a backend-specific query. For example, if your database stores chemical formulae with extraneous \"1\"'s, e.g., SiO 2 is represented as \"Si1O2\" , then the incoming OPTIMADE filter (which asserts that elements must be alphabetical, and \"1\"'s must be omitted) for chemical_formula_reduced=\"O2Si\" will also need to be transformed so that the corresponding database query matches the stored string, which in this case can be done easily. Instead, if you are storing chemical formulae as an unreduced count per simulation cell, e.g., \"Si4O8\" , then it is impossible to remap the filter chemical_formula_reduced=\"O2Si\" such that it matches all structures with the correct formula unit (e.g., \"SiO2\" , \"Si2O4\" , ...). This would then instead require option 2 above, namely either the addition of auxiliary fields that store the correct (or mappable) OPTIMADE format in the database, or the creation of a secondary database that returns the pre-converted structures. In the simplest case, the mapper classes can be used to define aliases between fields in the database and the OPTIMADE field name; these can be configured via the aliases option as a dictionary mapping stored in a dictionary under the appropriate endpoint name, e.g. \"aliases\": {\"structures\": {\"chemical_formula_reduced\": \"my_chem_form\"}} , or defined as part of a custom mapper class. In either option, you should now be able to insert your data into the corresponding MongoDB (or otherwise) collection. Serving custom fields/properties \u00b6 According to the OPTIMADE specification, any field not standardized in the specification must be prefixed with an appropriate \"provider prefix\" (e.g., \" _aflow \" for AFLOW and \" _cod \" for COD ). This prefix is intended to be unique across all OPTIMADE providers to enable filters to work across different implementations. The prefix can be set in the configuration as part of the provider option. Once the prefix has been set, custom fields can be listed by endpoint in the provider_fields configuration option. Filters that use the prefixed form of these fields will then be passed through to the underlying database without the prefix, and then the prefix will be reinstated in the response. Example Example JSON config file fragment for adding two fields to each of the structures and references endpoints, that will be served as, e.g., _exmpl_cell_volume if the provider.prefix is set to 'exmpl'. \"provider_fields\" : { \"structures\" : [ \"cell_volume\" , \"total_energy\" ], \"references\" : [ \"orcid\" , \"num_citations\" ], } It is recommended that you provide a description, type and unit for each custom field that can be returned at the corresponding /info/<entry_type> endpoint. This can be achieved by providing a dictionary per field at provider_fields , rather than a simple list. Example Example JSON config file fragment for adding a description, type and unit for the custom _exmpl_cell_volume field, which will cause it to be added to the /info/structures endpoint. \"provider_fields\" : { \"structures\" : [ { \"name\" : \"cell_volume\" , \"description\" : \"The volume of the cell per formula unit.\" , \"unit\" : \"Ao3\" , \"type\" : \"float\" }, \"total_energy\" ], \"references\" : [ \"orcid\" , \"num_citations\" ], } Extending the pydantic models \u00b6 The pydantic models can also be extended with your custom fields. This can be useful for validation, and for generating custom OpenAPI schemas for your implementation. To do this, the underlying EntryResourceAttributes model will need to be sub-classed, the pydantic fields added to that class, and the server adjusted to make use of those models in responses. In this case, it may be easier to write a custom endpoint for your entry type, that copies the existing reference endpoint. Your custom model will need to be registered in three places: The data collection. The resource mapper class used by the collection. The ENTRY_INFO_SCHEMAS dictionary. Finally, the model must be instructed to use the prefixed (aliased) fields when generating its schemas. Pulling all of this together: from optimade.server.schemas import ENTRY_INFO_SCHEMAS from optimade.models import ( StructureResource , StructureResourceAttributes , OptimadeField ) class MyStructureResourceAttributes ( StructureResourceAttributes ): my_custom_field : str = OptimadeField ( \"default value\" , description = \"This is a custom field\" , ) class Config : \"\"\"Add a pydantic `Config` that defines the alias generator, based on our configured `provider_fields`. \"\"\" @classmethod def alias_generator ( cls , name : str ) -> str : if name in CONFIG . provider_fields . get ( \"structures\" , []): return f \"_ { CONFIG . provider . prefix } _ { name } \" return name class MyStructureResource ( StructureResource ): attributes : MyStructureResourceAttributes ENTRY_INFO_SCHEMAS [ \"structures\" ] = MyStructureResource . schema Currently, the reference server is not flexible enough to use custom response classes via configuration only (there is an open issue tracking this #929 ), so instead the code will need to be forked and modified for your implementation. Note A similar procedure can be followed for the URL query parameter classes EntryListingQueryParams and SingleEntryQueryParams so that custom query parameters can be defined for your API. The individual API routes then need to be adjusted to use the custom query parameter classes. By default, the reference server will validate the incoming query parameters against these classes. If you want to use custom query parameters without redefining the classes mentioned above, you can disable this behaviour by setting the configuration option validate_query_parameters to false, after which all query parameters will be passed on to the corresponding router method (e.g., database queries). Validating your implementation \u00b6 With the database collections, mappers, aliases and provider configured, you can try running the web server (with e.g., uvicorn optimade.server.main:app , if your app is in the same file as the reference server) and validating it as an OPTIMADE API, following the validation guide . Registering as a provider \u00b6 If you host your API at a persistent URL, you should consider registering as an OPTIMADE provider, which will add you to the federated list used by users and clients to discover data. Instructions for how to do this can be found at in the Materials-Consortia/providers repository.","title":"Setting up an OPTIMADE API"},{"location":"getting_started/setting_up_an_api/#setting-up-an-optimade-api","text":"These notes describe how to set up and customize an OPTIMADE API based on the reference server in this package for some existing crystal structure data. To follow this guide, you will need to have a working development installation, as described in the installation instructions . Complete examples of APIs that use this package are described in the Use Cases section.","title":"Setting up an OPTIMADE API"},{"location":"getting_started/setting_up_an_api/#setting-up-the-database","text":"The optimade reference server requires a data source per OPTIMADE entry type ( structures , references , links ). In the simplest case, these can be configured as named MongoDB collections with a defined MongoDB URI and database name (see below), but they can also be set up as custom subclasses of EntryCollection that could simply read from a static file. In the reference server, these data sources, or collections, are created in the submodule for the corresponding routers/endpoints. Here, we shall use the built-in MongoDB collections for each entry type, by simply specifying the appropriate options in the configuration , namely \"database_backend\": \"mongodb\" , \"mongo_uri\": \"mongodb://localhost:27017\" , \"mongo_database\": \"optimade\" and the collection names for each entry type ( \"structures_collection\": \"structures\" etc.). These notes will now assume that you have a MongoDB instance running and you have created a database that matches your \"mongo_database\" config option. If you disable inserting test data (with the \"insert_test_data\": false configuration option), you can test your API/database connection by running the web server with uvicorn optimade.server.main:app --port 5000 and visiting the (hopefully empty) structures endpoint at localhost:5000/v1/structures (or your chosen base URL). Note As of version v0.16, the other supported database backend is Elasticsearch. If you are interested in using another backend, or would like it to be supported in the optimade package, please raise an issue on GitHub and visit the notes on implementing new filter transformers .","title":"Setting up the database"},{"location":"getting_started/setting_up_an_api/#mapping-non-optimade-data","text":"There are two ways to work with data that does not exactly match the OPTIMADE specification, both of which require configuring a subclass of BaseResourceMapper that converts your stored data format into an OPTIMADE-compliant entry. The two options are: Use the mapper to dynamically convert the data stored in the database, and the filters on that data, to an OPTIMADE format when responding to API requests. Apply the mapper to your entries before ingestion and use it to create a secondary database that stores the converted entries (e.g., normalized data), or equivalently, adding all the required OPTIMADE fields inside the existing entries (e.g., denormalized data) The main consideration when choosing these options is not necessarily how closely your data matches the OPTIMADE format, but instead how readily the OPTIMADE filtering of that document can be mapped into the corresponding database query. This could require writing or extending the BaseFilterTransformer class, which takes an OPTIMADE filter string and converts it into a backend-specific query. For example, if your database stores chemical formulae with extraneous \"1\"'s, e.g., SiO 2 is represented as \"Si1O2\" , then the incoming OPTIMADE filter (which asserts that elements must be alphabetical, and \"1\"'s must be omitted) for chemical_formula_reduced=\"O2Si\" will also need to be transformed so that the corresponding database query matches the stored string, which in this case can be done easily. Instead, if you are storing chemical formulae as an unreduced count per simulation cell, e.g., \"Si4O8\" , then it is impossible to remap the filter chemical_formula_reduced=\"O2Si\" such that it matches all structures with the correct formula unit (e.g., \"SiO2\" , \"Si2O4\" , ...). This would then instead require option 2 above, namely either the addition of auxiliary fields that store the correct (or mappable) OPTIMADE format in the database, or the creation of a secondary database that returns the pre-converted structures. In the simplest case, the mapper classes can be used to define aliases between fields in the database and the OPTIMADE field name; these can be configured via the aliases option as a dictionary mapping stored in a dictionary under the appropriate endpoint name, e.g. \"aliases\": {\"structures\": {\"chemical_formula_reduced\": \"my_chem_form\"}} , or defined as part of a custom mapper class. In either option, you should now be able to insert your data into the corresponding MongoDB (or otherwise) collection.","title":"Mapping non-OPTIMADE data"},{"location":"getting_started/setting_up_an_api/#serving-custom-fieldsproperties","text":"According to the OPTIMADE specification, any field not standardized in the specification must be prefixed with an appropriate \"provider prefix\" (e.g., \" _aflow \" for AFLOW and \" _cod \" for COD ). This prefix is intended to be unique across all OPTIMADE providers to enable filters to work across different implementations. The prefix can be set in the configuration as part of the provider option. Once the prefix has been set, custom fields can be listed by endpoint in the provider_fields configuration option. Filters that use the prefixed form of these fields will then be passed through to the underlying database without the prefix, and then the prefix will be reinstated in the response. Example Example JSON config file fragment for adding two fields to each of the structures and references endpoints, that will be served as, e.g., _exmpl_cell_volume if the provider.prefix is set to 'exmpl'. \"provider_fields\" : { \"structures\" : [ \"cell_volume\" , \"total_energy\" ], \"references\" : [ \"orcid\" , \"num_citations\" ], } It is recommended that you provide a description, type and unit for each custom field that can be returned at the corresponding /info/<entry_type> endpoint. This can be achieved by providing a dictionary per field at provider_fields , rather than a simple list. Example Example JSON config file fragment for adding a description, type and unit for the custom _exmpl_cell_volume field, which will cause it to be added to the /info/structures endpoint. \"provider_fields\" : { \"structures\" : [ { \"name\" : \"cell_volume\" , \"description\" : \"The volume of the cell per formula unit.\" , \"unit\" : \"Ao3\" , \"type\" : \"float\" }, \"total_energy\" ], \"references\" : [ \"orcid\" , \"num_citations\" ], }","title":"Serving custom fields/properties"},{"location":"getting_started/setting_up_an_api/#extending-the-pydantic-models","text":"The pydantic models can also be extended with your custom fields. This can be useful for validation, and for generating custom OpenAPI schemas for your implementation. To do this, the underlying EntryResourceAttributes model will need to be sub-classed, the pydantic fields added to that class, and the server adjusted to make use of those models in responses. In this case, it may be easier to write a custom endpoint for your entry type, that copies the existing reference endpoint. Your custom model will need to be registered in three places: The data collection. The resource mapper class used by the collection. The ENTRY_INFO_SCHEMAS dictionary. Finally, the model must be instructed to use the prefixed (aliased) fields when generating its schemas. Pulling all of this together: from optimade.server.schemas import ENTRY_INFO_SCHEMAS from optimade.models import ( StructureResource , StructureResourceAttributes , OptimadeField ) class MyStructureResourceAttributes ( StructureResourceAttributes ): my_custom_field : str = OptimadeField ( \"default value\" , description = \"This is a custom field\" , ) class Config : \"\"\"Add a pydantic `Config` that defines the alias generator, based on our configured `provider_fields`. \"\"\" @classmethod def alias_generator ( cls , name : str ) -> str : if name in CONFIG . provider_fields . get ( \"structures\" , []): return f \"_ { CONFIG . provider . prefix } _ { name } \" return name class MyStructureResource ( StructureResource ): attributes : MyStructureResourceAttributes ENTRY_INFO_SCHEMAS [ \"structures\" ] = MyStructureResource . schema Currently, the reference server is not flexible enough to use custom response classes via configuration only (there is an open issue tracking this #929 ), so instead the code will need to be forked and modified for your implementation. Note A similar procedure can be followed for the URL query parameter classes EntryListingQueryParams and SingleEntryQueryParams so that custom query parameters can be defined for your API. The individual API routes then need to be adjusted to use the custom query parameter classes. By default, the reference server will validate the incoming query parameters against these classes. If you want to use custom query parameters without redefining the classes mentioned above, you can disable this behaviour by setting the configuration option validate_query_parameters to false, after which all query parameters will be passed on to the corresponding router method (e.g., database queries).","title":"Extending the pydantic models"},{"location":"getting_started/setting_up_an_api/#validating-your-implementation","text":"With the database collections, mappers, aliases and provider configured, you can try running the web server (with e.g., uvicorn optimade.server.main:app , if your app is in the same file as the reference server) and validating it as an OPTIMADE API, following the validation guide .","title":"Validating your implementation"},{"location":"getting_started/setting_up_an_api/#registering-as-a-provider","text":"If you host your API at a persistent URL, you should consider registering as an OPTIMADE provider, which will add you to the federated list used by users and clients to discover data. Instructions for how to do this can be found at in the Materials-Consortia/providers repository.","title":"Registering as a provider"},{"location":"getting_started/use_cases/","text":"Example use cases \u00b6 Serving a single database \u00b6 The Materials Project uses optimade-python-tools alongside their existing API and MongoDB database, providing OPTIMADE-compliant access to highly-curated density-functional theory calculations across all known inorganic materials. optimade-python-tools handles filter parsing, database query generation and response validation by running the reference server implementation with minimal configuration. odbx , a small database of results from crystal structure prediction calculations, follows a similar approach. This implementation is open source, available on GitHub at ml-evs/odbx.science . Serving multiple databases \u00b6 Materials Cloud uses optimade-python-tools as a library to provide an OPTIMADE API entry to archived computational materials studies, created with the AiiDA Python framework and published through their archive. In this case, each individual study and archive entry has its own database and separate API entry. The Python classes within the optimade package have been extended to make use of AiiDA and its underlying PostgreSQL storage engine. Details of this implementation can be found on GitHub at aiidateam/aiida-optimade . Extending an existing API \u00b6 NOMAD uses optimade-python-tools as a library to add OPTIMADE API endpoints to an existing web app. Their implementation uses the Elasticsearch database backend to filter on millions of structures from aggregated first-principles calculations provided by their users and partners. NOMAD also uses the package to implement a GUI search bar that accepts the OPTIMADE filter language. NOMAD uses the release versions of the optimade-python-tools package, performing all customisation via configuration and sub-classing. The NOMAD OPTIMADE API implementation is available in the NOMAD FAIR GitLab repository . This use case is demonstrated in the example Integrate OPTIMADE with an existing web application .","title":"Example use cases"},{"location":"getting_started/use_cases/#example-use-cases","text":"","title":"Example use cases"},{"location":"getting_started/use_cases/#serving-a-single-database","text":"The Materials Project uses optimade-python-tools alongside their existing API and MongoDB database, providing OPTIMADE-compliant access to highly-curated density-functional theory calculations across all known inorganic materials. optimade-python-tools handles filter parsing, database query generation and response validation by running the reference server implementation with minimal configuration. odbx , a small database of results from crystal structure prediction calculations, follows a similar approach. This implementation is open source, available on GitHub at ml-evs/odbx.science .","title":"Serving a single database"},{"location":"getting_started/use_cases/#serving-multiple-databases","text":"Materials Cloud uses optimade-python-tools as a library to provide an OPTIMADE API entry to archived computational materials studies, created with the AiiDA Python framework and published through their archive. In this case, each individual study and archive entry has its own database and separate API entry. The Python classes within the optimade package have been extended to make use of AiiDA and its underlying PostgreSQL storage engine. Details of this implementation can be found on GitHub at aiidateam/aiida-optimade .","title":"Serving multiple databases"},{"location":"getting_started/use_cases/#extending-an-existing-api","text":"NOMAD uses optimade-python-tools as a library to add OPTIMADE API endpoints to an existing web app. Their implementation uses the Elasticsearch database backend to filter on millions of structures from aggregated first-principles calculations provided by their users and partners. NOMAD also uses the package to implement a GUI search bar that accepts the OPTIMADE filter language. NOMAD uses the release versions of the optimade-python-tools package, performing all customisation via configuration and sub-classing. The NOMAD OPTIMADE API implementation is available in the NOMAD FAIR GitLab repository . This use case is demonstrated in the example Integrate OPTIMADE with an existing web application .","title":"Extending an existing API"}]}